{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traditional machine learning models for age prediction on EEG data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook uses traditional ML methods to predict the age of infants using EEG data. The EEG data is preprocessed and features are extracted as shown in the notebook 'Deep learning EEG_dataset preprocessing'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, fnmatch, csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import dump, load\n",
    "\n",
    "sys.path.insert(0, os.path.dirname(os.getcwd()))\n",
    "\n",
    "from config import ROOT, PATH_CODE, PATH_DATA, PATH_DATA_PROCESSED, PATH_MODELS, PATH_METADATA, PATH_OUTPUT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load preprocessed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps:\n",
    "\n",
    "1. Get all the files in the output folder\n",
    "2. Get the full paths of the files without the .h5 or .csv extensions\n",
    "3. Load the features from the .h5 files\n",
    "4. Assign the proper labels to the files based on the metadata\n",
    "5. Assign the subject's code to the files based on the metadata\n",
    "6. Split the data into a training, validation and test set (NOTE: make sure data points from same subjects don't end up in same set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Step 1: Get all the files in the output folder\n",
    "file_names = os.listdir(PATH_OUTPUT)\n",
    "\n",
    "# Step 2: Get the full paths of the files (without extensions)\n",
    "files = [os.path.splitext(os.path.join(PATH_OUTPUT, file_name))[0] for file_name in fnmatch.filter(file_names, \"*.h5\")]\n",
    "\n",
    "# Step 3: Load the features\n",
    "frames = []\n",
    "\n",
    "for idx, feature_file in enumerate(files):\n",
    "    df_features = pd.read_hdf(feature_file + \".h5\")\n",
    "    df_metadata = pd.read_csv(feature_file.replace(\"extracted_features_\", \"processed_data_\") + \".csv\")\n",
    "    \n",
    "    # Step 4: Assign labels\n",
    "    df_features['label'] = df_metadata['age_months'][0]\n",
    "    \n",
    "    # Step 5: Assign subject code\n",
    "    df_features['code'] = df_metadata['code'][0]\n",
    "    frames.append(df_features)\n",
    "\n",
    "df = pd.concat(frames) \n",
    "\n",
    "# Step 6: Split data in train, validation and test\n",
    "# df_train, df_temp = train_test_split(df, test_size=0.3, random_state=42)\n",
    "# df_test, df_val = train_test_split(df_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# df_train, df_test = train_test_split(df, test_size=0.15, random_state=42)\n",
    "\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "train_inds, temp_inds = next(GroupShuffleSplit(test_size=.3, n_splits=2, random_state = 42).split(df, groups=df['code']))\n",
    "\n",
    "df_train = df.iloc[train_inds]\n",
    "df_temp = df.iloc[temp_inds]\n",
    "\n",
    "val_inds, test_inds = next(GroupShuffleSplit(test_size=.5, n_splits=2, random_state = 42).split(df_temp, groups=df_temp['code']))\n",
    "\n",
    "df_val = df.iloc[val_inds]\n",
    "df_test = df.iloc[test_inds]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/val/test proportions: 0.699321126227247/0.15172284230786381/0.14895603146488928\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train/val/test proportions: {len(df_train)/len(df)}/{len(df_val)/len(df)}/{len(df_test)/len(df)}\")\n",
    "# print(f\"Train/test proportions: {len(df_train)/len(df)}/{len(df_test)/len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop(['label', 'code'], axis=1)\n",
    "y_train = df_train['label']\n",
    "\n",
    "X_val = df_val.drop(['label', 'code'], axis=1)\n",
    "y_val = df_val['label']\n",
    "\n",
    "X_test = df_test.drop(['label', 'code'], axis=1)\n",
    "y_test = df_test['label']\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_val = scaler.fit_transform(X_val)\n",
    "# X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "# MARK: reducing from 64 bit float to 32 bit float, to reduce memory usage\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train)).astype('float32')\n",
    "X_val = pd.DataFrame(scaler.fit_transform(X_val)).astype('float32')\n",
    "X_test = pd.DataFrame(scaler.fit_transform(X_test)).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del(df, df_temp, frames, df_features, df_metadata, df_train, df_val, df_test)\n",
    "del(file_names, files, df, frames, df_features, df_metadata, df_train, df_test, df_val, df_temp, val_inds, test_inds, train_inds, temp_inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.722009728\n",
      "0.015306752\n",
      "0.373602728\n",
      "0.003320912\n",
      "0.366789728\n",
      "0.003260352\n"
     ]
    }
   ],
   "source": [
    "print(f\"{X_train.memory_usage(deep=True).sum()/1000000000}\")\n",
    "print(f\"{y_train.memory_usage(deep=True)/1000000000}\")\n",
    "print(f\"{X_val.memory_usage(deep=True).sum()/1000000000}\")\n",
    "print(f\"{y_val.memory_usage(deep=True)/1000000000}\")\n",
    "print(f\"{X_test.memory_usage(deep=True).sum()/1000000000}\")\n",
    "print(f\"{y_test.memory_usage(deep=True)/1000000000}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we make predictions with dummy regressors as a simple baseline to see whether other models learn \"something\". From the sklearn docs: \"DummyRegressor is a regressor that makes predictions using simple rules. This regressor is useful as a simple baseline to compare with other (real) regressors.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of Dummy regressor (mean): R-squared = -0.014748089469102332, RMSE = 11.403474593422112 and MAE = 10.091108290916761.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "dummy_regr = DummyRegressor(strategy=\"mean\")\n",
    "dummy_regr.fit(X_train, y_train)\n",
    "\n",
    "# R2\n",
    "score = dummy_regr.score(X_test, y_test)\n",
    "\n",
    "# MSE\n",
    "predictions = dummy_regr.predict(X_test)\n",
    "rmse = mean_squared_error(y_test, predictions, squared=False)\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "\n",
    "print(f\"Performance of Dummy regressor (mean): R-squared = {score}, RMSE = {rmse} and MAE = {mae}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of Dummy regressor (median): R-squared = -0.08580167513553905, RMSE = 11.795961103285558 and MAE = 10.273657977216367.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "dummy_regr = DummyRegressor(strategy=\"median\")\n",
    "dummy_regr.fit(X_train, y_train)\n",
    "\n",
    "# R2\n",
    "score = dummy_regr.score(X_test, y_test)\n",
    "\n",
    "# MSE\n",
    "predictions = dummy_regr.predict(X_test)\n",
    "rmse = mean_squared_error(y_test, predictions, squared=False)\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "\n",
    "print(f\"Performance of Dummy regressor (median): R-squared = {score}, RMSE = {rmse} and MAE = {mae}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: Random Forest regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 100building tree 2 of 100\n",
      "building tree 3 of 100\n",
      "building tree 4 of 100\n",
      "building tree 5 of 100\n",
      "building tree 6 of 100\n",
      "building tree 7 of 100\n",
      "\n",
      "building tree 8 of 100\n",
      "building tree 9 of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:  1.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 10 of 100\n",
      "building tree 11 of 100\n",
      "building tree 12 of 100\n",
      "building tree 13 of 100\n",
      "building tree 14 of 100\n",
      "building tree 15 of 100\n",
      "building tree 16 of 100\n",
      "building tree 17 of 100\n",
      "building tree 18 of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  2.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 19 of 100\n",
      "building tree 20 of 100\n",
      "building tree 21 of 100\n",
      "building tree 22 of 100\n",
      "building tree 23 of 100\n",
      "building tree 24 of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:  2.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 25 of 100\n",
      "building tree 26 of 100\n",
      "building tree 27 of 100\n",
      "building tree 28 of 100\n",
      "building tree 29 of 100\n",
      "building tree 30 of 100\n",
      "building tree 31 of 100\n",
      "building tree 32 of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  3.9min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 33 of 100\n",
      "building tree 34 of 100\n",
      "building tree 35 of 100\n",
      "building tree 36 of 100\n",
      "building tree 37 of 100\n",
      "building tree 38 of 100\n",
      "building tree 39 of 100\n",
      "building tree 40 of 100\n",
      "building tree 41 of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  4.8min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 42 of 100\n",
      "building tree 43 of 100\n",
      "building tree 44 of 100\n",
      "building tree 45 of 100\n",
      "building tree 46 of 100\n",
      "building tree 47 of 100\n",
      "building tree 48 of 100\n",
      "building tree 49 of 100\n",
      "building tree 50 of 100\n",
      "building tree 51 of 100\n",
      "building tree 52 of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:  5.9min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 53 of 100\n",
      "building tree 54 of 100\n",
      "building tree 55 of 100\n",
      "building tree 56 of 100\n",
      "building tree 57 of 100\n",
      "building tree 58 of 100\n",
      "building tree 59 of 100\n",
      "building tree 60 of 100\n",
      "building tree 61 of 100\n",
      "building tree 62 of 100\n",
      "building tree 63 of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:  7.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 64 of 100\n",
      "building tree 65 of 100\n",
      "building tree 66 of 100\n",
      "building tree 67 of 100\n",
      "building tree 68 of 100\n",
      "building tree 69 of 100\n",
      "building tree 70 of 100\n",
      "building tree 71 of 100\n",
      "building tree 72 of 100\n",
      "building tree 73 of 100\n",
      "building tree 74 of 100\n",
      "building tree 75 of 100\n",
      "building tree 76 of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  69 tasks      | elapsed:  9.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 77 of 100\n",
      "building tree 78 of 100\n",
      "building tree 79 of 100\n",
      "building tree 80 of 100\n",
      "building tree 81 of 100\n",
      "building tree 82 of 100\n",
      "building tree 83 of 100\n",
      "building tree 84 of 100\n",
      "building tree 85 of 100\n",
      "building tree 86 of 100\n",
      "building tree 87 of 100\n",
      "building tree 88 of 100\n",
      "building tree 89 of 100\n",
      "building tree 90 of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  82 tasks      | elapsed: 11.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 91 of 100\n",
      "building tree 92 of 100\n",
      "building tree 93 of 100\n",
      "building tree 94 of 100\n",
      "building tree 95 of 100\n",
      "building tree 96 of 100\n",
      "building tree 97 of 100\n",
      "building tree 98 of 100\n",
      "building tree 99 of 100\n",
      "building tree 100 of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  96 out of 100 | elapsed: 12.2min remaining:   30.5s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed: 12.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 33min 46s, sys: 28.1 s, total: 1h 34min 14s\n",
      "Wall time: 12min 53s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/rf_clf.joblib']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# parameters = {'n_estimators': [10, 25, 50, 100], \n",
    "#               'max_depth': [5, 10],\n",
    "#               'max_features': ['sqrt', 'log2'],\n",
    "#               'criterion' :['mse', 'mae'],\n",
    "#               'ccp_alpha': list(np.linspace(0, 1, 10))\n",
    "#              }\n",
    "\n",
    "# parameters = {'n_estimators': [16], \n",
    "#               'max_depth': [5],\n",
    "#               'max_features': ['sqrt']\n",
    "#              }\n",
    "\n",
    "# rf_clf = GridSearchCV(RandomForestRegressor(verbose=10), parameters, verbose=10, n_jobs=1)\n",
    "\n",
    "\n",
    "rf_clf = RandomForestRegressor(n_estimators=100, max_features='sqrt', n_jobs=-1, verbose=10)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "output_file = os.path.join(PATH_MODELS, 'rf_clf.joblib')\n",
    "dump(rf_clf, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of Random Forest regressor: R-squared = 0.39436138245205965, RMSE = 8.809775834036856 and MAE = 7.422071435212058.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "try:\n",
    "    rf_clf\n",
    "except:\n",
    "    rf_clf = load(os.path.join(PATH_MODELS, 'rf_clf.joblib'))    \n",
    "\n",
    "# Update verbosity\n",
    "rf_clf.verbose = 0\n",
    "\n",
    "# R2rf_clf\n",
    "score = rf_clf.score(X_test, y_test)\n",
    "\n",
    "# MSE\n",
    "predictions = rf_clf.predict(X_test)\n",
    "rmse = mean_squared_error(y_test, predictions, squared=False)\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "\n",
    "print(f\"Performance of Random Forest regressor: R-squared = {score}, RMSE = {rmse} and MAE = {mae}.\")\n",
    "\n",
    "del(rf_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: Linear Support Vector Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "956672"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of training examples in the training set. According to the sklearn docs: \"The fit time complexity is more than quadratic with the number of samples which makes it hard to scale to datasets with more than a couple of 10000 samples.\" \n",
    "\n",
    "They recommend using a linear SVR for large data sets. Therefore, let's try this first. If this doesn't work, we might split the training set in smaller sets, train multiple SVRs and average the outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Take a subset of the training data for faster prototyping\n",
    "\n",
    "# Shuffle data before using\n",
    "X_train, y_train = shuffle(X_train, y_train, random_state=42)\n",
    "\n",
    "# X_train_100000 = X_train.head(100000)\n",
    "# y_train_100000 = y_train.head(100000)\n",
    "\n",
    "n = len(X_train)/100  # Chunk size\n",
    "\n",
    "chunked_X_train = np.array_split(X_train, 100)    \n",
    "chunked_y_train = np.array_split(y_train, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1149402\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for chunk in chunked_X_train:\n",
    "    count += len(chunk)\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11495"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunked_X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bbruns/anaconda3/envs/mne/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/linearsvr_clf.joblib']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "linearsvr_clf  = make_pipeline(StandardScaler(),\n",
    "                     LinearSVR(verbose=10))\n",
    "linearsvr_clf.fit(X_train, y_train)\n",
    "\n",
    "output_file = os.path.join(PATH_MODELS, 'linearsvr_clf.joblib')\n",
    "dump(linearsvr_clf, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of Linear Support Vector regressor: R-squared = 0.14881684795610417 and RMSE = 9.509120481047196.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Update verbosity\n",
    "linearsvr_clf.verbose = 0\n",
    "\n",
    "# R2\n",
    "score = linearsvr_clf.score(X_test, y_test)\n",
    "\n",
    "# MSE\n",
    "predictions = linearsvr_clf.predict(X_test)\n",
    "rmse = mean_squared_error(y_test, predictions, squared=False)\n",
    "\n",
    "print(f\"Performance of Linear Support Vector regressor: R-squared = {score} and RMSE = {rmse}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3: (Non-linear) Support Vector Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try fitting a SVR on a (small) chunk of the training data. The parameter search below is quite small, but a broader search has been done before. However, a more fine-grained search is still necessary. The downside of SVR with a non-linear kernel is that it's very slow to fit and predict."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomized search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 300 candidates, totalling 1500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:   31.4s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  7.5min\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  8.4min\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:  9.7min\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed: 11.7min\n",
      "[Parallel(n_jobs=-1)]: Done  69 tasks      | elapsed: 13.1min\n",
      "[Parallel(n_jobs=-1)]: Done  82 tasks      | elapsed: 15.6min\n",
      "[Parallel(n_jobs=-1)]: Done  97 tasks      | elapsed: 18.8min\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed: 23.5min\n",
      "[Parallel(n_jobs=-1)]: Done 129 tasks      | elapsed: 26.2min\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed: 29.8min\n",
      "[Parallel(n_jobs=-1)]: Done 165 tasks      | elapsed: 31.7min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed: 34.1min\n",
      "[Parallel(n_jobs=-1)]: Done 205 tasks      | elapsed: 37.6min\n",
      "[Parallel(n_jobs=-1)]: Done 226 tasks      | elapsed: 41.9min\n",
      "[Parallel(n_jobs=-1)]: Done 249 tasks      | elapsed: 44.7min\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed: 54.0min\n",
      "[Parallel(n_jobs=-1)]: Done 297 tasks      | elapsed: 60.7min\n",
      "[Parallel(n_jobs=-1)]: Done 322 tasks      | elapsed: 67.8min\n",
      "[Parallel(n_jobs=-1)]: Done 349 tasks      | elapsed: 72.5min\n",
      "[Parallel(n_jobs=-1)]: Done 376 tasks      | elapsed: 75.3min\n",
      "[Parallel(n_jobs=-1)]: Done 405 tasks      | elapsed: 78.7min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed: 84.4min\n",
      "[Parallel(n_jobs=-1)]: Done 465 tasks      | elapsed: 90.2min\n",
      "[Parallel(n_jobs=-1)]: Done 496 tasks      | elapsed: 95.4min\n",
      "[Parallel(n_jobs=-1)]: Done 529 tasks      | elapsed: 106.1min\n",
      "[Parallel(n_jobs=-1)]: Done 562 tasks      | elapsed: 112.0min\n",
      "[Parallel(n_jobs=-1)]: Done 597 tasks      | elapsed: 117.7min\n",
      "[Parallel(n_jobs=-1)]: Done 632 tasks      | elapsed: 122.3min\n",
      "[Parallel(n_jobs=-1)]: Done 669 tasks      | elapsed: 128.6min\n",
      "[Parallel(n_jobs=-1)]: Done 706 tasks      | elapsed: 134.2min\n",
      "[Parallel(n_jobs=-1)]: Done 745 tasks      | elapsed: 143.6min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed: 154.5min\n",
      "[Parallel(n_jobs=-1)]: Done 825 tasks      | elapsed: 159.0min\n",
      "[Parallel(n_jobs=-1)]: Done 866 tasks      | elapsed: 166.0min\n",
      "[Parallel(n_jobs=-1)]: Done 909 tasks      | elapsed: 173.7min\n",
      "[Parallel(n_jobs=-1)]: Done 952 tasks      | elapsed: 178.8min\n",
      "[Parallel(n_jobs=-1)]: Done 997 tasks      | elapsed: 194.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1042 tasks      | elapsed: 201.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1089 tasks      | elapsed: 210.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1136 tasks      | elapsed: 218.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1185 tasks      | elapsed: 228.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed: 235.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1285 tasks      | elapsed: 245.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1336 tasks      | elapsed: 258.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1389 tasks      | elapsed: 266.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1442 tasks      | elapsed: 271.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1500 out of 1500 | elapsed: 281.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/svr_clf_rs.joblib']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.svm import SVR\n",
    "from scipy.stats import uniform\n",
    "\n",
    "parameters = {'svr__C': uniform(50, 500),\n",
    "              'svr__epsilon': uniform(2, 10),\n",
    "              'svr__gamma': uniform(0.0001, 0.005)\n",
    "}\n",
    "\n",
    "pipe  = make_pipeline(StandardScaler(),\n",
    "                      SVR(verbose=True, kernel='rbf'))\n",
    "\n",
    "rs = RandomizedSearchCV(pipe, parameters, n_iter=300, cv=5, n_jobs=-1, verbose=10)\n",
    "rs.fit(chunked_X_train[0], chunked_y_train[0])\n",
    "\n",
    "output_file = os.path.join(PATH_MODELS, 'svr_clf_rs.joblib')\n",
    "dump(rs, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of Support Vector regressor: R-squared = 0.3655311410902873 and RMSE = 8.41905968453532.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# R2\n",
    "score = rs.score(X_test, y_test)\n",
    "\n",
    "# MSE\n",
    "predictions = rs.predict(X_test)\n",
    "rmse = mean_squared_error(y_test, predictions, squared=False)\n",
    "\n",
    "print(f\"Performance of Support Vector regressor: R-squared = {score} and RMSE = {rmse}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'svr__C': 62.75534215376162,\n",
       " 'svr__epsilon': 6.52063140593676,\n",
       " 'svr__gamma': 0.0015588812348265573}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_svr__C</th>\n",
       "      <th>param_svr__epsilon</th>\n",
       "      <th>param_svr__gamma</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>50.483049</td>\n",
       "      <td>0.813903</td>\n",
       "      <td>11.004105</td>\n",
       "      <td>0.354420</td>\n",
       "      <td>62.7553</td>\n",
       "      <td>6.52063</td>\n",
       "      <td>0.00155888</td>\n",
       "      <td>{'svr__C': 62.75534215376162, 'svr__epsilon': ...</td>\n",
       "      <td>0.378640</td>\n",
       "      <td>0.352382</td>\n",
       "      <td>0.342213</td>\n",
       "      <td>0.355930</td>\n",
       "      <td>0.389598</td>\n",
       "      <td>0.363752</td>\n",
       "      <td>0.017573</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>51.987874</td>\n",
       "      <td>0.564698</td>\n",
       "      <td>11.694473</td>\n",
       "      <td>0.149925</td>\n",
       "      <td>82.9868</td>\n",
       "      <td>6.35537</td>\n",
       "      <td>0.00152127</td>\n",
       "      <td>{'svr__C': 82.98684283304459, 'svr__epsilon': ...</td>\n",
       "      <td>0.377454</td>\n",
       "      <td>0.350739</td>\n",
       "      <td>0.340394</td>\n",
       "      <td>0.352878</td>\n",
       "      <td>0.389137</td>\n",
       "      <td>0.362120</td>\n",
       "      <td>0.018177</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>69.776811</td>\n",
       "      <td>0.908279</td>\n",
       "      <td>15.971187</td>\n",
       "      <td>0.648246</td>\n",
       "      <td>74.3006</td>\n",
       "      <td>3.95923</td>\n",
       "      <td>0.00158948</td>\n",
       "      <td>{'svr__C': 74.30062021011342, 'svr__epsilon': ...</td>\n",
       "      <td>0.381973</td>\n",
       "      <td>0.346294</td>\n",
       "      <td>0.335272</td>\n",
       "      <td>0.353694</td>\n",
       "      <td>0.385732</td>\n",
       "      <td>0.360593</td>\n",
       "      <td>0.019911</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>70.931876</td>\n",
       "      <td>0.599660</td>\n",
       "      <td>16.208164</td>\n",
       "      <td>0.597785</td>\n",
       "      <td>75.3688</td>\n",
       "      <td>3.51867</td>\n",
       "      <td>0.00138493</td>\n",
       "      <td>{'svr__C': 75.36875999124737, 'svr__epsilon': ...</td>\n",
       "      <td>0.383890</td>\n",
       "      <td>0.345153</td>\n",
       "      <td>0.336102</td>\n",
       "      <td>0.351590</td>\n",
       "      <td>0.384439</td>\n",
       "      <td>0.360235</td>\n",
       "      <td>0.020149</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>55.371403</td>\n",
       "      <td>0.381032</td>\n",
       "      <td>12.595145</td>\n",
       "      <td>0.232462</td>\n",
       "      <td>123.686</td>\n",
       "      <td>5.75221</td>\n",
       "      <td>0.000646769</td>\n",
       "      <td>{'svr__C': 123.6858634395875, 'svr__epsilon': ...</td>\n",
       "      <td>0.376228</td>\n",
       "      <td>0.347502</td>\n",
       "      <td>0.336513</td>\n",
       "      <td>0.348152</td>\n",
       "      <td>0.381950</td>\n",
       "      <td>0.358069</td>\n",
       "      <td>0.017747</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>66.513369</td>\n",
       "      <td>1.171978</td>\n",
       "      <td>14.017700</td>\n",
       "      <td>0.668937</td>\n",
       "      <td>103.011</td>\n",
       "      <td>4.6016</td>\n",
       "      <td>0.00146429</td>\n",
       "      <td>{'svr__C': 103.01094408535872, 'svr__epsilon':...</td>\n",
       "      <td>0.377493</td>\n",
       "      <td>0.344886</td>\n",
       "      <td>0.332940</td>\n",
       "      <td>0.349401</td>\n",
       "      <td>0.384971</td>\n",
       "      <td>0.357938</td>\n",
       "      <td>0.019906</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>65.625069</td>\n",
       "      <td>0.619704</td>\n",
       "      <td>15.227950</td>\n",
       "      <td>0.253355</td>\n",
       "      <td>110.842</td>\n",
       "      <td>4.4584</td>\n",
       "      <td>0.00126384</td>\n",
       "      <td>{'svr__C': 110.8423048053841, 'svr__epsilon': ...</td>\n",
       "      <td>0.378437</td>\n",
       "      <td>0.344284</td>\n",
       "      <td>0.331595</td>\n",
       "      <td>0.349056</td>\n",
       "      <td>0.383037</td>\n",
       "      <td>0.357282</td>\n",
       "      <td>0.020036</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>69.361036</td>\n",
       "      <td>0.361106</td>\n",
       "      <td>14.824828</td>\n",
       "      <td>0.994449</td>\n",
       "      <td>113.93</td>\n",
       "      <td>4.23828</td>\n",
       "      <td>0.001224</td>\n",
       "      <td>{'svr__C': 113.93045640361544, 'svr__epsilon':...</td>\n",
       "      <td>0.378368</td>\n",
       "      <td>0.342979</td>\n",
       "      <td>0.330903</td>\n",
       "      <td>0.347936</td>\n",
       "      <td>0.381556</td>\n",
       "      <td>0.356348</td>\n",
       "      <td>0.020086</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>71.469218</td>\n",
       "      <td>0.606593</td>\n",
       "      <td>14.823627</td>\n",
       "      <td>0.794503</td>\n",
       "      <td>124.26</td>\n",
       "      <td>3.86364</td>\n",
       "      <td>0.000959965</td>\n",
       "      <td>{'svr__C': 124.26042510606202, 'svr__epsilon':...</td>\n",
       "      <td>0.379784</td>\n",
       "      <td>0.343834</td>\n",
       "      <td>0.333220</td>\n",
       "      <td>0.344463</td>\n",
       "      <td>0.380124</td>\n",
       "      <td>0.356285</td>\n",
       "      <td>0.019735</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>67.259774</td>\n",
       "      <td>1.985945</td>\n",
       "      <td>15.372470</td>\n",
       "      <td>0.598997</td>\n",
       "      <td>56.8449</td>\n",
       "      <td>4.38187</td>\n",
       "      <td>0.00340855</td>\n",
       "      <td>{'svr__C': 56.84494698101118, 'svr__epsilon': ...</td>\n",
       "      <td>0.369721</td>\n",
       "      <td>0.346879</td>\n",
       "      <td>0.332574</td>\n",
       "      <td>0.346955</td>\n",
       "      <td>0.381386</td>\n",
       "      <td>0.355503</td>\n",
       "      <td>0.017580</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>68.966296</td>\n",
       "      <td>1.137190</td>\n",
       "      <td>14.551928</td>\n",
       "      <td>0.406565</td>\n",
       "      <td>105.519</td>\n",
       "      <td>4.3431</td>\n",
       "      <td>0.00186064</td>\n",
       "      <td>{'svr__C': 105.5191055560903, 'svr__epsilon': ...</td>\n",
       "      <td>0.371867</td>\n",
       "      <td>0.341052</td>\n",
       "      <td>0.330355</td>\n",
       "      <td>0.344993</td>\n",
       "      <td>0.381051</td>\n",
       "      <td>0.353864</td>\n",
       "      <td>0.019281</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>70.944619</td>\n",
       "      <td>0.462534</td>\n",
       "      <td>15.793389</td>\n",
       "      <td>0.298398</td>\n",
       "      <td>139.028</td>\n",
       "      <td>4.13278</td>\n",
       "      <td>0.00106967</td>\n",
       "      <td>{'svr__C': 139.02799356057068, 'svr__epsilon':...</td>\n",
       "      <td>0.376456</td>\n",
       "      <td>0.340503</td>\n",
       "      <td>0.328422</td>\n",
       "      <td>0.343429</td>\n",
       "      <td>0.378039</td>\n",
       "      <td>0.353370</td>\n",
       "      <td>0.020141</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>40.604626</td>\n",
       "      <td>0.280528</td>\n",
       "      <td>9.374552</td>\n",
       "      <td>0.130623</td>\n",
       "      <td>101.556</td>\n",
       "      <td>7.98626</td>\n",
       "      <td>0.0013579</td>\n",
       "      <td>{'svr__C': 101.55572750576064, 'svr__epsilon':...</td>\n",
       "      <td>0.368703</td>\n",
       "      <td>0.344024</td>\n",
       "      <td>0.334105</td>\n",
       "      <td>0.342900</td>\n",
       "      <td>0.376586</td>\n",
       "      <td>0.353264</td>\n",
       "      <td>0.016384</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>64.580940</td>\n",
       "      <td>0.411343</td>\n",
       "      <td>14.871617</td>\n",
       "      <td>0.275756</td>\n",
       "      <td>170.401</td>\n",
       "      <td>4.47617</td>\n",
       "      <td>0.000463814</td>\n",
       "      <td>{'svr__C': 170.40087274839965, 'svr__epsilon':...</td>\n",
       "      <td>0.370290</td>\n",
       "      <td>0.342635</td>\n",
       "      <td>0.334307</td>\n",
       "      <td>0.337094</td>\n",
       "      <td>0.379319</td>\n",
       "      <td>0.352729</td>\n",
       "      <td>0.018445</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>43.563530</td>\n",
       "      <td>0.270244</td>\n",
       "      <td>9.645802</td>\n",
       "      <td>0.134481</td>\n",
       "      <td>164.92</td>\n",
       "      <td>7.5337</td>\n",
       "      <td>0.000697561</td>\n",
       "      <td>{'svr__C': 164.92008630848372, 'svr__epsilon':...</td>\n",
       "      <td>0.371970</td>\n",
       "      <td>0.342152</td>\n",
       "      <td>0.330271</td>\n",
       "      <td>0.338963</td>\n",
       "      <td>0.378082</td>\n",
       "      <td>0.352288</td>\n",
       "      <td>0.019067</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "65       50.483049      0.813903        11.004105        0.354420   \n",
       "95       51.987874      0.564698        11.694473        0.149925   \n",
       "11       69.776811      0.908279        15.971187        0.648246   \n",
       "122      70.931876      0.599660        16.208164        0.597785   \n",
       "51       55.371403      0.381032        12.595145        0.232462   \n",
       "257      66.513369      1.171978        14.017700        0.668937   \n",
       "125      65.625069      0.619704        15.227950        0.253355   \n",
       "261      69.361036      0.361106        14.824828        0.994449   \n",
       "37       71.469218      0.606593        14.823627        0.794503   \n",
       "16       67.259774      1.985945        15.372470        0.598997   \n",
       "184      68.966296      1.137190        14.551928        0.406565   \n",
       "234      70.944619      0.462534        15.793389        0.298398   \n",
       "289      40.604626      0.280528         9.374552        0.130623   \n",
       "29       64.580940      0.411343        14.871617        0.275756   \n",
       "233      43.563530      0.270244         9.645802        0.134481   \n",
       "\n",
       "    param_svr__C param_svr__epsilon param_svr__gamma  \\\n",
       "65       62.7553            6.52063       0.00155888   \n",
       "95       82.9868            6.35537       0.00152127   \n",
       "11       74.3006            3.95923       0.00158948   \n",
       "122      75.3688            3.51867       0.00138493   \n",
       "51       123.686            5.75221      0.000646769   \n",
       "257      103.011             4.6016       0.00146429   \n",
       "125      110.842             4.4584       0.00126384   \n",
       "261       113.93            4.23828         0.001224   \n",
       "37        124.26            3.86364      0.000959965   \n",
       "16       56.8449            4.38187       0.00340855   \n",
       "184      105.519             4.3431       0.00186064   \n",
       "234      139.028            4.13278       0.00106967   \n",
       "289      101.556            7.98626        0.0013579   \n",
       "29       170.401            4.47617      0.000463814   \n",
       "233       164.92             7.5337      0.000697561   \n",
       "\n",
       "                                                params  split0_test_score  \\\n",
       "65   {'svr__C': 62.75534215376162, 'svr__epsilon': ...           0.378640   \n",
       "95   {'svr__C': 82.98684283304459, 'svr__epsilon': ...           0.377454   \n",
       "11   {'svr__C': 74.30062021011342, 'svr__epsilon': ...           0.381973   \n",
       "122  {'svr__C': 75.36875999124737, 'svr__epsilon': ...           0.383890   \n",
       "51   {'svr__C': 123.6858634395875, 'svr__epsilon': ...           0.376228   \n",
       "257  {'svr__C': 103.01094408535872, 'svr__epsilon':...           0.377493   \n",
       "125  {'svr__C': 110.8423048053841, 'svr__epsilon': ...           0.378437   \n",
       "261  {'svr__C': 113.93045640361544, 'svr__epsilon':...           0.378368   \n",
       "37   {'svr__C': 124.26042510606202, 'svr__epsilon':...           0.379784   \n",
       "16   {'svr__C': 56.84494698101118, 'svr__epsilon': ...           0.369721   \n",
       "184  {'svr__C': 105.5191055560903, 'svr__epsilon': ...           0.371867   \n",
       "234  {'svr__C': 139.02799356057068, 'svr__epsilon':...           0.376456   \n",
       "289  {'svr__C': 101.55572750576064, 'svr__epsilon':...           0.368703   \n",
       "29   {'svr__C': 170.40087274839965, 'svr__epsilon':...           0.370290   \n",
       "233  {'svr__C': 164.92008630848372, 'svr__epsilon':...           0.371970   \n",
       "\n",
       "     split1_test_score  split2_test_score  split3_test_score  \\\n",
       "65            0.352382           0.342213           0.355930   \n",
       "95            0.350739           0.340394           0.352878   \n",
       "11            0.346294           0.335272           0.353694   \n",
       "122           0.345153           0.336102           0.351590   \n",
       "51            0.347502           0.336513           0.348152   \n",
       "257           0.344886           0.332940           0.349401   \n",
       "125           0.344284           0.331595           0.349056   \n",
       "261           0.342979           0.330903           0.347936   \n",
       "37            0.343834           0.333220           0.344463   \n",
       "16            0.346879           0.332574           0.346955   \n",
       "184           0.341052           0.330355           0.344993   \n",
       "234           0.340503           0.328422           0.343429   \n",
       "289           0.344024           0.334105           0.342900   \n",
       "29            0.342635           0.334307           0.337094   \n",
       "233           0.342152           0.330271           0.338963   \n",
       "\n",
       "     split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "65            0.389598         0.363752        0.017573                1  \n",
       "95            0.389137         0.362120        0.018177                2  \n",
       "11            0.385732         0.360593        0.019911                3  \n",
       "122           0.384439         0.360235        0.020149                4  \n",
       "51            0.381950         0.358069        0.017747                5  \n",
       "257           0.384971         0.357938        0.019906                6  \n",
       "125           0.383037         0.357282        0.020036                7  \n",
       "261           0.381556         0.356348        0.020086                8  \n",
       "37            0.380124         0.356285        0.019735                9  \n",
       "16            0.381386         0.355503        0.017580               10  \n",
       "184           0.381051         0.353864        0.019281               11  \n",
       "234           0.378039         0.353370        0.020141               12  \n",
       "289           0.376586         0.353264        0.016384               13  \n",
       "29            0.379319         0.352729        0.018445               14  \n",
       "233           0.378082         0.352288        0.019067               15  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df = pd.DataFrame(rs.cv_results_)\n",
    "res_df.sort_values(by=['rank_test_score']).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 90 candidates, totalling 450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  7.3min\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:  8.6min\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:  9.9min\n",
      "[Parallel(n_jobs=-1)]: Done  69 tasks      | elapsed: 11.8min\n",
      "[Parallel(n_jobs=-1)]: Done  82 tasks      | elapsed: 14.4min\n",
      "[Parallel(n_jobs=-1)]: Done  97 tasks      | elapsed: 17.3min\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed: 19.3min\n",
      "[Parallel(n_jobs=-1)]: Done 129 tasks      | elapsed: 22.4min\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed: 24.4min\n",
      "[Parallel(n_jobs=-1)]: Done 165 tasks      | elapsed: 28.1min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed: 31.4min\n",
      "[Parallel(n_jobs=-1)]: Done 205 tasks      | elapsed: 34.4min\n",
      "[Parallel(n_jobs=-1)]: Done 226 tasks      | elapsed: 38.4min\n",
      "[Parallel(n_jobs=-1)]: Done 249 tasks      | elapsed: 83.3min\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed: 87.4min\n",
      "[Parallel(n_jobs=-1)]: Done 297 tasks      | elapsed: 91.3min\n",
      "[Parallel(n_jobs=-1)]: Done 322 tasks      | elapsed: 99.1min\n",
      "[Parallel(n_jobs=-1)]: Done 349 tasks      | elapsed: 105.9min\n",
      "[Parallel(n_jobs=-1)]: Done 376 tasks      | elapsed: 111.6min\n",
      "[Parallel(n_jobs=-1)]: Done 405 tasks      | elapsed: 119.0min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed: 124.8min\n",
      "[Parallel(n_jobs=-1)]: Done 450 out of 450 | elapsed: 126.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/svr_clf_gs.joblib']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'svr__C': [30, 40, 50, 60, 70, 80],\n",
    "              'svr__epsilon': [3, 4, 5, 6, 7],\n",
    "              'svr__gamma': ['scale', 'auto', 0.0015]\n",
    "}\n",
    "\n",
    "pipe  = make_pipeline(StandardScaler(),\n",
    "                      SVR(verbose=True, kernel='rbf'))\n",
    "\n",
    "gs = GridSearchCV(pipe, parameters, cv=5, n_jobs=-1, verbose=10)\n",
    "\n",
    "gs.fit(chunked_X_train[0], chunked_y_train[0])\n",
    "\n",
    "output_file = os.path.join(PATH_MODELS, 'svr_clf_gs.joblib')\n",
    "dump(gs, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of Support Vector regressor: R-squared = 0.3704274055160367 and RMSE = 8.386511373656239.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# R2\n",
    "score = gs.score(X_test, y_test)\n",
    "\n",
    "# MSE\n",
    "predictions = gs.predict(X_test)\n",
    "rmse = mean_squared_error(y_test, predictions, squared=False)\n",
    "\n",
    "print(f\"Performance of Support Vector regressor: R-squared = {score} and RMSE = {rmse}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'svr__C': 30, 'svr__epsilon': 5, 'svr__gamma': 'scale'}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_svr__C</th>\n",
       "      <th>param_svr__epsilon</th>\n",
       "      <th>param_svr__gamma</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>78.480846</td>\n",
       "      <td>0.274900</td>\n",
       "      <td>18.109673</td>\n",
       "      <td>0.115503</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>scale</td>\n",
       "      <td>{'svr__C': 30, 'svr__epsilon': 3, 'svr__gamma'...</td>\n",
       "      <td>0.387437</td>\n",
       "      <td>0.347372</td>\n",
       "      <td>0.342176</td>\n",
       "      <td>0.362969</td>\n",
       "      <td>0.389639</td>\n",
       "      <td>0.365919</td>\n",
       "      <td>0.019708</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>78.575422</td>\n",
       "      <td>0.415047</td>\n",
       "      <td>18.351595</td>\n",
       "      <td>0.550710</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>{'svr__C': 30, 'svr__epsilon': 3, 'svr__gamma'...</td>\n",
       "      <td>0.387437</td>\n",
       "      <td>0.347372</td>\n",
       "      <td>0.342176</td>\n",
       "      <td>0.362969</td>\n",
       "      <td>0.389639</td>\n",
       "      <td>0.365919</td>\n",
       "      <td>0.019708</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77.460607</td>\n",
       "      <td>0.235881</td>\n",
       "      <td>18.566331</td>\n",
       "      <td>0.185527</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>{'svr__C': 30, 'svr__epsilon': 3, 'svr__gamma'...</td>\n",
       "      <td>0.382953</td>\n",
       "      <td>0.349031</td>\n",
       "      <td>0.342955</td>\n",
       "      <td>0.360312</td>\n",
       "      <td>0.388912</td>\n",
       "      <td>0.364833</td>\n",
       "      <td>0.018204</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>72.220071</td>\n",
       "      <td>0.792610</td>\n",
       "      <td>16.005668</td>\n",
       "      <td>0.501847</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>scale</td>\n",
       "      <td>{'svr__C': 30, 'svr__epsilon': 4, 'svr__gamma'...</td>\n",
       "      <td>0.387381</td>\n",
       "      <td>0.352735</td>\n",
       "      <td>0.343830</td>\n",
       "      <td>0.363617</td>\n",
       "      <td>0.391307</td>\n",
       "      <td>0.367774</td>\n",
       "      <td>0.018735</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72.071294</td>\n",
       "      <td>0.284025</td>\n",
       "      <td>16.541555</td>\n",
       "      <td>0.588890</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>auto</td>\n",
       "      <td>{'svr__C': 30, 'svr__epsilon': 4, 'svr__gamma'...</td>\n",
       "      <td>0.387381</td>\n",
       "      <td>0.352735</td>\n",
       "      <td>0.343830</td>\n",
       "      <td>0.363617</td>\n",
       "      <td>0.391307</td>\n",
       "      <td>0.367774</td>\n",
       "      <td>0.018735</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>72.842726</td>\n",
       "      <td>3.510390</td>\n",
       "      <td>19.518003</td>\n",
       "      <td>3.395048</td>\n",
       "      <td>80</td>\n",
       "      <td>6</td>\n",
       "      <td>auto</td>\n",
       "      <td>{'svr__C': 80, 'svr__epsilon': 6, 'svr__gamma'...</td>\n",
       "      <td>0.373194</td>\n",
       "      <td>0.349964</td>\n",
       "      <td>0.337240</td>\n",
       "      <td>0.347513</td>\n",
       "      <td>0.383667</td>\n",
       "      <td>0.358316</td>\n",
       "      <td>0.017290</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>74.523264</td>\n",
       "      <td>3.471962</td>\n",
       "      <td>15.298929</td>\n",
       "      <td>0.262055</td>\n",
       "      <td>80</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>{'svr__C': 80, 'svr__epsilon': 6, 'svr__gamma'...</td>\n",
       "      <td>0.378445</td>\n",
       "      <td>0.351056</td>\n",
       "      <td>0.340248</td>\n",
       "      <td>0.353950</td>\n",
       "      <td>0.390020</td>\n",
       "      <td>0.362744</td>\n",
       "      <td>0.018496</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>63.547777</td>\n",
       "      <td>0.724069</td>\n",
       "      <td>13.180865</td>\n",
       "      <td>0.540073</td>\n",
       "      <td>80</td>\n",
       "      <td>7</td>\n",
       "      <td>scale</td>\n",
       "      <td>{'svr__C': 80, 'svr__epsilon': 7, 'svr__gamma'...</td>\n",
       "      <td>0.369483</td>\n",
       "      <td>0.347866</td>\n",
       "      <td>0.334668</td>\n",
       "      <td>0.344106</td>\n",
       "      <td>0.379853</td>\n",
       "      <td>0.355195</td>\n",
       "      <td>0.016794</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>61.432022</td>\n",
       "      <td>0.797870</td>\n",
       "      <td>12.363378</td>\n",
       "      <td>0.684407</td>\n",
       "      <td>80</td>\n",
       "      <td>7</td>\n",
       "      <td>auto</td>\n",
       "      <td>{'svr__C': 80, 'svr__epsilon': 7, 'svr__gamma'...</td>\n",
       "      <td>0.369483</td>\n",
       "      <td>0.347866</td>\n",
       "      <td>0.334668</td>\n",
       "      <td>0.344106</td>\n",
       "      <td>0.379853</td>\n",
       "      <td>0.355195</td>\n",
       "      <td>0.016794</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>48.946218</td>\n",
       "      <td>8.523624</td>\n",
       "      <td>8.581207</td>\n",
       "      <td>1.870472</td>\n",
       "      <td>80</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>{'svr__C': 80, 'svr__epsilon': 7, 'svr__gamma'...</td>\n",
       "      <td>0.376336</td>\n",
       "      <td>0.350585</td>\n",
       "      <td>0.338724</td>\n",
       "      <td>0.350796</td>\n",
       "      <td>0.387317</td>\n",
       "      <td>0.360752</td>\n",
       "      <td>0.018090</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows  16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_svr__C  \\\n",
       "0       78.480846      0.274900        18.109673        0.115503           30   \n",
       "1       78.575422      0.415047        18.351595        0.550710           30   \n",
       "2       77.460607      0.235881        18.566331        0.185527           30   \n",
       "3       72.220071      0.792610        16.005668        0.501847           30   \n",
       "4       72.071294      0.284025        16.541555        0.588890           30   \n",
       "..            ...           ...              ...             ...          ...   \n",
       "85      72.842726      3.510390        19.518003        3.395048           80   \n",
       "86      74.523264      3.471962        15.298929        0.262055           80   \n",
       "87      63.547777      0.724069        13.180865        0.540073           80   \n",
       "88      61.432022      0.797870        12.363378        0.684407           80   \n",
       "89      48.946218      8.523624         8.581207        1.870472           80   \n",
       "\n",
       "   param_svr__epsilon param_svr__gamma  \\\n",
       "0                   3            scale   \n",
       "1                   3             auto   \n",
       "2                   3           0.0015   \n",
       "3                   4            scale   \n",
       "4                   4             auto   \n",
       "..                ...              ...   \n",
       "85                  6             auto   \n",
       "86                  6           0.0015   \n",
       "87                  7            scale   \n",
       "88                  7             auto   \n",
       "89                  7           0.0015   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'svr__C': 30, 'svr__epsilon': 3, 'svr__gamma'...           0.387437   \n",
       "1   {'svr__C': 30, 'svr__epsilon': 3, 'svr__gamma'...           0.387437   \n",
       "2   {'svr__C': 30, 'svr__epsilon': 3, 'svr__gamma'...           0.382953   \n",
       "3   {'svr__C': 30, 'svr__epsilon': 4, 'svr__gamma'...           0.387381   \n",
       "4   {'svr__C': 30, 'svr__epsilon': 4, 'svr__gamma'...           0.387381   \n",
       "..                                                ...                ...   \n",
       "85  {'svr__C': 80, 'svr__epsilon': 6, 'svr__gamma'...           0.373194   \n",
       "86  {'svr__C': 80, 'svr__epsilon': 6, 'svr__gamma'...           0.378445   \n",
       "87  {'svr__C': 80, 'svr__epsilon': 7, 'svr__gamma'...           0.369483   \n",
       "88  {'svr__C': 80, 'svr__epsilon': 7, 'svr__gamma'...           0.369483   \n",
       "89  {'svr__C': 80, 'svr__epsilon': 7, 'svr__gamma'...           0.376336   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.347372           0.342176           0.362969   \n",
       "1            0.347372           0.342176           0.362969   \n",
       "2            0.349031           0.342955           0.360312   \n",
       "3            0.352735           0.343830           0.363617   \n",
       "4            0.352735           0.343830           0.363617   \n",
       "..                ...                ...                ...   \n",
       "85           0.349964           0.337240           0.347513   \n",
       "86           0.351056           0.340248           0.353950   \n",
       "87           0.347866           0.334668           0.344106   \n",
       "88           0.347866           0.334668           0.344106   \n",
       "89           0.350585           0.338724           0.350796   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.389639         0.365919        0.019708               18  \n",
       "1            0.389639         0.365919        0.019708               17  \n",
       "2            0.388912         0.364833        0.018204               29  \n",
       "3            0.391307         0.367774        0.018735                5  \n",
       "4            0.391307         0.367774        0.018735                6  \n",
       "..                ...              ...             ...              ...  \n",
       "85           0.383667         0.358316        0.017290               76  \n",
       "86           0.390020         0.362744        0.018496               46  \n",
       "87           0.379853         0.355195        0.016794               87  \n",
       "88           0.379853         0.355195        0.016794               88  \n",
       "89           0.387317         0.360752        0.018090               65  \n",
       "\n",
       "[90 rows x 16 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(gs.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best SVR after small gridsearch on a subset of the data: \n",
    "{'svr__C': 50, 'svr__epsilon': 5, 'svr__gamma': 0.0015, 'svr__kernel': 'rbf'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVR with best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/svr_clf.joblib']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "svr_clf  = make_pipeline(StandardScaler(),\n",
    "                         SVR(verbose=True, kernel='rbf', gamma='scale', epsilon=5, C=30))\n",
    "svr_clf.fit(chunked_X_train[0], chunked_y_train[0])\n",
    "\n",
    "output_file = os.path.join(PATH_MODELS, 'svr_clf.joblib')\n",
    "dump(svr_clf, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of Support Vector regressor: R-squared = 0.30513466490429 and RMSE = 8.59170117961887.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# R2\n",
    "score = svr_clf.score(X_test, y_test)\n",
    "\n",
    "# MSE\n",
    "predictions = svr_clf.predict(X_test)\n",
    "rmse = mean_squared_error(y_test, predictions, squared=False)\n",
    "\n",
    "print(f\"Performance of Support Vector regressor: R-squared = {score} and RMSE = {rmse}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4: SGD Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting a SVR is too computationally expensive. Therefore, we try prediction with an SGD Regressor. According to the sklearn documentation, it's best to start with a RandomizedSearchCV to find reasonable hyperparameters. Therefore, we start with this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('standardscaler', StandardScaler()),\n",
       "  ('sgdregressor', SGDRegressor(verbose=10))],\n",
       " 'verbose': False,\n",
       " 'standardscaler': StandardScaler(),\n",
       " 'sgdregressor': SGDRegressor(verbose=10),\n",
       " 'standardscaler__copy': True,\n",
       " 'standardscaler__with_mean': True,\n",
       " 'standardscaler__with_std': True,\n",
       " 'sgdregressor__alpha': 0.0001,\n",
       " 'sgdregressor__average': False,\n",
       " 'sgdregressor__early_stopping': False,\n",
       " 'sgdregressor__epsilon': 0.1,\n",
       " 'sgdregressor__eta0': 0.01,\n",
       " 'sgdregressor__fit_intercept': True,\n",
       " 'sgdregressor__l1_ratio': 0.15,\n",
       " 'sgdregressor__learning_rate': 'invscaling',\n",
       " 'sgdregressor__loss': 'squared_loss',\n",
       " 'sgdregressor__max_iter': 1000,\n",
       " 'sgdregressor__n_iter_no_change': 5,\n",
       " 'sgdregressor__penalty': 'l2',\n",
       " 'sgdregressor__power_t': 0.25,\n",
       " 'sgdregressor__random_state': None,\n",
       " 'sgdregressor__shuffle': True,\n",
       " 'sgdregressor__tol': 0.001,\n",
       " 'sgdregressor__validation_fraction': 0.1,\n",
       " 'sgdregressor__verbose': 10,\n",
       " 'sgdregressor__warm_start': False}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import uniform, loguniform\n",
    "\n",
    "# specify parameters and distributions to sample from\n",
    "parameters = {'sgdregressor__average': [True, False],\n",
    "              'sgdregressor__l1_ratio': uniform(0, 1),\n",
    "              'sgdregressor__alpha': loguniform(1e-6, 1e0),\n",
    "              'sgdregressor__epsilon': uniform(0.1, 10),\n",
    "             }\n",
    "\n",
    "pipe = make_pipeline(StandardScaler(),\n",
    "                     SGDRegressor(verbose=10))\n",
    "pipe.get_params()\n",
    "\n",
    "sgd_reg = RandomizedSearchCV(pipe, parameters, n_iter=20, cv=5, n_jobs=1, verbose=10)\n",
    "sgd_reg.fit(X_train, y_train)\n",
    "\n",
    "output_file = os.path.join(PATH_MODELS, 'sgd_reg.joblib')\n",
    "dump(sgd_reg, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of SGD regressor: R-squared = -8613876701713962.0 and RMSE = 956595131.138941.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# R2\n",
    "score = sgd_reg.score(X_test, y_test)\n",
    "\n",
    "# MSE\n",
    "predictions = sgd_reg.predict(X_test)\n",
    "rmse = mean_squared_error(y_test, predictions, squared=False)\n",
    "\n",
    "print(f\"Performance of SGD regressor: R-squared = {score} and RMSE = {rmse}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nystroem feature map "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bbruns/anaconda3/envs/mne/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.008753980739107048"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "\n",
    "feature_map_nystroem = Nystroem(gamma=.2,\n",
    "                                random_state=42,\n",
    "                                n_components=100)\n",
    "\n",
    "nystroem_approx_svr = Pipeline([(\"feature_map\", feature_map_nystroem),\n",
    "                                        (\"svr\", svm.LinearSVR(epsilon=5, C=30))])\n",
    "\n",
    "nystroem_approx_svr.fit(X_train, y_train)\n",
    "nystroem_approx_svr.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.357453e-189</td>\n",
       "      <td>-1.998314e-187</td>\n",
       "      <td>1.331167e-198</td>\n",
       "      <td>-4.251526e-184</td>\n",
       "      <td>-2.683210e-197</td>\n",
       "      <td>-4.800417e-197</td>\n",
       "      <td>-4.492310e-197</td>\n",
       "      <td>4.080903e-196</td>\n",
       "      <td>1.128112e-196</td>\n",
       "      <td>...</td>\n",
       "      <td>9.330504e-186</td>\n",
       "      <td>-1.684957e-198</td>\n",
       "      <td>-1.076902e-182</td>\n",
       "      <td>-5.831859e-183</td>\n",
       "      <td>-6.017852e-220</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-3.941304e-196</td>\n",
       "      <td>4.026794e-196</td>\n",
       "      <td>-4.130026e-201</td>\n",
       "      <td>1.175862e-177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.644618e-227</td>\n",
       "      <td>-1.659330e-226</td>\n",
       "      <td>-8.471396e-237</td>\n",
       "      <td>4.663544e-226</td>\n",
       "      <td>-7.504412e-237</td>\n",
       "      <td>-6.804332e-238</td>\n",
       "      <td>4.706109e-238</td>\n",
       "      <td>4.655101e-237</td>\n",
       "      <td>-4.677742e-239</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.500008e-246</td>\n",
       "      <td>3.951526e-260</td>\n",
       "      <td>1.159096e-244</td>\n",
       "      <td>3.880443e-245</td>\n",
       "      <td>1.186209e-273</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-3.947650e-257</td>\n",
       "      <td>5.308090e-258</td>\n",
       "      <td>8.140899e-255</td>\n",
       "      <td>-1.466768e-230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.605093e-157</td>\n",
       "      <td>-5.310001e-157</td>\n",
       "      <td>-5.997433e-167</td>\n",
       "      <td>1.147804e-155</td>\n",
       "      <td>-1.627418e-166</td>\n",
       "      <td>6.197006e-167</td>\n",
       "      <td>1.339166e-167</td>\n",
       "      <td>6.992740e-167</td>\n",
       "      <td>1.137568e-166</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.548931e-176</td>\n",
       "      <td>-1.094959e-189</td>\n",
       "      <td>-1.036338e-173</td>\n",
       "      <td>-6.202395e-174</td>\n",
       "      <td>-3.346010e-211</td>\n",
       "      <td>2.223295e-322</td>\n",
       "      <td>-5.248134e-187</td>\n",
       "      <td>6.249766e-187</td>\n",
       "      <td>-2.296352e-192</td>\n",
       "      <td>-3.612283e-160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.218993e-222</td>\n",
       "      <td>-2.479054e-221</td>\n",
       "      <td>-2.825894e-231</td>\n",
       "      <td>7.170523e-218</td>\n",
       "      <td>-5.175678e-231</td>\n",
       "      <td>4.424318e-231</td>\n",
       "      <td>7.781086e-232</td>\n",
       "      <td>8.635006e-230</td>\n",
       "      <td>1.463465e-230</td>\n",
       "      <td>...</td>\n",
       "      <td>1.374276e-226</td>\n",
       "      <td>-3.574392e-240</td>\n",
       "      <td>-1.049199e-224</td>\n",
       "      <td>-3.513721e-225</td>\n",
       "      <td>-1.483034e-261</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.499189e-238</td>\n",
       "      <td>-4.796726e-238</td>\n",
       "      <td>-1.017800e-242</td>\n",
       "      <td>1.077237e-213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.210566e-208</td>\n",
       "      <td>-5.987974e-208</td>\n",
       "      <td>7.505245e-219</td>\n",
       "      <td>-9.024713e-206</td>\n",
       "      <td>3.874734e-218</td>\n",
       "      <td>2.305826e-218</td>\n",
       "      <td>5.099725e-219</td>\n",
       "      <td>2.230963e-218</td>\n",
       "      <td>3.146908e-219</td>\n",
       "      <td>...</td>\n",
       "      <td>1.166142e-216</td>\n",
       "      <td>-3.122088e-230</td>\n",
       "      <td>-9.150044e-215</td>\n",
       "      <td>-3.061970e-215</td>\n",
       "      <td>1.239936e-246</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.287751e-228</td>\n",
       "      <td>-4.199096e-228</td>\n",
       "      <td>8.509627e-228</td>\n",
       "      <td>-5.161687e-212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149397</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.482197e-323</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149398</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.325538e-182</td>\n",
       "      <td>-8.167521e-178</td>\n",
       "      <td>-2.499960e-186</td>\n",
       "      <td>-9.294050e-182</td>\n",
       "      <td>2.341961e-186</td>\n",
       "      <td>6.570808e-186</td>\n",
       "      <td>3.633165e-187</td>\n",
       "      <td>-5.823522e-181</td>\n",
       "      <td>-1.455904e-181</td>\n",
       "      <td>...</td>\n",
       "      <td>9.426953e-201</td>\n",
       "      <td>-2.507895e-214</td>\n",
       "      <td>-7.352491e-199</td>\n",
       "      <td>-2.460845e-199</td>\n",
       "      <td>-1.041725e-235</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.062701e-212</td>\n",
       "      <td>-3.371401e-212</td>\n",
       "      <td>-7.149315e-217</td>\n",
       "      <td>1.203667e-186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149399</th>\n",
       "      <td>0.0</td>\n",
       "      <td>7.403441e-176</td>\n",
       "      <td>5.278982e-163</td>\n",
       "      <td>-3.479020e-180</td>\n",
       "      <td>-1.293482e-175</td>\n",
       "      <td>3.259065e-180</td>\n",
       "      <td>9.143992e-180</td>\n",
       "      <td>5.055933e-181</td>\n",
       "      <td>-8.104091e-175</td>\n",
       "      <td>-2.026055e-175</td>\n",
       "      <td>...</td>\n",
       "      <td>3.818280e-195</td>\n",
       "      <td>-7.944344e-209</td>\n",
       "      <td>-2.363792e-193</td>\n",
       "      <td>-7.968449e-194</td>\n",
       "      <td>-3.254088e-230</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.948035e-207</td>\n",
       "      <td>-1.045247e-206</td>\n",
       "      <td>-2.233267e-211</td>\n",
       "      <td>1.511541e-180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149400</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.268540e-190</td>\n",
       "      <td>-1.154708e-184</td>\n",
       "      <td>-1.783962e-193</td>\n",
       "      <td>8.714300e-189</td>\n",
       "      <td>1.950189e-193</td>\n",
       "      <td>1.846071e-194</td>\n",
       "      <td>-6.974548e-194</td>\n",
       "      <td>-7.999785e-189</td>\n",
       "      <td>-2.000108e-189</td>\n",
       "      <td>...</td>\n",
       "      <td>1.877611e-212</td>\n",
       "      <td>-4.935428e-226</td>\n",
       "      <td>-1.447874e-210</td>\n",
       "      <td>-4.847502e-211</td>\n",
       "      <td>-2.048834e-247</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.080074e-224</td>\n",
       "      <td>-6.628644e-224</td>\n",
       "      <td>-1.406106e-228</td>\n",
       "      <td>5.998402e-195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149401</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.512036e-240</td>\n",
       "      <td>-1.216331e-233</td>\n",
       "      <td>1.803880e-242</td>\n",
       "      <td>-7.773312e-238</td>\n",
       "      <td>3.006467e-243</td>\n",
       "      <td>5.063523e-243</td>\n",
       "      <td>-1.184174e-242</td>\n",
       "      <td>7.871229e-242</td>\n",
       "      <td>8.064188e-243</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.072644e-256</td>\n",
       "      <td>2.849710e-270</td>\n",
       "      <td>8.355212e-255</td>\n",
       "      <td>2.796551e-255</td>\n",
       "      <td>1.183627e-291</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.206807e-268</td>\n",
       "      <td>3.830508e-268</td>\n",
       "      <td>8.123180e-273</td>\n",
       "      <td>-2.407903e-243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1149402 rows  300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0              1              2              3              4    \\\n",
       "0        0.0 -1.357453e-189 -1.998314e-187  1.331167e-198 -4.251526e-184   \n",
       "1        0.0  3.644618e-227 -1.659330e-226 -8.471396e-237  4.663544e-226   \n",
       "2        0.0  1.605093e-157 -5.310001e-157 -5.997433e-167  1.147804e-155   \n",
       "3        0.0  1.218993e-222 -2.479054e-221 -2.825894e-231  7.170523e-218   \n",
       "4        0.0  1.210566e-208 -5.987974e-208  7.505245e-219 -9.024713e-206   \n",
       "...      ...            ...            ...            ...            ...   \n",
       "1149397  0.0   0.000000e+00   0.000000e+00   0.000000e+00  1.482197e-323   \n",
       "1149398  0.0  5.325538e-182 -8.167521e-178 -2.499960e-186 -9.294050e-182   \n",
       "1149399  0.0  7.403441e-176  5.278982e-163 -3.479020e-180 -1.293482e-175   \n",
       "1149400  0.0  6.268540e-190 -1.154708e-184 -1.783962e-193  8.714300e-189   \n",
       "1149401  0.0 -6.512036e-240 -1.216331e-233  1.803880e-242 -7.773312e-238   \n",
       "\n",
       "                   5              6              7              8    \\\n",
       "0       -2.683210e-197 -4.800417e-197 -4.492310e-197  4.080903e-196   \n",
       "1       -7.504412e-237 -6.804332e-238  4.706109e-238  4.655101e-237   \n",
       "2       -1.627418e-166  6.197006e-167  1.339166e-167  6.992740e-167   \n",
       "3       -5.175678e-231  4.424318e-231  7.781086e-232  8.635006e-230   \n",
       "4        3.874734e-218  2.305826e-218  5.099725e-219  2.230963e-218   \n",
       "...                ...            ...            ...            ...   \n",
       "1149397   0.000000e+00   0.000000e+00   0.000000e+00   0.000000e+00   \n",
       "1149398  2.341961e-186  6.570808e-186  3.633165e-187 -5.823522e-181   \n",
       "1149399  3.259065e-180  9.143992e-180  5.055933e-181 -8.104091e-175   \n",
       "1149400  1.950189e-193  1.846071e-194 -6.974548e-194 -7.999785e-189   \n",
       "1149401  3.006467e-243  5.063523e-243 -1.184174e-242  7.871229e-242   \n",
       "\n",
       "                   9    ...            290            291            292  \\\n",
       "0        1.128112e-196  ...  9.330504e-186 -1.684957e-198 -1.076902e-182   \n",
       "1       -4.677742e-239  ... -1.500008e-246  3.951526e-260  1.159096e-244   \n",
       "2        1.137568e-166  ... -2.548931e-176 -1.094959e-189 -1.036338e-173   \n",
       "3        1.463465e-230  ...  1.374276e-226 -3.574392e-240 -1.049199e-224   \n",
       "4        3.146908e-219  ...  1.166142e-216 -3.122088e-230 -9.150044e-215   \n",
       "...                ...  ...            ...            ...            ...   \n",
       "1149397   0.000000e+00  ...   0.000000e+00   0.000000e+00   0.000000e+00   \n",
       "1149398 -1.455904e-181  ...  9.426953e-201 -2.507895e-214 -7.352491e-199   \n",
       "1149399 -2.026055e-175  ...  3.818280e-195 -7.944344e-209 -2.363792e-193   \n",
       "1149400 -2.000108e-189  ...  1.877611e-212 -4.935428e-226 -1.447874e-210   \n",
       "1149401  8.064188e-243  ... -1.072644e-256  2.849710e-270  8.355212e-255   \n",
       "\n",
       "                   293            294            295            296  \\\n",
       "0       -5.831859e-183 -6.017852e-220   0.000000e+00 -3.941304e-196   \n",
       "1        3.880443e-245  1.186209e-273   0.000000e+00 -3.947650e-257   \n",
       "2       -6.202395e-174 -3.346010e-211  2.223295e-322 -5.248134e-187   \n",
       "3       -3.513721e-225 -1.483034e-261   0.000000e+00  1.499189e-238   \n",
       "4       -3.061970e-215  1.239936e-246   0.000000e+00  1.287751e-228   \n",
       "...                ...            ...            ...            ...   \n",
       "1149397   0.000000e+00   0.000000e+00   0.000000e+00   0.000000e+00   \n",
       "1149398 -2.460845e-199 -1.041725e-235   0.000000e+00  1.062701e-212   \n",
       "1149399 -7.968449e-194 -3.254088e-230   0.000000e+00  2.948035e-207   \n",
       "1149400 -4.847502e-211 -2.048834e-247   0.000000e+00  2.080074e-224   \n",
       "1149401  2.796551e-255  1.183627e-291   0.000000e+00 -1.206807e-268   \n",
       "\n",
       "                   297            298            299  \n",
       "0        4.026794e-196 -4.130026e-201  1.175862e-177  \n",
       "1        5.308090e-258  8.140899e-255 -1.466768e-230  \n",
       "2        6.249766e-187 -2.296352e-192 -3.612283e-160  \n",
       "3       -4.796726e-238 -1.017800e-242  1.077237e-213  \n",
       "4       -4.199096e-228  8.509627e-228 -5.161687e-212  \n",
       "...                ...            ...            ...  \n",
       "1149397   0.000000e+00   0.000000e+00   0.000000e+00  \n",
       "1149398 -3.371401e-212 -7.149315e-217  1.203667e-186  \n",
       "1149399 -1.045247e-206 -2.233267e-211  1.511541e-180  \n",
       "1149400 -6.628644e-224 -1.406106e-228  5.998402e-195  \n",
       "1149401  3.830508e-268  8.123180e-273 -2.407903e-243  \n",
       "\n",
       "[1149402 rows x 300 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of Nystroem LinearSVR regressor: R-squared = -0.007994716809803792 and RMSE = 10.34803689522995.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# R2\n",
    "score = nystroem_approx_svr.score(X_test, y_test)\n",
    "\n",
    "# MSE\n",
    "predictions = nystroem_approx_svr.predict(X_test)\n",
    "rmse = mean_squared_error(y_test, predictions, squared=False)\n",
    "\n",
    "print(f\"Performance of Nystroem LinearSVR regressor: R-squared = {score} and RMSE = {rmse}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 5: Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(956672, 450)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape=(450, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dropout, Dense, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, Adadelta\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "def fully_connected_model():\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    model.add(Dense(512, activation='tanh', input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "        \n",
    "    model.add(Dense(128, activation='tanh'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_11 (Dense)             (None, 512)               230912    \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 299,265\n",
      "Trainable params: 297,985\n",
      "Non-trainable params: 1,280\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = fully_connected_model()\n",
    "\n",
    "optimizer = Adam(learning_rate=0.01, \n",
    "                 beta_1=0.9, \n",
    "                 beta_2=0.999, \n",
    "                 epsilon=1e-07, \n",
    "                 amsgrad=False,\n",
    "                 name='Adam')\n",
    "\n",
    "model.build(input_shape)\n",
    "model.compile(loss='mean_squared_error', optimizer=optimizer, metrics=[tf.keras.metrics.RootMeanSquaredError(), tf.keras.metrics.MeanAbsoluteError()])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_filename = 'FC_regressor_01'\n",
    "output_file = os.path.join(PATH_MODELS, output_filename)\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath = output_file + \".hdf5\", monitor='val_loss', verbose=1, save_best_only=True)\n",
    "earlystopper = EarlyStopping(monitor='val_loss', patience=25, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=0.0001, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(X_train, X_val, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "29896/29896 [==============================] - 89s 3ms/step - loss: 71.9831 - root_mean_squared_error: 8.4843 - mean_absolute_error: 6.9533 - val_loss: 69.0405 - val_root_mean_squared_error: 8.3091 - val_mean_absolute_error: 6.7363\n",
      "\n",
      "Epoch 00001: val_loss improved from 121.39967 to 69.04053, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/FC_regressor_01.hdf5\n",
      "Epoch 2/1500\n",
      "29896/29896 [==============================] - 87s 3ms/step - loss: 67.5524 - root_mean_squared_error: 8.2190 - mean_absolute_error: 6.6843 - val_loss: 66.1549 - val_root_mean_squared_error: 8.1336 - val_mean_absolute_error: 6.5416\n",
      "\n",
      "Epoch 00002: val_loss improved from 69.04053 to 66.15494, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/FC_regressor_01.hdf5\n",
      "Epoch 3/1500\n",
      "29896/29896 [==============================] - 87s 3ms/step - loss: 66.1400 - root_mean_squared_error: 8.1327 - mean_absolute_error: 6.5983 - val_loss: 66.4940 - val_root_mean_squared_error: 8.1544 - val_mean_absolute_error: 6.5490\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 66.15494\n",
      "Epoch 4/1500\n",
      "29896/29896 [==============================] - 93s 3ms/step - loss: 65.2442 - root_mean_squared_error: 8.0774 - mean_absolute_error: 6.5413 - val_loss: 67.2301 - val_root_mean_squared_error: 8.1994 - val_mean_absolute_error: 6.6587\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 66.15494\n",
      "Epoch 5/1500\n",
      "29896/29896 [==============================] - 97s 3ms/step - loss: 64.3693 - root_mean_squared_error: 8.0230 - mean_absolute_error: 6.4875 - val_loss: 64.8757 - val_root_mean_squared_error: 8.0545 - val_mean_absolute_error: 6.4627\n",
      "\n",
      "Epoch 00005: val_loss improved from 66.15494 to 64.87569, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/FC_regressor_01.hdf5\n",
      "Epoch 6/1500\n",
      "29896/29896 [==============================] - 88s 3ms/step - loss: 64.0533 - root_mean_squared_error: 8.0033 - mean_absolute_error: 6.4674 - val_loss: 66.7703 - val_root_mean_squared_error: 8.1713 - val_mean_absolute_error: 6.5360\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 64.87569\n",
      "Epoch 7/1500\n",
      "29896/29896 [==============================] - 88s 3ms/step - loss: 63.6008 - root_mean_squared_error: 7.9750 - mean_absolute_error: 6.4391 - val_loss: 65.9060 - val_root_mean_squared_error: 8.1182 - val_mean_absolute_error: 6.4773\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 64.87569\n",
      "Epoch 8/1500\n",
      "29896/29896 [==============================] - 91s 3ms/step - loss: 63.1705 - root_mean_squared_error: 7.9480 - mean_absolute_error: 6.4084 - val_loss: 66.4266 - val_root_mean_squared_error: 8.1502 - val_mean_absolute_error: 6.4673\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 64.87569\n",
      "Epoch 9/1500\n",
      "29896/29896 [==============================] - 90s 3ms/step - loss: 62.8125 - root_mean_squared_error: 7.9254 - mean_absolute_error: 6.3896 - val_loss: 65.0929 - val_root_mean_squared_error: 8.0680 - val_mean_absolute_error: 6.4887\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 64.87569\n",
      "Epoch 10/1500\n",
      "29896/29896 [==============================] - 87s 3ms/step - loss: 62.5726 - root_mean_squared_error: 7.9103 - mean_absolute_error: 6.3720 - val_loss: 66.3553 - val_root_mean_squared_error: 8.1459 - val_mean_absolute_error: 6.4728\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 64.87569\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "Epoch 11/1500\n",
      "29896/29896 [==============================] - 87s 3ms/step - loss: 61.3113 - root_mean_squared_error: 7.8302 - mean_absolute_error: 6.2914 - val_loss: 65.3170 - val_root_mean_squared_error: 8.0819 - val_mean_absolute_error: 6.4594\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 64.87569\n",
      "Epoch 12/1500\n",
      "29896/29896 [==============================] - 83s 3ms/step - loss: 60.6122 - root_mean_squared_error: 7.7854 - mean_absolute_error: 6.2473 - val_loss: 67.1186 - val_root_mean_squared_error: 8.1926 - val_mean_absolute_error: 6.4572\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 64.87569\n",
      "Epoch 13/1500\n",
      "29896/29896 [==============================] - 83s 3ms/step - loss: 60.2013 - root_mean_squared_error: 7.7590 - mean_absolute_error: 6.2224 - val_loss: 65.1399 - val_root_mean_squared_error: 8.0709 - val_mean_absolute_error: 6.4280\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 64.87569\n",
      "Epoch 14/1500\n",
      "29896/29896 [==============================] - 83s 3ms/step - loss: 59.9743 - root_mean_squared_error: 7.7443 - mean_absolute_error: 6.2075 - val_loss: 64.5842 - val_root_mean_squared_error: 8.0364 - val_mean_absolute_error: 6.4022\n",
      "\n",
      "Epoch 00014: val_loss improved from 64.87569 to 64.58420, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/FC_regressor_01.hdf5\n",
      "Epoch 15/1500\n",
      "29896/29896 [==============================] - 90s 3ms/step - loss: 59.7542 - root_mean_squared_error: 7.7301 - mean_absolute_error: 6.1950 - val_loss: 67.1944 - val_root_mean_squared_error: 8.1972 - val_mean_absolute_error: 6.4701\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 64.58420\n",
      "Epoch 16/1500\n",
      "29896/29896 [==============================] - 92s 3ms/step - loss: 59.5595 - root_mean_squared_error: 7.7175 - mean_absolute_error: 6.1812 - val_loss: 64.5035 - val_root_mean_squared_error: 8.0314 - val_mean_absolute_error: 6.3918\n",
      "\n",
      "Epoch 00016: val_loss improved from 64.58420 to 64.50346, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/FC_regressor_01.hdf5\n",
      "Epoch 17/1500\n",
      "29896/29896 [==============================] - 84s 3ms/step - loss: 59.3240 - root_mean_squared_error: 7.7022 - mean_absolute_error: 6.1666 - val_loss: 65.9738 - val_root_mean_squared_error: 8.1224 - val_mean_absolute_error: 6.4220\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 64.50346\n",
      "Epoch 18/1500\n",
      "29896/29896 [==============================] - 84s 3ms/step - loss: 59.1745 - root_mean_squared_error: 7.6925 - mean_absolute_error: 6.1584 - val_loss: 64.8732 - val_root_mean_squared_error: 8.0544 - val_mean_absolute_error: 6.3897\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 64.50346\n",
      "Epoch 19/1500\n",
      "29896/29896 [==============================] - 84s 3ms/step - loss: 59.0259 - root_mean_squared_error: 7.6828 - mean_absolute_error: 6.1492 - val_loss: 67.7588 - val_root_mean_squared_error: 8.2316 - val_mean_absolute_error: 6.4664\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 64.50346\n",
      "Epoch 20/1500\n",
      "29896/29896 [==============================] - 84s 3ms/step - loss: 58.9423 - root_mean_squared_error: 7.6774 - mean_absolute_error: 6.1435 - val_loss: 67.2637 - val_root_mean_squared_error: 8.2014 - val_mean_absolute_error: 6.4250\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 64.50346\n",
      "Epoch 21/1500\n",
      "29896/29896 [==============================] - 85s 3ms/step - loss: 58.7720 - root_mean_squared_error: 7.6663 - mean_absolute_error: 6.1305 - val_loss: 66.7414 - val_root_mean_squared_error: 8.1695 - val_mean_absolute_error: 6.4313\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 64.50346\n",
      "Epoch 22/1500\n",
      "29896/29896 [==============================] - 88s 3ms/step - loss: 58.6961 - root_mean_squared_error: 7.6613 - mean_absolute_error: 6.1240 - val_loss: 67.7999 - val_root_mean_squared_error: 8.2341 - val_mean_absolute_error: 6.4566\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 64.50346\n",
      "Epoch 23/1500\n",
      "29896/29896 [==============================] - 86s 3ms/step - loss: 58.5395 - root_mean_squared_error: 7.6511 - mean_absolute_error: 6.1156 - val_loss: 66.3489 - val_root_mean_squared_error: 8.1455 - val_mean_absolute_error: 6.4070\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 64.50346\n",
      "Epoch 24/1500\n",
      "29896/29896 [==============================] - 91s 3ms/step - loss: 58.4541 - root_mean_squared_error: 7.6455 - mean_absolute_error: 6.1130 - val_loss: 64.2353 - val_root_mean_squared_error: 8.0147 - val_mean_absolute_error: 6.3776\n",
      "\n",
      "Epoch 00024: val_loss improved from 64.50346 to 64.23534, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/FC_regressor_01.hdf5\n",
      "Epoch 25/1500\n",
      "29896/29896 [==============================] - 93s 3ms/step - loss: 58.3383 - root_mean_squared_error: 7.6380 - mean_absolute_error: 6.1040 - val_loss: 65.3862 - val_root_mean_squared_error: 8.0862 - val_mean_absolute_error: 6.3762\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 64.23534\n",
      "Epoch 26/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29896/29896 [==============================] - 81s 3ms/step - loss: 58.2185 - root_mean_squared_error: 7.6301 - mean_absolute_error: 6.0966 - val_loss: 65.4717 - val_root_mean_squared_error: 8.0915 - val_mean_absolute_error: 6.3847\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 64.23534\n",
      "Epoch 27/1500\n",
      "29896/29896 [==============================] - 81s 3ms/step - loss: 58.1174 - root_mean_squared_error: 7.6235 - mean_absolute_error: 6.0881 - val_loss: 65.4810 - val_root_mean_squared_error: 8.0920 - val_mean_absolute_error: 6.3908\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 64.23534\n",
      "Epoch 28/1500\n",
      "29896/29896 [==============================] - 82s 3ms/step - loss: 58.0315 - root_mean_squared_error: 7.6178 - mean_absolute_error: 6.0829 - val_loss: 64.5021 - val_root_mean_squared_error: 8.0313 - val_mean_absolute_error: 6.3921\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 64.23534\n",
      "Epoch 29/1500\n",
      "29896/29896 [==============================] - 82s 3ms/step - loss: 57.8626 - root_mean_squared_error: 7.6067 - mean_absolute_error: 6.0740 - val_loss: 64.8024 - val_root_mean_squared_error: 8.0500 - val_mean_absolute_error: 6.3751\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 64.23534\n",
      "Epoch 30/1500\n",
      "29896/29896 [==============================] - 82s 3ms/step - loss: 57.7579 - root_mean_squared_error: 7.5999 - mean_absolute_error: 6.0675 - val_loss: 66.4618 - val_root_mean_squared_error: 8.1524 - val_mean_absolute_error: 6.4140\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 64.23534\n",
      "Epoch 31/1500\n",
      "29896/29896 [==============================] - 83s 3ms/step - loss: 57.7011 - root_mean_squared_error: 7.5961 - mean_absolute_error: 6.0639 - val_loss: 64.9220 - val_root_mean_squared_error: 8.0574 - val_mean_absolute_error: 6.3955\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 64.23534\n",
      "Epoch 32/1500\n",
      "29896/29896 [==============================] - 84s 3ms/step - loss: 57.6567 - root_mean_squared_error: 7.5932 - mean_absolute_error: 6.0593 - val_loss: 64.6807 - val_root_mean_squared_error: 8.0424 - val_mean_absolute_error: 6.3769\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 64.23534\n",
      "Epoch 33/1500\n",
      "29896/29896 [==============================] - 83s 3ms/step - loss: 57.5138 - root_mean_squared_error: 7.5838 - mean_absolute_error: 6.0509 - val_loss: 64.9954 - val_root_mean_squared_error: 8.0620 - val_mean_absolute_error: 6.3636\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 64.23534\n",
      "Epoch 34/1500\n",
      "29896/29896 [==============================] - 85s 3ms/step - loss: 57.3765 - root_mean_squared_error: 7.5747 - mean_absolute_error: 6.0409 - val_loss: 64.3969 - val_root_mean_squared_error: 8.0248 - val_mean_absolute_error: 6.3596\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 64.23534\n",
      "Epoch 35/1500\n",
      "29896/29896 [==============================] - 89s 3ms/step - loss: 57.3963 - root_mean_squared_error: 7.5760 - mean_absolute_error: 6.0433 - val_loss: 65.6736 - val_root_mean_squared_error: 8.1039 - val_mean_absolute_error: 6.3803\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 64.23534\n",
      "Epoch 36/1500\n",
      "29896/29896 [==============================] - 122s 4ms/step - loss: 57.3224 - root_mean_squared_error: 7.5712 - mean_absolute_error: 6.0385 - val_loss: 64.4859 - val_root_mean_squared_error: 8.0303 - val_mean_absolute_error: 6.3496\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 64.23534\n",
      "Epoch 37/1500\n",
      "29896/29896 [==============================] - 118s 4ms/step - loss: 57.1923 - root_mean_squared_error: 7.5626 - mean_absolute_error: 6.0285 - val_loss: 65.4177 - val_root_mean_squared_error: 8.0881 - val_mean_absolute_error: 6.3628\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 64.23534\n",
      "Epoch 38/1500\n",
      "29896/29896 [==============================] - 117s 4ms/step - loss: 57.0282 - root_mean_squared_error: 7.5517 - mean_absolute_error: 6.0224 - val_loss: 64.8970 - val_root_mean_squared_error: 8.0559 - val_mean_absolute_error: 6.3305\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 64.23534\n",
      "Epoch 39/1500\n",
      "29896/29896 [==============================] - 89s 3ms/step - loss: 57.0629 - root_mean_squared_error: 7.5540 - mean_absolute_error: 6.0212 - val_loss: 64.5566 - val_root_mean_squared_error: 8.0347 - val_mean_absolute_error: 6.3589\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 64.23534\n",
      "Epoch 40/1500\n",
      "29896/29896 [==============================] - 93s 3ms/step - loss: 56.9179 - root_mean_squared_error: 7.5444 - mean_absolute_error: 6.0120 - val_loss: 64.3319 - val_root_mean_squared_error: 8.0207 - val_mean_absolute_error: 6.3382\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 64.23534\n",
      "Epoch 41/1500\n",
      "29896/29896 [==============================] - 109s 4ms/step - loss: 56.8027 - root_mean_squared_error: 7.5368 - mean_absolute_error: 6.0038 - val_loss: 67.4015 - val_root_mean_squared_error: 8.2098 - val_mean_absolute_error: 6.4160\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 64.23534\n",
      "Epoch 42/1500\n",
      "29896/29896 [==============================] - 113s 4ms/step - loss: 56.8147 - root_mean_squared_error: 7.5376 - mean_absolute_error: 6.0035 - val_loss: 63.9011 - val_root_mean_squared_error: 7.9938 - val_mean_absolute_error: 6.3299\n",
      "\n",
      "Epoch 00042: val_loss improved from 64.23534 to 63.90107, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/FC_regressor_01.hdf5\n",
      "Epoch 43/1500\n",
      "29896/29896 [==============================] - 122s 4ms/step - loss: 56.7219 - root_mean_squared_error: 7.5314 - mean_absolute_error: 6.0004 - val_loss: 64.1191 - val_root_mean_squared_error: 8.0074 - val_mean_absolute_error: 6.3155\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 63.90107\n",
      "Epoch 44/1500\n",
      "29896/29896 [==============================] - 125s 4ms/step - loss: 56.5072 - root_mean_squared_error: 7.5171 - mean_absolute_error: 5.9846 - val_loss: 68.6932 - val_root_mean_squared_error: 8.2881 - val_mean_absolute_error: 6.4616\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 63.90107\n",
      "Epoch 45/1500\n",
      "29896/29896 [==============================] - 138s 5ms/step - loss: 56.5893 - root_mean_squared_error: 7.5226 - mean_absolute_error: 5.9906 - val_loss: 63.5708 - val_root_mean_squared_error: 7.9731 - val_mean_absolute_error: 6.3119\n",
      "\n",
      "Epoch 00045: val_loss improved from 63.90107 to 63.57076, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/FC_regressor_01.hdf5\n",
      "Epoch 46/1500\n",
      "29896/29896 [==============================] - 130s 4ms/step - loss: 56.4464 - root_mean_squared_error: 7.5131 - mean_absolute_error: 5.9782 - val_loss: 68.1645 - val_root_mean_squared_error: 8.2562 - val_mean_absolute_error: 6.4142\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 63.57076\n",
      "Epoch 47/1500\n",
      "29896/29896 [==============================] - 127s 4ms/step - loss: 56.4275 - root_mean_squared_error: 7.5118 - mean_absolute_error: 5.9758 - val_loss: 64.2616 - val_root_mean_squared_error: 8.0163 - val_mean_absolute_error: 6.3508\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 63.57076\n",
      "Epoch 48/1500\n",
      "29896/29896 [==============================] - 126s 4ms/step - loss: 56.4388 - root_mean_squared_error: 7.5126 - mean_absolute_error: 5.9801 - val_loss: 67.3178 - val_root_mean_squared_error: 8.2047 - val_mean_absolute_error: 6.4068\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 63.57076\n",
      "Epoch 49/1500\n",
      "29896/29896 [==============================] - 149s 5ms/step - loss: 56.1812 - root_mean_squared_error: 7.4954 - mean_absolute_error: 5.9627 - val_loss: 65.2214 - val_root_mean_squared_error: 8.0760 - val_mean_absolute_error: 6.3477\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 63.57076\n",
      "Epoch 50/1500\n",
      "29896/29896 [==============================] - 148s 5ms/step - loss: 56.1595 - root_mean_squared_error: 7.4940 - mean_absolute_error: 5.9621 - val_loss: 65.4589 - val_root_mean_squared_error: 8.0907 - val_mean_absolute_error: 6.3744\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 63.57076\n",
      "Epoch 51/1500\n",
      "29896/29896 [==============================] - 138s 5ms/step - loss: 56.1778 - root_mean_squared_error: 7.4952 - mean_absolute_error: 5.9604 - val_loss: 65.3100 - val_root_mean_squared_error: 8.0815 - val_mean_absolute_error: 6.3551\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 63.57076\n",
      "Epoch 52/1500\n",
      "29896/29896 [==============================] - 135s 5ms/step - loss: 56.1060 - root_mean_squared_error: 7.4904 - mean_absolute_error: 5.9568 - val_loss: 65.2054 - val_root_mean_squared_error: 8.0750 - val_mean_absolute_error: 6.3479\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 63.57076\n",
      "Epoch 53/1500\n",
      "29896/29896 [==============================] - 130s 4ms/step - loss: 56.0632 - root_mean_squared_error: 7.4875 - mean_absolute_error: 5.9529 - val_loss: 65.0487 - val_root_mean_squared_error: 8.0653 - val_mean_absolute_error: 6.3488\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 63.57076\n",
      "Epoch 54/1500\n",
      "29896/29896 [==============================] - 134s 4ms/step - loss: 55.9212 - root_mean_squared_error: 7.4780 - mean_absolute_error: 5.9426 - val_loss: 64.4836 - val_root_mean_squared_error: 8.0302 - val_mean_absolute_error: 6.3231\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 63.57076\n",
      "Epoch 55/1500\n",
      "29896/29896 [==============================] - 145s 5ms/step - loss: 55.8307 - root_mean_squared_error: 7.4720 - mean_absolute_error: 5.9366 - val_loss: 63.1618 - val_root_mean_squared_error: 7.9474 - val_mean_absolute_error: 6.2966\n",
      "\n",
      "Epoch 00055: val_loss improved from 63.57076 to 63.16182, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/FC_regressor_01.hdf5\n",
      "Epoch 56/1500\n",
      "29896/29896 [==============================] - 132s 4ms/step - loss: 55.8610 - root_mean_squared_error: 7.4740 - mean_absolute_error: 5.9389 - val_loss: 70.1081 - val_root_mean_squared_error: 8.3731 - val_mean_absolute_error: 6.4186\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 63.16182\n",
      "Epoch 57/1500\n",
      "20968/29896 [====================>.........] - ETA: 37s - loss: 55.7621 - root_mean_squared_error: 7.4674 - mean_absolute_error: 5.9315"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-2a22d1496fb3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# fit network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m history = model.fit(x=X_train_standard,\n\u001b[0m\u001b[1;32m      5\u001b[0m                     \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val_standard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mne/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1133\u001b[0m                 _r=1):\n\u001b[1;32m   1134\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mne/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    795\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mne/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    823\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mne/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2969\u001b[0m       (graph_function,\n\u001b[0;32m-> 2970\u001b[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[1;32m   2971\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m   2972\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
      "\u001b[0;32m~/anaconda3/envs/mne/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3347\u001b[0m     \u001b[0mcache_key_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache_key_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3348\u001b[0;31m     \u001b[0mcache_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_key_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3350\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mne/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_cache_key\u001b[0;34m(self, args, kwargs, cache_key_context, include_tensor_ranks_only)\u001b[0m\n\u001b[1;32m   3127\u001b[0m       input_signature = pywrap_tfe.TFE_Py_EncodeArg(inputs,\n\u001b[1;32m   3128\u001b[0m                                                     include_tensor_ranks_only)\n\u001b[0;32m-> 3129\u001b[0;31m       \u001b[0mhashable_input_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_input_signature_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3130\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3131\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mne/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_make_input_signature_hashable\u001b[0;34m(elem)\u001b[0m\n\u001b[1;32m    112\u001b[0m   \"\"\"\n\u001b[1;32m    113\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m     \u001b[0mhash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;31m# TODO(slebedev): consider using nest.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mne/lib/python3.8/site-packages/tensorflow/python/framework/type_spec.py\u001b[0m in \u001b[0;36m__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__hash__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mhash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_cmp_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mne/lib/python3.8/site-packages/tensorflow/python/framework/tensor_spec.py\u001b[0m in \u001b[0;36m__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__hash__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mhash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape_tuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__eq__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 1500\n",
    "\n",
    "# fit network\n",
    "history = model.fit(x=X_train,\n",
    "                    y=y_train,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    epochs=epochs,\n",
    "                    callbacks = [checkpointer, earlystopper, reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of simple FC neural network regressor: RMSE = 7.968837618299955 and MAE = 6.325835159002935.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "filename = os.path.join(PATH_MODELS, 'FC_regressor_01')\n",
    "model = tf.keras.models.load_model(filename + \".hdf5\")\n",
    "\n",
    "# MSE\n",
    "predictions = model.predict(X_test)\n",
    "rmse = mean_squared_error(y_test, predictions, squared=False)\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "\n",
    "print(f\"Performance of simple FC neural network regressor: RMSE = {rmse} and MAE = {mae}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
