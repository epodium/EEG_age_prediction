{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning models for age prediction on EEG data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook uses deep learning methods to predict the age of infants using EEG data. The EEG data is preprocessed as shown in the notebook 'Deep learning EEG_dataset preprocessing raw'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, fnmatch, csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.insert(0, os.path.dirname(os.getcwd()))\n",
    "\n",
    "from config import PATH_DATA_PROCESSED_DL_REDUCED, PATH_MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load preprocessed data (reduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data can be found in 'PATH_DATA_PROCESSED_DL_REDUCED'. This is a single folder with all the data and metadata. The EEG data is in the .zarr files and the metadata is in .csv files. The .zarr files are divided in chunks of 1-second epochs (average of 10 original EEG epochs) from the same subject and the metadata contains the information like the subject's identification code and age. The notebook \"Deep learning EEG_DL dataset_reduction.ipynb\" takes care of reducing the original processed data set to the reduced size.\n",
    "\n",
    "Generator loads all the data into memory. The generators generate averaged epochs on the fly. The data is split in train/validation/test and no subject can be found in more than one of these splits. \n",
    "\n",
    "Originally, we used the original EEG epochs and averaged 30 of them into a new EEG epoch in the generator object. This had two disadvantages: (1) many files had to be openened and closed during the training process, and (2) the data set was too large to fit into memory. Therefore, we decided to randomly create chunks of 10 EEG epochs and average those for each subject/age group. This reduced the data set from ±145GB to ±14.5 GB. We now use these already averaged EEG epochs as \"original\" epcohs, and average those another 3-5 times to reduce noise. We have also experimented with averaging all EEG epochs of a subject at a specific age into a single EEG epoch, but performance was lower, most likely because this reduced the size of the data set a lot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.98 s, sys: 478 ms, total: 3.46 s\n",
      "Wall time: 4.18 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Load all the metadata\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Step 1: Get all the files in the output folder\n",
    "file_names = os.listdir(PATH_DATA_PROCESSED_DL_REDUCED)\n",
    "\n",
    "# Step 2: Get the full paths of the files (without extensions)\n",
    "files = [os.path.splitext(os.path.join(PATH_DATA_PROCESSED_DL_REDUCED, file_name))[0] for file_name in fnmatch.filter(file_names, \"*.zarr\")]\n",
    "\n",
    "# Step 3: Load all the metadata\n",
    "frames = []\n",
    "\n",
    "for idx, feature_file in enumerate(files):\n",
    "    df_metadata = pd.read_csv(feature_file + \".csv\")\n",
    "    frames.append(df_metadata)\n",
    "\n",
    "df_metadata = pd.concat(frames) \n",
    "\n",
    "# Step 4: Add missing age information based on the age group the subject is in\n",
    "df_metadata['age_months'].fillna(df_metadata['age_group'], inplace=True)\n",
    "df_metadata['age_days'].fillna(df_metadata['age_group']*30, inplace=True)\n",
    "df_metadata['age_years'].fillna(df_metadata['age_group']/12, inplace=True)\n",
    "\n",
    "# Step 5: List all the unique subject IDs\n",
    "subject_ids = sorted(list(set(df_metadata[\"code\"].tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "IDs_train, IDs_temp = train_test_split(subject_ids, test_size=0.3, random_state=42)\n",
    "IDs_test, IDs_val = train_test_split(IDs_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>cnt_path</th>\n",
       "      <th>cnt_file</th>\n",
       "      <th>age_group</th>\n",
       "      <th>age_days</th>\n",
       "      <th>age_months</th>\n",
       "      <th>age_years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>146</td>\n",
       "      <td>/Volumes/Seagate Expansion Drive/ePodium/Data/...</td>\n",
       "      <td>146_29</td>\n",
       "      <td>29</td>\n",
       "      <td>860.0</td>\n",
       "      <td>28.666667</td>\n",
       "      <td>2.388889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>156</td>\n",
       "      <td>/Volumes/Seagate Expansion Drive/ePodium/Data/...</td>\n",
       "      <td>156_29</td>\n",
       "      <td>29</td>\n",
       "      <td>870.0</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>2.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>713</td>\n",
       "      <td>/Volumes/Seagate Expansion Drive/ePodium/Data/...</td>\n",
       "      <td>713_29</td>\n",
       "      <td>29</td>\n",
       "      <td>868.0</td>\n",
       "      <td>28.933333</td>\n",
       "      <td>2.411111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>411</td>\n",
       "      <td>/Volumes/Seagate Expansion Drive/ePodium/Data/...</td>\n",
       "      <td>411_41</td>\n",
       "      <td>41</td>\n",
       "      <td>1231.0</td>\n",
       "      <td>41.033333</td>\n",
       "      <td>3.419444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>703</td>\n",
       "      <td>/Volumes/Seagate Expansion Drive/ePodium/Data/...</td>\n",
       "      <td>703_29</td>\n",
       "      <td>29</td>\n",
       "      <td>866.0</td>\n",
       "      <td>28.866667</td>\n",
       "      <td>2.405556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>145</td>\n",
       "      <td>/Volumes/Seagate Expansion Drive/ePodium/Data/...</td>\n",
       "      <td>145_41</td>\n",
       "      <td>41</td>\n",
       "      <td>1232.0</td>\n",
       "      <td>41.066667</td>\n",
       "      <td>3.422222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>124</td>\n",
       "      <td>/Volumes/Seagate Expansion Drive/ePodium/Data/...</td>\n",
       "      <td>124_47</td>\n",
       "      <td>47</td>\n",
       "      <td>1407.0</td>\n",
       "      <td>46.900000</td>\n",
       "      <td>3.908333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>710</td>\n",
       "      <td>/Volumes/Seagate Expansion Drive/ePodium/Data/...</td>\n",
       "      <td>710_41</td>\n",
       "      <td>41</td>\n",
       "      <td>1234.0</td>\n",
       "      <td>41.133333</td>\n",
       "      <td>3.427778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>182</td>\n",
       "      <td>/Volumes/Seagate Expansion Drive/ePodium/Data/...</td>\n",
       "      <td>182_23</td>\n",
       "      <td>23</td>\n",
       "      <td>697.0</td>\n",
       "      <td>23.233333</td>\n",
       "      <td>1.936111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>412</td>\n",
       "      <td>/Volumes/Seagate Expansion Drive/ePodium/Data/...</td>\n",
       "      <td>412_29</td>\n",
       "      <td>29</td>\n",
       "      <td>873.0</td>\n",
       "      <td>29.100000</td>\n",
       "      <td>2.425000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1189 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    code                                           cnt_path cnt_file  \\\n",
       "0    146  /Volumes/Seagate Expansion Drive/ePodium/Data/...   146_29   \n",
       "0    156  /Volumes/Seagate Expansion Drive/ePodium/Data/...   156_29   \n",
       "0    713  /Volumes/Seagate Expansion Drive/ePodium/Data/...   713_29   \n",
       "0    411  /Volumes/Seagate Expansion Drive/ePodium/Data/...   411_41   \n",
       "0    703  /Volumes/Seagate Expansion Drive/ePodium/Data/...   703_29   \n",
       "..   ...                                                ...      ...   \n",
       "0    145  /Volumes/Seagate Expansion Drive/ePodium/Data/...   145_41   \n",
       "0    124  /Volumes/Seagate Expansion Drive/ePodium/Data/...   124_47   \n",
       "0    710  /Volumes/Seagate Expansion Drive/ePodium/Data/...   710_41   \n",
       "0    182  /Volumes/Seagate Expansion Drive/ePodium/Data/...   182_23   \n",
       "0    412  /Volumes/Seagate Expansion Drive/ePodium/Data/...   412_29   \n",
       "\n",
       "    age_group  age_days  age_months  age_years  \n",
       "0          29     860.0   28.666667   2.388889  \n",
       "0          29     870.0   29.000000   2.416667  \n",
       "0          29     868.0   28.933333   2.411111  \n",
       "0          41    1231.0   41.033333   3.419444  \n",
       "0          29     866.0   28.866667   2.405556  \n",
       "..        ...       ...         ...        ...  \n",
       "0          41    1232.0   41.066667   3.422222  \n",
       "0          47    1407.0   46.900000   3.908333  \n",
       "0          41    1234.0   41.133333   3.427778  \n",
       "0          23     697.0   23.233333   1.936111  \n",
       "0          29     873.0   29.100000   2.425000  \n",
       "\n",
       "[1189 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset_generator_reduced import DataGeneratorReduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import libraries\n",
    "# from tensorflow.keras.utils import Sequence\n",
    "# import numpy as np\n",
    "# import zarr\n",
    "# import os\n",
    "\n",
    "# class DataGeneratorReduced(Sequence):\n",
    "#     \"\"\"Generates data for loading (preprocessed) EEG timeseries data.\n",
    "#     Create batches for training or prediction from given folders and filenames.\n",
    "\n",
    "#     \"\"\"\n",
    "#     def __init__(self,\n",
    "#                  list_IDs,\n",
    "#                  BASE_PATH,\n",
    "#                  metadata,\n",
    "#                  gaussian_noise=0.0,\n",
    "#                  n_average = 3,\n",
    "#                  batch_size=10,\n",
    "#                  iter_per_epoch = 1,\n",
    "#                  n_timepoints = 501,\n",
    "#                  n_channels=30,\n",
    "#                  shuffle=True,\n",
    "#                  warnings=False):\n",
    "#         \"\"\"Initialization\n",
    "\n",
    "#         Args:\n",
    "#         --------\n",
    "#         list_IDs:\n",
    "#             list of all filename/label ids to use in the generator\n",
    "#         metadata:\n",
    "#             DataFrame containing all the metadata.\n",
    "#         n_average: int\n",
    "#             Number of EEG/time series epochs to average.\n",
    "#         batch_size:\n",
    "#             batch size at each iteration\n",
    "#         iter_per_epoch: int\n",
    "#             Number of iterations over all data points within one epoch.\n",
    "#         n_timepoints: int\n",
    "#             Timepoint dimension of data.\n",
    "#         n_channels:\n",
    "#             number of input channels\n",
    "#         shuffle:\n",
    "#             True to shuffle label indexes after every epoch\n",
    "#         \"\"\"\n",
    "#         self.list_IDs = list_IDs\n",
    "#         self.BASE_PATH = BASE_PATH\n",
    "#         self.metadata = metadata\n",
    "#         self.metadata_temp = None\n",
    "#         self.gaussian_noise = gaussian_noise\n",
    "#         self.n_average = n_average\n",
    "#         self.batch_size = batch_size\n",
    "#         self.iter_per_epoch = iter_per_epoch\n",
    "#         self.n_timepoints = n_timepoints\n",
    "#         self.n_channels = n_channels\n",
    "#         self.shuffle = shuffle\n",
    "#         self.warnings = warnings\n",
    "#         self.on_epoch_end()\n",
    "\n",
    "#         # Store all data in here\n",
    "#         self.X_data_all = []\n",
    "#         self.y_data_all = []\n",
    "#         self.load_all_data()\n",
    "\n",
    "\n",
    "#     def __len__(self):\n",
    "#         \"\"\"Denotes the number of batches per epoch\n",
    "\n",
    "#         return: number of batches per epoch\n",
    "#         \"\"\"\n",
    "#         return int(np.floor(len(self.metadata_temp) / self.batch_size))\n",
    "\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "#         \"\"\"Generate one batch of data\n",
    "\n",
    "#         Args:\n",
    "#         --------\n",
    "#         index: int\n",
    "#             index of the batch\n",
    "\n",
    "#         return: X and y when fitting. X only when predicting\n",
    "#         \"\"\"\n",
    "        \n",
    "#         # Generate indexes of the batch\n",
    "#         indexes = self.indexes[index * self.batch_size:((index + 1) * self.batch_size)]\n",
    "\n",
    "#         # Generate data\n",
    "#         X, y = self.generate_data(indexes)\n",
    "\n",
    "#         return X, y\n",
    "\n",
    "#     def load_all_data(self):\n",
    "#         \"\"\" Loads all data into memory. \"\"\"\n",
    "#         for i, metadata_file in self.metadata_temp.iterrows():\n",
    "#             filename = os.path.join(self.BASE_PATH, metadata_file['cnt_file'] + '.zarr')\n",
    "            \n",
    "#             X_data = np.zeros((0, self.n_channels, self.n_timepoints))\n",
    "\n",
    "#             data_signal = self.load_signal(filename)\n",
    "\n",
    "#             if (len(data_signal) == 0) and self.warnings:\n",
    "#                 print(f\"EMPTY SIGNAL, filename: {filename}\")\n",
    "\n",
    "#             X_data = np.concatenate((X_data, data_signal), axis=0)\n",
    "\n",
    "#             self.X_data_all.append(X_data)\n",
    "#             self.y_data_all.append(metadata_file['age_months'])\n",
    "        \n",
    "#     def on_epoch_end(self):\n",
    "#         \"\"\"Updates indexes after each epoch.\"\"\"\n",
    "\n",
    "#         # Create new metadata DataFrame with only the current subject IDs\n",
    "#         if self.metadata_temp is None:\n",
    "#             self.metadata_temp = self.metadata[self.metadata['code'].isin(self.list_IDs)].reset_index(drop=True)\n",
    "                               \n",
    "#         idx_base = np.arange(len(self.metadata_temp))\n",
    "#         idx_epoch = np.tile(idx_base, self.iter_per_epoch)\n",
    "\n",
    "#         self.indexes = idx_epoch\n",
    "\n",
    "#         if self.shuffle == True:\n",
    "#             np.random.shuffle(self.indexes)\n",
    "\n",
    "#     def generate_data(self, indexes):\n",
    "#         \"\"\"Generates data containing batch_size averaged time series.\n",
    "\n",
    "#         Args:\n",
    "#         -------\n",
    "#         list_IDs_temp: list\n",
    "#             list of label ids to load\n",
    "\n",
    "#         return: batch of averaged time series\n",
    "#         \"\"\"\n",
    "#         X_data = np.zeros((0, self.n_channels, self.n_timepoints))\n",
    "#         y_data = []\n",
    "\n",
    "#         for index in indexes:\n",
    "#             X = self.create_averaged_epoch(self.X_data_all[index])\n",
    "\n",
    "#             X_data = np.concatenate((X_data, X), axis=0)\n",
    "#             y_data.append(self.y_data_all[index])\n",
    "            \n",
    "#         return np.swapaxes(X_data,1,2), np.array(y_data).reshape((-1,1))\n",
    "    \n",
    "#     def create_averaged_epoch(self,\n",
    "#                               data_signal):\n",
    "#         \"\"\"\n",
    "#         Function to create averages of self.n_average epochs.\n",
    "#         Will create one averaged epoch per found unique label from self.n_average random epochs.\n",
    "\n",
    "#         Args:\n",
    "#         --------\n",
    "#         data_signal: numpy array\n",
    "#             Data from one person as numpy array\n",
    "#         \"\"\"\n",
    "                                               \n",
    "#         # Create new data collection:\n",
    "#         X_data = np.zeros((0, self.n_channels, self.n_timepoints))\n",
    "#         num_epochs = len(data_signal)\n",
    "                                               \n",
    "#         if num_epochs >= self.n_average:\n",
    "#             select = np.random.choice(num_epochs, self.n_average, replace=False)\n",
    "#             signal_averaged = np.mean(data_signal[select,:,:], axis=0)\n",
    "\n",
    "#         else:\n",
    "#             if self.warnings:\n",
    "#                 print(\"Found only\", num_epochs, \" epochs and will take those!\")          \n",
    "#             signal_averaged = np.mean(data_signal[:,:,:], axis=0)\n",
    "                                                                                              \n",
    "#         X_data = np.concatenate([X_data, np.expand_dims(signal_averaged, axis=0)], axis=0)\n",
    "                                    \n",
    "#         if self.gaussian_noise != 0.0:\n",
    "#             X_data += np.random.normal(0, self.gaussian_noise, X_data.shape)\n",
    "\n",
    "#         return X_data\n",
    "\n",
    "\n",
    "#     def load_signal(self,\n",
    "#                     filename):\n",
    "#         \"\"\"Load EEG signal from one person.\n",
    "\n",
    "#         Args:\n",
    "#         -------\n",
    "#         filename: str\n",
    "#             filename...\n",
    "\n",
    "#         return: loaded array\n",
    "#         \"\"\"\n",
    "#         return zarr.open(os.path.join(filename), mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.5 s, sys: 22 s, total: 44.5 s\n",
      "Wall time: 1min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# IDs_train = [152, 18, 11, 435, 617]\n",
    "# IDs_val = [180, 105, 19, 332]\n",
    "\n",
    "train_generator_noise = DataGeneratorReduced(list_IDs = IDs_train,\n",
    "                                             BASE_PATH = PATH_DATA_PROCESSED_DL_REDUCED,\n",
    "                                             metadata = df_metadata,\n",
    "                                             n_average = 3,\n",
    "                                             batch_size = 10,\n",
    "                                             gaussian_noise=0.01,\n",
    "                                             iter_per_epoch = 3,\n",
    "                                             n_timepoints = 501, \n",
    "                                             n_channels=30, \n",
    "                                             shuffle=True)\n",
    "\n",
    "val_generator = DataGeneratorReduced(list_IDs = IDs_val,\n",
    "                                     BASE_PATH = PATH_DATA_PROCESSED_DL_REDUCED,\n",
    "                                     metadata = df_metadata,\n",
    "                                     n_average = 3,\n",
    "                                     batch_size = 10,\n",
    "                                     n_timepoints = 501,\n",
    "                                     iter_per_epoch = 3,\n",
    "                                     n_channels=30,\n",
    "                                     shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 501, 30)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Input, Sequential\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM, Dropout, BatchNormalization, Dense, Conv1D, LeakyReLU, AveragePooling1D, Flatten, Reshape, MaxPooling1D\n",
    "from tensorflow.keras.optimizers import Adam, Adadelta, SGD\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError, MeanAbsoluteError\n",
    "import time\n",
    "\n",
    "n_timesteps = 501\n",
    "n_features = 30 \n",
    "n_outputs = 1\n",
    "\n",
    "input_shape = (n_timesteps, n_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing of different architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we will test multiple different architectures, most of them as discussed in \"Deep learning for time series classification: a review\", by Ismail Fawaz et al (2019). Most of them are inspired again on other papers. Refer to the Ismail Fawaz paper for the original papers.\n",
    "\n",
    "1. Fully-connected NN\n",
    "2. CNN\n",
    "3. ResNet\n",
    "4. Encoder\n",
    "5. Time-CNN\n",
    "\n",
    "Other architectures to test:\n",
    "\n",
    "6. BLSTM-LSTM \n",
    "7. InceptionTime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Fully connected NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fully_connected_model():\n",
    "    \"\"\" Returns the fully connected model from Ismail Fawaz et al. (2019). \"\"\"\n",
    "\n",
    "    input_layer = keras.layers.Input(input_shape)\n",
    "\n",
    "    input_layer_flattened = keras.layers.Flatten()(input_layer)\n",
    "\n",
    "    layer_1 = keras.layers.Dropout(0.1)(input_layer_flattened)\n",
    "    layer_1 = keras.layers.Dense(500, activation='relu')(layer_1)\n",
    "\n",
    "    layer_2 = keras.layers.Dropout(0.2)(layer_1)\n",
    "    layer_2 = keras.layers.Dense(500, activation='relu')(layer_2)\n",
    "\n",
    "    layer_3 = keras.layers.Dropout(0.2)(layer_2)\n",
    "    layer_3 = keras.layers.Dense(500, activation='relu')(layer_3)\n",
    "\n",
    "    output_layer = keras.layers.Dropout(0.3)(layer_3)\n",
    "    output_layer = keras.layers.Dense(1)(output_layer)\n",
    "\n",
    "    model = keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fully_connected_model()\n",
    "\n",
    "optimizer = Adadelta(learning_rate=0.01)    \n",
    "              \n",
    "model.compile(loss='mean_squared_error', \n",
    "              optimizer=optimizer, \n",
    "              metrics=[RootMeanSquaredError(), MeanAbsoluteError()])\n",
    "\n",
    "# 01 seems to be incorrect (makes too many predictions, changed model)\n",
    "# Fully_connected_regressor_01: MSE, Adadelta, N_average=30, 5000 epochs, ES=1000, RLR=200, gaussian=0.01\n",
    "# Fully_connected_regressor_02: MSE, Adadelta, N_average=30, 5000 epochs, ES=1000, RLR=200, gaussian=0.01\n",
    "output_filename = 'Fully_connected_regressor_03'\n",
    "output_file = os.path.join(PATH_MODELS, output_filename)\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath = output_file + \".hdf5\", monitor='val_loss', verbose=1, save_best_only=True)\n",
    "earlystopper = EarlyStopping(monitor='val_loss', patience=1000, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=200, min_lr=0.0001, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "83/83 [==============================] - 6s 68ms/step - loss: 868.5831 - root_mean_squared_error: 29.4656 - mean_absolute_error: 27.5962 - val_loss: 638.1409 - val_root_mean_squared_error: 25.2614 - val_mean_absolute_error: 23.1626\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 638.14087, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/Fully_connected_regressor_03.hdf5\n",
      "Epoch 2/5000\n",
      "83/83 [==============================] - 5s 55ms/step - loss: 505.3884 - root_mean_squared_error: 22.4179 - mean_absolute_error: 20.1228 - val_loss: 298.9310 - val_root_mean_squared_error: 17.2896 - val_mean_absolute_error: 14.1719\n",
      "\n",
      "Epoch 00002: val_loss improved from 638.14087 to 298.93100, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/Fully_connected_regressor_03.hdf5\n",
      "Epoch 3/5000\n",
      "83/83 [==============================] - 4s 47ms/step - loss: 272.8383 - root_mean_squared_error: 16.5092 - mean_absolute_error: 13.5751 - val_loss: 249.6371 - val_root_mean_squared_error: 15.7999 - val_mean_absolute_error: 12.6086\n",
      "\n",
      "Epoch 00003: val_loss improved from 298.93100 to 249.63713, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/Fully_connected_regressor_03.hdf5\n",
      "Epoch 4/5000\n",
      "13/83 [===>..........................] - ETA: 3s - loss: 183.4938 - root_mean_squared_error: 13.5264 - mean_absolute_error: 10.8085"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mne/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mne/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mne/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mne/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mne/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/anaconda3/envs/mne/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mne/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "epochs = 5000\n",
    "\n",
    "# fit network\n",
    "history = model.fit(x=train_generator_noise,\n",
    "                    validation_data=val_generator,\n",
    "                    epochs=epochs, \n",
    "                    callbacks=[checkpointer, earlystopper, reduce_lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model():\n",
    "    \"\"\" Returns the CNN (FCN) model from Ismail Fawaz et al. (2019). \"\"\"\n",
    "\n",
    "    input_layer = keras.layers.Input(input_shape)\n",
    "\n",
    "    conv1 = keras.layers.Conv1D(filters=128, kernel_size=8, padding='same')(input_layer)\n",
    "    conv1 = keras.layers.BatchNormalization()(conv1)\n",
    "    conv1 = keras.layers.Activation(activation='relu')(conv1)\n",
    "\n",
    "    conv2 = keras.layers.Conv1D(filters=256, kernel_size=5, padding='same')(conv1)\n",
    "    conv2 = keras.layers.BatchNormalization()(conv2)\n",
    "    conv2 = keras.layers.Activation('relu')(conv2)\n",
    "\n",
    "    conv3 = keras.layers.Conv1D(128, kernel_size=3, padding='same')(conv2)\n",
    "    conv3 = keras.layers.BatchNormalization()(conv3)\n",
    "    conv3 = keras.layers.Activation('relu')(conv3)\n",
    "\n",
    "    gap_layer = keras.layers.GlobalAveragePooling1D()(conv3)\n",
    "\n",
    "    output_layer = keras.layers.Dense(1)(gap_layer)\n",
    "\n",
    "    model = keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cnn_model()\n",
    "\n",
    "optimizer = Adam(learning_rate=0.01)    \n",
    "              \n",
    "model.compile(loss='mean_squared_error', \n",
    "              optimizer=optimizer, \n",
    "              metrics=[RootMeanSquaredError(), MeanAbsoluteError()])\n",
    "\n",
    "# CNN_regressor_01: MSE, Adam, N_average=30, 2000 epochs, ES=250, RLR=50, gaussian=0.01\n",
    "output_filename = 'CNN_regressor_03'\n",
    "output_file = os.path.join(PATH_MODELS, output_filename)\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath = output_file + \".hdf5\", monitor='val_loss', verbose=1, save_best_only=True)\n",
    "earlystopper = EarlyStopping(monitor='val_loss', patience=250, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=50, min_lr=0.0001, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "84/84 [==============================] - ETA: 0s - loss: nan - root_mean_squared_error: nan - mean_absolute_error: nan"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mne/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1129\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m                 steps_per_execution=self._steps_per_execution)\n\u001b[0;32m-> 1131\u001b[0;31m           val_logs = self.evaluate(\n\u001b[0m\u001b[1;32m   1132\u001b[0m               \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1133\u001b[0m               \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mne/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1387\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mne/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mne/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    860\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/anaconda3/envs/mne/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mne/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/anaconda3/envs/mne/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mne/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "epochs = 2000\n",
    "\n",
    "# fit network\n",
    "history = model.fit(x=train_generator_noise,\n",
    "                    validation_data=val_generator,\n",
    "                    epochs=epochs, \n",
    "                    callbacks=[checkpointer, earlystopper, reduce_lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_model():\n",
    "    \"\"\" Returns the ResNet model from Ismail Fawaz et al. (2019). \"\"\"\n",
    "    n_feature_maps = 64\n",
    "\n",
    "    input_layer = keras.layers.Input(input_shape)\n",
    "\n",
    "    # BLOCK 1\n",
    "\n",
    "    conv_x = keras.layers.Conv1D(filters=n_feature_maps, kernel_size=8, padding='same')(input_layer)\n",
    "    conv_x = keras.layers.BatchNormalization()(conv_x)\n",
    "    conv_x = keras.layers.Activation('relu')(conv_x)\n",
    "\n",
    "    conv_y = keras.layers.Conv1D(filters=n_feature_maps, kernel_size=5, padding='same')(conv_x)\n",
    "    conv_y = keras.layers.BatchNormalization()(conv_y)\n",
    "    conv_y = keras.layers.Activation('relu')(conv_y)\n",
    "\n",
    "    conv_z = keras.layers.Conv1D(filters=n_feature_maps, kernel_size=3, padding='same')(conv_y)\n",
    "    conv_z = keras.layers.BatchNormalization()(conv_z)\n",
    "\n",
    "    # expand channels for the sum\n",
    "    shortcut_y = keras.layers.Conv1D(filters=n_feature_maps, kernel_size=1, padding='same')(input_layer)\n",
    "    shortcut_y = keras.layers.BatchNormalization()(shortcut_y)\n",
    "\n",
    "    output_block_1 = keras.layers.add([shortcut_y, conv_z])\n",
    "    output_block_1 = keras.layers.Activation('relu')(output_block_1)\n",
    "\n",
    "    # BLOCK 2\n",
    "\n",
    "    conv_x = keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=8, padding='same')(output_block_1)\n",
    "    conv_x = keras.layers.BatchNormalization()(conv_x)\n",
    "    conv_x = keras.layers.Activation('relu')(conv_x)\n",
    "\n",
    "    conv_y = keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=5, padding='same')(conv_x)\n",
    "    conv_y = keras.layers.BatchNormalization()(conv_y)\n",
    "    conv_y = keras.layers.Activation('relu')(conv_y)\n",
    "\n",
    "    conv_z = keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=3, padding='same')(conv_y)\n",
    "    conv_z = keras.layers.BatchNormalization()(conv_z)\n",
    "\n",
    "    # expand channels for the sum\n",
    "    shortcut_y = keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=1, padding='same')(output_block_1)\n",
    "    shortcut_y = keras.layers.BatchNormalization()(shortcut_y)\n",
    "\n",
    "    output_block_2 = keras.layers.add([shortcut_y, conv_z])\n",
    "    output_block_2 = keras.layers.Activation('relu')(output_block_2)\n",
    "\n",
    "    # BLOCK 3\n",
    "\n",
    "    conv_x = keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=8, padding='same')(output_block_2)\n",
    "    conv_x = keras.layers.BatchNormalization()(conv_x)\n",
    "    conv_x = keras.layers.Activation('relu')(conv_x)\n",
    "\n",
    "    conv_y = keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=5, padding='same')(conv_x)\n",
    "    conv_y = keras.layers.BatchNormalization()(conv_y)\n",
    "    conv_y = keras.layers.Activation('relu')(conv_y)\n",
    "\n",
    "    conv_z = keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=3, padding='same')(conv_y)\n",
    "    conv_z = keras.layers.BatchNormalization()(conv_z)\n",
    "\n",
    "    # no need to expand channels because they are equal\n",
    "    shortcut_y = keras.layers.BatchNormalization()(output_block_2)\n",
    "\n",
    "    output_block_3 = keras.layers.add([shortcut_y, conv_z])\n",
    "    output_block_3 = keras.layers.Activation('relu')(output_block_3)\n",
    "\n",
    "    # FINAL\n",
    "\n",
    "    gap_layer = keras.layers.GlobalAveragePooling1D()(output_block_3)\n",
    "\n",
    "    output_layer = keras.layers.Dense(1)(gap_layer)\n",
    "\n",
    "    model = keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet_model()\n",
    "\n",
    "optimizer = Adam(learning_rate=0.01)    \n",
    "              \n",
    "model.compile(loss='mean_squared_error', \n",
    "              optimizer=optimizer, \n",
    "              metrics=[RootMeanSquaredError(), MeanAbsoluteError()])\n",
    "\n",
    "# ResNet_regressor_01: MSE, Adam, N_average=30, 1500 epochs, ES=250, RLR=50, gaussian=0.01\n",
    "output_filename = 'ResNet_regressor_02'\n",
    "output_file = os.path.join(PATH_MODELS, output_filename)\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath = output_file + \".hdf5\", monitor='val_loss', verbose=1, save_best_only=True)\n",
    "earlystopper = EarlyStopping(monitor='val_loss', patience=250, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=50, min_lr=0.0001, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "143/143 [==============================] - 95s 646ms/step - loss: 189.6503 - root_mean_squared_error: 13.4258 - mean_absolute_error: 11.0235 - val_loss: 1908.8988 - val_root_mean_squared_error: 43.6909 - val_mean_absolute_error: 35.3563\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1908.89880, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/ResNet_regressor_01.hdf5\n",
      "Epoch 2/1500\n",
      "143/143 [==============================] - 89s 619ms/step - loss: 109.5164 - root_mean_squared_error: 10.4630 - mean_absolute_error: 8.7816 - val_loss: 142.7589 - val_root_mean_squared_error: 11.9482 - val_mean_absolute_error: 9.5680\n",
      "\n",
      "Epoch 00002: val_loss improved from 1908.89880 to 142.75887, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/ResNet_regressor_01.hdf5\n",
      "Epoch 3/1500\n",
      "143/143 [==============================] - 90s 630ms/step - loss: 104.9589 - root_mean_squared_error: 10.2428 - mean_absolute_error: 8.6765 - val_loss: 228.4236 - val_root_mean_squared_error: 15.1137 - val_mean_absolute_error: 12.9282\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 142.75887\n",
      "Epoch 4/1500\n",
      "143/143 [==============================] - 91s 636ms/step - loss: 95.8011 - root_mean_squared_error: 9.7849 - mean_absolute_error: 8.1211 - val_loss: 272.4052 - val_root_mean_squared_error: 16.5047 - val_mean_absolute_error: 14.2625\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 142.75887\n",
      "Epoch 5/1500\n",
      "143/143 [==============================] - 92s 642ms/step - loss: 91.6355 - root_mean_squared_error: 9.5710 - mean_absolute_error: 7.8031 - val_loss: 241.3839 - val_root_mean_squared_error: 15.5365 - val_mean_absolute_error: 13.0222\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 142.75887\n",
      "Epoch 6/1500\n",
      "143/143 [==============================] - 89s 622ms/step - loss: 86.8286 - root_mean_squared_error: 9.3154 - mean_absolute_error: 7.7598 - val_loss: 126.3296 - val_root_mean_squared_error: 11.2396 - val_mean_absolute_error: 9.3906\n",
      "\n",
      "Epoch 00006: val_loss improved from 142.75887 to 126.32958, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/ResNet_regressor_01.hdf5\n",
      "Epoch 7/1500\n",
      "143/143 [==============================] - 90s 626ms/step - loss: 80.0882 - root_mean_squared_error: 8.9473 - mean_absolute_error: 7.2957 - val_loss: 89.9653 - val_root_mean_squared_error: 9.4850 - val_mean_absolute_error: 7.8484\n",
      "\n",
      "Epoch 00007: val_loss improved from 126.32958 to 89.96535, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/ResNet_regressor_01.hdf5\n",
      "Epoch 8/1500\n",
      "143/143 [==============================] - 91s 638ms/step - loss: 90.1785 - root_mean_squared_error: 9.4806 - mean_absolute_error: 7.7877 - val_loss: 78.7158 - val_root_mean_squared_error: 8.8722 - val_mean_absolute_error: 7.3058\n",
      "\n",
      "Epoch 00008: val_loss improved from 89.96535 to 78.71581, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/ResNet_regressor_01.hdf5\n",
      "Epoch 9/1500\n",
      "143/143 [==============================] - 92s 645ms/step - loss: 79.6564 - root_mean_squared_error: 8.9225 - mean_absolute_error: 7.4064 - val_loss: 79.7196 - val_root_mean_squared_error: 8.9286 - val_mean_absolute_error: 7.1766\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 78.71581\n",
      "Epoch 10/1500\n",
      "143/143 [==============================] - 105s 736ms/step - loss: 86.4660 - root_mean_squared_error: 9.2920 - mean_absolute_error: 7.6199 - val_loss: 88.8053 - val_root_mean_squared_error: 9.4237 - val_mean_absolute_error: 7.4797\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 78.71581\n",
      "Epoch 11/1500\n",
      "143/143 [==============================] - 105s 732ms/step - loss: 83.9275 - root_mean_squared_error: 9.1596 - mean_absolute_error: 7.6586 - val_loss: 83.2743 - val_root_mean_squared_error: 9.1255 - val_mean_absolute_error: 7.5565\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 78.71581\n",
      "Epoch 12/1500\n",
      "143/143 [==============================] - 106s 742ms/step - loss: 77.2123 - root_mean_squared_error: 8.7848 - mean_absolute_error: 7.2019 - val_loss: 77.3329 - val_root_mean_squared_error: 8.7939 - val_mean_absolute_error: 7.2557\n",
      "\n",
      "Epoch 00012: val_loss improved from 78.71581 to 77.33290, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/ResNet_regressor_01.hdf5\n",
      "Epoch 13/1500\n",
      "143/143 [==============================] - 110s 771ms/step - loss: 81.2060 - root_mean_squared_error: 9.0076 - mean_absolute_error: 7.4402 - val_loss: 113.4069 - val_root_mean_squared_error: 10.6493 - val_mean_absolute_error: 9.0016\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 77.33290\n",
      "Epoch 14/1500\n",
      "143/143 [==============================] - 114s 795ms/step - loss: 71.6700 - root_mean_squared_error: 8.4645 - mean_absolute_error: 6.9752 - val_loss: 81.5897 - val_root_mean_squared_error: 9.0327 - val_mean_absolute_error: 7.4944\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 77.33290\n",
      "Epoch 15/1500\n",
      "143/143 [==============================] - 106s 742ms/step - loss: 68.9629 - root_mean_squared_error: 8.2892 - mean_absolute_error: 6.8038 - val_loss: 80.9801 - val_root_mean_squared_error: 8.9989 - val_mean_absolute_error: 7.4730\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 77.33290\n",
      "Epoch 16/1500\n",
      "143/143 [==============================] - 111s 774ms/step - loss: 71.9417 - root_mean_squared_error: 8.4713 - mean_absolute_error: 6.9657 - val_loss: 92.6945 - val_root_mean_squared_error: 9.6278 - val_mean_absolute_error: 7.6826\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 77.33290\n",
      "Epoch 17/1500\n",
      "143/143 [==============================] - 99s 691ms/step - loss: 71.9811 - root_mean_squared_error: 8.4760 - mean_absolute_error: 6.9940 - val_loss: 72.3637 - val_root_mean_squared_error: 8.5067 - val_mean_absolute_error: 6.7794\n",
      "\n",
      "Epoch 00017: val_loss improved from 77.33290 to 72.36372, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/ResNet_regressor_01.hdf5\n",
      "Epoch 18/1500\n",
      "143/143 [==============================] - 99s 692ms/step - loss: 68.4494 - root_mean_squared_error: 8.2717 - mean_absolute_error: 6.7179 - val_loss: 70.3735 - val_root_mean_squared_error: 8.3889 - val_mean_absolute_error: 6.9978\n",
      "\n",
      "Epoch 00018: val_loss improved from 72.36372 to 70.37347, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/ResNet_regressor_01.hdf5\n",
      "Epoch 19/1500\n",
      "143/143 [==============================] - 98s 686ms/step - loss: 72.0947 - root_mean_squared_error: 8.4884 - mean_absolute_error: 6.9949 - val_loss: 76.5319 - val_root_mean_squared_error: 8.7483 - val_mean_absolute_error: 7.2481\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 70.37347\n",
      "Epoch 20/1500\n",
      "143/143 [==============================] - 90s 630ms/step - loss: 77.1732 - root_mean_squared_error: 8.7809 - mean_absolute_error: 7.2781 - val_loss: 75.1429 - val_root_mean_squared_error: 8.6685 - val_mean_absolute_error: 7.3116\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 70.37347\n",
      "Epoch 21/1500\n",
      "143/143 [==============================] - 106s 741ms/step - loss: 74.0540 - root_mean_squared_error: 8.6037 - mean_absolute_error: 7.0492 - val_loss: 85.7402 - val_root_mean_squared_error: 9.2596 - val_mean_absolute_error: 7.8605\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 70.37347\n",
      "Epoch 22/1500\n",
      "143/143 [==============================] - 107s 750ms/step - loss: 70.4943 - root_mean_squared_error: 8.3921 - mean_absolute_error: 6.7825 - val_loss: 101.5608 - val_root_mean_squared_error: 10.0777 - val_mean_absolute_error: 7.7259\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 70.37347\n",
      "Epoch 23/1500\n",
      "143/143 [==============================] - 112s 787ms/step - loss: 78.1200 - root_mean_squared_error: 8.8360 - mean_absolute_error: 7.3000 - val_loss: 75.4041 - val_root_mean_squared_error: 8.6836 - val_mean_absolute_error: 7.1064\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 70.37347\n",
      "Epoch 24/1500\n",
      "143/143 [==============================] - 102s 710ms/step - loss: 71.3385 - root_mean_squared_error: 8.4325 - mean_absolute_error: 6.9428 - val_loss: 82.3248 - val_root_mean_squared_error: 9.0733 - val_mean_absolute_error: 7.5593\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 70.37347\n",
      "Epoch 25/1500\n",
      "143/143 [==============================] - 107s 746ms/step - loss: 72.0813 - root_mean_squared_error: 8.4859 - mean_absolute_error: 6.9389 - val_loss: 83.5116 - val_root_mean_squared_error: 9.1385 - val_mean_absolute_error: 7.0916\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 70.37347\n",
      "Epoch 26/1500\n",
      "143/143 [==============================] - 92s 644ms/step - loss: 74.2156 - root_mean_squared_error: 8.6119 - mean_absolute_error: 7.0195 - val_loss: 72.3177 - val_root_mean_squared_error: 8.5040 - val_mean_absolute_error: 6.9120\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 70.37347\n",
      "Epoch 27/1500\n",
      "143/143 [==============================] - 90s 633ms/step - loss: 71.1526 - root_mean_squared_error: 8.4274 - mean_absolute_error: 6.9941 - val_loss: 72.8520 - val_root_mean_squared_error: 8.5353 - val_mean_absolute_error: 6.8288\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 70.37347\n",
      "Epoch 28/1500\n",
      "143/143 [==============================] - 91s 638ms/step - loss: 69.1653 - root_mean_squared_error: 8.3122 - mean_absolute_error: 6.8269 - val_loss: 85.1062 - val_root_mean_squared_error: 9.2253 - val_mean_absolute_error: 7.7128\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 70.37347\n",
      "Epoch 29/1500\n",
      "143/143 [==============================] - 91s 632ms/step - loss: 70.5513 - root_mean_squared_error: 8.3962 - mean_absolute_error: 6.8115 - val_loss: 76.5549 - val_root_mean_squared_error: 8.7496 - val_mean_absolute_error: 6.9410\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 70.37347\n",
      "Epoch 30/1500\n",
      "143/143 [==============================] - 92s 642ms/step - loss: 68.4690 - root_mean_squared_error: 8.2715 - mean_absolute_error: 6.6722 - val_loss: 74.4097 - val_root_mean_squared_error: 8.6261 - val_mean_absolute_error: 7.0838\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 70.37347\n",
      "Epoch 31/1500\n",
      "143/143 [==============================] - 88s 616ms/step - loss: 65.0973 - root_mean_squared_error: 8.0661 - mean_absolute_error: 6.7196 - val_loss: 77.8043 - val_root_mean_squared_error: 8.8207 - val_mean_absolute_error: 7.2696\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 70.37347\n",
      "Epoch 32/1500\n",
      "143/143 [==============================] - 91s 635ms/step - loss: 67.5973 - root_mean_squared_error: 8.2147 - mean_absolute_error: 6.7475 - val_loss: 79.2735 - val_root_mean_squared_error: 8.9036 - val_mean_absolute_error: 7.3533\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 70.37347\n",
      "Epoch 33/1500\n",
      "143/143 [==============================] - 92s 644ms/step - loss: 68.1532 - root_mean_squared_error: 8.2549 - mean_absolute_error: 6.7795 - val_loss: 77.8617 - val_root_mean_squared_error: 8.8239 - val_mean_absolute_error: 7.2443\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 70.37347\n",
      "Epoch 34/1500\n",
      "143/143 [==============================] - 90s 632ms/step - loss: 72.9266 - root_mean_squared_error: 8.5356 - mean_absolute_error: 7.0710 - val_loss: 76.7343 - val_root_mean_squared_error: 8.7598 - val_mean_absolute_error: 7.0923\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 70.37347\n",
      "Epoch 35/1500\n",
      "143/143 [==============================] - 90s 631ms/step - loss: 69.5488 - root_mean_squared_error: 8.3381 - mean_absolute_error: 6.8532 - val_loss: 82.7001 - val_root_mean_squared_error: 9.0940 - val_mean_absolute_error: 7.5884\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 70.37347\n",
      "Epoch 36/1500\n",
      "143/143 [==============================] - 89s 621ms/step - loss: 74.3179 - root_mean_squared_error: 8.6170 - mean_absolute_error: 7.0566 - val_loss: 67.8561 - val_root_mean_squared_error: 8.2375 - val_mean_absolute_error: 6.6302\n",
      "\n",
      "Epoch 00036: val_loss improved from 70.37347 to 67.85609, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/ResNet_regressor_01.hdf5\n",
      "Epoch 37/1500\n",
      "143/143 [==============================] - 92s 640ms/step - loss: 71.3332 - root_mean_squared_error: 8.4441 - mean_absolute_error: 6.9686 - val_loss: 108.9224 - val_root_mean_squared_error: 10.4366 - val_mean_absolute_error: 8.3211\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 67.85609\n",
      "Epoch 38/1500\n",
      "143/143 [==============================] - 89s 621ms/step - loss: 70.2082 - root_mean_squared_error: 8.3764 - mean_absolute_error: 6.8896 - val_loss: 84.1218 - val_root_mean_squared_error: 9.1718 - val_mean_absolute_error: 7.1769\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 67.85609\n",
      "Epoch 39/1500\n",
      "143/143 [==============================] - 89s 619ms/step - loss: 66.9194 - root_mean_squared_error: 8.1753 - mean_absolute_error: 6.7015 - val_loss: 72.2793 - val_root_mean_squared_error: 8.5017 - val_mean_absolute_error: 6.8805\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 67.85609\n",
      "Epoch 40/1500\n",
      "143/143 [==============================] - 88s 617ms/step - loss: 64.9632 - root_mean_squared_error: 8.0546 - mean_absolute_error: 6.6104 - val_loss: 66.2614 - val_root_mean_squared_error: 8.1401 - val_mean_absolute_error: 6.6867\n",
      "\n",
      "Epoch 00040: val_loss improved from 67.85609 to 66.26140, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/ResNet_regressor_01.hdf5\n",
      "Epoch 41/1500\n",
      "143/143 [==============================] - 91s 635ms/step - loss: 69.0539 - root_mean_squared_error: 8.3072 - mean_absolute_error: 6.9215 - val_loss: 74.7959 - val_root_mean_squared_error: 8.6485 - val_mean_absolute_error: 7.2636\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 66.26140\n",
      "Epoch 42/1500\n",
      "143/143 [==============================] - 88s 612ms/step - loss: 66.4410 - root_mean_squared_error: 8.1500 - mean_absolute_error: 6.7207 - val_loss: 163.3766 - val_root_mean_squared_error: 12.7819 - val_mean_absolute_error: 10.6524\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 66.26140\n",
      "Epoch 43/1500\n",
      "143/143 [==============================] - 87s 611ms/step - loss: 66.3014 - root_mean_squared_error: 8.1367 - mean_absolute_error: 6.7232 - val_loss: 63.9243 - val_root_mean_squared_error: 7.9953 - val_mean_absolute_error: 6.4128\n",
      "\n",
      "Epoch 00043: val_loss improved from 66.26140 to 63.92428, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/ResNet_regressor_01.hdf5\n",
      "Epoch 44/1500\n",
      "143/143 [==============================] - 88s 614ms/step - loss: 62.6011 - root_mean_squared_error: 7.9104 - mean_absolute_error: 6.5342 - val_loss: 91.8094 - val_root_mean_squared_error: 9.5817 - val_mean_absolute_error: 7.2893\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 63.92428\n",
      "Epoch 45/1500\n",
      "143/143 [==============================] - 91s 635ms/step - loss: 66.0208 - root_mean_squared_error: 8.1245 - mean_absolute_error: 6.6349 - val_loss: 73.6395 - val_root_mean_squared_error: 8.5813 - val_mean_absolute_error: 6.8897\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 63.92428\n",
      "Epoch 46/1500\n",
      "143/143 [==============================] - 92s 641ms/step - loss: 65.8439 - root_mean_squared_error: 8.1125 - mean_absolute_error: 6.6356 - val_loss: 67.7396 - val_root_mean_squared_error: 8.2304 - val_mean_absolute_error: 6.9133\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 63.92428\n",
      "Epoch 47/1500\n",
      "143/143 [==============================] - 91s 635ms/step - loss: 64.4962 - root_mean_squared_error: 8.0281 - mean_absolute_error: 6.6546 - val_loss: 82.6598 - val_root_mean_squared_error: 9.0917 - val_mean_absolute_error: 6.9917\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 63.92428\n",
      "Epoch 48/1500\n",
      "143/143 [==============================] - 91s 634ms/step - loss: 63.2066 - root_mean_squared_error: 7.9450 - mean_absolute_error: 6.4814 - val_loss: 65.6836 - val_root_mean_squared_error: 8.1045 - val_mean_absolute_error: 6.6772\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 63.92428\n",
      "Epoch 49/1500\n",
      "143/143 [==============================] - 92s 641ms/step - loss: 64.0040 - root_mean_squared_error: 7.9942 - mean_absolute_error: 6.4138 - val_loss: 67.4757 - val_root_mean_squared_error: 8.2144 - val_mean_absolute_error: 6.7633\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 63.92428\n",
      "Epoch 50/1500\n",
      "143/143 [==============================] - 92s 641ms/step - loss: 63.2552 - root_mean_squared_error: 7.9489 - mean_absolute_error: 6.4070 - val_loss: 71.4500 - val_root_mean_squared_error: 8.4528 - val_mean_absolute_error: 6.5624\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 63.92428\n",
      "Epoch 51/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 91s 635ms/step - loss: 62.4524 - root_mean_squared_error: 7.8951 - mean_absolute_error: 6.3252 - val_loss: 68.3334 - val_root_mean_squared_error: 8.2664 - val_mean_absolute_error: 6.7822\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 63.92428\n",
      "Epoch 52/1500\n",
      "143/143 [==============================] - 91s 635ms/step - loss: 68.8643 - root_mean_squared_error: 8.2923 - mean_absolute_error: 6.8354 - val_loss: 74.9792 - val_root_mean_squared_error: 8.6591 - val_mean_absolute_error: 6.7676\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 63.92428\n",
      "Epoch 53/1500\n",
      "143/143 [==============================] - 90s 631ms/step - loss: 65.4128 - root_mean_squared_error: 8.0848 - mean_absolute_error: 6.5465 - val_loss: 70.1540 - val_root_mean_squared_error: 8.3758 - val_mean_absolute_error: 6.7421\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 63.92428\n",
      "Epoch 54/1500\n",
      "143/143 [==============================] - 92s 640ms/step - loss: 62.5797 - root_mean_squared_error: 7.9066 - mean_absolute_error: 6.3008 - val_loss: 76.8420 - val_root_mean_squared_error: 8.7660 - val_mean_absolute_error: 7.3147\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 63.92428\n",
      "Epoch 55/1500\n",
      "143/143 [==============================] - 91s 636ms/step - loss: 60.6346 - root_mean_squared_error: 7.7858 - mean_absolute_error: 6.3735 - val_loss: 68.7157 - val_root_mean_squared_error: 8.2895 - val_mean_absolute_error: 6.6371\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 63.92428\n",
      "Epoch 56/1500\n",
      "143/143 [==============================] - 90s 630ms/step - loss: 67.2820 - root_mean_squared_error: 8.2003 - mean_absolute_error: 6.6464 - val_loss: 70.3743 - val_root_mean_squared_error: 8.3889 - val_mean_absolute_error: 6.6665\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 63.92428\n",
      "Epoch 57/1500\n",
      "143/143 [==============================] - 91s 636ms/step - loss: 63.5928 - root_mean_squared_error: 7.9719 - mean_absolute_error: 6.5254 - val_loss: 69.1159 - val_root_mean_squared_error: 8.3136 - val_mean_absolute_error: 6.5540\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 63.92428\n",
      "Epoch 58/1500\n",
      "143/143 [==============================] - 89s 625ms/step - loss: 60.0767 - root_mean_squared_error: 7.7446 - mean_absolute_error: 6.2522 - val_loss: 70.3177 - val_root_mean_squared_error: 8.3856 - val_mean_absolute_error: 6.7573\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 63.92428\n",
      "Epoch 59/1500\n",
      "143/143 [==============================] - 90s 632ms/step - loss: 72.7318 - root_mean_squared_error: 8.5039 - mean_absolute_error: 6.7977 - val_loss: 74.4622 - val_root_mean_squared_error: 8.6291 - val_mean_absolute_error: 7.1643\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 63.92428\n",
      "Epoch 60/1500\n",
      "143/143 [==============================] - 91s 633ms/step - loss: 69.1721 - root_mean_squared_error: 8.3136 - mean_absolute_error: 6.7806 - val_loss: 67.9090 - val_root_mean_squared_error: 8.2407 - val_mean_absolute_error: 6.7154\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 63.92428\n",
      "Epoch 61/1500\n",
      "143/143 [==============================] - 91s 634ms/step - loss: 67.4517 - root_mean_squared_error: 8.2116 - mean_absolute_error: 6.7212 - val_loss: 85.9310 - val_root_mean_squared_error: 9.2699 - val_mean_absolute_error: 7.0246\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 63.92428\n",
      "Epoch 62/1500\n",
      "143/143 [==============================] - 91s 638ms/step - loss: 64.7820 - root_mean_squared_error: 8.0472 - mean_absolute_error: 6.6206 - val_loss: 75.9668 - val_root_mean_squared_error: 8.7159 - val_mean_absolute_error: 6.7431\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 63.92428\n",
      "Epoch 63/1500\n",
      "143/143 [==============================] - 90s 632ms/step - loss: 64.0022 - root_mean_squared_error: 7.9970 - mean_absolute_error: 6.4433 - val_loss: 117.3764 - val_root_mean_squared_error: 10.8340 - val_mean_absolute_error: 8.9804\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 63.92428\n",
      "Epoch 64/1500\n",
      "143/143 [==============================] - 89s 625ms/step - loss: 64.3868 - root_mean_squared_error: 8.0209 - mean_absolute_error: 6.5160 - val_loss: 90.2703 - val_root_mean_squared_error: 9.5011 - val_mean_absolute_error: 7.6342\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 63.92428\n",
      "Epoch 65/1500\n",
      "143/143 [==============================] - 90s 631ms/step - loss: 63.2645 - root_mean_squared_error: 7.9513 - mean_absolute_error: 6.3222 - val_loss: 87.0612 - val_root_mean_squared_error: 9.3307 - val_mean_absolute_error: 6.8971\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 63.92428\n",
      "Epoch 66/1500\n",
      "143/143 [==============================] - 90s 627ms/step - loss: 67.0222 - root_mean_squared_error: 8.1753 - mean_absolute_error: 6.7276 - val_loss: 90.4227 - val_root_mean_squared_error: 9.5091 - val_mean_absolute_error: 7.5970\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 63.92428\n",
      "Epoch 67/1500\n",
      "143/143 [==============================] - 89s 622ms/step - loss: 65.4084 - root_mean_squared_error: 8.0832 - mean_absolute_error: 6.6359 - val_loss: 63.9135 - val_root_mean_squared_error: 7.9946 - val_mean_absolute_error: 6.4659\n",
      "\n",
      "Epoch 00067: val_loss improved from 63.92428 to 63.91346, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/ResNet_regressor_01.hdf5\n",
      "Epoch 68/1500\n",
      "143/143 [==============================] - 90s 627ms/step - loss: 62.6322 - root_mean_squared_error: 7.9104 - mean_absolute_error: 6.4122 - val_loss: 62.2188 - val_root_mean_squared_error: 7.8879 - val_mean_absolute_error: 6.5380\n",
      "\n",
      "Epoch 00068: val_loss improved from 63.91346 to 62.21881, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/ResNet_regressor_01.hdf5\n",
      "Epoch 69/1500\n",
      "143/143 [==============================] - 87s 606ms/step - loss: 60.3935 - root_mean_squared_error: 7.7694 - mean_absolute_error: 6.3645 - val_loss: 69.1774 - val_root_mean_squared_error: 8.3173 - val_mean_absolute_error: 6.6165\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 62.21881\n",
      "Epoch 70/1500\n",
      "143/143 [==============================] - 87s 612ms/step - loss: 64.0904 - root_mean_squared_error: 8.0035 - mean_absolute_error: 6.4921 - val_loss: 70.8910 - val_root_mean_squared_error: 8.4197 - val_mean_absolute_error: 6.9028\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 62.21881\n",
      "Epoch 71/1500\n",
      "143/143 [==============================] - 89s 620ms/step - loss: 65.8544 - root_mean_squared_error: 8.1114 - mean_absolute_error: 6.5727 - val_loss: 100.4449 - val_root_mean_squared_error: 10.0222 - val_mean_absolute_error: 7.7882\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 62.21881\n",
      "Epoch 72/1500\n",
      "143/143 [==============================] - 88s 612ms/step - loss: 62.9381 - root_mean_squared_error: 7.9283 - mean_absolute_error: 6.3934 - val_loss: 63.8464 - val_root_mean_squared_error: 7.9904 - val_mean_absolute_error: 6.5739\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 62.21881\n",
      "Epoch 73/1500\n",
      "143/143 [==============================] - 87s 610ms/step - loss: 64.7716 - root_mean_squared_error: 8.0437 - mean_absolute_error: 6.4474 - val_loss: 65.0178 - val_root_mean_squared_error: 8.0634 - val_mean_absolute_error: 6.6521\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 62.21881\n",
      "Epoch 74/1500\n",
      "143/143 [==============================] - 88s 619ms/step - loss: 66.6263 - root_mean_squared_error: 8.1578 - mean_absolute_error: 6.5728 - val_loss: 57.2691 - val_root_mean_squared_error: 7.5676 - val_mean_absolute_error: 6.2060\n",
      "\n",
      "Epoch 00074: val_loss improved from 62.21881 to 57.26908, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/ResNet_regressor_01.hdf5\n",
      "Epoch 75/1500\n",
      "143/143 [==============================] - 92s 642ms/step - loss: 59.9275 - root_mean_squared_error: 7.7405 - mean_absolute_error: 6.3817 - val_loss: 86.3821 - val_root_mean_squared_error: 9.2942 - val_mean_absolute_error: 7.6217\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 57.26908\n",
      "Epoch 76/1500\n",
      "143/143 [==============================] - 92s 640ms/step - loss: 61.4379 - root_mean_squared_error: 7.8329 - mean_absolute_error: 6.3628 - val_loss: 83.8188 - val_root_mean_squared_error: 9.1553 - val_mean_absolute_error: 7.5363\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 57.26908\n",
      "Epoch 77/1500\n",
      "143/143 [==============================] - 90s 633ms/step - loss: 63.2216 - root_mean_squared_error: 7.9491 - mean_absolute_error: 6.5619 - val_loss: 102.8337 - val_root_mean_squared_error: 10.1407 - val_mean_absolute_error: 8.4312\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 57.26908\n",
      "Epoch 78/1500\n",
      "143/143 [==============================] - 90s 626ms/step - loss: 63.1861 - root_mean_squared_error: 7.9428 - mean_absolute_error: 6.4335 - val_loss: 106.8368 - val_root_mean_squared_error: 10.3362 - val_mean_absolute_error: 7.8874\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 57.26908\n",
      "Epoch 79/1500\n",
      "143/143 [==============================] - 89s 621ms/step - loss: 60.7315 - root_mean_squared_error: 7.7907 - mean_absolute_error: 6.3348 - val_loss: 70.4691 - val_root_mean_squared_error: 8.3946 - val_mean_absolute_error: 6.8243\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 57.26908\n",
      "Epoch 80/1500\n",
      "143/143 [==============================] - 91s 634ms/step - loss: 60.3137 - root_mean_squared_error: 7.7631 - mean_absolute_error: 6.3685 - val_loss: 75.9543 - val_root_mean_squared_error: 8.7152 - val_mean_absolute_error: 7.0971\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 57.26908\n",
      "Epoch 81/1500\n",
      "143/143 [==============================] - 90s 632ms/step - loss: 68.6142 - root_mean_squared_error: 8.2816 - mean_absolute_error: 6.6575 - val_loss: 78.2994 - val_root_mean_squared_error: 8.8487 - val_mean_absolute_error: 7.2855\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 57.26908\n",
      "Epoch 82/1500\n",
      "143/143 [==============================] - 90s 627ms/step - loss: 67.3451 - root_mean_squared_error: 8.2052 - mean_absolute_error: 6.7432 - val_loss: 78.1672 - val_root_mean_squared_error: 8.8412 - val_mean_absolute_error: 6.8718\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 57.26908\n",
      "Epoch 83/1500\n",
      "143/143 [==============================] - 95s 664ms/step - loss: 63.4678 - root_mean_squared_error: 7.9647 - mean_absolute_error: 6.4562 - val_loss: 77.1339 - val_root_mean_squared_error: 8.7826 - val_mean_absolute_error: 7.3361\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 57.26908\n",
      "Epoch 84/1500\n",
      "143/143 [==============================] - 93s 648ms/step - loss: 58.8134 - root_mean_squared_error: 7.6634 - mean_absolute_error: 6.2269 - val_loss: 69.7153 - val_root_mean_squared_error: 8.3496 - val_mean_absolute_error: 6.8325\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 57.26908\n",
      "Epoch 85/1500\n",
      "143/143 [==============================] - 91s 634ms/step - loss: 60.0538 - root_mean_squared_error: 7.7475 - mean_absolute_error: 6.1785 - val_loss: 69.8659 - val_root_mean_squared_error: 8.3586 - val_mean_absolute_error: 6.6058\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 57.26908\n",
      "Epoch 86/1500\n",
      "143/143 [==============================] - 89s 622ms/step - loss: 65.5872 - root_mean_squared_error: 8.0939 - mean_absolute_error: 6.5301 - val_loss: 68.1769 - val_root_mean_squared_error: 8.2569 - val_mean_absolute_error: 6.6061\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 57.26908\n",
      "Epoch 87/1500\n",
      "143/143 [==============================] - 87s 612ms/step - loss: 65.3779 - root_mean_squared_error: 8.0829 - mean_absolute_error: 6.6660 - val_loss: 71.7152 - val_root_mean_squared_error: 8.4685 - val_mean_absolute_error: 6.8663\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 57.26908\n",
      "Epoch 88/1500\n",
      "143/143 [==============================] - 87s 612ms/step - loss: 67.8834 - root_mean_squared_error: 8.2376 - mean_absolute_error: 6.7865 - val_loss: 74.4723 - val_root_mean_squared_error: 8.6297 - val_mean_absolute_error: 7.1970\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 57.26908\n",
      "Epoch 89/1500\n",
      "143/143 [==============================] - 90s 626ms/step - loss: 63.0446 - root_mean_squared_error: 7.9374 - mean_absolute_error: 6.5277 - val_loss: 68.4259 - val_root_mean_squared_error: 8.2720 - val_mean_absolute_error: 6.8754\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 57.26908\n",
      "Epoch 90/1500\n",
      "143/143 [==============================] - 89s 624ms/step - loss: 64.3245 - root_mean_squared_error: 8.0151 - mean_absolute_error: 6.4571 - val_loss: 63.5880 - val_root_mean_squared_error: 7.9742 - val_mean_absolute_error: 6.3906\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 57.26908\n",
      "Epoch 91/1500\n",
      "143/143 [==============================] - 87s 612ms/step - loss: 59.8378 - root_mean_squared_error: 7.7334 - mean_absolute_error: 6.2840 - val_loss: 63.1597 - val_root_mean_squared_error: 7.9473 - val_mean_absolute_error: 6.4565\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 57.26908\n",
      "Epoch 92/1500\n",
      "143/143 [==============================] - 91s 635ms/step - loss: 59.0908 - root_mean_squared_error: 7.6821 - mean_absolute_error: 6.3055 - val_loss: 78.2917 - val_root_mean_squared_error: 8.8483 - val_mean_absolute_error: 7.3037\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 57.26908\n",
      "Epoch 93/1500\n",
      "143/143 [==============================] - 91s 639ms/step - loss: 62.5171 - root_mean_squared_error: 7.9045 - mean_absolute_error: 6.4372 - val_loss: 73.5979 - val_root_mean_squared_error: 8.5789 - val_mean_absolute_error: 6.8885\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 57.26908\n",
      "Epoch 94/1500\n",
      "143/143 [==============================] - 91s 636ms/step - loss: 60.1915 - root_mean_squared_error: 7.7546 - mean_absolute_error: 6.3444 - val_loss: 70.4738 - val_root_mean_squared_error: 8.3949 - val_mean_absolute_error: 6.5093\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 57.26908\n",
      "Epoch 95/1500\n",
      "143/143 [==============================] - 94s 656ms/step - loss: 60.0903 - root_mean_squared_error: 7.7491 - mean_absolute_error: 6.3717 - val_loss: 63.3871 - val_root_mean_squared_error: 7.9616 - val_mean_absolute_error: 6.3825\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 57.26908\n",
      "Epoch 96/1500\n",
      "143/143 [==============================] - 93s 650ms/step - loss: 57.5136 - root_mean_squared_error: 7.5816 - mean_absolute_error: 6.2514 - val_loss: 66.1397 - val_root_mean_squared_error: 8.1326 - val_mean_absolute_error: 6.6749\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 57.26908\n",
      "Epoch 97/1500\n",
      "143/143 [==============================] - 92s 642ms/step - loss: 63.7848 - root_mean_squared_error: 7.9852 - mean_absolute_error: 6.5239 - val_loss: 114.8542 - val_root_mean_squared_error: 10.7170 - val_mean_absolute_error: 9.0469\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 57.26908\n",
      "Epoch 98/1500\n",
      "143/143 [==============================] - 93s 652ms/step - loss: 63.8761 - root_mean_squared_error: 7.9859 - mean_absolute_error: 6.3675 - val_loss: 63.8718 - val_root_mean_squared_error: 7.9920 - val_mean_absolute_error: 6.4267\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 57.26908\n",
      "Epoch 99/1500\n",
      "143/143 [==============================] - 92s 647ms/step - loss: 59.3470 - root_mean_squared_error: 7.7000 - mean_absolute_error: 6.2462 - val_loss: 56.6541 - val_root_mean_squared_error: 7.5269 - val_mean_absolute_error: 6.1512\n",
      "\n",
      "Epoch 00099: val_loss improved from 57.26908 to 56.65411, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/ResNet_regressor_01.hdf5\n",
      "Epoch 100/1500\n",
      "143/143 [==============================] - 93s 647ms/step - loss: 60.9316 - root_mean_squared_error: 7.7911 - mean_absolute_error: 6.4213 - val_loss: 73.4552 - val_root_mean_squared_error: 8.5706 - val_mean_absolute_error: 6.6414\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 56.65411\n",
      "Epoch 101/1500\n",
      "143/143 [==============================] - 93s 647ms/step - loss: 66.0823 - root_mean_squared_error: 8.1243 - mean_absolute_error: 6.5788 - val_loss: 70.4239 - val_root_mean_squared_error: 8.3919 - val_mean_absolute_error: 6.8018\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 56.65411\n",
      "Epoch 102/1500\n",
      "143/143 [==============================] - 93s 654ms/step - loss: 59.7575 - root_mean_squared_error: 7.7198 - mean_absolute_error: 6.2725 - val_loss: 67.2000 - val_root_mean_squared_error: 8.1976 - val_mean_absolute_error: 6.5594\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 56.65411\n",
      "Epoch 103/1500\n",
      "143/143 [==============================] - 92s 645ms/step - loss: 58.3557 - root_mean_squared_error: 7.6357 - mean_absolute_error: 6.1341 - val_loss: 69.2255 - val_root_mean_squared_error: 8.3202 - val_mean_absolute_error: 6.7408\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 56.65411\n",
      "Epoch 104/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 93s 647ms/step - loss: 60.9838 - root_mean_squared_error: 7.7936 - mean_absolute_error: 6.3301 - val_loss: 74.6349 - val_root_mean_squared_error: 8.6391 - val_mean_absolute_error: 6.9218\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 56.65411\n",
      "Epoch 105/1500\n",
      "143/143 [==============================] - 93s 651ms/step - loss: 62.2411 - root_mean_squared_error: 7.8813 - mean_absolute_error: 6.3707 - val_loss: 122.1213 - val_root_mean_squared_error: 11.0509 - val_mean_absolute_error: 9.3274\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 56.65411\n",
      "Epoch 106/1500\n",
      "143/143 [==============================] - 93s 652ms/step - loss: 62.3770 - root_mean_squared_error: 7.8961 - mean_absolute_error: 6.4425 - val_loss: 82.1519 - val_root_mean_squared_error: 9.0638 - val_mean_absolute_error: 7.4407\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 56.65411\n",
      "Epoch 107/1500\n",
      "143/143 [==============================] - 92s 643ms/step - loss: 58.2403 - root_mean_squared_error: 7.6308 - mean_absolute_error: 6.1886 - val_loss: 61.2371 - val_root_mean_squared_error: 7.8254 - val_mean_absolute_error: 6.3873\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 56.65411\n",
      "Epoch 108/1500\n",
      "143/143 [==============================] - 92s 645ms/step - loss: 57.4957 - root_mean_squared_error: 7.5779 - mean_absolute_error: 6.1329 - val_loss: 88.4216 - val_root_mean_squared_error: 9.4033 - val_mean_absolute_error: 7.8456\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 56.65411\n",
      "Epoch 109/1500\n",
      "143/143 [==============================] - 92s 643ms/step - loss: 62.3932 - root_mean_squared_error: 7.8981 - mean_absolute_error: 6.4501 - val_loss: 89.5161 - val_root_mean_squared_error: 9.4613 - val_mean_absolute_error: 7.3546\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 56.65411\n",
      "Epoch 110/1500\n",
      "143/143 [==============================] - 93s 647ms/step - loss: 60.5679 - root_mean_squared_error: 7.7799 - mean_absolute_error: 6.2159 - val_loss: 1048.1630 - val_root_mean_squared_error: 32.3753 - val_mean_absolute_error: 27.1068\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 56.65411\n",
      "Epoch 111/1500\n",
      "143/143 [==============================] - 94s 655ms/step - loss: 62.9328 - root_mean_squared_error: 7.9309 - mean_absolute_error: 6.4173 - val_loss: 66.6947 - val_root_mean_squared_error: 8.1667 - val_mean_absolute_error: 6.5725\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 56.65411\n",
      "Epoch 112/1500\n",
      "143/143 [==============================] - 94s 657ms/step - loss: 59.9905 - root_mean_squared_error: 7.7384 - mean_absolute_error: 6.1651 - val_loss: 75.3704 - val_root_mean_squared_error: 8.6816 - val_mean_absolute_error: 6.9746\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 56.65411\n",
      "Epoch 113/1500\n",
      "143/143 [==============================] - 92s 642ms/step - loss: 58.4257 - root_mean_squared_error: 7.6402 - mean_absolute_error: 6.2448 - val_loss: 82.3594 - val_root_mean_squared_error: 9.0752 - val_mean_absolute_error: 7.5076\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 56.65411\n",
      "Epoch 114/1500\n",
      "143/143 [==============================] - 93s 648ms/step - loss: 63.8927 - root_mean_squared_error: 7.9865 - mean_absolute_error: 6.5063 - val_loss: 79.7111 - val_root_mean_squared_error: 8.9281 - val_mean_absolute_error: 7.3093\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 56.65411\n",
      "Epoch 115/1500\n",
      "143/143 [==============================] - 93s 648ms/step - loss: 56.9534 - root_mean_squared_error: 7.5444 - mean_absolute_error: 6.0963 - val_loss: 67.6826 - val_root_mean_squared_error: 8.2269 - val_mean_absolute_error: 6.6309\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 56.65411\n",
      "Epoch 116/1500\n",
      "143/143 [==============================] - 93s 653ms/step - loss: 55.6039 - root_mean_squared_error: 7.4559 - mean_absolute_error: 6.0654 - val_loss: 82.4876 - val_root_mean_squared_error: 9.0823 - val_mean_absolute_error: 6.9458\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 56.65411\n",
      "Epoch 117/1500\n",
      "143/143 [==============================] - 93s 649ms/step - loss: 56.0461 - root_mean_squared_error: 7.4847 - mean_absolute_error: 6.0018 - val_loss: 72.6937 - val_root_mean_squared_error: 8.5261 - val_mean_absolute_error: 7.0227\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 56.65411\n",
      "Epoch 118/1500\n",
      "143/143 [==============================] - 93s 650ms/step - loss: 55.6018 - root_mean_squared_error: 7.4484 - mean_absolute_error: 5.9255 - val_loss: 82.7952 - val_root_mean_squared_error: 9.0992 - val_mean_absolute_error: 7.1504\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 56.65411\n",
      "Epoch 119/1500\n",
      "143/143 [==============================] - 94s 656ms/step - loss: 66.2583 - root_mean_squared_error: 8.1344 - mean_absolute_error: 6.5894 - val_loss: 79.2712 - val_root_mean_squared_error: 8.9034 - val_mean_absolute_error: 7.3352\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 56.65411\n",
      "Epoch 120/1500\n",
      "143/143 [==============================] - 94s 658ms/step - loss: 57.5774 - root_mean_squared_error: 7.5866 - mean_absolute_error: 6.1439 - val_loss: 66.7790 - val_root_mean_squared_error: 8.1718 - val_mean_absolute_error: 6.6900\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 56.65411\n",
      "Epoch 121/1500\n",
      "143/143 [==============================] - 93s 647ms/step - loss: 57.5590 - root_mean_squared_error: 7.5837 - mean_absolute_error: 6.1573 - val_loss: 74.3992 - val_root_mean_squared_error: 8.6255 - val_mean_absolute_error: 6.9144\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 56.65411\n",
      "Epoch 122/1500\n",
      "143/143 [==============================] - 92s 646ms/step - loss: 59.4519 - root_mean_squared_error: 7.7061 - mean_absolute_error: 6.3424 - val_loss: 58.6880 - val_root_mean_squared_error: 7.6608 - val_mean_absolute_error: 6.3554\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 56.65411\n",
      "Epoch 123/1500\n",
      "143/143 [==============================] - 93s 652ms/step - loss: 66.9139 - root_mean_squared_error: 8.1771 - mean_absolute_error: 6.7483 - val_loss: 71.6550 - val_root_mean_squared_error: 8.4649 - val_mean_absolute_error: 6.8034\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 56.65411\n",
      "Epoch 124/1500\n",
      "143/143 [==============================] - 94s 660ms/step - loss: 59.1240 - root_mean_squared_error: 7.6858 - mean_absolute_error: 6.2393 - val_loss: 77.7150 - val_root_mean_squared_error: 8.8156 - val_mean_absolute_error: 7.2091\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 56.65411\n",
      "Epoch 125/1500\n",
      "143/143 [==============================] - 93s 654ms/step - loss: 61.1303 - root_mean_squared_error: 7.8111 - mean_absolute_error: 6.4111 - val_loss: 73.0100 - val_root_mean_squared_error: 8.5446 - val_mean_absolute_error: 7.0754\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 56.65411\n",
      "Epoch 126/1500\n",
      "143/143 [==============================] - 91s 639ms/step - loss: 62.9836 - root_mean_squared_error: 7.9299 - mean_absolute_error: 6.4316 - val_loss: 63.4422 - val_root_mean_squared_error: 7.9651 - val_mean_absolute_error: 6.2677\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 56.65411\n",
      "Epoch 127/1500\n",
      "143/143 [==============================] - 91s 633ms/step - loss: 58.9659 - root_mean_squared_error: 7.6745 - mean_absolute_error: 6.1737 - val_loss: 109.6977 - val_root_mean_squared_error: 10.4737 - val_mean_absolute_error: 8.6107\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 56.65411\n",
      "Epoch 128/1500\n",
      "143/143 [==============================] - 92s 645ms/step - loss: 57.3902 - root_mean_squared_error: 7.5735 - mean_absolute_error: 6.0622 - val_loss: 51.6072 - val_root_mean_squared_error: 7.1838 - val_mean_absolute_error: 5.8831\n",
      "\n",
      "Epoch 00128: val_loss improved from 56.65411 to 51.60717, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/ResNet_regressor_01.hdf5\n",
      "Epoch 129/1500\n",
      "143/143 [==============================] - 93s 647ms/step - loss: 56.1978 - root_mean_squared_error: 7.4851 - mean_absolute_error: 5.9250 - val_loss: 55.5705 - val_root_mean_squared_error: 7.4546 - val_mean_absolute_error: 5.9708\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 51.60717\n",
      "Epoch 130/1500\n",
      "143/143 [==============================] - 92s 645ms/step - loss: 62.1957 - root_mean_squared_error: 7.8844 - mean_absolute_error: 6.3941 - val_loss: 66.4611 - val_root_mean_squared_error: 8.1524 - val_mean_absolute_error: 6.3561\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 51.60717\n",
      "Epoch 131/1500\n",
      "143/143 [==============================] - 93s 653ms/step - loss: 61.6281 - root_mean_squared_error: 7.8347 - mean_absolute_error: 6.2987 - val_loss: 98.1600 - val_root_mean_squared_error: 9.9076 - val_mean_absolute_error: 7.9224\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 51.60717\n",
      "Epoch 132/1500\n",
      "143/143 [==============================] - 92s 644ms/step - loss: 64.5233 - root_mean_squared_error: 8.0308 - mean_absolute_error: 6.4288 - val_loss: 63.7879 - val_root_mean_squared_error: 7.9867 - val_mean_absolute_error: 6.6205\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 51.60717\n",
      "Epoch 133/1500\n",
      "143/143 [==============================] - 91s 636ms/step - loss: 55.4161 - root_mean_squared_error: 7.4413 - mean_absolute_error: 6.0848 - val_loss: 62.9688 - val_root_mean_squared_error: 7.9353 - val_mean_absolute_error: 6.2068\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 51.60717\n",
      "Epoch 134/1500\n",
      "143/143 [==============================] - 91s 637ms/step - loss: 55.5643 - root_mean_squared_error: 7.4451 - mean_absolute_error: 5.9801 - val_loss: 85.4269 - val_root_mean_squared_error: 9.2427 - val_mean_absolute_error: 7.1541\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 51.60717\n",
      "Epoch 135/1500\n",
      "143/143 [==============================] - 94s 657ms/step - loss: 62.1910 - root_mean_squared_error: 7.8788 - mean_absolute_error: 6.3342 - val_loss: 70.4319 - val_root_mean_squared_error: 8.3924 - val_mean_absolute_error: 6.6383\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 51.60717\n",
      "Epoch 136/1500\n",
      "143/143 [==============================] - 93s 651ms/step - loss: 58.9451 - root_mean_squared_error: 7.6756 - mean_absolute_error: 6.2935 - val_loss: 80.3200 - val_root_mean_squared_error: 8.9621 - val_mean_absolute_error: 6.9008\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 51.60717\n",
      "Epoch 137/1500\n",
      "143/143 [==============================] - 94s 655ms/step - loss: 56.5976 - root_mean_squared_error: 7.5209 - mean_absolute_error: 6.1463 - val_loss: 59.4145 - val_root_mean_squared_error: 7.7081 - val_mean_absolute_error: 6.3287\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 51.60717\n",
      "Epoch 138/1500\n",
      "143/143 [==============================] - 95s 663ms/step - loss: 55.8810 - root_mean_squared_error: 7.4725 - mean_absolute_error: 6.1131 - val_loss: 78.0253 - val_root_mean_squared_error: 8.8332 - val_mean_absolute_error: 7.2166\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 51.60717\n",
      "Epoch 139/1500\n",
      "143/143 [==============================] - 94s 655ms/step - loss: 55.3184 - root_mean_squared_error: 7.4360 - mean_absolute_error: 5.9503 - val_loss: 66.8455 - val_root_mean_squared_error: 8.1759 - val_mean_absolute_error: 6.3982\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 51.60717\n",
      "Epoch 140/1500\n",
      "143/143 [==============================] - 94s 658ms/step - loss: 55.2225 - root_mean_squared_error: 7.4289 - mean_absolute_error: 6.0690 - val_loss: 70.0086 - val_root_mean_squared_error: 8.3671 - val_mean_absolute_error: 6.6112\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 51.60717\n",
      "Epoch 141/1500\n",
      "143/143 [==============================] - 92s 645ms/step - loss: 59.3577 - root_mean_squared_error: 7.6949 - mean_absolute_error: 6.1425 - val_loss: 213.5872 - val_root_mean_squared_error: 14.6146 - val_mean_absolute_error: 11.7594\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 51.60717\n",
      "Epoch 142/1500\n",
      "143/143 [==============================] - 92s 646ms/step - loss: 55.1725 - root_mean_squared_error: 7.4258 - mean_absolute_error: 6.0607 - val_loss: 72.1781 - val_root_mean_squared_error: 8.4958 - val_mean_absolute_error: 7.1284\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 51.60717\n",
      "Epoch 143/1500\n",
      "143/143 [==============================] - 91s 639ms/step - loss: 58.2073 - root_mean_squared_error: 7.6288 - mean_absolute_error: 6.1765 - val_loss: 63.3715 - val_root_mean_squared_error: 7.9606 - val_mean_absolute_error: 6.6250\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 51.60717\n",
      "Epoch 144/1500\n",
      "143/143 [==============================] - 95s 667ms/step - loss: 56.4484 - root_mean_squared_error: 7.5115 - mean_absolute_error: 6.1266 - val_loss: 64.6881 - val_root_mean_squared_error: 8.0429 - val_mean_absolute_error: 6.5609\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 51.60717\n",
      "Epoch 145/1500\n",
      "143/143 [==============================] - 92s 645ms/step - loss: 57.0638 - root_mean_squared_error: 7.5527 - mean_absolute_error: 6.1373 - val_loss: 66.0716 - val_root_mean_squared_error: 8.1284 - val_mean_absolute_error: 6.3930\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 51.60717\n",
      "Epoch 146/1500\n",
      "143/143 [==============================] - 91s 636ms/step - loss: 57.2095 - root_mean_squared_error: 7.5574 - mean_absolute_error: 6.1086 - val_loss: 66.8421 - val_root_mean_squared_error: 8.1757 - val_mean_absolute_error: 6.9604\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 51.60717\n",
      "Epoch 147/1500\n",
      "143/143 [==============================] - 90s 633ms/step - loss: 54.3557 - root_mean_squared_error: 7.3685 - mean_absolute_error: 5.9313 - val_loss: 67.4259 - val_root_mean_squared_error: 8.2113 - val_mean_absolute_error: 6.6653\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 51.60717\n",
      "Epoch 148/1500\n",
      "143/143 [==============================] - 90s 630ms/step - loss: 51.8658 - root_mean_squared_error: 7.1939 - mean_absolute_error: 5.8350 - val_loss: 108.5982 - val_root_mean_squared_error: 10.4210 - val_mean_absolute_error: 8.6029\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 51.60717\n",
      "Epoch 149/1500\n",
      "143/143 [==============================] - 90s 631ms/step - loss: 64.5702 - root_mean_squared_error: 8.0240 - mean_absolute_error: 6.5699 - val_loss: 70.2491 - val_root_mean_squared_error: 8.3815 - val_mean_absolute_error: 6.6157\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 51.60717\n",
      "Epoch 150/1500\n",
      "143/143 [==============================] - 91s 635ms/step - loss: 59.0600 - root_mean_squared_error: 7.6825 - mean_absolute_error: 6.2822 - val_loss: 78.2247 - val_root_mean_squared_error: 8.8445 - val_mean_absolute_error: 6.7665\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 51.60717\n",
      "Epoch 151/1500\n",
      "143/143 [==============================] - 92s 640ms/step - loss: 56.2064 - root_mean_squared_error: 7.4926 - mean_absolute_error: 5.9754 - val_loss: 83.1641 - val_root_mean_squared_error: 9.1194 - val_mean_absolute_error: 7.1135\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 51.60717\n",
      "Epoch 152/1500\n",
      "143/143 [==============================] - 89s 623ms/step - loss: 56.6795 - root_mean_squared_error: 7.5227 - mean_absolute_error: 6.1195 - val_loss: 78.1468 - val_root_mean_squared_error: 8.8401 - val_mean_absolute_error: 7.0497\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 51.60717\n",
      "Epoch 153/1500\n",
      "143/143 [==============================] - 91s 635ms/step - loss: 52.6316 - root_mean_squared_error: 7.2521 - mean_absolute_error: 5.7829 - val_loss: 63.6564 - val_root_mean_squared_error: 7.9785 - val_mean_absolute_error: 6.8679\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 51.60717\n",
      "Epoch 154/1500\n",
      "143/143 [==============================] - 89s 626ms/step - loss: 56.8541 - root_mean_squared_error: 7.5355 - mean_absolute_error: 6.0901 - val_loss: 186.1458 - val_root_mean_squared_error: 13.6435 - val_mean_absolute_error: 10.9304\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 51.60717\n",
      "Epoch 155/1500\n",
      "143/143 [==============================] - 92s 642ms/step - loss: 54.8038 - root_mean_squared_error: 7.3991 - mean_absolute_error: 6.0485 - val_loss: 72.4448 - val_root_mean_squared_error: 8.5114 - val_mean_absolute_error: 6.9643\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 51.60717\n",
      "Epoch 156/1500\n",
      "143/143 [==============================] - 91s 638ms/step - loss: 52.5949 - root_mean_squared_error: 7.2434 - mean_absolute_error: 5.7824 - val_loss: 70.6870 - val_root_mean_squared_error: 8.4076 - val_mean_absolute_error: 6.5376\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 51.60717\n",
      "Epoch 157/1500\n",
      "143/143 [==============================] - 91s 640ms/step - loss: 55.7940 - root_mean_squared_error: 7.4669 - mean_absolute_error: 5.9690 - val_loss: 88.0427 - val_root_mean_squared_error: 9.3831 - val_mean_absolute_error: 7.5048\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 51.60717\n",
      "Epoch 158/1500\n",
      "143/143 [==============================] - 90s 630ms/step - loss: 56.8534 - root_mean_squared_error: 7.5390 - mean_absolute_error: 6.1409 - val_loss: 67.9726 - val_root_mean_squared_error: 8.2446 - val_mean_absolute_error: 6.7145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00158: val_loss did not improve from 51.60717\n",
      "Epoch 159/1500\n",
      "143/143 [==============================] - 91s 638ms/step - loss: 54.2945 - root_mean_squared_error: 7.3653 - mean_absolute_error: 6.0166 - val_loss: 73.6091 - val_root_mean_squared_error: 8.5796 - val_mean_absolute_error: 6.9942\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 51.60717\n",
      "Epoch 160/1500\n",
      "143/143 [==============================] - 91s 634ms/step - loss: 57.3901 - root_mean_squared_error: 7.5715 - mean_absolute_error: 6.1807 - val_loss: 84.3955 - val_root_mean_squared_error: 9.1867 - val_mean_absolute_error: 7.2678\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 51.60717\n",
      "Epoch 161/1500\n",
      "143/143 [==============================] - 90s 631ms/step - loss: 62.8495 - root_mean_squared_error: 7.9244 - mean_absolute_error: 6.3541 - val_loss: 102.1664 - val_root_mean_squared_error: 10.1077 - val_mean_absolute_error: 7.8854\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 51.60717\n",
      "Epoch 162/1500\n",
      "143/143 [==============================] - 91s 636ms/step - loss: 52.8654 - root_mean_squared_error: 7.2692 - mean_absolute_error: 5.8821 - val_loss: 63.8618 - val_root_mean_squared_error: 7.9914 - val_mean_absolute_error: 6.3684\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 51.60717\n",
      "Epoch 163/1500\n",
      "143/143 [==============================] - 90s 632ms/step - loss: 59.6475 - root_mean_squared_error: 7.7176 - mean_absolute_error: 6.1871 - val_loss: 117.5643 - val_root_mean_squared_error: 10.8427 - val_mean_absolute_error: 8.9715\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 51.60717\n",
      "Epoch 164/1500\n",
      "143/143 [==============================] - 90s 632ms/step - loss: 61.5743 - root_mean_squared_error: 7.8429 - mean_absolute_error: 6.2987 - val_loss: 80.3139 - val_root_mean_squared_error: 8.9618 - val_mean_absolute_error: 7.2710\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 51.60717\n",
      "Epoch 165/1500\n",
      "143/143 [==============================] - 90s 631ms/step - loss: 56.6965 - root_mean_squared_error: 7.5280 - mean_absolute_error: 6.1217 - val_loss: 70.3630 - val_root_mean_squared_error: 8.3883 - val_mean_absolute_error: 6.5682\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 51.60717\n",
      "Epoch 166/1500\n",
      "143/143 [==============================] - 90s 633ms/step - loss: 56.9908 - root_mean_squared_error: 7.5457 - mean_absolute_error: 6.0143 - val_loss: 63.3337 - val_root_mean_squared_error: 7.9582 - val_mean_absolute_error: 6.5760\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 51.60717\n",
      "Epoch 167/1500\n",
      "143/143 [==============================] - 90s 632ms/step - loss: 60.2084 - root_mean_squared_error: 7.7561 - mean_absolute_error: 6.3743 - val_loss: 66.9444 - val_root_mean_squared_error: 8.1820 - val_mean_absolute_error: 6.5297\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 51.60717\n",
      "Epoch 168/1500\n",
      "143/143 [==============================] - 90s 630ms/step - loss: 58.2184 - root_mean_squared_error: 7.6279 - mean_absolute_error: 6.2198 - val_loss: 77.0314 - val_root_mean_squared_error: 8.7768 - val_mean_absolute_error: 7.0661\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 51.60717\n",
      "Epoch 169/1500\n",
      "143/143 [==============================] - 91s 634ms/step - loss: 51.9938 - root_mean_squared_error: 7.2092 - mean_absolute_error: 5.8281 - val_loss: 88.2291 - val_root_mean_squared_error: 9.3930 - val_mean_absolute_error: 7.3374\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 51.60717\n",
      "Epoch 170/1500\n",
      "143/143 [==============================] - 91s 640ms/step - loss: 53.7182 - root_mean_squared_error: 7.3266 - mean_absolute_error: 5.8015 - val_loss: 75.1642 - val_root_mean_squared_error: 8.6697 - val_mean_absolute_error: 6.9392\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 51.60717\n",
      "Epoch 171/1500\n",
      "143/143 [==============================] - 92s 642ms/step - loss: 60.1827 - root_mean_squared_error: 7.7555 - mean_absolute_error: 6.2198 - val_loss: 67.5701 - val_root_mean_squared_error: 8.2201 - val_mean_absolute_error: 6.6429\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 51.60717\n",
      "Epoch 172/1500\n",
      "143/143 [==============================] - 90s 630ms/step - loss: 60.5846 - root_mean_squared_error: 7.7819 - mean_absolute_error: 6.3272 - val_loss: 64.9728 - val_root_mean_squared_error: 8.0606 - val_mean_absolute_error: 6.4653\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 51.60717\n",
      "Epoch 173/1500\n",
      "143/143 [==============================] - 92s 641ms/step - loss: 60.3886 - root_mean_squared_error: 7.7700 - mean_absolute_error: 6.2334 - val_loss: 72.4246 - val_root_mean_squared_error: 8.5103 - val_mean_absolute_error: 6.6013\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 51.60717\n",
      "Epoch 174/1500\n",
      "143/143 [==============================] - 89s 624ms/step - loss: 60.6409 - root_mean_squared_error: 7.7839 - mean_absolute_error: 6.2133 - val_loss: 67.7659 - val_root_mean_squared_error: 8.2320 - val_mean_absolute_error: 6.8881\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 51.60717\n",
      "Epoch 175/1500\n",
      "143/143 [==============================] - 92s 640ms/step - loss: 59.7910 - root_mean_squared_error: 7.7281 - mean_absolute_error: 6.2797 - val_loss: 66.1015 - val_root_mean_squared_error: 8.1303 - val_mean_absolute_error: 6.7927\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 51.60717\n",
      "Epoch 176/1500\n",
      "143/143 [==============================] - 91s 638ms/step - loss: 56.2848 - root_mean_squared_error: 7.5009 - mean_absolute_error: 6.0983 - val_loss: 66.4884 - val_root_mean_squared_error: 8.1540 - val_mean_absolute_error: 6.5990\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 51.60717\n",
      "Epoch 177/1500\n",
      "143/143 [==============================] - 91s 637ms/step - loss: 56.5304 - root_mean_squared_error: 7.5147 - mean_absolute_error: 6.0812 - val_loss: 73.7942 - val_root_mean_squared_error: 8.5904 - val_mean_absolute_error: 6.7500\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 51.60717\n",
      "Epoch 178/1500\n",
      "143/143 [==============================] - 91s 638ms/step - loss: 56.3849 - root_mean_squared_error: 7.5060 - mean_absolute_error: 6.0456 - val_loss: 71.1197 - val_root_mean_squared_error: 8.4332 - val_mean_absolute_error: 6.9161\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 51.60717\n",
      "\n",
      "Epoch 00178: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "Epoch 179/1500\n",
      "143/143 [==============================] - 91s 634ms/step - loss: 57.5845 - root_mean_squared_error: 7.5868 - mean_absolute_error: 6.0708 - val_loss: 58.6086 - val_root_mean_squared_error: 7.6556 - val_mean_absolute_error: 6.1441\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 51.60717\n",
      "Epoch 180/1500\n",
      "143/143 [==============================] - 90s 629ms/step - loss: 55.2987 - root_mean_squared_error: 7.4298 - mean_absolute_error: 6.0563 - val_loss: 56.1736 - val_root_mean_squared_error: 7.4949 - val_mean_absolute_error: 6.2270\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 51.60717\n",
      "Epoch 181/1500\n",
      "143/143 [==============================] - 92s 641ms/step - loss: 50.7225 - root_mean_squared_error: 7.1191 - mean_absolute_error: 5.7222 - val_loss: 64.9932 - val_root_mean_squared_error: 8.0618 - val_mean_absolute_error: 6.5211\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 51.60717\n",
      "Epoch 182/1500\n",
      "143/143 [==============================] - 91s 635ms/step - loss: 56.1391 - root_mean_squared_error: 7.4830 - mean_absolute_error: 6.0532 - val_loss: 65.4392 - val_root_mean_squared_error: 8.0895 - val_mean_absolute_error: 6.4088\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 51.60717\n",
      "Epoch 183/1500\n",
      "143/143 [==============================] - 91s 636ms/step - loss: 55.6326 - root_mean_squared_error: 7.4563 - mean_absolute_error: 6.0289 - val_loss: 78.2912 - val_root_mean_squared_error: 8.8482 - val_mean_absolute_error: 7.2880\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 51.60717\n",
      "Epoch 184/1500\n",
      "143/143 [==============================] - 91s 639ms/step - loss: 54.6386 - root_mean_squared_error: 7.3846 - mean_absolute_error: 5.9882 - val_loss: 61.9245 - val_root_mean_squared_error: 7.8692 - val_mean_absolute_error: 6.3465\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 51.60717\n",
      "Epoch 185/1500\n",
      "143/143 [==============================] - 90s 630ms/step - loss: 50.5610 - root_mean_squared_error: 7.1051 - mean_absolute_error: 5.7797 - val_loss: 70.5231 - val_root_mean_squared_error: 8.3978 - val_mean_absolute_error: 6.9346\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 51.60717\n",
      "Epoch 186/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 91s 639ms/step - loss: 52.3391 - root_mean_squared_error: 7.2312 - mean_absolute_error: 5.9196 - val_loss: 59.0580 - val_root_mean_squared_error: 7.6849 - val_mean_absolute_error: 6.1612\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 51.60717\n",
      "Epoch 187/1500\n",
      "143/143 [==============================] - 90s 630ms/step - loss: 57.1198 - root_mean_squared_error: 7.5562 - mean_absolute_error: 6.1553 - val_loss: 57.7867 - val_root_mean_squared_error: 7.6018 - val_mean_absolute_error: 6.0612\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 51.60717\n",
      "Epoch 188/1500\n",
      "143/143 [==============================] - 90s 628ms/step - loss: 53.4742 - root_mean_squared_error: 7.3093 - mean_absolute_error: 5.8384 - val_loss: 72.1455 - val_root_mean_squared_error: 8.4938 - val_mean_absolute_error: 6.8769\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 51.60717\n",
      "Epoch 189/1500\n",
      "143/143 [==============================] - 91s 635ms/step - loss: 53.1975 - root_mean_squared_error: 7.2880 - mean_absolute_error: 5.8544 - val_loss: 57.6279 - val_root_mean_squared_error: 7.5913 - val_mean_absolute_error: 6.2989\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 51.60717\n",
      "Epoch 190/1500\n",
      "143/143 [==============================] - 91s 640ms/step - loss: 57.3013 - root_mean_squared_error: 7.5532 - mean_absolute_error: 6.1288 - val_loss: 94.4336 - val_root_mean_squared_error: 9.7177 - val_mean_absolute_error: 7.9622\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 51.60717\n",
      "Epoch 191/1500\n",
      "143/143 [==============================] - 91s 636ms/step - loss: 57.9385 - root_mean_squared_error: 7.6100 - mean_absolute_error: 6.1847 - val_loss: 65.5793 - val_root_mean_squared_error: 8.0981 - val_mean_absolute_error: 6.5401\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 51.60717\n",
      "Epoch 192/1500\n",
      "143/143 [==============================] - 91s 637ms/step - loss: 54.7482 - root_mean_squared_error: 7.3963 - mean_absolute_error: 5.9642 - val_loss: 67.3411 - val_root_mean_squared_error: 8.2062 - val_mean_absolute_error: 6.4476\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 51.60717\n",
      "Epoch 193/1500\n",
      "143/143 [==============================] - 91s 634ms/step - loss: 55.3389 - root_mean_squared_error: 7.4352 - mean_absolute_error: 6.0332 - val_loss: 59.8153 - val_root_mean_squared_error: 7.7340 - val_mean_absolute_error: 6.3173\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 51.60717\n",
      "Epoch 194/1500\n",
      "143/143 [==============================] - 91s 635ms/step - loss: 53.7234 - root_mean_squared_error: 7.3197 - mean_absolute_error: 5.8861 - val_loss: 61.7575 - val_root_mean_squared_error: 7.8586 - val_mean_absolute_error: 6.3827\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 51.60717\n",
      "Epoch 195/1500\n",
      "143/143 [==============================] - 92s 643ms/step - loss: 49.6522 - root_mean_squared_error: 7.0437 - mean_absolute_error: 5.6346 - val_loss: 80.9982 - val_root_mean_squared_error: 8.9999 - val_mean_absolute_error: 7.4815\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 51.60717\n",
      "Epoch 196/1500\n",
      "143/143 [==============================] - 91s 640ms/step - loss: 55.5200 - root_mean_squared_error: 7.4431 - mean_absolute_error: 5.9267 - val_loss: 81.1403 - val_root_mean_squared_error: 9.0078 - val_mean_absolute_error: 6.8638\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 51.60717\n",
      "Epoch 197/1500\n",
      "143/143 [==============================] - 92s 641ms/step - loss: 48.4924 - root_mean_squared_error: 6.9598 - mean_absolute_error: 5.5467 - val_loss: 63.4144 - val_root_mean_squared_error: 7.9633 - val_mean_absolute_error: 6.3367\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 51.60717\n",
      "Epoch 198/1500\n",
      "143/143 [==============================] - 93s 647ms/step - loss: 48.9795 - root_mean_squared_error: 6.9956 - mean_absolute_error: 5.5343 - val_loss: 69.3152 - val_root_mean_squared_error: 8.3256 - val_mean_absolute_error: 6.6521\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 51.60717\n",
      "Epoch 199/1500\n",
      "143/143 [==============================] - 93s 648ms/step - loss: 55.6648 - root_mean_squared_error: 7.4594 - mean_absolute_error: 5.9052 - val_loss: 78.1213 - val_root_mean_squared_error: 8.8386 - val_mean_absolute_error: 6.9749\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 51.60717\n",
      "Epoch 200/1500\n",
      "143/143 [==============================] - 92s 641ms/step - loss: 52.1982 - root_mean_squared_error: 7.2231 - mean_absolute_error: 5.7489 - val_loss: 58.9179 - val_root_mean_squared_error: 7.6758 - val_mean_absolute_error: 6.1007\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 51.60717\n",
      "Epoch 201/1500\n",
      "143/143 [==============================] - 89s 626ms/step - loss: 50.2784 - root_mean_squared_error: 7.0888 - mean_absolute_error: 5.6794 - val_loss: 65.4875 - val_root_mean_squared_error: 8.0924 - val_mean_absolute_error: 6.2321\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 51.60717\n",
      "Epoch 202/1500\n",
      "143/143 [==============================] - 89s 619ms/step - loss: 50.6868 - root_mean_squared_error: 7.1161 - mean_absolute_error: 5.7692 - val_loss: 67.5245 - val_root_mean_squared_error: 8.2173 - val_mean_absolute_error: 6.7026\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 51.60717\n",
      "Epoch 203/1500\n",
      "143/143 [==============================] - 90s 632ms/step - loss: 54.0079 - root_mean_squared_error: 7.3471 - mean_absolute_error: 5.8878 - val_loss: 63.8930 - val_root_mean_squared_error: 7.9933 - val_mean_absolute_error: 6.4705\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 51.60717\n",
      "Epoch 204/1500\n",
      "143/143 [==============================] - 93s 650ms/step - loss: 49.2870 - root_mean_squared_error: 7.0149 - mean_absolute_error: 5.6999 - val_loss: 67.3566 - val_root_mean_squared_error: 8.2071 - val_mean_absolute_error: 6.4027\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 51.60717\n",
      "Epoch 205/1500\n",
      "143/143 [==============================] - 91s 640ms/step - loss: 52.9220 - root_mean_squared_error: 7.2737 - mean_absolute_error: 5.9064 - val_loss: 67.6814 - val_root_mean_squared_error: 8.2269 - val_mean_absolute_error: 6.5107\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 51.60717\n",
      "Epoch 206/1500\n",
      "143/143 [==============================] - 90s 632ms/step - loss: 51.0620 - root_mean_squared_error: 7.1425 - mean_absolute_error: 5.7908 - val_loss: 70.6336 - val_root_mean_squared_error: 8.4044 - val_mean_absolute_error: 6.6301\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 51.60717\n",
      "Epoch 207/1500\n",
      "143/143 [==============================] - 93s 653ms/step - loss: 51.6779 - root_mean_squared_error: 7.1857 - mean_absolute_error: 5.7306 - val_loss: 73.0098 - val_root_mean_squared_error: 8.5446 - val_mean_absolute_error: 6.8436\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 51.60717\n",
      "Epoch 208/1500\n",
      "143/143 [==============================] - 93s 653ms/step - loss: 52.7169 - root_mean_squared_error: 7.2593 - mean_absolute_error: 5.7557 - val_loss: 97.9111 - val_root_mean_squared_error: 9.8950 - val_mean_absolute_error: 7.9856\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 51.60717\n",
      "Epoch 209/1500\n",
      "143/143 [==============================] - 92s 645ms/step - loss: 58.2578 - root_mean_squared_error: 7.6312 - mean_absolute_error: 6.1470 - val_loss: 74.7535 - val_root_mean_squared_error: 8.6460 - val_mean_absolute_error: 7.0224\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 51.60717\n",
      "Epoch 210/1500\n",
      "143/143 [==============================] - 91s 639ms/step - loss: 55.9472 - root_mean_squared_error: 7.4747 - mean_absolute_error: 6.0948 - val_loss: 65.5027 - val_root_mean_squared_error: 8.0934 - val_mean_absolute_error: 6.5551\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 51.60717\n",
      "Epoch 211/1500\n",
      "143/143 [==============================] - 92s 644ms/step - loss: 55.2037 - root_mean_squared_error: 7.4257 - mean_absolute_error: 6.0145 - val_loss: 86.0560 - val_root_mean_squared_error: 9.2766 - val_mean_absolute_error: 7.3258\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 51.60717\n",
      "Epoch 212/1500\n",
      "143/143 [==============================] - 92s 643ms/step - loss: 50.6449 - root_mean_squared_error: 7.1151 - mean_absolute_error: 5.7706 - val_loss: 64.6202 - val_root_mean_squared_error: 8.0387 - val_mean_absolute_error: 6.5927\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 51.60717\n",
      "Epoch 213/1500\n",
      "143/143 [==============================] - 94s 657ms/step - loss: 51.1702 - root_mean_squared_error: 7.1511 - mean_absolute_error: 5.7315 - val_loss: 73.2731 - val_root_mean_squared_error: 8.5600 - val_mean_absolute_error: 6.7019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00213: val_loss did not improve from 51.60717\n",
      "Epoch 214/1500\n",
      "143/143 [==============================] - 91s 639ms/step - loss: 53.8704 - root_mean_squared_error: 7.3385 - mean_absolute_error: 5.9369 - val_loss: 63.3280 - val_root_mean_squared_error: 7.9579 - val_mean_absolute_error: 6.4370\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 51.60717\n",
      "Epoch 215/1500\n",
      "143/143 [==============================] - 93s 654ms/step - loss: 54.4770 - root_mean_squared_error: 7.3721 - mean_absolute_error: 5.9932 - val_loss: 87.2230 - val_root_mean_squared_error: 9.3393 - val_mean_absolute_error: 6.9571\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 51.60717\n",
      "Epoch 216/1500\n",
      "143/143 [==============================] - 94s 657ms/step - loss: 52.6363 - root_mean_squared_error: 7.2537 - mean_absolute_error: 5.8201 - val_loss: 71.1705 - val_root_mean_squared_error: 8.4363 - val_mean_absolute_error: 7.0487\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 51.60717\n",
      "Epoch 217/1500\n",
      "143/143 [==============================] - 91s 637ms/step - loss: 48.2122 - root_mean_squared_error: 6.9402 - mean_absolute_error: 5.5648 - val_loss: 65.1168 - val_root_mean_squared_error: 8.0695 - val_mean_absolute_error: 6.2949\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 51.60717\n",
      "Epoch 218/1500\n",
      "143/143 [==============================] - 91s 638ms/step - loss: 53.9316 - root_mean_squared_error: 7.3418 - mean_absolute_error: 5.9793 - val_loss: 62.2686 - val_root_mean_squared_error: 7.8910 - val_mean_absolute_error: 6.1156\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 51.60717\n",
      "Epoch 219/1500\n",
      "143/143 [==============================] - 93s 650ms/step - loss: 54.1420 - root_mean_squared_error: 7.3539 - mean_absolute_error: 5.9078 - val_loss: 67.5263 - val_root_mean_squared_error: 8.2174 - val_mean_absolute_error: 6.6993\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 51.60717\n",
      "Epoch 220/1500\n",
      "143/143 [==============================] - 92s 642ms/step - loss: 50.5221 - root_mean_squared_error: 7.1071 - mean_absolute_error: 5.6637 - val_loss: 75.4353 - val_root_mean_squared_error: 8.6853 - val_mean_absolute_error: 6.9463\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 51.60717\n",
      "Epoch 221/1500\n",
      "143/143 [==============================] - 92s 642ms/step - loss: 50.7644 - root_mean_squared_error: 7.1198 - mean_absolute_error: 5.7522 - val_loss: 74.3149 - val_root_mean_squared_error: 8.6206 - val_mean_absolute_error: 6.9813\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 51.60717\n",
      "Epoch 222/1500\n",
      "143/143 [==============================] - 92s 645ms/step - loss: 51.7584 - root_mean_squared_error: 7.1934 - mean_absolute_error: 5.8292 - val_loss: 65.6797 - val_root_mean_squared_error: 8.1043 - val_mean_absolute_error: 6.6550\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 51.60717\n",
      "Epoch 223/1500\n",
      "143/143 [==============================] - 92s 645ms/step - loss: 51.8086 - root_mean_squared_error: 7.1956 - mean_absolute_error: 5.8744 - val_loss: 64.3107 - val_root_mean_squared_error: 8.0194 - val_mean_absolute_error: 6.5559\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 51.60717\n",
      "Epoch 224/1500\n",
      "143/143 [==============================] - 91s 638ms/step - loss: 52.4691 - root_mean_squared_error: 7.2378 - mean_absolute_error: 5.8308 - val_loss: 68.4442 - val_root_mean_squared_error: 8.2731 - val_mean_absolute_error: 6.6758\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 51.60717\n",
      "Epoch 225/1500\n",
      "143/143 [==============================] - 92s 641ms/step - loss: 50.8858 - root_mean_squared_error: 7.1293 - mean_absolute_error: 5.8029 - val_loss: 83.9284 - val_root_mean_squared_error: 9.1612 - val_mean_absolute_error: 7.0271\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 51.60717\n",
      "Epoch 226/1500\n",
      "143/143 [==============================] - 90s 631ms/step - loss: 50.4081 - root_mean_squared_error: 7.0972 - mean_absolute_error: 5.7633 - val_loss: 63.7262 - val_root_mean_squared_error: 7.9829 - val_mean_absolute_error: 6.7293\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 51.60717\n",
      "Epoch 227/1500\n",
      "143/143 [==============================] - 91s 635ms/step - loss: 48.8863 - root_mean_squared_error: 6.9862 - mean_absolute_error: 5.5170 - val_loss: 70.6323 - val_root_mean_squared_error: 8.4043 - val_mean_absolute_error: 6.6139\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 51.60717\n",
      "Epoch 228/1500\n",
      "143/143 [==============================] - 92s 646ms/step - loss: 54.3700 - root_mean_squared_error: 7.3666 - mean_absolute_error: 5.8722 - val_loss: 63.5362 - val_root_mean_squared_error: 7.9710 - val_mean_absolute_error: 6.5693\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 51.60717\n",
      "\n",
      "Epoch 00228: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "Epoch 229/1500\n",
      "143/143 [==============================] - 92s 641ms/step - loss: 53.5353 - root_mean_squared_error: 7.3149 - mean_absolute_error: 5.9623 - val_loss: 76.7287 - val_root_mean_squared_error: 8.7595 - val_mean_absolute_error: 6.3606\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 51.60717\n",
      "Epoch 230/1500\n",
      "143/143 [==============================] - 90s 631ms/step - loss: 49.1127 - root_mean_squared_error: 7.0066 - mean_absolute_error: 5.6137 - val_loss: 77.4127 - val_root_mean_squared_error: 8.7984 - val_mean_absolute_error: 6.9205\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 51.60717\n",
      "Epoch 231/1500\n",
      "143/143 [==============================] - 91s 636ms/step - loss: 50.8635 - root_mean_squared_error: 7.1286 - mean_absolute_error: 5.6653 - val_loss: 72.0814 - val_root_mean_squared_error: 8.4901 - val_mean_absolute_error: 6.8694\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 51.60717\n",
      "Epoch 232/1500\n",
      "143/143 [==============================] - 91s 633ms/step - loss: 50.5279 - root_mean_squared_error: 7.1040 - mean_absolute_error: 5.7142 - val_loss: 60.4896 - val_root_mean_squared_error: 7.7775 - val_mean_absolute_error: 6.4248\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 51.60717\n",
      "Epoch 233/1500\n",
      "143/143 [==============================] - 91s 637ms/step - loss: 54.3922 - root_mean_squared_error: 7.3712 - mean_absolute_error: 6.0098 - val_loss: 66.0624 - val_root_mean_squared_error: 8.1279 - val_mean_absolute_error: 6.6691\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 51.60717\n",
      "Epoch 234/1500\n",
      "143/143 [==============================] - 93s 653ms/step - loss: 49.2723 - root_mean_squared_error: 7.0174 - mean_absolute_error: 5.7672 - val_loss: 62.7762 - val_root_mean_squared_error: 7.9231 - val_mean_absolute_error: 6.4566\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 51.60717\n",
      "Epoch 235/1500\n",
      "143/143 [==============================] - 91s 638ms/step - loss: 50.1831 - root_mean_squared_error: 7.0817 - mean_absolute_error: 5.6322 - val_loss: 68.9649 - val_root_mean_squared_error: 8.3045 - val_mean_absolute_error: 6.7989\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 51.60717\n",
      "Epoch 236/1500\n",
      "143/143 [==============================] - 92s 643ms/step - loss: 48.3845 - root_mean_squared_error: 6.9527 - mean_absolute_error: 5.5803 - val_loss: 65.5416 - val_root_mean_squared_error: 8.0958 - val_mean_absolute_error: 6.3948\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 51.60717\n",
      "Epoch 237/1500\n",
      "143/143 [==============================] - 90s 628ms/step - loss: 46.8816 - root_mean_squared_error: 6.8457 - mean_absolute_error: 5.5741 - val_loss: 67.2660 - val_root_mean_squared_error: 8.2016 - val_mean_absolute_error: 6.6943\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 51.60717\n",
      "Epoch 238/1500\n",
      "143/143 [==============================] - 92s 647ms/step - loss: 51.8354 - root_mean_squared_error: 7.1975 - mean_absolute_error: 5.8152 - val_loss: 58.8560 - val_root_mean_squared_error: 7.6718 - val_mean_absolute_error: 6.1839\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 51.60717\n",
      "Epoch 239/1500\n",
      "143/143 [==============================] - 91s 635ms/step - loss: 52.1143 - root_mean_squared_error: 7.2105 - mean_absolute_error: 5.7782 - val_loss: 55.1014 - val_root_mean_squared_error: 7.4230 - val_mean_absolute_error: 5.9301\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 51.60717\n",
      "Epoch 240/1500\n",
      "143/143 [==============================] - 91s 638ms/step - loss: 53.0581 - root_mean_squared_error: 7.2809 - mean_absolute_error: 5.8638 - val_loss: 75.1722 - val_root_mean_squared_error: 8.6702 - val_mean_absolute_error: 6.8129\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 51.60717\n",
      "Epoch 241/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 93s 649ms/step - loss: 47.4824 - root_mean_squared_error: 6.8890 - mean_absolute_error: 5.4390 - val_loss: 66.1820 - val_root_mean_squared_error: 8.1352 - val_mean_absolute_error: 6.4028\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 51.60717\n",
      "Epoch 242/1500\n",
      "143/143 [==============================] - 91s 635ms/step - loss: 48.2756 - root_mean_squared_error: 6.9446 - mean_absolute_error: 5.6467 - val_loss: 68.9743 - val_root_mean_squared_error: 8.3051 - val_mean_absolute_error: 6.8368\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 51.60717\n",
      "Epoch 243/1500\n",
      "143/143 [==============================] - 90s 627ms/step - loss: 48.9278 - root_mean_squared_error: 6.9846 - mean_absolute_error: 5.6127 - val_loss: 65.1797 - val_root_mean_squared_error: 8.0734 - val_mean_absolute_error: 6.5285\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 51.60717\n",
      "Epoch 244/1500\n",
      "143/143 [==============================] - 88s 616ms/step - loss: 48.3505 - root_mean_squared_error: 6.9512 - mean_absolute_error: 5.5338 - val_loss: 72.8381 - val_root_mean_squared_error: 8.5345 - val_mean_absolute_error: 6.8036\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 51.60717\n",
      "Epoch 245/1500\n",
      "143/143 [==============================] - 88s 612ms/step - loss: 47.9539 - root_mean_squared_error: 6.9226 - mean_absolute_error: 5.6206 - val_loss: 66.2231 - val_root_mean_squared_error: 8.1378 - val_mean_absolute_error: 6.6967\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 51.60717\n",
      "Epoch 246/1500\n",
      "143/143 [==============================] - 88s 615ms/step - loss: 44.9984 - root_mean_squared_error: 6.7042 - mean_absolute_error: 5.4215 - val_loss: 58.2696 - val_root_mean_squared_error: 7.6334 - val_mean_absolute_error: 6.4803\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 51.60717\n",
      "Epoch 247/1500\n",
      "143/143 [==============================] - 89s 621ms/step - loss: 53.2625 - root_mean_squared_error: 7.2972 - mean_absolute_error: 5.9166 - val_loss: 66.3645 - val_root_mean_squared_error: 8.1464 - val_mean_absolute_error: 6.4157\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 51.60717\n",
      "Epoch 248/1500\n",
      "143/143 [==============================] - 89s 619ms/step - loss: 50.7393 - root_mean_squared_error: 7.1207 - mean_absolute_error: 5.7390 - val_loss: 73.4400 - val_root_mean_squared_error: 8.5697 - val_mean_absolute_error: 6.6554\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 51.60717\n",
      "Epoch 249/1500\n",
      "143/143 [==============================] - 88s 616ms/step - loss: 59.1921 - root_mean_squared_error: 7.6902 - mean_absolute_error: 6.2567 - val_loss: 99.6664 - val_root_mean_squared_error: 9.9833 - val_mean_absolute_error: 6.6987\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 51.60717\n",
      "Epoch 250/1500\n",
      "143/143 [==============================] - 90s 633ms/step - loss: 49.0315 - root_mean_squared_error: 6.9967 - mean_absolute_error: 5.6681 - val_loss: 58.6647 - val_root_mean_squared_error: 7.6593 - val_mean_absolute_error: 6.2140\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 51.60717\n",
      "Epoch 251/1500\n",
      "143/143 [==============================] - 92s 645ms/step - loss: 47.8931 - root_mean_squared_error: 6.9178 - mean_absolute_error: 5.5208 - val_loss: 58.1740 - val_root_mean_squared_error: 7.6272 - val_mean_absolute_error: 6.1343\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 51.60717\n",
      "Epoch 252/1500\n",
      "143/143 [==============================] - 91s 636ms/step - loss: 50.4738 - root_mean_squared_error: 7.1018 - mean_absolute_error: 5.7576 - val_loss: 61.6525 - val_root_mean_squared_error: 7.8519 - val_mean_absolute_error: 6.3797\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 51.60717\n",
      "Epoch 253/1500\n",
      "143/143 [==============================] - 91s 636ms/step - loss: 49.7503 - root_mean_squared_error: 7.0516 - mean_absolute_error: 5.6363 - val_loss: 64.7641 - val_root_mean_squared_error: 8.0476 - val_mean_absolute_error: 6.4630\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 51.60717\n",
      "Epoch 254/1500\n",
      "143/143 [==============================] - 90s 630ms/step - loss: 48.6659 - root_mean_squared_error: 6.9693 - mean_absolute_error: 5.5613 - val_loss: 64.7935 - val_root_mean_squared_error: 8.0494 - val_mean_absolute_error: 6.3676\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 51.60717\n",
      "Epoch 255/1500\n",
      "143/143 [==============================] - 91s 637ms/step - loss: 50.7911 - root_mean_squared_error: 7.1230 - mean_absolute_error: 5.6864 - val_loss: 64.6017 - val_root_mean_squared_error: 8.0375 - val_mean_absolute_error: 6.4670\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 51.60717\n",
      "Epoch 256/1500\n",
      "143/143 [==============================] - 90s 632ms/step - loss: 48.5957 - root_mean_squared_error: 6.9702 - mean_absolute_error: 5.5626 - val_loss: 66.6091 - val_root_mean_squared_error: 8.1614 - val_mean_absolute_error: 6.5208\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 51.60717\n",
      "Epoch 257/1500\n",
      "143/143 [==============================] - 91s 637ms/step - loss: 48.4855 - root_mean_squared_error: 6.9556 - mean_absolute_error: 5.6212 - val_loss: 65.6027 - val_root_mean_squared_error: 8.0995 - val_mean_absolute_error: 6.3651\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 51.60717\n",
      "Epoch 258/1500\n",
      "143/143 [==============================] - 92s 641ms/step - loss: 49.1823 - root_mean_squared_error: 7.0057 - mean_absolute_error: 5.6512 - val_loss: 65.5864 - val_root_mean_squared_error: 8.0985 - val_mean_absolute_error: 6.3671\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 51.60717\n",
      "Epoch 259/1500\n",
      "143/143 [==============================] - 91s 633ms/step - loss: 54.4564 - root_mean_squared_error: 7.3743 - mean_absolute_error: 5.9710 - val_loss: 65.5395 - val_root_mean_squared_error: 8.0956 - val_mean_absolute_error: 6.3675\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 51.60717\n",
      "Epoch 260/1500\n",
      "143/143 [==============================] - 90s 632ms/step - loss: 51.5074 - root_mean_squared_error: 7.1756 - mean_absolute_error: 5.8862 - val_loss: 61.6545 - val_root_mean_squared_error: 7.8520 - val_mean_absolute_error: 6.1804\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 51.60717\n",
      "Epoch 261/1500\n",
      "143/143 [==============================] - 92s 642ms/step - loss: 49.0619 - root_mean_squared_error: 7.0020 - mean_absolute_error: 5.5026 - val_loss: 69.1090 - val_root_mean_squared_error: 8.3132 - val_mean_absolute_error: 6.6890\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 51.60717\n",
      "Epoch 262/1500\n",
      "143/143 [==============================] - 90s 627ms/step - loss: 52.6634 - root_mean_squared_error: 7.2506 - mean_absolute_error: 5.8132 - val_loss: 66.4105 - val_root_mean_squared_error: 8.1493 - val_mean_absolute_error: 6.5547\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 51.60717\n",
      "Epoch 263/1500\n",
      "143/143 [==============================] - 91s 634ms/step - loss: 51.6061 - root_mean_squared_error: 7.1825 - mean_absolute_error: 5.8466 - val_loss: 90.1609 - val_root_mean_squared_error: 9.4953 - val_mean_absolute_error: 7.2005\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 51.60717\n",
      "Epoch 264/1500\n",
      "143/143 [==============================] - 91s 634ms/step - loss: 55.1760 - root_mean_squared_error: 7.4230 - mean_absolute_error: 5.9315 - val_loss: 55.3654 - val_root_mean_squared_error: 7.4408 - val_mean_absolute_error: 5.8121\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 51.60717\n",
      "Epoch 265/1500\n",
      "143/143 [==============================] - 91s 640ms/step - loss: 50.6273 - root_mean_squared_error: 7.1140 - mean_absolute_error: 5.7955 - val_loss: 85.2305 - val_root_mean_squared_error: 9.2320 - val_mean_absolute_error: 6.5008\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 51.60717\n",
      "Epoch 266/1500\n",
      "143/143 [==============================] - 92s 643ms/step - loss: 51.1883 - root_mean_squared_error: 7.1509 - mean_absolute_error: 5.6958 - val_loss: 60.0798 - val_root_mean_squared_error: 7.7511 - val_mean_absolute_error: 6.3491\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 51.60717\n",
      "Epoch 267/1500\n",
      "143/143 [==============================] - 91s 639ms/step - loss: 48.4602 - root_mean_squared_error: 6.9602 - mean_absolute_error: 5.6357 - val_loss: 58.7184 - val_root_mean_squared_error: 7.6628 - val_mean_absolute_error: 6.0279\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 51.60717\n",
      "Epoch 268/1500\n",
      "143/143 [==============================] - 91s 633ms/step - loss: 54.4686 - root_mean_squared_error: 7.3758 - mean_absolute_error: 5.8081 - val_loss: 61.7105 - val_root_mean_squared_error: 7.8556 - val_mean_absolute_error: 6.3222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00268: val_loss did not improve from 51.60717\n",
      "Epoch 269/1500\n",
      "143/143 [==============================] - 90s 632ms/step - loss: 49.6948 - root_mean_squared_error: 7.0430 - mean_absolute_error: 5.5605 - val_loss: 66.4047 - val_root_mean_squared_error: 8.1489 - val_mean_absolute_error: 6.6196\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 51.60717\n",
      "Epoch 270/1500\n",
      "143/143 [==============================] - 90s 630ms/step - loss: 48.8633 - root_mean_squared_error: 6.9869 - mean_absolute_error: 5.5902 - val_loss: 71.9904 - val_root_mean_squared_error: 8.4847 - val_mean_absolute_error: 6.6699\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 51.60717\n",
      "Epoch 271/1500\n",
      "143/143 [==============================] - 91s 635ms/step - loss: 51.0616 - root_mean_squared_error: 7.1275 - mean_absolute_error: 5.7137 - val_loss: 68.7816 - val_root_mean_squared_error: 8.2935 - val_mean_absolute_error: 6.5994\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 51.60717\n",
      "Epoch 272/1500\n",
      "143/143 [==============================] - 88s 616ms/step - loss: 51.5025 - root_mean_squared_error: 7.1671 - mean_absolute_error: 5.8713 - val_loss: 64.6850 - val_root_mean_squared_error: 8.0427 - val_mean_absolute_error: 6.3601\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 51.60717\n",
      "Epoch 273/1500\n",
      "143/143 [==============================] - 91s 638ms/step - loss: 48.6758 - root_mean_squared_error: 6.9702 - mean_absolute_error: 5.6256 - val_loss: 62.9630 - val_root_mean_squared_error: 7.9349 - val_mean_absolute_error: 6.3193\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 51.60717\n",
      "Epoch 274/1500\n",
      "143/143 [==============================] - 91s 633ms/step - loss: 49.0779 - root_mean_squared_error: 7.0034 - mean_absolute_error: 5.6632 - val_loss: 63.5323 - val_root_mean_squared_error: 7.9707 - val_mean_absolute_error: 6.2868\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 51.60717\n",
      "Epoch 275/1500\n",
      "143/143 [==============================] - 91s 633ms/step - loss: 52.5130 - root_mean_squared_error: 7.2393 - mean_absolute_error: 5.8277 - val_loss: 60.7718 - val_root_mean_squared_error: 7.7956 - val_mean_absolute_error: 6.3770\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 51.60717\n",
      "Epoch 276/1500\n",
      "143/143 [==============================] - 88s 616ms/step - loss: 50.2573 - root_mean_squared_error: 7.0839 - mean_absolute_error: 5.6847 - val_loss: 51.7590 - val_root_mean_squared_error: 7.1944 - val_mean_absolute_error: 5.8428\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 51.60717\n",
      "Epoch 277/1500\n",
      "143/143 [==============================] - 90s 631ms/step - loss: 51.4712 - root_mean_squared_error: 7.1697 - mean_absolute_error: 5.7626 - val_loss: 62.4040 - val_root_mean_squared_error: 7.8996 - val_mean_absolute_error: 6.5454\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 51.60717\n",
      "Epoch 278/1500\n",
      "143/143 [==============================] - 90s 628ms/step - loss: 50.7169 - root_mean_squared_error: 7.1194 - mean_absolute_error: 5.7023 - val_loss: 71.4963 - val_root_mean_squared_error: 8.4556 - val_mean_absolute_error: 6.6556\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 51.60717\n",
      "\n",
      "Epoch 00278: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "Epoch 279/1500\n",
      "143/143 [==============================] - 89s 622ms/step - loss: 51.4784 - root_mean_squared_error: 7.1709 - mean_absolute_error: 5.8026 - val_loss: 63.1936 - val_root_mean_squared_error: 7.9494 - val_mean_absolute_error: 6.3126\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 51.60717\n",
      "Epoch 280/1500\n",
      "143/143 [==============================] - 90s 632ms/step - loss: 48.2270 - root_mean_squared_error: 6.9402 - mean_absolute_error: 5.6067 - val_loss: 62.7547 - val_root_mean_squared_error: 7.9218 - val_mean_absolute_error: 6.3203\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 51.60717\n",
      "Epoch 281/1500\n",
      "143/143 [==============================] - 91s 633ms/step - loss: 50.0737 - root_mean_squared_error: 7.0751 - mean_absolute_error: 5.6889 - val_loss: 60.2050 - val_root_mean_squared_error: 7.7592 - val_mean_absolute_error: 6.3275\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 51.60717\n",
      "Epoch 282/1500\n",
      "143/143 [==============================] - 90s 630ms/step - loss: 51.9563 - root_mean_squared_error: 7.2045 - mean_absolute_error: 5.7681 - val_loss: 53.6983 - val_root_mean_squared_error: 7.3279 - val_mean_absolute_error: 6.0921\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 51.60717\n",
      "Epoch 283/1500\n",
      "143/143 [==============================] - 91s 636ms/step - loss: 46.5478 - root_mean_squared_error: 6.8204 - mean_absolute_error: 5.5412 - val_loss: 64.2615 - val_root_mean_squared_error: 8.0163 - val_mean_absolute_error: 6.2531\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 51.60717\n",
      "Epoch 284/1500\n",
      "143/143 [==============================] - 89s 622ms/step - loss: 46.6898 - root_mean_squared_error: 6.8289 - mean_absolute_error: 5.4232 - val_loss: 68.7330 - val_root_mean_squared_error: 8.2905 - val_mean_absolute_error: 6.7691\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 51.60717\n",
      "Epoch 285/1500\n",
      "143/143 [==============================] - 91s 634ms/step - loss: 44.7136 - root_mean_squared_error: 6.6846 - mean_absolute_error: 5.4429 - val_loss: 66.8083 - val_root_mean_squared_error: 8.1736 - val_mean_absolute_error: 6.4893\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 51.60717\n",
      "Epoch 286/1500\n",
      "143/143 [==============================] - 91s 634ms/step - loss: 46.8595 - root_mean_squared_error: 6.8405 - mean_absolute_error: 5.4600 - val_loss: 66.1382 - val_root_mean_squared_error: 8.1325 - val_mean_absolute_error: 6.5675\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 51.60717\n",
      "Epoch 287/1500\n",
      "143/143 [==============================] - 90s 627ms/step - loss: 45.1621 - root_mean_squared_error: 6.7176 - mean_absolute_error: 5.4162 - val_loss: 58.8978 - val_root_mean_squared_error: 7.6745 - val_mean_absolute_error: 6.1691\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 51.60717\n",
      "Epoch 288/1500\n",
      "143/143 [==============================] - 91s 634ms/step - loss: 51.6547 - root_mean_squared_error: 7.1820 - mean_absolute_error: 5.8609 - val_loss: 58.6705 - val_root_mean_squared_error: 7.6597 - val_mean_absolute_error: 6.0135\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 51.60717\n",
      "Epoch 289/1500\n",
      "143/143 [==============================] - 91s 634ms/step - loss: 53.2544 - root_mean_squared_error: 7.2867 - mean_absolute_error: 5.8590 - val_loss: 69.9233 - val_root_mean_squared_error: 8.3620 - val_mean_absolute_error: 6.7104\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 51.60717\n",
      "Epoch 290/1500\n",
      "143/143 [==============================] - 90s 632ms/step - loss: 47.7309 - root_mean_squared_error: 6.9059 - mean_absolute_error: 5.5704 - val_loss: 61.9058 - val_root_mean_squared_error: 7.8680 - val_mean_absolute_error: 6.2544\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 51.60717\n",
      "Epoch 291/1500\n",
      "143/143 [==============================] - 91s 638ms/step - loss: 46.4476 - root_mean_squared_error: 6.8067 - mean_absolute_error: 5.5051 - val_loss: 66.9914 - val_root_mean_squared_error: 8.1848 - val_mean_absolute_error: 6.4089\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 51.60717\n",
      "Epoch 292/1500\n",
      "143/143 [==============================] - 91s 635ms/step - loss: 50.6160 - root_mean_squared_error: 7.1045 - mean_absolute_error: 5.6946 - val_loss: 62.7346 - val_root_mean_squared_error: 7.9205 - val_mean_absolute_error: 6.3729\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 51.60717\n",
      "Epoch 293/1500\n",
      "143/143 [==============================] - 92s 641ms/step - loss: 46.1796 - root_mean_squared_error: 6.7933 - mean_absolute_error: 5.5321 - val_loss: 66.7015 - val_root_mean_squared_error: 8.1671 - val_mean_absolute_error: 6.3610\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 51.60717\n",
      "Epoch 294/1500\n",
      "143/143 [==============================] - 92s 646ms/step - loss: 51.6462 - root_mean_squared_error: 7.1803 - mean_absolute_error: 5.7028 - val_loss: 63.2177 - val_root_mean_squared_error: 7.9510 - val_mean_absolute_error: 6.6379\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 51.60717\n",
      "Epoch 295/1500\n",
      "143/143 [==============================] - 91s 636ms/step - loss: 49.6013 - root_mean_squared_error: 7.0391 - mean_absolute_error: 5.6214 - val_loss: 78.5907 - val_root_mean_squared_error: 8.8651 - val_mean_absolute_error: 6.5446\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 51.60717\n",
      "Epoch 296/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 90s 632ms/step - loss: 52.0311 - root_mean_squared_error: 7.2117 - mean_absolute_error: 5.8255 - val_loss: 68.0905 - val_root_mean_squared_error: 8.2517 - val_mean_absolute_error: 6.5943\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 51.60717\n",
      "Epoch 297/1500\n",
      "143/143 [==============================] - 91s 639ms/step - loss: 52.5157 - root_mean_squared_error: 7.2415 - mean_absolute_error: 5.8090 - val_loss: 68.0638 - val_root_mean_squared_error: 8.2501 - val_mean_absolute_error: 6.5434\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 51.60717\n",
      "Epoch 298/1500\n",
      "143/143 [==============================] - 92s 644ms/step - loss: 48.5344 - root_mean_squared_error: 6.9594 - mean_absolute_error: 5.5647 - val_loss: 57.6487 - val_root_mean_squared_error: 7.5927 - val_mean_absolute_error: 6.0853\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 51.60717\n",
      "Epoch 299/1500\n",
      "143/143 [==============================] - 91s 633ms/step - loss: 49.6067 - root_mean_squared_error: 7.0400 - mean_absolute_error: 5.5705 - val_loss: 63.6562 - val_root_mean_squared_error: 7.9785 - val_mean_absolute_error: 6.0329\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 51.60717\n",
      "Epoch 300/1500\n",
      "143/143 [==============================] - 91s 639ms/step - loss: 48.1349 - root_mean_squared_error: 6.9359 - mean_absolute_error: 5.4715 - val_loss: 71.4221 - val_root_mean_squared_error: 8.4512 - val_mean_absolute_error: 6.6000\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 51.60717\n",
      "Epoch 301/1500\n",
      "143/143 [==============================] - 90s 627ms/step - loss: 47.9717 - root_mean_squared_error: 6.9226 - mean_absolute_error: 5.6208 - val_loss: 62.7362 - val_root_mean_squared_error: 7.9206 - val_mean_absolute_error: 6.1841\n",
      "\n",
      "Epoch 00301: val_loss did not improve from 51.60717\n",
      "Epoch 302/1500\n",
      "143/143 [==============================] - 91s 636ms/step - loss: 47.0898 - root_mean_squared_error: 6.8594 - mean_absolute_error: 5.5265 - val_loss: 58.4853 - val_root_mean_squared_error: 7.6476 - val_mean_absolute_error: 6.1809\n",
      "\n",
      "Epoch 00302: val_loss did not improve from 51.60717\n",
      "Epoch 303/1500\n",
      "143/143 [==============================] - 91s 637ms/step - loss: 48.6011 - root_mean_squared_error: 6.9693 - mean_absolute_error: 5.6190 - val_loss: 62.7619 - val_root_mean_squared_error: 7.9222 - val_mean_absolute_error: 6.5565\n",
      "\n",
      "Epoch 00303: val_loss did not improve from 51.60717\n",
      "Epoch 304/1500\n",
      "143/143 [==============================] - 91s 634ms/step - loss: 45.9739 - root_mean_squared_error: 6.7775 - mean_absolute_error: 5.6086 - val_loss: 84.2881 - val_root_mean_squared_error: 9.1809 - val_mean_absolute_error: 6.8167\n",
      "\n",
      "Epoch 00304: val_loss did not improve from 51.60717\n",
      "Epoch 305/1500\n",
      "143/143 [==============================] - 91s 637ms/step - loss: 46.5969 - root_mean_squared_error: 6.8239 - mean_absolute_error: 5.5284 - val_loss: 64.1758 - val_root_mean_squared_error: 8.0110 - val_mean_absolute_error: 6.4988\n",
      "\n",
      "Epoch 00305: val_loss did not improve from 51.60717\n",
      "Epoch 306/1500\n",
      "143/143 [==============================] - 92s 641ms/step - loss: 49.6163 - root_mean_squared_error: 7.0430 - mean_absolute_error: 5.7268 - val_loss: 62.3636 - val_root_mean_squared_error: 7.8971 - val_mean_absolute_error: 6.4367\n",
      "\n",
      "Epoch 00306: val_loss did not improve from 51.60717\n",
      "Epoch 307/1500\n",
      "143/143 [==============================] - 91s 634ms/step - loss: 50.9331 - root_mean_squared_error: 7.1337 - mean_absolute_error: 5.7167 - val_loss: 55.4494 - val_root_mean_squared_error: 7.4464 - val_mean_absolute_error: 5.8772\n",
      "\n",
      "Epoch 00307: val_loss did not improve from 51.60717\n",
      "Epoch 308/1500\n",
      "143/143 [==============================] - 91s 634ms/step - loss: 57.0562 - root_mean_squared_error: 7.5469 - mean_absolute_error: 6.0245 - val_loss: 67.1426 - val_root_mean_squared_error: 8.1941 - val_mean_absolute_error: 6.7628\n",
      "\n",
      "Epoch 00308: val_loss did not improve from 51.60717\n",
      "Epoch 309/1500\n",
      "143/143 [==============================] - 92s 646ms/step - loss: 47.5989 - root_mean_squared_error: 6.8959 - mean_absolute_error: 5.5876 - val_loss: 64.7506 - val_root_mean_squared_error: 8.0468 - val_mean_absolute_error: 6.2486\n",
      "\n",
      "Epoch 00309: val_loss did not improve from 51.60717\n",
      "Epoch 310/1500\n",
      "143/143 [==============================] - 90s 631ms/step - loss: 48.2228 - root_mean_squared_error: 6.9388 - mean_absolute_error: 5.5876 - val_loss: 61.1364 - val_root_mean_squared_error: 7.8190 - val_mean_absolute_error: 6.3624\n",
      "\n",
      "Epoch 00310: val_loss did not improve from 51.60717\n",
      "Epoch 311/1500\n",
      "143/143 [==============================] - 91s 639ms/step - loss: 48.2162 - root_mean_squared_error: 6.9312 - mean_absolute_error: 5.4688 - val_loss: 57.5264 - val_root_mean_squared_error: 7.5846 - val_mean_absolute_error: 6.3237\n",
      "\n",
      "Epoch 00311: val_loss did not improve from 51.60717\n",
      "Epoch 312/1500\n",
      "143/143 [==============================] - 92s 641ms/step - loss: 51.6851 - root_mean_squared_error: 7.1868 - mean_absolute_error: 5.7863 - val_loss: 60.8182 - val_root_mean_squared_error: 7.7986 - val_mean_absolute_error: 6.4172\n",
      "\n",
      "Epoch 00312: val_loss did not improve from 51.60717\n",
      "Epoch 313/1500\n",
      "143/143 [==============================] - 90s 628ms/step - loss: 52.4500 - root_mean_squared_error: 7.2391 - mean_absolute_error: 5.9035 - val_loss: 70.5203 - val_root_mean_squared_error: 8.3976 - val_mean_absolute_error: 6.6167\n",
      "\n",
      "Epoch 00313: val_loss did not improve from 51.60717\n",
      "Epoch 314/1500\n",
      "143/143 [==============================] - 93s 648ms/step - loss: 46.8899 - root_mean_squared_error: 6.8320 - mean_absolute_error: 5.4740 - val_loss: 64.9889 - val_root_mean_squared_error: 8.0616 - val_mean_absolute_error: 6.3216\n",
      "\n",
      "Epoch 00314: val_loss did not improve from 51.60717\n",
      "Epoch 315/1500\n",
      "143/143 [==============================] - 92s 640ms/step - loss: 56.6245 - root_mean_squared_error: 7.5200 - mean_absolute_error: 6.0041 - val_loss: 98.2005 - val_root_mean_squared_error: 9.9096 - val_mean_absolute_error: 7.2725\n",
      "\n",
      "Epoch 00315: val_loss did not improve from 51.60717\n",
      "Epoch 316/1500\n",
      "143/143 [==============================] - 91s 637ms/step - loss: 49.5259 - root_mean_squared_error: 7.0337 - mean_absolute_error: 5.6682 - val_loss: 68.0346 - val_root_mean_squared_error: 8.2483 - val_mean_absolute_error: 6.7657\n",
      "\n",
      "Epoch 00316: val_loss did not improve from 51.60717\n",
      "Epoch 317/1500\n",
      "143/143 [==============================] - 89s 622ms/step - loss: 51.4146 - root_mean_squared_error: 7.1610 - mean_absolute_error: 5.6681 - val_loss: 66.7403 - val_root_mean_squared_error: 8.1695 - val_mean_absolute_error: 6.6308\n",
      "\n",
      "Epoch 00317: val_loss did not improve from 51.60717\n",
      "Epoch 318/1500\n",
      "143/143 [==============================] - 91s 636ms/step - loss: 51.8629 - root_mean_squared_error: 7.1972 - mean_absolute_error: 5.6845 - val_loss: 67.4914 - val_root_mean_squared_error: 8.2153 - val_mean_absolute_error: 6.6660\n",
      "\n",
      "Epoch 00318: val_loss did not improve from 51.60717\n",
      "Epoch 319/1500\n",
      "143/143 [==============================] - 90s 631ms/step - loss: 45.8040 - root_mean_squared_error: 6.7520 - mean_absolute_error: 5.4098 - val_loss: 59.4986 - val_root_mean_squared_error: 7.7135 - val_mean_absolute_error: 6.0320\n",
      "\n",
      "Epoch 00319: val_loss did not improve from 51.60717\n",
      "Epoch 320/1500\n",
      "143/143 [==============================] - 90s 633ms/step - loss: 50.0152 - root_mean_squared_error: 7.0678 - mean_absolute_error: 5.7255 - val_loss: 67.0031 - val_root_mean_squared_error: 8.1855 - val_mean_absolute_error: 6.7963\n",
      "\n",
      "Epoch 00320: val_loss did not improve from 51.60717\n",
      "Epoch 321/1500\n",
      "143/143 [==============================] - 91s 633ms/step - loss: 51.1405 - root_mean_squared_error: 7.1492 - mean_absolute_error: 5.7136 - val_loss: 60.2743 - val_root_mean_squared_error: 7.7637 - val_mean_absolute_error: 6.0450\n",
      "\n",
      "Epoch 00321: val_loss did not improve from 51.60717\n",
      "Epoch 322/1500\n",
      "143/143 [==============================] - 91s 637ms/step - loss: 47.4344 - root_mean_squared_error: 6.8835 - mean_absolute_error: 5.5413 - val_loss: 74.5174 - val_root_mean_squared_error: 8.6323 - val_mean_absolute_error: 6.9021\n",
      "\n",
      "Epoch 00322: val_loss did not improve from 51.60717\n",
      "Epoch 323/1500\n",
      "143/143 [==============================] - 90s 627ms/step - loss: 56.0919 - root_mean_squared_error: 7.4763 - mean_absolute_error: 5.9190 - val_loss: 61.3261 - val_root_mean_squared_error: 7.8311 - val_mean_absolute_error: 6.1927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00323: val_loss did not improve from 51.60717\n",
      "Epoch 324/1500\n",
      "143/143 [==============================] - 91s 635ms/step - loss: 50.7925 - root_mean_squared_error: 7.1204 - mean_absolute_error: 5.7234 - val_loss: 58.8398 - val_root_mean_squared_error: 7.6707 - val_mean_absolute_error: 6.3481\n",
      "\n",
      "Epoch 00324: val_loss did not improve from 51.60717\n",
      "Epoch 325/1500\n",
      "143/143 [==============================] - 92s 642ms/step - loss: 49.7355 - root_mean_squared_error: 7.0500 - mean_absolute_error: 5.7444 - val_loss: 61.8390 - val_root_mean_squared_error: 7.8638 - val_mean_absolute_error: 6.3203\n",
      "\n",
      "Epoch 00325: val_loss did not improve from 51.60717\n",
      "Epoch 326/1500\n",
      "143/143 [==============================] - 91s 638ms/step - loss: 49.4509 - root_mean_squared_error: 7.0230 - mean_absolute_error: 5.6665 - val_loss: 59.2194 - val_root_mean_squared_error: 7.6954 - val_mean_absolute_error: 6.2665\n",
      "\n",
      "Epoch 00326: val_loss did not improve from 51.60717\n",
      "Epoch 327/1500\n",
      "143/143 [==============================] - 93s 648ms/step - loss: 47.1994 - root_mean_squared_error: 6.8662 - mean_absolute_error: 5.5131 - val_loss: 61.2523 - val_root_mean_squared_error: 7.8264 - val_mean_absolute_error: 6.1677\n",
      "\n",
      "Epoch 00327: val_loss did not improve from 51.60717\n",
      "Epoch 328/1500\n",
      "143/143 [==============================] - 92s 643ms/step - loss: 52.0915 - root_mean_squared_error: 7.2162 - mean_absolute_error: 5.8128 - val_loss: 68.0661 - val_root_mean_squared_error: 8.2502 - val_mean_absolute_error: 6.4440\n",
      "\n",
      "Epoch 00328: val_loss did not improve from 51.60717\n",
      "\n",
      "Epoch 00328: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "Epoch 329/1500\n",
      "143/143 [==============================] - 92s 647ms/step - loss: 49.1336 - root_mean_squared_error: 7.0032 - mean_absolute_error: 5.6992 - val_loss: 57.7829 - val_root_mean_squared_error: 7.6015 - val_mean_absolute_error: 6.0713\n",
      "\n",
      "Epoch 00329: val_loss did not improve from 51.60717\n",
      "Epoch 330/1500\n",
      "143/143 [==============================] - 92s 641ms/step - loss: 51.4399 - root_mean_squared_error: 7.1437 - mean_absolute_error: 5.7116 - val_loss: 57.9148 - val_root_mean_squared_error: 7.6102 - val_mean_absolute_error: 6.2656\n",
      "\n",
      "Epoch 00330: val_loss did not improve from 51.60717\n",
      "Epoch 331/1500\n",
      "143/143 [==============================] - 92s 645ms/step - loss: 48.7748 - root_mean_squared_error: 6.9822 - mean_absolute_error: 5.6549 - val_loss: 69.7974 - val_root_mean_squared_error: 8.3545 - val_mean_absolute_error: 6.5801\n",
      "\n",
      "Epoch 00331: val_loss did not improve from 51.60717\n",
      "Epoch 332/1500\n",
      "143/143 [==============================] - 92s 645ms/step - loss: 49.1416 - root_mean_squared_error: 7.0045 - mean_absolute_error: 5.6255 - val_loss: 69.2181 - val_root_mean_squared_error: 8.3197 - val_mean_absolute_error: 6.8404\n",
      "\n",
      "Epoch 00332: val_loss did not improve from 51.60717\n",
      "Epoch 333/1500\n",
      "143/143 [==============================] - 92s 645ms/step - loss: 48.7689 - root_mean_squared_error: 6.9809 - mean_absolute_error: 5.6219 - val_loss: 55.5410 - val_root_mean_squared_error: 7.4526 - val_mean_absolute_error: 5.9600\n",
      "\n",
      "Epoch 00333: val_loss did not improve from 51.60717\n",
      "Epoch 334/1500\n",
      "143/143 [==============================] - 92s 642ms/step - loss: 47.3150 - root_mean_squared_error: 6.8751 - mean_absolute_error: 5.5384 - val_loss: 64.0563 - val_root_mean_squared_error: 8.0035 - val_mean_absolute_error: 6.3399\n",
      "\n",
      "Epoch 00334: val_loss did not improve from 51.60717\n",
      "Epoch 335/1500\n",
      "143/143 [==============================] - 93s 648ms/step - loss: 51.7522 - root_mean_squared_error: 7.1868 - mean_absolute_error: 5.7709 - val_loss: 61.9545 - val_root_mean_squared_error: 7.8711 - val_mean_absolute_error: 6.3297\n",
      "\n",
      "Epoch 00335: val_loss did not improve from 51.60717\n",
      "Epoch 336/1500\n",
      "143/143 [==============================] - 90s 633ms/step - loss: 48.1270 - root_mean_squared_error: 6.9366 - mean_absolute_error: 5.5318 - val_loss: 63.7436 - val_root_mean_squared_error: 7.9840 - val_mean_absolute_error: 6.0483\n",
      "\n",
      "Epoch 00336: val_loss did not improve from 51.60717\n",
      "Epoch 337/1500\n",
      "143/143 [==============================] - 93s 653ms/step - loss: 54.9343 - root_mean_squared_error: 7.4049 - mean_absolute_error: 5.9767 - val_loss: 59.9567 - val_root_mean_squared_error: 7.7432 - val_mean_absolute_error: 6.2314\n",
      "\n",
      "Epoch 00337: val_loss did not improve from 51.60717\n",
      "Epoch 338/1500\n",
      "143/143 [==============================] - 91s 640ms/step - loss: 44.6031 - root_mean_squared_error: 6.6712 - mean_absolute_error: 5.3599 - val_loss: 66.1931 - val_root_mean_squared_error: 8.1359 - val_mean_absolute_error: 6.5166\n",
      "\n",
      "Epoch 00338: val_loss did not improve from 51.60717\n",
      "Epoch 339/1500\n",
      "143/143 [==============================] - 92s 642ms/step - loss: 43.1912 - root_mean_squared_error: 6.5657 - mean_absolute_error: 5.2359 - val_loss: 57.7564 - val_root_mean_squared_error: 7.5998 - val_mean_absolute_error: 5.9901\n",
      "\n",
      "Epoch 00339: val_loss did not improve from 51.60717\n",
      "Epoch 340/1500\n",
      "143/143 [==============================] - 91s 635ms/step - loss: 46.5412 - root_mean_squared_error: 6.8184 - mean_absolute_error: 5.5342 - val_loss: 65.5359 - val_root_mean_squared_error: 8.0954 - val_mean_absolute_error: 6.5518\n",
      "\n",
      "Epoch 00340: val_loss did not improve from 51.60717\n",
      "Epoch 341/1500\n",
      "143/143 [==============================] - 93s 650ms/step - loss: 49.3067 - root_mean_squared_error: 7.0199 - mean_absolute_error: 5.6686 - val_loss: 63.6000 - val_root_mean_squared_error: 7.9750 - val_mean_absolute_error: 6.2398\n",
      "\n",
      "Epoch 00341: val_loss did not improve from 51.60717\n",
      "Epoch 342/1500\n",
      "143/143 [==============================] - 91s 635ms/step - loss: 50.4582 - root_mean_squared_error: 7.0972 - mean_absolute_error: 5.6424 - val_loss: 60.4084 - val_root_mean_squared_error: 7.7723 - val_mean_absolute_error: 6.2645\n",
      "\n",
      "Epoch 00342: val_loss did not improve from 51.60717\n",
      "Epoch 343/1500\n",
      "143/143 [==============================] - 90s 631ms/step - loss: 47.7835 - root_mean_squared_error: 6.9078 - mean_absolute_error: 5.6009 - val_loss: 60.6517 - val_root_mean_squared_error: 7.7879 - val_mean_absolute_error: 6.2387\n",
      "\n",
      "Epoch 00343: val_loss did not improve from 51.60717\n",
      "Epoch 344/1500\n",
      "143/143 [==============================] - 93s 650ms/step - loss: 47.8942 - root_mean_squared_error: 6.9189 - mean_absolute_error: 5.5392 - val_loss: 67.3223 - val_root_mean_squared_error: 8.2050 - val_mean_absolute_error: 6.5042\n",
      "\n",
      "Epoch 00344: val_loss did not improve from 51.60717\n",
      "Epoch 345/1500\n",
      "143/143 [==============================] - 92s 643ms/step - loss: 43.5991 - root_mean_squared_error: 6.5920 - mean_absolute_error: 5.2636 - val_loss: 63.6549 - val_root_mean_squared_error: 7.9784 - val_mean_absolute_error: 6.2696\n",
      "\n",
      "Epoch 00345: val_loss did not improve from 51.60717\n",
      "Epoch 346/1500\n",
      "143/143 [==============================] - 91s 639ms/step - loss: 48.7592 - root_mean_squared_error: 6.9809 - mean_absolute_error: 5.5482 - val_loss: 61.6993 - val_root_mean_squared_error: 7.8549 - val_mean_absolute_error: 6.4499\n",
      "\n",
      "Epoch 00346: val_loss did not improve from 51.60717\n",
      "Epoch 347/1500\n",
      "143/143 [==============================] - 93s 648ms/step - loss: 45.8057 - root_mean_squared_error: 6.7608 - mean_absolute_error: 5.4281 - val_loss: 63.5132 - val_root_mean_squared_error: 7.9695 - val_mean_absolute_error: 6.3774\n",
      "\n",
      "Epoch 00347: val_loss did not improve from 51.60717\n",
      "Epoch 348/1500\n",
      "143/143 [==============================] - 91s 639ms/step - loss: 51.9243 - root_mean_squared_error: 7.1852 - mean_absolute_error: 5.8519 - val_loss: 65.4867 - val_root_mean_squared_error: 8.0924 - val_mean_absolute_error: 6.3719\n",
      "\n",
      "Epoch 00348: val_loss did not improve from 51.60717\n",
      "Epoch 349/1500\n",
      "143/143 [==============================] - 92s 640ms/step - loss: 49.4740 - root_mean_squared_error: 7.0243 - mean_absolute_error: 5.6311 - val_loss: 57.0299 - val_root_mean_squared_error: 7.5518 - val_mean_absolute_error: 5.9688\n",
      "\n",
      "Epoch 00349: val_loss did not improve from 51.60717\n",
      "Epoch 350/1500\n",
      "143/143 [==============================] - 93s 650ms/step - loss: 46.3120 - root_mean_squared_error: 6.8041 - mean_absolute_error: 5.4807 - val_loss: 63.4954 - val_root_mean_squared_error: 7.9684 - val_mean_absolute_error: 6.1540\n",
      "\n",
      "Epoch 00350: val_loss did not improve from 51.60717\n",
      "Epoch 351/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 92s 642ms/step - loss: 46.9661 - root_mean_squared_error: 6.8459 - mean_absolute_error: 5.5580 - val_loss: 60.7570 - val_root_mean_squared_error: 7.7947 - val_mean_absolute_error: 6.1445\n",
      "\n",
      "Epoch 00351: val_loss did not improve from 51.60717\n",
      "Epoch 352/1500\n",
      "143/143 [==============================] - 91s 638ms/step - loss: 47.3128 - root_mean_squared_error: 6.8743 - mean_absolute_error: 5.5568 - val_loss: 64.8969 - val_root_mean_squared_error: 8.0559 - val_mean_absolute_error: 6.6133\n",
      "\n",
      "Epoch 00352: val_loss did not improve from 51.60717\n",
      "Epoch 353/1500\n",
      "143/143 [==============================] - 92s 647ms/step - loss: 49.4599 - root_mean_squared_error: 7.0276 - mean_absolute_error: 5.6301 - val_loss: 73.7757 - val_root_mean_squared_error: 8.5893 - val_mean_absolute_error: 6.8152\n",
      "\n",
      "Epoch 00353: val_loss did not improve from 51.60717\n",
      "Epoch 354/1500\n",
      "143/143 [==============================] - 94s 656ms/step - loss: 49.8391 - root_mean_squared_error: 7.0551 - mean_absolute_error: 5.6219 - val_loss: 58.7557 - val_root_mean_squared_error: 7.6652 - val_mean_absolute_error: 6.1868\n",
      "\n",
      "Epoch 00354: val_loss did not improve from 51.60717\n",
      "Epoch 355/1500\n",
      "143/143 [==============================] - 91s 638ms/step - loss: 53.9882 - root_mean_squared_error: 7.3417 - mean_absolute_error: 5.9264 - val_loss: 76.9344 - val_root_mean_squared_error: 8.7712 - val_mean_absolute_error: 7.1389\n",
      "\n",
      "Epoch 00355: val_loss did not improve from 51.60717\n",
      "Epoch 356/1500\n",
      "143/143 [==============================] - 92s 646ms/step - loss: 47.7477 - root_mean_squared_error: 6.9092 - mean_absolute_error: 5.5625 - val_loss: 54.9268 - val_root_mean_squared_error: 7.4113 - val_mean_absolute_error: 5.9464\n",
      "\n",
      "Epoch 00356: val_loss did not improve from 51.60717\n",
      "Epoch 357/1500\n",
      "143/143 [==============================] - 94s 654ms/step - loss: 49.6650 - root_mean_squared_error: 7.0436 - mean_absolute_error: 5.7051 - val_loss: 59.0380 - val_root_mean_squared_error: 7.6836 - val_mean_absolute_error: 6.2227\n",
      "\n",
      "Epoch 00357: val_loss did not improve from 51.60717\n",
      "Epoch 358/1500\n",
      "143/143 [==============================] - 92s 647ms/step - loss: 47.9646 - root_mean_squared_error: 6.9234 - mean_absolute_error: 5.5316 - val_loss: 71.6259 - val_root_mean_squared_error: 8.4632 - val_mean_absolute_error: 6.6583\n",
      "\n",
      "Epoch 00358: val_loss did not improve from 51.60717\n",
      "Epoch 359/1500\n",
      "143/143 [==============================] - 94s 661ms/step - loss: 53.6335 - root_mean_squared_error: 7.3193 - mean_absolute_error: 5.9331 - val_loss: 62.9342 - val_root_mean_squared_error: 7.9331 - val_mean_absolute_error: 6.3374\n",
      "\n",
      "Epoch 00359: val_loss did not improve from 51.60717\n",
      "Epoch 360/1500\n",
      "143/143 [==============================] - 91s 635ms/step - loss: 50.0683 - root_mean_squared_error: 7.0670 - mean_absolute_error: 5.6885 - val_loss: 71.2415 - val_root_mean_squared_error: 8.4405 - val_mean_absolute_error: 6.6667\n",
      "\n",
      "Epoch 00360: val_loss did not improve from 51.60717\n",
      "Epoch 361/1500\n",
      "143/143 [==============================] - 92s 646ms/step - loss: 49.1881 - root_mean_squared_error: 7.0017 - mean_absolute_error: 5.5584 - val_loss: 73.3644 - val_root_mean_squared_error: 8.5653 - val_mean_absolute_error: 6.9534\n",
      "\n",
      "Epoch 00361: val_loss did not improve from 51.60717\n",
      "Epoch 362/1500\n",
      "143/143 [==============================] - 93s 650ms/step - loss: 51.5954 - root_mean_squared_error: 7.1773 - mean_absolute_error: 5.8509 - val_loss: 64.1919 - val_root_mean_squared_error: 8.0120 - val_mean_absolute_error: 6.3514\n",
      "\n",
      "Epoch 00362: val_loss did not improve from 51.60717\n",
      "Epoch 363/1500\n",
      "143/143 [==============================] - 93s 647ms/step - loss: 50.9101 - root_mean_squared_error: 7.1333 - mean_absolute_error: 5.7375 - val_loss: 55.9490 - val_root_mean_squared_error: 7.4799 - val_mean_absolute_error: 5.8219\n",
      "\n",
      "Epoch 00363: val_loss did not improve from 51.60717\n",
      "Epoch 364/1500\n",
      "143/143 [==============================] - 93s 648ms/step - loss: 45.1229 - root_mean_squared_error: 6.7164 - mean_absolute_error: 5.3268 - val_loss: 66.8529 - val_root_mean_squared_error: 8.1764 - val_mean_absolute_error: 6.5392\n",
      "\n",
      "Epoch 00364: val_loss did not improve from 51.60717\n",
      "Epoch 365/1500\n",
      "143/143 [==============================] - 94s 656ms/step - loss: 46.8669 - root_mean_squared_error: 6.8436 - mean_absolute_error: 5.5220 - val_loss: 62.1157 - val_root_mean_squared_error: 7.8813 - val_mean_absolute_error: 6.4219\n",
      "\n",
      "Epoch 00365: val_loss did not improve from 51.60717\n",
      "Epoch 366/1500\n",
      "143/143 [==============================] - 93s 652ms/step - loss: 47.4326 - root_mean_squared_error: 6.8846 - mean_absolute_error: 5.5291 - val_loss: 62.5744 - val_root_mean_squared_error: 7.9104 - val_mean_absolute_error: 6.2098\n",
      "\n",
      "Epoch 00366: val_loss did not improve from 51.60717\n",
      "Epoch 367/1500\n",
      "143/143 [==============================] - 92s 643ms/step - loss: 47.1004 - root_mean_squared_error: 6.8609 - mean_absolute_error: 5.4753 - val_loss: 58.3839 - val_root_mean_squared_error: 7.6409 - val_mean_absolute_error: 6.0998\n",
      "\n",
      "Epoch 00367: val_loss did not improve from 51.60717\n",
      "Epoch 368/1500\n",
      "143/143 [==============================] - 91s 637ms/step - loss: 48.4732 - root_mean_squared_error: 6.9572 - mean_absolute_error: 5.5961 - val_loss: 57.3231 - val_root_mean_squared_error: 7.5712 - val_mean_absolute_error: 6.0256\n",
      "\n",
      "Epoch 00368: val_loss did not improve from 51.60717\n",
      "Epoch 369/1500\n",
      "143/143 [==============================] - 93s 650ms/step - loss: 47.9992 - root_mean_squared_error: 6.9267 - mean_absolute_error: 5.5453 - val_loss: 61.0149 - val_root_mean_squared_error: 7.8112 - val_mean_absolute_error: 6.2544\n",
      "\n",
      "Epoch 00369: val_loss did not improve from 51.60717\n",
      "Epoch 370/1500\n",
      "143/143 [==============================] - 93s 647ms/step - loss: 51.3478 - root_mean_squared_error: 7.1647 - mean_absolute_error: 5.7510 - val_loss: 67.9144 - val_root_mean_squared_error: 8.2410 - val_mean_absolute_error: 6.6686\n",
      "\n",
      "Epoch 00370: val_loss did not improve from 51.60717\n",
      "Epoch 371/1500\n",
      "143/143 [==============================] - 92s 645ms/step - loss: 51.1006 - root_mean_squared_error: 7.1374 - mean_absolute_error: 5.7728 - val_loss: 92.2407 - val_root_mean_squared_error: 9.6042 - val_mean_absolute_error: 6.8482\n",
      "\n",
      "Epoch 00371: val_loss did not improve from 51.60717\n",
      "Epoch 372/1500\n",
      "143/143 [==============================] - 92s 646ms/step - loss: 48.8172 - root_mean_squared_error: 6.9818 - mean_absolute_error: 5.6596 - val_loss: 70.0003 - val_root_mean_squared_error: 8.3666 - val_mean_absolute_error: 6.4813\n",
      "\n",
      "Epoch 00372: val_loss did not improve from 51.60717\n",
      "Epoch 373/1500\n",
      "143/143 [==============================] - 93s 647ms/step - loss: 51.3564 - root_mean_squared_error: 7.1654 - mean_absolute_error: 5.7635 - val_loss: 66.5094 - val_root_mean_squared_error: 8.1553 - val_mean_absolute_error: 6.4623\n",
      "\n",
      "Epoch 00373: val_loss did not improve from 51.60717\n",
      "Epoch 374/1500\n",
      "143/143 [==============================] - 92s 645ms/step - loss: 49.2394 - root_mean_squared_error: 7.0121 - mean_absolute_error: 5.6700 - val_loss: 68.6751 - val_root_mean_squared_error: 8.2870 - val_mean_absolute_error: 6.8018\n",
      "\n",
      "Epoch 00374: val_loss did not improve from 51.60717\n",
      "Epoch 375/1500\n",
      "143/143 [==============================] - 94s 658ms/step - loss: 48.7040 - root_mean_squared_error: 6.9767 - mean_absolute_error: 5.5182 - val_loss: 60.7788 - val_root_mean_squared_error: 7.7961 - val_mean_absolute_error: 6.1128\n",
      "\n",
      "Epoch 00375: val_loss did not improve from 51.60717\n",
      "Epoch 376/1500\n",
      "143/143 [==============================] - 92s 643ms/step - loss: 45.2180 - root_mean_squared_error: 6.7200 - mean_absolute_error: 5.3752 - val_loss: 64.0754 - val_root_mean_squared_error: 8.0047 - val_mean_absolute_error: 6.5785\n",
      "\n",
      "Epoch 00376: val_loss did not improve from 51.60717\n",
      "Epoch 377/1500\n",
      "143/143 [==============================] - 91s 639ms/step - loss: 47.5149 - root_mean_squared_error: 6.8908 - mean_absolute_error: 5.5711 - val_loss: 58.5599 - val_root_mean_squared_error: 7.6524 - val_mean_absolute_error: 6.0238\n",
      "\n",
      "Epoch 00377: val_loss did not improve from 51.60717\n",
      "Epoch 378/1500\n",
      "143/143 [==============================] - 93s 654ms/step - loss: 47.2697 - root_mean_squared_error: 6.8728 - mean_absolute_error: 5.4788 - val_loss: 66.2149 - val_root_mean_squared_error: 8.1373 - val_mean_absolute_error: 6.4647\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00378: val_loss did not improve from 51.60717\n",
      "\n",
      "Epoch 00378: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "Epoch 00378: early stopping\n",
      "CPU times: user 14h 37min 6s, sys: 6h 8min 32s, total: 20h 45min 38s\n",
      "Wall time: 9h 38min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "epochs = 1500\n",
    "\n",
    "# fit network\n",
    "history = model.fit(x=train_generator_noise,\n",
    "                    validation_data=val_generator,\n",
    "                    epochs=epochs, \n",
    "                    callbacks=[checkpointer, earlystopper, reduce_lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bbruns/anaconda3/envs/mne/lib/python3.8/site-packages/tensorflow_addons/utils/ensure_tf_install.py:54: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.2.0 and strictly below 2.4.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.4.1 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_addons as tfa\n",
    "\n",
    "def encoder_model():\n",
    "    \"\"\" Returns the Encoder model from Ismail Fawaz et al. (2019). \"\"\"\n",
    "    input_layer = keras.layers.Input(input_shape)\n",
    "\n",
    "    # conv block -1\n",
    "    conv1 = keras.layers.Conv1D(filters=128,kernel_size=5,strides=1,padding='same')(input_layer)\n",
    "    conv1 = tfa.layers.InstanceNormalization()(conv1)\n",
    "    conv1 = keras.layers.PReLU(shared_axes=[1])(conv1)\n",
    "    conv1 = keras.layers.Dropout(rate=0.2)(conv1)\n",
    "    conv1 = keras.layers.MaxPooling1D(pool_size=2)(conv1)\n",
    "    # conv block -2\n",
    "    conv2 = keras.layers.Conv1D(filters=256,kernel_size=11,strides=1,padding='same')(conv1)\n",
    "    conv2 = tfa.layers.InstanceNormalization()(conv2)\n",
    "    conv2 = keras.layers.PReLU(shared_axes=[1])(conv2)\n",
    "    conv2 = keras.layers.Dropout(rate=0.2)(conv2)\n",
    "    conv2 = keras.layers.MaxPooling1D(pool_size=2)(conv2)\n",
    "    # conv block -3\n",
    "    conv3 = keras.layers.Conv1D(filters=512,kernel_size=21,strides=1,padding='same')(conv2)\n",
    "    conv3 = tfa.layers.InstanceNormalization()(conv3)\n",
    "    conv3 = keras.layers.PReLU(shared_axes=[1])(conv3)\n",
    "    conv3 = keras.layers.Dropout(rate=0.2)(conv3)\n",
    "    # split for attention\n",
    "    attention_data = keras.layers.Lambda(lambda x: x[:,:,:256])(conv3)\n",
    "    attention_softmax = keras.layers.Lambda(lambda x: x[:,:,256:])(conv3)\n",
    "    # attention mechanism\n",
    "    attention_softmax = keras.layers.Softmax()(attention_softmax)\n",
    "    multiply_layer = keras.layers.Multiply()([attention_softmax,attention_data])\n",
    "    # last layer\n",
    "    dense_layer = keras.layers.Dense(units=256,activation='sigmoid')(multiply_layer)\n",
    "    dense_layer = tfa.layers.InstanceNormalization()(dense_layer)\n",
    "    # output layer\n",
    "    flatten_layer = keras.layers.Flatten()(dense_layer)\n",
    "    output_layer = keras.layers.Dense(1)(flatten_layer)\n",
    "\n",
    "    model = keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = encoder_model()\n",
    "\n",
    "optimizer = Adam(learning_rate=0.00001)    \n",
    "              \n",
    "model.compile(loss='mean_squared_error', \n",
    "              optimizer=optimizer, \n",
    "              metrics=[RootMeanSquaredError(), MeanAbsoluteError()])\n",
    "\n",
    "# Encoder_regressor_01: MSE, Adam, N_average=30, 1500 epochs, ES=250, RLR=50, gaussian=0.01 (LR = 0.0001, no reduction)\n",
    "output_filename = 'Encoder_regressor_02'\n",
    "output_file = os.path.join(PATH_MODELS, output_filename)\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath = output_file + \".hdf5\", monitor='val_loss', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "143/143 [==============================] - 97s 669ms/step - loss: 772.3317 - root_mean_squared_error: 27.7892 - mean_absolute_error: 25.8278 - val_loss: 711.6334 - val_root_mean_squared_error: 26.6765 - val_mean_absolute_error: 24.4745\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 711.63336, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/Encoder_regressor_01.hdf5\n",
      "Epoch 2/100\n",
      "143/143 [==============================] - 93s 654ms/step - loss: 585.1881 - root_mean_squared_error: 24.1294 - mean_absolute_error: 21.6805 - val_loss: 317.0688 - val_root_mean_squared_error: 17.8064 - val_mean_absolute_error: 15.0762\n",
      "\n",
      "Epoch 00002: val_loss improved from 711.63336 to 317.06882, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/Encoder_regressor_01.hdf5\n",
      "Epoch 3/100\n",
      "143/143 [==============================] - 92s 641ms/step - loss: 192.9793 - root_mean_squared_error: 13.8633 - mean_absolute_error: 11.2211 - val_loss: 119.1811 - val_root_mean_squared_error: 10.9170 - val_mean_absolute_error: 9.0976\n",
      "\n",
      "Epoch 00003: val_loss improved from 317.06882 to 119.18111, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/Encoder_regressor_01.hdf5\n",
      "Epoch 4/100\n",
      "143/143 [==============================] - 101s 708ms/step - loss: 115.5599 - root_mean_squared_error: 10.7434 - mean_absolute_error: 8.7749 - val_loss: 97.7810 - val_root_mean_squared_error: 9.8884 - val_mean_absolute_error: 8.1416\n",
      "\n",
      "Epoch 00004: val_loss improved from 119.18111 to 97.78098, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/Encoder_regressor_01.hdf5\n",
      "Epoch 5/100\n",
      "143/143 [==============================] - 91s 633ms/step - loss: 113.6988 - root_mean_squared_error: 10.6613 - mean_absolute_error: 8.8497 - val_loss: 105.7301 - val_root_mean_squared_error: 10.2825 - val_mean_absolute_error: 8.3916\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 97.78098\n",
      "Epoch 6/100\n",
      "143/143 [==============================] - 96s 669ms/step - loss: 104.5132 - root_mean_squared_error: 10.2221 - mean_absolute_error: 8.4639 - val_loss: 99.3917 - val_root_mean_squared_error: 9.9695 - val_mean_absolute_error: 8.2206\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 97.78098\n",
      "Epoch 7/100\n",
      "143/143 [==============================] - 91s 638ms/step - loss: 90.6976 - root_mean_squared_error: 9.5225 - mean_absolute_error: 7.8129 - val_loss: 107.1788 - val_root_mean_squared_error: 10.3527 - val_mean_absolute_error: 8.4468\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 97.78098\n",
      "Epoch 8/100\n",
      "143/143 [==============================] - 91s 638ms/step - loss: 93.6731 - root_mean_squared_error: 9.6744 - mean_absolute_error: 8.0119 - val_loss: 103.9820 - val_root_mean_squared_error: 10.1972 - val_mean_absolute_error: 8.2138\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 97.78098\n",
      "Epoch 9/100\n",
      "143/143 [==============================] - 88s 615ms/step - loss: 100.3607 - root_mean_squared_error: 10.0156 - mean_absolute_error: 8.2841 - val_loss: 103.4269 - val_root_mean_squared_error: 10.1699 - val_mean_absolute_error: 8.2058\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 97.78098\n",
      "Epoch 10/100\n",
      "143/143 [==============================] - 101s 703ms/step - loss: 93.9217 - root_mean_squared_error: 9.6886 - mean_absolute_error: 7.9968 - val_loss: 109.0523 - val_root_mean_squared_error: 10.4428 - val_mean_absolute_error: 8.5018\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 97.78098\n",
      "Epoch 11/100\n",
      "143/143 [==============================] - 91s 633ms/step - loss: 90.0347 - root_mean_squared_error: 9.4839 - mean_absolute_error: 7.6899 - val_loss: 86.0153 - val_root_mean_squared_error: 9.2744 - val_mean_absolute_error: 7.5431\n",
      "\n",
      "Epoch 00011: val_loss improved from 97.78098 to 86.01527, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/Encoder_regressor_01.hdf5\n",
      "Epoch 12/100\n",
      "143/143 [==============================] - 88s 613ms/step - loss: 90.3721 - root_mean_squared_error: 9.5056 - mean_absolute_error: 7.8273 - val_loss: 96.9974 - val_root_mean_squared_error: 9.8487 - val_mean_absolute_error: 8.0015\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 86.01527\n",
      "Epoch 13/100\n",
      "143/143 [==============================] - 92s 641ms/step - loss: 93.4380 - root_mean_squared_error: 9.6659 - mean_absolute_error: 7.8142 - val_loss: 83.1533 - val_root_mean_squared_error: 9.1188 - val_mean_absolute_error: 7.4598\n",
      "\n",
      "Epoch 00013: val_loss improved from 86.01527 to 83.15334, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/Encoder_regressor_01.hdf5\n",
      "Epoch 14/100\n",
      "143/143 [==============================] - 88s 616ms/step - loss: 89.6694 - root_mean_squared_error: 9.4677 - mean_absolute_error: 7.8087 - val_loss: 92.1634 - val_root_mean_squared_error: 9.6002 - val_mean_absolute_error: 7.6308\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 83.15334\n",
      "Epoch 15/100\n",
      "143/143 [==============================] - 92s 643ms/step - loss: 91.1400 - root_mean_squared_error: 9.5394 - mean_absolute_error: 7.8822 - val_loss: 87.9325 - val_root_mean_squared_error: 9.3772 - val_mean_absolute_error: 7.5609\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 83.15334\n",
      "Epoch 16/100\n",
      "143/143 [==============================] - 90s 630ms/step - loss: 85.8155 - root_mean_squared_error: 9.2586 - mean_absolute_error: 7.6032 - val_loss: 100.5172 - val_root_mean_squared_error: 10.0258 - val_mean_absolute_error: 8.1647\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 83.15334\n",
      "Epoch 17/100\n",
      "143/143 [==============================] - 87s 611ms/step - loss: 86.2741 - root_mean_squared_error: 9.2813 - mean_absolute_error: 7.7589 - val_loss: 90.5447 - val_root_mean_squared_error: 9.5155 - val_mean_absolute_error: 7.6003\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 83.15334\n",
      "Epoch 18/100\n",
      "143/143 [==============================] - 87s 609ms/step - loss: 84.3297 - root_mean_squared_error: 9.1776 - mean_absolute_error: 7.5654 - val_loss: 92.8470 - val_root_mean_squared_error: 9.6357 - val_mean_absolute_error: 7.7830\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 83.15334\n",
      "Epoch 19/100\n",
      "143/143 [==============================] - 90s 627ms/step - loss: 87.2082 - root_mean_squared_error: 9.3329 - mean_absolute_error: 7.6329 - val_loss: 91.4946 - val_root_mean_squared_error: 9.5653 - val_mean_absolute_error: 7.7322\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 83.15334\n",
      "Epoch 20/100\n",
      "143/143 [==============================] - 89s 619ms/step - loss: 76.8833 - root_mean_squared_error: 8.7623 - mean_absolute_error: 7.0250 - val_loss: 87.1644 - val_root_mean_squared_error: 9.3362 - val_mean_absolute_error: 7.5570\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 83.15334\n",
      "Epoch 21/100\n",
      "143/143 [==============================] - 90s 629ms/step - loss: 77.1577 - root_mean_squared_error: 8.7765 - mean_absolute_error: 7.2236 - val_loss: 89.3316 - val_root_mean_squared_error: 9.4515 - val_mean_absolute_error: 7.2824\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 83.15334\n",
      "Epoch 22/100\n",
      "143/143 [==============================] - 98s 689ms/step - loss: 76.0371 - root_mean_squared_error: 8.7183 - mean_absolute_error: 7.2137 - val_loss: 87.4321 - val_root_mean_squared_error: 9.3505 - val_mean_absolute_error: 7.3587\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 83.15334\n",
      "Epoch 23/100\n",
      "143/143 [==============================] - 90s 632ms/step - loss: 80.9298 - root_mean_squared_error: 8.9922 - mean_absolute_error: 7.3858 - val_loss: 99.8187 - val_root_mean_squared_error: 9.9909 - val_mean_absolute_error: 7.9354\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 83.15334\n",
      "Epoch 24/100\n",
      "143/143 [==============================] - 95s 668ms/step - loss: 75.1391 - root_mean_squared_error: 8.6647 - mean_absolute_error: 6.9909 - val_loss: 94.9820 - val_root_mean_squared_error: 9.7459 - val_mean_absolute_error: 7.8078\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 83.15334\n",
      "Epoch 25/100\n",
      "143/143 [==============================] - 91s 636ms/step - loss: 73.1027 - root_mean_squared_error: 8.5468 - mean_absolute_error: 7.0696 - val_loss: 84.6156 - val_root_mean_squared_error: 9.1987 - val_mean_absolute_error: 7.4124\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 83.15334\n",
      "Epoch 26/100\n",
      "143/143 [==============================] - 91s 635ms/step - loss: 76.1716 - root_mean_squared_error: 8.7254 - mean_absolute_error: 7.0830 - val_loss: 88.9103 - val_root_mean_squared_error: 9.4292 - val_mean_absolute_error: 7.4021\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 83.15334\n",
      "Epoch 27/100\n",
      "143/143 [==============================] - 91s 640ms/step - loss: 69.8963 - root_mean_squared_error: 8.3573 - mean_absolute_error: 6.7663 - val_loss: 92.0392 - val_root_mean_squared_error: 9.5937 - val_mean_absolute_error: 7.4944\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 83.15334\n",
      "Epoch 28/100\n",
      "143/143 [==============================] - 91s 635ms/step - loss: 74.9668 - root_mean_squared_error: 8.6569 - mean_absolute_error: 7.1663 - val_loss: 88.0731 - val_root_mean_squared_error: 9.3847 - val_mean_absolute_error: 7.4984\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 83.15334\n",
      "Epoch 29/100\n",
      "143/143 [==============================] - 92s 644ms/step - loss: 69.5787 - root_mean_squared_error: 8.3390 - mean_absolute_error: 6.8060 - val_loss: 79.6919 - val_root_mean_squared_error: 8.9270 - val_mean_absolute_error: 7.2391\n",
      "\n",
      "Epoch 00029: val_loss improved from 83.15334 to 79.69195, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/Encoder_regressor_01.hdf5\n",
      "Epoch 30/100\n",
      "143/143 [==============================] - 90s 631ms/step - loss: 73.7332 - root_mean_squared_error: 8.5827 - mean_absolute_error: 6.9903 - val_loss: 82.3226 - val_root_mean_squared_error: 9.0732 - val_mean_absolute_error: 7.1346\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 79.69195\n",
      "Epoch 31/100\n",
      "143/143 [==============================] - 90s 629ms/step - loss: 70.6832 - root_mean_squared_error: 8.4052 - mean_absolute_error: 6.9186 - val_loss: 77.7285 - val_root_mean_squared_error: 8.8164 - val_mean_absolute_error: 6.9827\n",
      "\n",
      "Epoch 00031: val_loss improved from 79.69195 to 77.72848, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/Encoder_regressor_01.hdf5\n",
      "Epoch 32/100\n",
      "143/143 [==============================] - 100s 703ms/step - loss: 67.2049 - root_mean_squared_error: 8.1875 - mean_absolute_error: 6.6777 - val_loss: 79.6944 - val_root_mean_squared_error: 8.9272 - val_mean_absolute_error: 6.9279\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 77.72848\n",
      "Epoch 33/100\n",
      "143/143 [==============================] - 233s 2s/step - loss: 67.7685 - root_mean_squared_error: 8.2283 - mean_absolute_error: 6.7073 - val_loss: 92.5188 - val_root_mean_squared_error: 9.6187 - val_mean_absolute_error: 7.4291\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 77.72848\n",
      "Epoch 34/100\n",
      "143/143 [==============================] - 187s 1s/step - loss: 70.5729 - root_mean_squared_error: 8.3979 - mean_absolute_error: 6.8071 - val_loss: 86.1864 - val_root_mean_squared_error: 9.2837 - val_mean_absolute_error: 7.1908\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 77.72848\n",
      "Epoch 35/100\n",
      "143/143 [==============================] - 203s 1s/step - loss: 63.4630 - root_mean_squared_error: 7.9651 - mean_absolute_error: 6.5924 - val_loss: 74.4163 - val_root_mean_squared_error: 8.6265 - val_mean_absolute_error: 6.7725\n",
      "\n",
      "Epoch 00035: val_loss improved from 77.72848 to 74.41628, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/Encoder_regressor_01.hdf5\n",
      "Epoch 36/100\n",
      "143/143 [==============================] - 159s 1s/step - loss: 65.6995 - root_mean_squared_error: 8.1041 - mean_absolute_error: 6.6536 - val_loss: 73.9194 - val_root_mean_squared_error: 8.5976 - val_mean_absolute_error: 6.7574\n",
      "\n",
      "Epoch 00036: val_loss improved from 74.41628 to 73.91944, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/Encoder_regressor_01.hdf5\n",
      "Epoch 37/100\n",
      "143/143 [==============================] - 137s 963ms/step - loss: 66.2885 - root_mean_squared_error: 8.1343 - mean_absolute_error: 6.5932 - val_loss: 86.9031 - val_root_mean_squared_error: 9.3222 - val_mean_absolute_error: 7.2796\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 73.91944\n",
      "Epoch 38/100\n",
      "143/143 [==============================] - 156s 1s/step - loss: 64.0693 - root_mean_squared_error: 8.0004 - mean_absolute_error: 6.5501 - val_loss: 87.4698 - val_root_mean_squared_error: 9.3525 - val_mean_absolute_error: 7.2317\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 73.91944\n",
      "Epoch 39/100\n",
      "143/143 [==============================] - 148s 1s/step - loss: 68.3771 - root_mean_squared_error: 8.2660 - mean_absolute_error: 6.6814 - val_loss: 89.7692 - val_root_mean_squared_error: 9.4747 - val_mean_absolute_error: 7.5561\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 73.91944\n",
      "Epoch 40/100\n",
      "143/143 [==============================] - 156s 1s/step - loss: 68.7578 - root_mean_squared_error: 8.2856 - mean_absolute_error: 6.8180 - val_loss: 77.6263 - val_root_mean_squared_error: 8.8106 - val_mean_absolute_error: 6.9655\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 73.91944\n",
      "Epoch 41/100\n",
      "143/143 [==============================] - 150s 1s/step - loss: 66.5962 - root_mean_squared_error: 8.1576 - mean_absolute_error: 6.5709 - val_loss: 76.2795 - val_root_mean_squared_error: 8.7338 - val_mean_absolute_error: 6.6799\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 73.91944\n",
      "Epoch 42/100\n",
      "143/143 [==============================] - 139s 973ms/step - loss: 67.8849 - root_mean_squared_error: 8.2327 - mean_absolute_error: 6.7084 - val_loss: 105.6871 - val_root_mean_squared_error: 10.2804 - val_mean_absolute_error: 8.0920\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 73.91944\n",
      "Epoch 43/100\n",
      "143/143 [==============================] - 140s 977ms/step - loss: 69.3341 - root_mean_squared_error: 8.3174 - mean_absolute_error: 6.7298 - val_loss: 83.2589 - val_root_mean_squared_error: 9.1246 - val_mean_absolute_error: 7.0563\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 73.91944\n",
      "Epoch 44/100\n",
      "143/143 [==============================] - 97s 680ms/step - loss: 66.9825 - root_mean_squared_error: 8.1836 - mean_absolute_error: 6.7266 - val_loss: 75.8376 - val_root_mean_squared_error: 8.7085 - val_mean_absolute_error: 6.8557\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 73.91944\n",
      "Epoch 45/100\n",
      "143/143 [==============================] - 116s 814ms/step - loss: 71.5344 - root_mean_squared_error: 8.4413 - mean_absolute_error: 6.8235 - val_loss: 91.2728 - val_root_mean_squared_error: 9.5537 - val_mean_absolute_error: 7.6825\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 73.91944\n",
      "Epoch 46/100\n",
      "143/143 [==============================] - 141s 987ms/step - loss: 66.0325 - root_mean_squared_error: 8.1214 - mean_absolute_error: 6.6097 - val_loss: 84.4165 - val_root_mean_squared_error: 9.1878 - val_mean_absolute_error: 7.1246\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 73.91944\n",
      "Epoch 47/100\n",
      "143/143 [==============================] - 128s 895ms/step - loss: 64.2660 - root_mean_squared_error: 8.0143 - mean_absolute_error: 6.5114 - val_loss: 94.6704 - val_root_mean_squared_error: 9.7299 - val_mean_absolute_error: 7.5579\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 73.91944\n",
      "Epoch 48/100\n",
      "143/143 [==============================] - 144s 1s/step - loss: 63.1661 - root_mean_squared_error: 7.9417 - mean_absolute_error: 6.3978 - val_loss: 82.2724 - val_root_mean_squared_error: 9.0704 - val_mean_absolute_error: 6.9691\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 73.91944\n",
      "Epoch 49/100\n",
      "143/143 [==============================] - 147s 1s/step - loss: 60.9813 - root_mean_squared_error: 7.8072 - mean_absolute_error: 6.3396 - val_loss: 87.1990 - val_root_mean_squared_error: 9.3380 - val_mean_absolute_error: 7.4420\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 73.91944\n",
      "Epoch 50/100\n",
      "143/143 [==============================] - 157s 1s/step - loss: 61.8997 - root_mean_squared_error: 7.8649 - mean_absolute_error: 6.3194 - val_loss: 76.1341 - val_root_mean_squared_error: 8.7255 - val_mean_absolute_error: 6.7180\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 73.91944\n",
      "Epoch 51/100\n",
      "143/143 [==============================] - 163s 1s/step - loss: 61.2401 - root_mean_squared_error: 7.8215 - mean_absolute_error: 6.2570 - val_loss: 74.2720 - val_root_mean_squared_error: 8.6181 - val_mean_absolute_error: 6.6085\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 73.91944\n",
      "Epoch 52/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 131s 916ms/step - loss: 63.3927 - root_mean_squared_error: 7.9580 - mean_absolute_error: 6.3827 - val_loss: 83.8684 - val_root_mean_squared_error: 9.1580 - val_mean_absolute_error: 7.2467\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 73.91944\n",
      "Epoch 53/100\n",
      "143/143 [==============================] - 142s 993ms/step - loss: 62.4662 - root_mean_squared_error: 7.9010 - mean_absolute_error: 6.3508 - val_loss: 84.5560 - val_root_mean_squared_error: 9.1954 - val_mean_absolute_error: 7.0287\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 73.91944\n",
      "Epoch 54/100\n",
      "143/143 [==============================] - 143s 997ms/step - loss: 61.8955 - root_mean_squared_error: 7.8632 - mean_absolute_error: 6.2992 - val_loss: 83.9788 - val_root_mean_squared_error: 9.1640 - val_mean_absolute_error: 7.1886\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 73.91944\n",
      "Epoch 55/100\n",
      "143/143 [==============================] - 175s 1s/step - loss: 58.3629 - root_mean_squared_error: 7.6310 - mean_absolute_error: 6.2127 - val_loss: 79.9120 - val_root_mean_squared_error: 8.9394 - val_mean_absolute_error: 6.7880\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 73.91944\n",
      "Epoch 56/100\n",
      "143/143 [==============================] - 166s 1s/step - loss: 62.9155 - root_mean_squared_error: 7.9305 - mean_absolute_error: 6.4772 - val_loss: 86.8377 - val_root_mean_squared_error: 9.3187 - val_mean_absolute_error: 7.3229\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 73.91944\n",
      "Epoch 57/100\n",
      "143/143 [==============================] - 90s 630ms/step - loss: 59.3997 - root_mean_squared_error: 7.7043 - mean_absolute_error: 6.1593 - val_loss: 83.9263 - val_root_mean_squared_error: 9.1611 - val_mean_absolute_error: 6.7343\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 73.91944\n",
      "Epoch 58/100\n",
      "143/143 [==============================] - 92s 640ms/step - loss: 58.6444 - root_mean_squared_error: 7.6559 - mean_absolute_error: 6.1886 - val_loss: 90.5425 - val_root_mean_squared_error: 9.5154 - val_mean_absolute_error: 7.4466\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 73.91944\n",
      "Epoch 59/100\n",
      "143/143 [==============================] - 94s 655ms/step - loss: 61.7376 - root_mean_squared_error: 7.8557 - mean_absolute_error: 6.3478 - val_loss: 80.5449 - val_root_mean_squared_error: 8.9747 - val_mean_absolute_error: 6.9983\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 73.91944\n",
      "Epoch 60/100\n",
      "143/143 [==============================] - 92s 644ms/step - loss: 56.6727 - root_mean_squared_error: 7.5263 - mean_absolute_error: 6.0170 - val_loss: 87.2620 - val_root_mean_squared_error: 9.3414 - val_mean_absolute_error: 7.4118\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 73.91944\n",
      "Epoch 61/100\n",
      "143/143 [==============================] - 89s 625ms/step - loss: 61.6254 - root_mean_squared_error: 7.8491 - mean_absolute_error: 6.3527 - val_loss: 86.9608 - val_root_mean_squared_error: 9.3253 - val_mean_absolute_error: 7.2337\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 73.91944\n",
      "Epoch 62/100\n",
      "143/143 [==============================] - 89s 626ms/step - loss: 60.2464 - root_mean_squared_error: 7.7557 - mean_absolute_error: 6.2051 - val_loss: 92.9298 - val_root_mean_squared_error: 9.6400 - val_mean_absolute_error: 7.6107\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 73.91944\n",
      "Epoch 63/100\n",
      "143/143 [==============================] - 89s 624ms/step - loss: 58.6149 - root_mean_squared_error: 7.6526 - mean_absolute_error: 6.1100 - val_loss: 79.2435 - val_root_mean_squared_error: 8.9019 - val_mean_absolute_error: 7.0549\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 73.91944\n",
      "Epoch 64/100\n",
      "143/143 [==============================] - 88s 613ms/step - loss: 56.4108 - root_mean_squared_error: 7.5069 - mean_absolute_error: 5.9913 - val_loss: 79.0392 - val_root_mean_squared_error: 8.8904 - val_mean_absolute_error: 7.1354\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 73.91944\n",
      "Epoch 65/100\n",
      "143/143 [==============================] - 101s 704ms/step - loss: 63.0142 - root_mean_squared_error: 7.9348 - mean_absolute_error: 6.3652 - val_loss: 79.0550 - val_root_mean_squared_error: 8.8913 - val_mean_absolute_error: 6.8961\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 73.91944\n",
      "Epoch 66/100\n",
      "143/143 [==============================] - 91s 637ms/step - loss: 54.5976 - root_mean_squared_error: 7.3867 - mean_absolute_error: 5.9582 - val_loss: 77.6568 - val_root_mean_squared_error: 8.8123 - val_mean_absolute_error: 6.7999\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 73.91944\n",
      "Epoch 67/100\n",
      "143/143 [==============================] - 89s 621ms/step - loss: 55.1738 - root_mean_squared_error: 7.4243 - mean_absolute_error: 5.9704 - val_loss: 80.3852 - val_root_mean_squared_error: 8.9658 - val_mean_absolute_error: 7.0955\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 73.91944\n",
      "Epoch 68/100\n",
      "143/143 [==============================] - 89s 621ms/step - loss: 59.3783 - root_mean_squared_error: 7.7041 - mean_absolute_error: 6.2121 - val_loss: 84.7434 - val_root_mean_squared_error: 9.2056 - val_mean_absolute_error: 7.1865\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 73.91944\n",
      "Epoch 69/100\n",
      "143/143 [==============================] - 89s 624ms/step - loss: 61.9466 - root_mean_squared_error: 7.8638 - mean_absolute_error: 6.4040 - val_loss: 85.2340 - val_root_mean_squared_error: 9.2322 - val_mean_absolute_error: 7.2813\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 73.91944\n",
      "Epoch 70/100\n",
      "143/143 [==============================] - 89s 625ms/step - loss: 63.7934 - root_mean_squared_error: 7.9828 - mean_absolute_error: 6.4054 - val_loss: 84.9379 - val_root_mean_squared_error: 9.2162 - val_mean_absolute_error: 7.1078\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 73.91944\n",
      "Epoch 71/100\n",
      "143/143 [==============================] - 89s 621ms/step - loss: 55.3448 - root_mean_squared_error: 7.4297 - mean_absolute_error: 6.0147 - val_loss: 73.2034 - val_root_mean_squared_error: 8.5559 - val_mean_absolute_error: 6.7513\n",
      "\n",
      "Epoch 00071: val_loss improved from 73.91944 to 73.20343, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/Encoder_regressor_01.hdf5\n",
      "Epoch 72/100\n",
      "143/143 [==============================] - 92s 640ms/step - loss: 60.5683 - root_mean_squared_error: 7.7806 - mean_absolute_error: 6.2679 - val_loss: 69.5679 - val_root_mean_squared_error: 8.3407 - val_mean_absolute_error: 6.4872\n",
      "\n",
      "Epoch 00072: val_loss improved from 73.20343 to 69.56792, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/Encoder_regressor_01.hdf5\n",
      "Epoch 73/100\n",
      "143/143 [==============================] - 93s 653ms/step - loss: 60.2814 - root_mean_squared_error: 7.7539 - mean_absolute_error: 6.1701 - val_loss: 87.4938 - val_root_mean_squared_error: 9.3538 - val_mean_absolute_error: 7.1587\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 69.56792\n",
      "Epoch 74/100\n",
      "143/143 [==============================] - 90s 628ms/step - loss: 59.2389 - root_mean_squared_error: 7.6942 - mean_absolute_error: 6.0881 - val_loss: 65.9575 - val_root_mean_squared_error: 8.1214 - val_mean_absolute_error: 6.3233\n",
      "\n",
      "Epoch 00074: val_loss improved from 69.56792 to 65.95747, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/Encoder_regressor_01.hdf5\n",
      "Epoch 75/100\n",
      "143/143 [==============================] - 93s 649ms/step - loss: 54.1964 - root_mean_squared_error: 7.3606 - mean_absolute_error: 5.8593 - val_loss: 74.5836 - val_root_mean_squared_error: 8.6362 - val_mean_absolute_error: 6.6934\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 65.95747\n",
      "Epoch 76/100\n",
      "143/143 [==============================] - 91s 639ms/step - loss: 62.9112 - root_mean_squared_error: 7.9275 - mean_absolute_error: 6.3023 - val_loss: 75.0585 - val_root_mean_squared_error: 8.6636 - val_mean_absolute_error: 6.9039\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 65.95747\n",
      "Epoch 77/100\n",
      "143/143 [==============================] - 91s 636ms/step - loss: 54.9828 - root_mean_squared_error: 7.4124 - mean_absolute_error: 6.0736 - val_loss: 67.6115 - val_root_mean_squared_error: 8.2226 - val_mean_absolute_error: 6.4248\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 65.95747\n",
      "Epoch 78/100\n",
      "143/143 [==============================] - 92s 642ms/step - loss: 60.4756 - root_mean_squared_error: 7.7721 - mean_absolute_error: 6.3918 - val_loss: 67.6245 - val_root_mean_squared_error: 8.2234 - val_mean_absolute_error: 6.4307\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 65.95747\n",
      "Epoch 79/100\n",
      "143/143 [==============================] - 92s 641ms/step - loss: 53.8899 - root_mean_squared_error: 7.3374 - mean_absolute_error: 5.8079 - val_loss: 79.8955 - val_root_mean_squared_error: 8.9384 - val_mean_absolute_error: 6.9086\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 65.95747\n",
      "Epoch 80/100\n",
      "143/143 [==============================] - 91s 635ms/step - loss: 60.0260 - root_mean_squared_error: 7.7439 - mean_absolute_error: 6.2445 - val_loss: 91.4287 - val_root_mean_squared_error: 9.5618 - val_mean_absolute_error: 7.2927\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 65.95747\n",
      "Epoch 81/100\n",
      "143/143 [==============================] - 90s 632ms/step - loss: 58.9900 - root_mean_squared_error: 7.6788 - mean_absolute_error: 6.2173 - val_loss: 71.7492 - val_root_mean_squared_error: 8.4705 - val_mean_absolute_error: 6.5799\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 65.95747\n",
      "Epoch 82/100\n",
      "143/143 [==============================] - 91s 634ms/step - loss: 53.3458 - root_mean_squared_error: 7.3017 - mean_absolute_error: 5.7675 - val_loss: 67.8949 - val_root_mean_squared_error: 8.2398 - val_mean_absolute_error: 6.5142\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 65.95747\n",
      "Epoch 83/100\n",
      "143/143 [==============================] - 90s 633ms/step - loss: 55.9352 - root_mean_squared_error: 7.4745 - mean_absolute_error: 5.9014 - val_loss: 63.6865 - val_root_mean_squared_error: 7.9804 - val_mean_absolute_error: 6.3703\n",
      "\n",
      "Epoch 00083: val_loss improved from 65.95747 to 63.68650, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/Encoder_regressor_01.hdf5\n",
      "Epoch 84/100\n",
      "143/143 [==============================] - 90s 633ms/step - loss: 60.3952 - root_mean_squared_error: 7.7654 - mean_absolute_error: 6.2049 - val_loss: 68.5710 - val_root_mean_squared_error: 8.2808 - val_mean_absolute_error: 6.3730\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 63.68650\n",
      "Epoch 85/100\n",
      "143/143 [==============================] - 91s 640ms/step - loss: 49.2732 - root_mean_squared_error: 7.0181 - mean_absolute_error: 5.5984 - val_loss: 84.6682 - val_root_mean_squared_error: 9.2015 - val_mean_absolute_error: 7.0806\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 63.68650\n",
      "Epoch 86/100\n",
      "143/143 [==============================] - 90s 632ms/step - loss: 54.9363 - root_mean_squared_error: 7.4050 - mean_absolute_error: 5.9382 - val_loss: 77.1437 - val_root_mean_squared_error: 8.7831 - val_mean_absolute_error: 6.8220\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 63.68650\n",
      "Epoch 87/100\n",
      "143/143 [==============================] - 91s 637ms/step - loss: 57.0477 - root_mean_squared_error: 7.5487 - mean_absolute_error: 5.9841 - val_loss: 78.8664 - val_root_mean_squared_error: 8.8807 - val_mean_absolute_error: 6.9878\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 63.68650\n",
      "Epoch 88/100\n",
      "143/143 [==============================] - 91s 638ms/step - loss: 53.6833 - root_mean_squared_error: 7.3251 - mean_absolute_error: 5.8917 - val_loss: 73.2882 - val_root_mean_squared_error: 8.5609 - val_mean_absolute_error: 6.6777\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 63.68650\n",
      "Epoch 89/100\n",
      "143/143 [==============================] - 93s 653ms/step - loss: 52.2100 - root_mean_squared_error: 7.2180 - mean_absolute_error: 5.7977 - val_loss: 74.1083 - val_root_mean_squared_error: 8.6086 - val_mean_absolute_error: 6.6185\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 63.68650\n",
      "Epoch 90/100\n",
      "143/143 [==============================] - 91s 637ms/step - loss: 55.2805 - root_mean_squared_error: 7.4319 - mean_absolute_error: 5.9857 - val_loss: 79.1343 - val_root_mean_squared_error: 8.8957 - val_mean_absolute_error: 6.7790\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 63.68650\n",
      "Epoch 91/100\n",
      "143/143 [==============================] - 88s 619ms/step - loss: 57.1737 - root_mean_squared_error: 7.5598 - mean_absolute_error: 5.8725 - val_loss: 75.3674 - val_root_mean_squared_error: 8.6814 - val_mean_absolute_error: 6.8193\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 63.68650\n",
      "Epoch 92/100\n",
      "143/143 [==============================] - 91s 633ms/step - loss: 56.9202 - root_mean_squared_error: 7.5433 - mean_absolute_error: 6.0169 - val_loss: 80.4033 - val_root_mean_squared_error: 8.9668 - val_mean_absolute_error: 6.8821\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 63.68650\n",
      "Epoch 93/100\n",
      "143/143 [==============================] - 90s 629ms/step - loss: 50.7410 - root_mean_squared_error: 7.1177 - mean_absolute_error: 5.6985 - val_loss: 72.7064 - val_root_mean_squared_error: 8.5268 - val_mean_absolute_error: 6.6766\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 63.68650\n",
      "Epoch 94/100\n",
      "143/143 [==============================] - 93s 651ms/step - loss: 56.5708 - root_mean_squared_error: 7.5177 - mean_absolute_error: 6.0827 - val_loss: 77.0832 - val_root_mean_squared_error: 8.7797 - val_mean_absolute_error: 6.8544\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 63.68650\n",
      "Epoch 95/100\n",
      "143/143 [==============================] - 94s 655ms/step - loss: 54.2360 - root_mean_squared_error: 7.3619 - mean_absolute_error: 5.9443 - val_loss: 76.3714 - val_root_mean_squared_error: 8.7391 - val_mean_absolute_error: 6.7700\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 63.68650\n",
      "Epoch 96/100\n",
      "143/143 [==============================] - 93s 651ms/step - loss: 53.6963 - root_mean_squared_error: 7.3232 - mean_absolute_error: 5.8528 - val_loss: 72.8547 - val_root_mean_squared_error: 8.5355 - val_mean_absolute_error: 6.7037\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 63.68650\n",
      "Epoch 97/100\n",
      "143/143 [==============================] - 94s 661ms/step - loss: 58.9672 - root_mean_squared_error: 7.6754 - mean_absolute_error: 6.1538 - val_loss: 81.2080 - val_root_mean_squared_error: 9.0115 - val_mean_absolute_error: 7.1373\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 63.68650\n",
      "Epoch 98/100\n",
      "143/143 [==============================] - 93s 650ms/step - loss: 49.5335 - root_mean_squared_error: 7.0353 - mean_absolute_error: 5.6271 - val_loss: 83.2024 - val_root_mean_squared_error: 9.1215 - val_mean_absolute_error: 7.1172\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 63.68650\n",
      "Epoch 99/100\n",
      "143/143 [==============================] - 93s 651ms/step - loss: 51.7088 - root_mean_squared_error: 7.1867 - mean_absolute_error: 5.7197 - val_loss: 68.4387 - val_root_mean_squared_error: 8.2728 - val_mean_absolute_error: 6.3115\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 63.68650\n",
      "Epoch 100/100\n",
      "143/143 [==============================] - 94s 660ms/step - loss: 54.0384 - root_mean_squared_error: 7.3446 - mean_absolute_error: 5.9635 - val_loss: 69.8382 - val_root_mean_squared_error: 8.3569 - val_mean_absolute_error: 6.5210\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 63.68650\n",
      "CPU times: user 5h 30min 45s, sys: 1h 16min 34s, total: 6h 47min 20s\n",
      "Wall time: 2h 57min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "# fit network\n",
    "history = model.fit(x=train_generator_noise,\n",
    "                    validation_data=val_generator,\n",
    "                    epochs=epochs, \n",
    "                    callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Time-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/hfawaz/dl-4-tsc/blob/master/classifiers/cnn.py\n",
    "\n",
    "def timecnn_model():\n",
    "    \"\"\" Returns the Time-CNN model from Ismail Fawaz et al. (2019). \"\"\"\n",
    "    \n",
    "    padding = 'valid'\n",
    "    input_layer = keras.layers.Input(input_shape)\n",
    "\n",
    "    conv1 = keras.layers.Conv1D(filters=6,kernel_size=7,padding=padding,activation='sigmoid')(input_layer)\n",
    "    conv1 = keras.layers.AveragePooling1D(pool_size=3)(conv1)\n",
    "\n",
    "    conv2 = keras.layers.Conv1D(filters=12,kernel_size=7,padding=padding,activation='sigmoid')(conv1)\n",
    "    conv2 = keras.layers.AveragePooling1D(pool_size=3)(conv2)\n",
    "\n",
    "    flatten_layer = keras.layers.Flatten()(conv2)\n",
    "\n",
    "    output_layer = keras.layers.Dense(units=1)(flatten_layer)\n",
    "\n",
    "    model = keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cnn_model()\n",
    "\n",
    "optimizer = Adam(learning_rate=0.01)    \n",
    "              \n",
    "model.compile(loss='mean_squared_error', \n",
    "              optimizer=optimizer, \n",
    "              metrics=[RootMeanSquaredError(), MeanAbsoluteError()])\n",
    "\n",
    "# TimeCNN_regressor_01: MSE, Adam, N_average=30, 2000 epochs, ES=250, RLR=50, gaussian=0.01\n",
    "output_filename = 'TimeCNN_regressor_02'\n",
    "output_file = os.path.join(PATH_MODELS, output_filename)\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath = output_file + \".hdf5\", monitor='val_loss', verbose=1, save_best_only=True)\n",
    "earlystopper = EarlyStopping(monitor='val_loss', patience=250, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=50, min_lr=0.0001, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "143/143 [==============================] - 93s 642ms/step - loss: 321.7530 - root_mean_squared_error: 17.4269 - mean_absolute_error: 14.5173 - val_loss: 160.2513 - val_root_mean_squared_error: 12.6590 - val_mean_absolute_error: 10.2964\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 160.25128, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/TimeCNN_regressor_01.hdf5\n",
      "Epoch 2/2000\n",
      "143/143 [==============================] - 89s 623ms/step - loss: 99.1723 - root_mean_squared_error: 9.9552 - mean_absolute_error: 8.2079 - val_loss: 187.8685 - val_root_mean_squared_error: 13.7065 - val_mean_absolute_error: 10.9276\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 160.25128\n",
      "Epoch 3/2000\n",
      "143/143 [==============================] - 89s 622ms/step - loss: 105.3432 - root_mean_squared_error: 10.2628 - mean_absolute_error: 8.5573 - val_loss: 121.3760 - val_root_mean_squared_error: 11.0171 - val_mean_absolute_error: 9.1967\n",
      "\n",
      "Epoch 00003: val_loss improved from 160.25128 to 121.37595, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/TimeCNN_regressor_01.hdf5\n",
      "Epoch 4/2000\n",
      "143/143 [==============================] - 89s 621ms/step - loss: 95.5844 - root_mean_squared_error: 9.7746 - mean_absolute_error: 8.1093 - val_loss: 114.2874 - val_root_mean_squared_error: 10.6905 - val_mean_absolute_error: 8.7811\n",
      "\n",
      "Epoch 00004: val_loss improved from 121.37595 to 114.28737, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/TimeCNN_regressor_01.hdf5\n",
      "Epoch 5/2000\n",
      "143/143 [==============================] - 92s 646ms/step - loss: 105.7083 - root_mean_squared_error: 10.2787 - mean_absolute_error: 8.6549 - val_loss: 108.9185 - val_root_mean_squared_error: 10.4364 - val_mean_absolute_error: 8.8403\n",
      "\n",
      "Epoch 00005: val_loss improved from 114.28737 to 108.91852, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/TimeCNN_regressor_01.hdf5\n",
      "Epoch 6/2000\n",
      "143/143 [==============================] - 90s 631ms/step - loss: 100.1056 - root_mean_squared_error: 10.0033 - mean_absolute_error: 8.3740 - val_loss: 106.0813 - val_root_mean_squared_error: 10.2996 - val_mean_absolute_error: 8.3509\n",
      "\n",
      "Epoch 00006: val_loss improved from 108.91852 to 106.08126, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/TimeCNN_regressor_01.hdf5\n",
      "Epoch 7/2000\n",
      "143/143 [==============================] - 90s 632ms/step - loss: 99.4573 - root_mean_squared_error: 9.9688 - mean_absolute_error: 8.3393 - val_loss: 97.8220 - val_root_mean_squared_error: 9.8905 - val_mean_absolute_error: 8.1904\n",
      "\n",
      "Epoch 00007: val_loss improved from 106.08126 to 97.82200, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/TimeCNN_regressor_01.hdf5\n",
      "Epoch 8/2000\n",
      "143/143 [==============================] - 90s 632ms/step - loss: 101.4385 - root_mean_squared_error: 10.0708 - mean_absolute_error: 8.4045 - val_loss: 108.4507 - val_root_mean_squared_error: 10.4140 - val_mean_absolute_error: 8.4923\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 97.82200\n",
      "Epoch 9/2000\n",
      "143/143 [==============================] - 91s 640ms/step - loss: 100.1712 - root_mean_squared_error: 10.0011 - mean_absolute_error: 8.3887 - val_loss: 98.7186 - val_root_mean_squared_error: 9.9357 - val_mean_absolute_error: 8.3237\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 97.82200\n",
      "Epoch 10/2000\n",
      "143/143 [==============================] - 89s 625ms/step - loss: 104.4047 - root_mean_squared_error: 10.2141 - mean_absolute_error: 8.4323 - val_loss: 86.2776 - val_root_mean_squared_error: 9.2886 - val_mean_absolute_error: 7.5354\n",
      "\n",
      "Epoch 00010: val_loss improved from 97.82200 to 86.27763, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/TimeCNN_regressor_01.hdf5\n",
      "Epoch 11/2000\n",
      "143/143 [==============================] - 89s 619ms/step - loss: 96.0538 - root_mean_squared_error: 9.7971 - mean_absolute_error: 8.2811 - val_loss: 85.8803 - val_root_mean_squared_error: 9.2672 - val_mean_absolute_error: 7.8067\n",
      "\n",
      "Epoch 00011: val_loss improved from 86.27763 to 85.88030, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/TimeCNN_regressor_01.hdf5\n",
      "Epoch 12/2000\n",
      "143/143 [==============================] - 86s 602ms/step - loss: 95.7204 - root_mean_squared_error: 9.7815 - mean_absolute_error: 8.1421 - val_loss: 102.2162 - val_root_mean_squared_error: 10.1102 - val_mean_absolute_error: 8.1997\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 85.88030\n",
      "Epoch 13/2000\n",
      "143/143 [==============================] - 88s 620ms/step - loss: 100.9609 - root_mean_squared_error: 10.0461 - mean_absolute_error: 8.2951 - val_loss: 104.2514 - val_root_mean_squared_error: 10.2104 - val_mean_absolute_error: 8.4857\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 85.88030\n",
      "Epoch 14/2000\n",
      "143/143 [==============================] - 88s 613ms/step - loss: 94.0129 - root_mean_squared_error: 9.6876 - mean_absolute_error: 8.0031 - val_loss: 93.8560 - val_root_mean_squared_error: 9.6879 - val_mean_absolute_error: 8.0384\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 85.88030\n",
      "Epoch 15/2000\n",
      "143/143 [==============================] - 87s 610ms/step - loss: 99.1740 - root_mean_squared_error: 9.9550 - mean_absolute_error: 8.1152 - val_loss: 100.4412 - val_root_mean_squared_error: 10.0220 - val_mean_absolute_error: 8.2490\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 85.88030\n",
      "Epoch 16/2000\n",
      "143/143 [==============================] - 87s 609ms/step - loss: 101.6519 - root_mean_squared_error: 10.0720 - mean_absolute_error: 8.4074 - val_loss: 91.2553 - val_root_mean_squared_error: 9.5528 - val_mean_absolute_error: 7.9031\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 85.88030\n",
      "Epoch 17/2000\n",
      "143/143 [==============================] - 86s 601ms/step - loss: 94.0430 - root_mean_squared_error: 9.6938 - mean_absolute_error: 8.1399 - val_loss: 83.4371 - val_root_mean_squared_error: 9.1344 - val_mean_absolute_error: 7.6300\n",
      "\n",
      "Epoch 00017: val_loss improved from 85.88030 to 83.43713, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/TimeCNN_regressor_01.hdf5\n",
      "Epoch 18/2000\n",
      "143/143 [==============================] - 87s 608ms/step - loss: 95.3041 - root_mean_squared_error: 9.7586 - mean_absolute_error: 8.0848 - val_loss: 100.7756 - val_root_mean_squared_error: 10.0387 - val_mean_absolute_error: 8.3295\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 83.43713\n",
      "Epoch 19/2000\n",
      "143/143 [==============================] - 86s 603ms/step - loss: 90.7610 - root_mean_squared_error: 9.5233 - mean_absolute_error: 7.8411 - val_loss: 104.2443 - val_root_mean_squared_error: 10.2100 - val_mean_absolute_error: 8.6717\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 83.43713\n",
      "Epoch 20/2000\n",
      "143/143 [==============================] - 89s 623ms/step - loss: 84.6012 - root_mean_squared_error: 9.1840 - mean_absolute_error: 7.5757 - val_loss: 90.6247 - val_root_mean_squared_error: 9.5197 - val_mean_absolute_error: 8.0230\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 83.43713\n",
      "Epoch 21/2000\n",
      "143/143 [==============================] - 88s 615ms/step - loss: 98.2383 - root_mean_squared_error: 9.8994 - mean_absolute_error: 8.2951 - val_loss: 95.1110 - val_root_mean_squared_error: 9.7525 - val_mean_absolute_error: 7.9910\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 83.43713\n",
      "Epoch 22/2000\n",
      "143/143 [==============================] - 88s 613ms/step - loss: 88.9431 - root_mean_squared_error: 9.4257 - mean_absolute_error: 7.7663 - val_loss: 96.3697 - val_root_mean_squared_error: 9.8168 - val_mean_absolute_error: 8.0716\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 83.43713\n",
      "Epoch 23/2000\n",
      "143/143 [==============================] - 86s 605ms/step - loss: 90.7467 - root_mean_squared_error: 9.5250 - mean_absolute_error: 7.9629 - val_loss: 98.1927 - val_root_mean_squared_error: 9.9092 - val_mean_absolute_error: 8.3837\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 83.43713\n",
      "Epoch 24/2000\n",
      "143/143 [==============================] - 87s 610ms/step - loss: 86.0974 - root_mean_squared_error: 9.2751 - mean_absolute_error: 7.6923 - val_loss: 87.1649 - val_root_mean_squared_error: 9.3362 - val_mean_absolute_error: 7.8683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00024: val_loss did not improve from 83.43713\n",
      "Epoch 25/2000\n",
      "143/143 [==============================] - 86s 603ms/step - loss: 84.7795 - root_mean_squared_error: 9.2056 - mean_absolute_error: 7.6125 - val_loss: 95.3176 - val_root_mean_squared_error: 9.7631 - val_mean_absolute_error: 7.7439\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 83.43713\n",
      "Epoch 26/2000\n",
      "143/143 [==============================] - 83s 581ms/step - loss: 89.2550 - root_mean_squared_error: 9.4411 - mean_absolute_error: 7.7936 - val_loss: 89.3617 - val_root_mean_squared_error: 9.4531 - val_mean_absolute_error: 7.7796\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 83.43713\n",
      "Epoch 27/2000\n",
      "143/143 [==============================] - 83s 584ms/step - loss: 84.8994 - root_mean_squared_error: 9.2108 - mean_absolute_error: 7.6540 - val_loss: 100.0338 - val_root_mean_squared_error: 10.0017 - val_mean_absolute_error: 8.5045\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 83.43713\n",
      "Epoch 28/2000\n",
      "143/143 [==============================] - 89s 622ms/step - loss: 78.2484 - root_mean_squared_error: 8.8445 - mean_absolute_error: 7.1857 - val_loss: 107.2955 - val_root_mean_squared_error: 10.3584 - val_mean_absolute_error: 8.5334\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 83.43713\n",
      "Epoch 29/2000\n",
      "143/143 [==============================] - 89s 622ms/step - loss: 89.8421 - root_mean_squared_error: 9.4742 - mean_absolute_error: 7.8992 - val_loss: 83.3537 - val_root_mean_squared_error: 9.1298 - val_mean_absolute_error: 7.5530\n",
      "\n",
      "Epoch 00029: val_loss improved from 83.43713 to 83.35370, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/TimeCNN_regressor_01.hdf5\n",
      "Epoch 30/2000\n",
      "143/143 [==============================] - 89s 620ms/step - loss: 85.2116 - root_mean_squared_error: 9.2262 - mean_absolute_error: 7.6313 - val_loss: 92.3459 - val_root_mean_squared_error: 9.6097 - val_mean_absolute_error: 7.7594\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 83.35370\n",
      "Epoch 31/2000\n",
      "143/143 [==============================] - 91s 637ms/step - loss: 84.2700 - root_mean_squared_error: 9.1789 - mean_absolute_error: 7.5847 - val_loss: 98.4211 - val_root_mean_squared_error: 9.9207 - val_mean_absolute_error: 8.0536\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 83.35370\n",
      "Epoch 32/2000\n",
      "143/143 [==============================] - 88s 615ms/step - loss: 84.9068 - root_mean_squared_error: 9.2134 - mean_absolute_error: 7.6085 - val_loss: 123.8970 - val_root_mean_squared_error: 11.1309 - val_mean_absolute_error: 8.9462\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 83.35370\n",
      "Epoch 33/2000\n",
      "143/143 [==============================] - 89s 625ms/step - loss: 80.5916 - root_mean_squared_error: 8.9762 - mean_absolute_error: 7.4320 - val_loss: 76.7062 - val_root_mean_squared_error: 8.7582 - val_mean_absolute_error: 7.2419\n",
      "\n",
      "Epoch 00033: val_loss improved from 83.35370 to 76.70616, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/TimeCNN_regressor_01.hdf5\n",
      "Epoch 34/2000\n",
      "143/143 [==============================] - 89s 624ms/step - loss: 87.7201 - root_mean_squared_error: 9.3621 - mean_absolute_error: 7.7552 - val_loss: 73.9552 - val_root_mean_squared_error: 8.5997 - val_mean_absolute_error: 7.2376\n",
      "\n",
      "Epoch 00034: val_loss improved from 76.70616 to 73.95519, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/TimeCNN_regressor_01.hdf5\n",
      "Epoch 35/2000\n",
      "143/143 [==============================] - 90s 630ms/step - loss: 81.6038 - root_mean_squared_error: 9.0299 - mean_absolute_error: 7.3340 - val_loss: 82.3007 - val_root_mean_squared_error: 9.0720 - val_mean_absolute_error: 7.3391\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 73.95519\n",
      "Epoch 36/2000\n",
      "143/143 [==============================] - 83s 581ms/step - loss: 72.7281 - root_mean_squared_error: 8.5248 - mean_absolute_error: 7.0287 - val_loss: 80.9013 - val_root_mean_squared_error: 8.9945 - val_mean_absolute_error: 7.4509\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 73.95519\n",
      "Epoch 37/2000\n",
      "143/143 [==============================] - 87s 607ms/step - loss: 81.6315 - root_mean_squared_error: 9.0317 - mean_absolute_error: 7.4395 - val_loss: 75.2304 - val_root_mean_squared_error: 8.6735 - val_mean_absolute_error: 7.2150\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 73.95519\n",
      "Epoch 38/2000\n",
      "143/143 [==============================] - 87s 608ms/step - loss: 79.3894 - root_mean_squared_error: 8.9030 - mean_absolute_error: 7.3660 - val_loss: 86.4909 - val_root_mean_squared_error: 9.3000 - val_mean_absolute_error: 7.5311\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 73.95519\n",
      "Epoch 39/2000\n",
      "143/143 [==============================] - 87s 607ms/step - loss: 83.9699 - root_mean_squared_error: 9.1604 - mean_absolute_error: 7.5416 - val_loss: 75.9056 - val_root_mean_squared_error: 8.7124 - val_mean_absolute_error: 7.1268\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 73.95519\n",
      "Epoch 40/2000\n",
      "143/143 [==============================] - 88s 616ms/step - loss: 77.6581 - root_mean_squared_error: 8.8058 - mean_absolute_error: 7.1384 - val_loss: 84.2852 - val_root_mean_squared_error: 9.1807 - val_mean_absolute_error: 7.4975\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 73.95519\n",
      "Epoch 41/2000\n",
      "143/143 [==============================] - 87s 609ms/step - loss: 73.4788 - root_mean_squared_error: 8.5696 - mean_absolute_error: 7.0616 - val_loss: 72.6816 - val_root_mean_squared_error: 8.5254 - val_mean_absolute_error: 6.8613\n",
      "\n",
      "Epoch 00041: val_loss improved from 73.95519 to 72.68159, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/TimeCNN_regressor_01.hdf5\n",
      "Epoch 42/2000\n",
      "143/143 [==============================] - 87s 609ms/step - loss: 68.8885 - root_mean_squared_error: 8.2950 - mean_absolute_error: 6.8532 - val_loss: 89.4707 - val_root_mean_squared_error: 9.4589 - val_mean_absolute_error: 7.6700\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 72.68159\n",
      "Epoch 43/2000\n",
      "143/143 [==============================] - 88s 616ms/step - loss: 69.7549 - root_mean_squared_error: 8.3486 - mean_absolute_error: 6.8707 - val_loss: 76.9786 - val_root_mean_squared_error: 8.7737 - val_mean_absolute_error: 7.2227\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 72.68159\n",
      "Epoch 44/2000\n",
      "143/143 [==============================] - 86s 605ms/step - loss: 70.5918 - root_mean_squared_error: 8.4003 - mean_absolute_error: 6.8380 - val_loss: 77.8997 - val_root_mean_squared_error: 8.8261 - val_mean_absolute_error: 7.2509\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 72.68159\n",
      "Epoch 45/2000\n",
      "143/143 [==============================] - 88s 616ms/step - loss: 72.9770 - root_mean_squared_error: 8.5414 - mean_absolute_error: 7.1168 - val_loss: 95.6813 - val_root_mean_squared_error: 9.7817 - val_mean_absolute_error: 7.6623\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 72.68159\n",
      "Epoch 46/2000\n",
      "143/143 [==============================] - 89s 621ms/step - loss: 72.1342 - root_mean_squared_error: 8.4926 - mean_absolute_error: 7.0273 - val_loss: 81.5451 - val_root_mean_squared_error: 9.0302 - val_mean_absolute_error: 7.4914\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 72.68159\n",
      "Epoch 47/2000\n",
      "143/143 [==============================] - 90s 627ms/step - loss: 68.4006 - root_mean_squared_error: 8.2688 - mean_absolute_error: 6.7283 - val_loss: 66.4430 - val_root_mean_squared_error: 8.1513 - val_mean_absolute_error: 6.4974\n",
      "\n",
      "Epoch 00047: val_loss improved from 72.68159 to 66.44296, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/TimeCNN_regressor_01.hdf5\n",
      "Epoch 48/2000\n",
      "143/143 [==============================] - 88s 615ms/step - loss: 63.5105 - root_mean_squared_error: 7.9662 - mean_absolute_error: 6.3546 - val_loss: 76.0176 - val_root_mean_squared_error: 8.7188 - val_mean_absolute_error: 6.9861\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 66.44296\n",
      "Epoch 49/2000\n",
      "143/143 [==============================] - 83s 583ms/step - loss: 75.1507 - root_mean_squared_error: 8.6665 - mean_absolute_error: 6.9726 - val_loss: 86.3216 - val_root_mean_squared_error: 9.2909 - val_mean_absolute_error: 7.8321\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 66.44296\n",
      "Epoch 50/2000\n",
      "143/143 [==============================] - 88s 613ms/step - loss: 63.3316 - root_mean_squared_error: 7.9527 - mean_absolute_error: 6.4595 - val_loss: 87.0124 - val_root_mean_squared_error: 9.3280 - val_mean_absolute_error: 7.5680\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 66.44296\n",
      "Epoch 51/2000\n",
      "143/143 [==============================] - 90s 632ms/step - loss: 73.2359 - root_mean_squared_error: 8.5534 - mean_absolute_error: 7.1119 - val_loss: 69.1601 - val_root_mean_squared_error: 8.3163 - val_mean_absolute_error: 6.8026\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 66.44296\n",
      "Epoch 52/2000\n",
      "143/143 [==============================] - 86s 598ms/step - loss: 68.8978 - root_mean_squared_error: 8.2992 - mean_absolute_error: 6.7474 - val_loss: 79.7884 - val_root_mean_squared_error: 8.9324 - val_mean_absolute_error: 7.1868\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 66.44296\n",
      "Epoch 53/2000\n",
      "143/143 [==============================] - 89s 622ms/step - loss: 64.7696 - root_mean_squared_error: 8.0451 - mean_absolute_error: 6.5921 - val_loss: 70.7515 - val_root_mean_squared_error: 8.4114 - val_mean_absolute_error: 6.8309\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 66.44296\n",
      "Epoch 54/2000\n",
      "143/143 [==============================] - 89s 624ms/step - loss: 68.5075 - root_mean_squared_error: 8.2754 - mean_absolute_error: 6.7165 - val_loss: 65.7518 - val_root_mean_squared_error: 8.1088 - val_mean_absolute_error: 6.6465\n",
      "\n",
      "Epoch 00054: val_loss improved from 66.44296 to 65.75184, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/TimeCNN_regressor_01.hdf5\n",
      "Epoch 55/2000\n",
      "143/143 [==============================] - 88s 617ms/step - loss: 64.2692 - root_mean_squared_error: 8.0131 - mean_absolute_error: 6.5667 - val_loss: 90.1047 - val_root_mean_squared_error: 9.4923 - val_mean_absolute_error: 7.8539\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 65.75184\n",
      "Epoch 56/2000\n",
      "143/143 [==============================] - 85s 598ms/step - loss: 68.3584 - root_mean_squared_error: 8.2635 - mean_absolute_error: 6.7626 - val_loss: 86.6272 - val_root_mean_squared_error: 9.3074 - val_mean_absolute_error: 7.2297\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 65.75184\n",
      "Epoch 57/2000\n",
      "143/143 [==============================] - 88s 619ms/step - loss: 68.5786 - root_mean_squared_error: 8.2640 - mean_absolute_error: 6.5919 - val_loss: 74.8679 - val_root_mean_squared_error: 8.6526 - val_mean_absolute_error: 6.8976\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 65.75184\n",
      "Epoch 58/2000\n",
      "143/143 [==============================] - 90s 627ms/step - loss: 71.7110 - root_mean_squared_error: 8.4622 - mean_absolute_error: 6.9699 - val_loss: 83.9268 - val_root_mean_squared_error: 9.1612 - val_mean_absolute_error: 7.1081\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 65.75184\n",
      "Epoch 59/2000\n",
      "143/143 [==============================] - 90s 628ms/step - loss: 75.5757 - root_mean_squared_error: 8.6834 - mean_absolute_error: 7.0716 - val_loss: 82.1698 - val_root_mean_squared_error: 9.0648 - val_mean_absolute_error: 7.3408\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 65.75184\n",
      "Epoch 60/2000\n",
      "143/143 [==============================] - 88s 618ms/step - loss: 69.6252 - root_mean_squared_error: 8.3412 - mean_absolute_error: 6.7261 - val_loss: 63.8201 - val_root_mean_squared_error: 7.9887 - val_mean_absolute_error: 6.2891\n",
      "\n",
      "Epoch 00060: val_loss improved from 65.75184 to 63.82006, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/TimeCNN_regressor_01.hdf5\n",
      "Epoch 61/2000\n",
      "143/143 [==============================] - 92s 642ms/step - loss: 69.3007 - root_mean_squared_error: 8.3193 - mean_absolute_error: 6.7108 - val_loss: 75.1939 - val_root_mean_squared_error: 8.6714 - val_mean_absolute_error: 7.0874\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 63.82006\n",
      "Epoch 62/2000\n",
      "143/143 [==============================] - 90s 630ms/step - loss: 69.6418 - root_mean_squared_error: 8.3397 - mean_absolute_error: 6.7787 - val_loss: 82.1347 - val_root_mean_squared_error: 9.0628 - val_mean_absolute_error: 7.4725\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 63.82006\n",
      "Epoch 63/2000\n",
      "143/143 [==============================] - 90s 627ms/step - loss: 70.1890 - root_mean_squared_error: 8.3733 - mean_absolute_error: 6.8040 - val_loss: 71.5667 - val_root_mean_squared_error: 8.4597 - val_mean_absolute_error: 6.8697\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 63.82006\n",
      "Epoch 64/2000\n",
      "143/143 [==============================] - 88s 619ms/step - loss: 63.8932 - root_mean_squared_error: 7.9913 - mean_absolute_error: 6.5250 - val_loss: 86.0679 - val_root_mean_squared_error: 9.2773 - val_mean_absolute_error: 7.2752\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 63.82006\n",
      "Epoch 65/2000\n",
      "143/143 [==============================] - 88s 618ms/step - loss: 63.6013 - root_mean_squared_error: 7.9711 - mean_absolute_error: 6.4878 - val_loss: 96.4608 - val_root_mean_squared_error: 9.8214 - val_mean_absolute_error: 8.2707\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 63.82006\n",
      "Epoch 66/2000\n",
      "143/143 [==============================] - 88s 617ms/step - loss: 72.9812 - root_mean_squared_error: 8.5378 - mean_absolute_error: 6.9313 - val_loss: 74.2348 - val_root_mean_squared_error: 8.6160 - val_mean_absolute_error: 6.9395\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 63.82006\n",
      "Epoch 67/2000\n",
      "143/143 [==============================] - 91s 640ms/step - loss: 60.4799 - root_mean_squared_error: 7.7680 - mean_absolute_error: 6.3061 - val_loss: 67.1760 - val_root_mean_squared_error: 8.1961 - val_mean_absolute_error: 6.7143\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 63.82006\n",
      "Epoch 68/2000\n",
      "143/143 [==============================] - 91s 639ms/step - loss: 66.5826 - root_mean_squared_error: 8.1574 - mean_absolute_error: 6.5555 - val_loss: 82.8291 - val_root_mean_squared_error: 9.1011 - val_mean_absolute_error: 7.0557\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 63.82006\n",
      "Epoch 69/2000\n",
      "143/143 [==============================] - 90s 631ms/step - loss: 62.7558 - root_mean_squared_error: 7.9209 - mean_absolute_error: 6.4415 - val_loss: 82.3923 - val_root_mean_squared_error: 9.0770 - val_mean_absolute_error: 7.1195\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 63.82006\n",
      "Epoch 70/2000\n",
      "143/143 [==============================] - 89s 624ms/step - loss: 62.1049 - root_mean_squared_error: 7.8774 - mean_absolute_error: 6.4351 - val_loss: 68.6898 - val_root_mean_squared_error: 8.2879 - val_mean_absolute_error: 6.9239\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 63.82006\n",
      "Epoch 71/2000\n",
      "143/143 [==============================] - 91s 640ms/step - loss: 58.4370 - root_mean_squared_error: 7.6418 - mean_absolute_error: 6.2045 - val_loss: 83.2492 - val_root_mean_squared_error: 9.1241 - val_mean_absolute_error: 7.6297\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 63.82006\n",
      "Epoch 72/2000\n",
      "143/143 [==============================] - 90s 628ms/step - loss: 68.1754 - root_mean_squared_error: 8.2553 - mean_absolute_error: 6.7558 - val_loss: 77.6442 - val_root_mean_squared_error: 8.8116 - val_mean_absolute_error: 7.3763\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 63.82006\n",
      "Epoch 73/2000\n",
      "143/143 [==============================] - 91s 636ms/step - loss: 68.4342 - root_mean_squared_error: 8.2673 - mean_absolute_error: 6.7513 - val_loss: 77.1966 - val_root_mean_squared_error: 8.7862 - val_mean_absolute_error: 6.9698\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 63.82006\n",
      "Epoch 74/2000\n",
      "143/143 [==============================] - 90s 627ms/step - loss: 68.5929 - root_mean_squared_error: 8.2779 - mean_absolute_error: 6.8105 - val_loss: 67.2716 - val_root_mean_squared_error: 8.2019 - val_mean_absolute_error: 6.4442\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 63.82006\n",
      "Epoch 75/2000\n",
      "143/143 [==============================] - 90s 629ms/step - loss: 64.5191 - root_mean_squared_error: 8.0263 - mean_absolute_error: 6.5908 - val_loss: 75.6242 - val_root_mean_squared_error: 8.6962 - val_mean_absolute_error: 7.1146\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 63.82006\n",
      "Epoch 76/2000\n",
      "143/143 [==============================] - 89s 620ms/step - loss: 64.0448 - root_mean_squared_error: 7.9987 - mean_absolute_error: 6.4883 - val_loss: 93.9209 - val_root_mean_squared_error: 9.6913 - val_mean_absolute_error: 7.9341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00076: val_loss did not improve from 63.82006\n",
      "Epoch 77/2000\n",
      "143/143 [==============================] - 90s 628ms/step - loss: 61.4023 - root_mean_squared_error: 7.8217 - mean_absolute_error: 6.2745 - val_loss: 91.0890 - val_root_mean_squared_error: 9.5441 - val_mean_absolute_error: 7.3644\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 63.82006\n",
      "Epoch 78/2000\n",
      "143/143 [==============================] - 89s 621ms/step - loss: 68.1493 - root_mean_squared_error: 8.2511 - mean_absolute_error: 6.6158 - val_loss: 62.1471 - val_root_mean_squared_error: 7.8833 - val_mean_absolute_error: 6.4276\n",
      "\n",
      "Epoch 00078: val_loss improved from 63.82006 to 62.14713, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/TimeCNN_regressor_01.hdf5\n",
      "Epoch 79/2000\n",
      "143/143 [==============================] - 88s 618ms/step - loss: 66.1399 - root_mean_squared_error: 8.1301 - mean_absolute_error: 6.6317 - val_loss: 75.2805 - val_root_mean_squared_error: 8.6764 - val_mean_absolute_error: 7.0529\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 62.14713\n",
      "Epoch 80/2000\n",
      "143/143 [==============================] - 89s 622ms/step - loss: 62.7796 - root_mean_squared_error: 7.9132 - mean_absolute_error: 6.3067 - val_loss: 89.8013 - val_root_mean_squared_error: 9.4764 - val_mean_absolute_error: 7.2379\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 62.14713\n",
      "Epoch 81/2000\n",
      "143/143 [==============================] - 92s 642ms/step - loss: 62.0323 - root_mean_squared_error: 7.8737 - mean_absolute_error: 6.3497 - val_loss: 69.2202 - val_root_mean_squared_error: 8.3199 - val_mean_absolute_error: 6.7549\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 62.14713\n",
      "Epoch 82/2000\n",
      "143/143 [==============================] - 91s 634ms/step - loss: 65.1513 - root_mean_squared_error: 8.0694 - mean_absolute_error: 6.5474 - val_loss: 67.1233 - val_root_mean_squared_error: 8.1929 - val_mean_absolute_error: 6.8338\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 62.14713\n",
      "Epoch 83/2000\n",
      "143/143 [==============================] - 89s 624ms/step - loss: 67.9601 - root_mean_squared_error: 8.2365 - mean_absolute_error: 6.7767 - val_loss: 84.5236 - val_root_mean_squared_error: 9.1937 - val_mean_absolute_error: 7.5101\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 62.14713\n",
      "Epoch 84/2000\n",
      "143/143 [==============================] - 89s 624ms/step - loss: 68.2456 - root_mean_squared_error: 8.2544 - mean_absolute_error: 6.6661 - val_loss: 98.8336 - val_root_mean_squared_error: 9.9415 - val_mean_absolute_error: 7.8885\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 62.14713\n",
      "Epoch 85/2000\n",
      "143/143 [==============================] - 90s 628ms/step - loss: 72.3032 - root_mean_squared_error: 8.4996 - mean_absolute_error: 7.0134 - val_loss: 83.3387 - val_root_mean_squared_error: 9.1290 - val_mean_absolute_error: 7.1375\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 62.14713\n",
      "Epoch 86/2000\n",
      "143/143 [==============================] - 84s 590ms/step - loss: 68.3435 - root_mean_squared_error: 8.2658 - mean_absolute_error: 6.7523 - val_loss: 78.6105 - val_root_mean_squared_error: 8.8663 - val_mean_absolute_error: 7.2385\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 62.14713\n",
      "Epoch 87/2000\n",
      "143/143 [==============================] - 84s 587ms/step - loss: 66.6214 - root_mean_squared_error: 8.1595 - mean_absolute_error: 6.6493 - val_loss: 81.5768 - val_root_mean_squared_error: 9.0320 - val_mean_absolute_error: 7.3459\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 62.14713\n",
      "Epoch 88/2000\n",
      "143/143 [==============================] - 85s 593ms/step - loss: 60.9849 - root_mean_squared_error: 7.8078 - mean_absolute_error: 6.2876 - val_loss: 90.0832 - val_root_mean_squared_error: 9.4912 - val_mean_absolute_error: 7.2282\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 62.14713\n",
      "Epoch 89/2000\n",
      "143/143 [==============================] - 84s 588ms/step - loss: 58.6859 - root_mean_squared_error: 7.6568 - mean_absolute_error: 6.0919 - val_loss: 75.5346 - val_root_mean_squared_error: 8.6911 - val_mean_absolute_error: 7.2215\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 62.14713\n",
      "Epoch 90/2000\n",
      "143/143 [==============================] - 88s 612ms/step - loss: 66.2389 - root_mean_squared_error: 8.1367 - mean_absolute_error: 6.6819 - val_loss: 60.7884 - val_root_mean_squared_error: 7.7967 - val_mean_absolute_error: 6.4829\n",
      "\n",
      "Epoch 00090: val_loss improved from 62.14713 to 60.78840, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/TimeCNN_regressor_01.hdf5\n",
      "Epoch 91/2000\n",
      "143/143 [==============================] - 89s 620ms/step - loss: 64.1322 - root_mean_squared_error: 8.0073 - mean_absolute_error: 6.4372 - val_loss: 67.9584 - val_root_mean_squared_error: 8.2437 - val_mean_absolute_error: 6.9186\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 60.78840\n",
      "Epoch 92/2000\n",
      "143/143 [==============================] - 89s 627ms/step - loss: 64.5502 - root_mean_squared_error: 8.0327 - mean_absolute_error: 6.5587 - val_loss: 75.0672 - val_root_mean_squared_error: 8.6641 - val_mean_absolute_error: 7.1083\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 60.78840\n",
      "Epoch 93/2000\n",
      "143/143 [==============================] - 90s 631ms/step - loss: 66.7013 - root_mean_squared_error: 8.1643 - mean_absolute_error: 6.6395 - val_loss: 72.9549 - val_root_mean_squared_error: 8.5414 - val_mean_absolute_error: 6.7135\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 60.78840\n",
      "Epoch 94/2000\n",
      "143/143 [==============================] - 89s 625ms/step - loss: 57.1100 - root_mean_squared_error: 7.5544 - mean_absolute_error: 6.1478 - val_loss: 77.5183 - val_root_mean_squared_error: 8.8044 - val_mean_absolute_error: 7.0274\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 60.78840\n",
      "Epoch 95/2000\n",
      "143/143 [==============================] - 87s 611ms/step - loss: 60.0991 - root_mean_squared_error: 7.7502 - mean_absolute_error: 6.2446 - val_loss: 74.1099 - val_root_mean_squared_error: 8.6087 - val_mean_absolute_error: 7.0935\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 60.78840\n",
      "Epoch 96/2000\n",
      "143/143 [==============================] - 88s 615ms/step - loss: 58.6207 - root_mean_squared_error: 7.6539 - mean_absolute_error: 6.2124 - val_loss: 76.0140 - val_root_mean_squared_error: 8.7186 - val_mean_absolute_error: 6.8459\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 60.78840\n",
      "Epoch 97/2000\n",
      "143/143 [==============================] - 86s 601ms/step - loss: 62.6919 - root_mean_squared_error: 7.9087 - mean_absolute_error: 6.4468 - val_loss: 60.1693 - val_root_mean_squared_error: 7.7569 - val_mean_absolute_error: 6.3421\n",
      "\n",
      "Epoch 00097: val_loss improved from 60.78840 to 60.16933, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/TimeCNN_regressor_01.hdf5\n",
      "Epoch 98/2000\n",
      "143/143 [==============================] - 88s 618ms/step - loss: 64.6985 - root_mean_squared_error: 8.0374 - mean_absolute_error: 6.6133 - val_loss: 79.2278 - val_root_mean_squared_error: 8.9010 - val_mean_absolute_error: 7.3583\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 60.16933\n",
      "Epoch 99/2000\n",
      "143/143 [==============================] - 89s 621ms/step - loss: 64.0167 - root_mean_squared_error: 7.9979 - mean_absolute_error: 6.4942 - val_loss: 70.1537 - val_root_mean_squared_error: 8.3758 - val_mean_absolute_error: 6.7939\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 60.16933\n",
      "Epoch 100/2000\n",
      "143/143 [==============================] - 89s 620ms/step - loss: 62.6218 - root_mean_squared_error: 7.9099 - mean_absolute_error: 6.3744 - val_loss: 68.0350 - val_root_mean_squared_error: 8.2483 - val_mean_absolute_error: 5.9996\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 60.16933\n",
      "Epoch 101/2000\n",
      "143/143 [==============================] - 89s 620ms/step - loss: 62.0474 - root_mean_squared_error: 7.8644 - mean_absolute_error: 6.4139 - val_loss: 66.8784 - val_root_mean_squared_error: 8.1779 - val_mean_absolute_error: 6.7268\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 60.16933\n",
      "Epoch 102/2000\n",
      "143/143 [==============================] - 86s 603ms/step - loss: 68.2792 - root_mean_squared_error: 8.2611 - mean_absolute_error: 6.7061 - val_loss: 70.4241 - val_root_mean_squared_error: 8.3919 - val_mean_absolute_error: 6.7937\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 60.16933\n",
      "Epoch 103/2000\n",
      "143/143 [==============================] - 90s 630ms/step - loss: 64.2954 - root_mean_squared_error: 8.0121 - mean_absolute_error: 6.4398 - val_loss: 62.0226 - val_root_mean_squared_error: 7.8754 - val_mean_absolute_error: 6.5179\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 60.16933\n",
      "Epoch 104/2000\n",
      "143/143 [==============================] - 88s 617ms/step - loss: 63.9415 - root_mean_squared_error: 7.9945 - mean_absolute_error: 6.4161 - val_loss: 79.7883 - val_root_mean_squared_error: 8.9324 - val_mean_absolute_error: 7.2007\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 60.16933\n",
      "Epoch 105/2000\n",
      "143/143 [==============================] - 87s 607ms/step - loss: 65.6162 - root_mean_squared_error: 8.0979 - mean_absolute_error: 6.6591 - val_loss: 79.1635 - val_root_mean_squared_error: 8.8974 - val_mean_absolute_error: 7.2823\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 60.16933\n",
      "Epoch 106/2000\n",
      "143/143 [==============================] - 89s 626ms/step - loss: 61.2338 - root_mean_squared_error: 7.8217 - mean_absolute_error: 6.3829 - val_loss: 74.6282 - val_root_mean_squared_error: 8.6388 - val_mean_absolute_error: 7.1162\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 60.16933\n",
      "Epoch 107/2000\n",
      "143/143 [==============================] - 92s 642ms/step - loss: 61.1451 - root_mean_squared_error: 7.8178 - mean_absolute_error: 6.4572 - val_loss: 65.1709 - val_root_mean_squared_error: 8.0728 - val_mean_absolute_error: 6.5588\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 60.16933\n",
      "Epoch 108/2000\n",
      "143/143 [==============================] - 90s 630ms/step - loss: 59.5435 - root_mean_squared_error: 7.7141 - mean_absolute_error: 6.3535 - val_loss: 67.9817 - val_root_mean_squared_error: 8.2451 - val_mean_absolute_error: 6.7167\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 60.16933\n",
      "Epoch 109/2000\n",
      "143/143 [==============================] - 91s 636ms/step - loss: 63.1950 - root_mean_squared_error: 7.9464 - mean_absolute_error: 6.4215 - val_loss: 62.5984 - val_root_mean_squared_error: 7.9119 - val_mean_absolute_error: 6.3254\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 60.16933\n",
      "Epoch 110/2000\n",
      "143/143 [==============================] - 90s 628ms/step - loss: 66.5082 - root_mean_squared_error: 8.1537 - mean_absolute_error: 6.7007 - val_loss: 70.1299 - val_root_mean_squared_error: 8.3744 - val_mean_absolute_error: 6.8032\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 60.16933\n",
      "Epoch 111/2000\n",
      "143/143 [==============================] - 90s 633ms/step - loss: 62.2150 - root_mean_squared_error: 7.8858 - mean_absolute_error: 6.4358 - val_loss: 66.8209 - val_root_mean_squared_error: 8.1744 - val_mean_absolute_error: 6.3998\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 60.16933\n",
      "Epoch 112/2000\n",
      "143/143 [==============================] - 91s 636ms/step - loss: 63.8977 - root_mean_squared_error: 7.9882 - mean_absolute_error: 6.4334 - val_loss: 67.6226 - val_root_mean_squared_error: 8.2233 - val_mean_absolute_error: 6.6403\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 60.16933\n",
      "Epoch 113/2000\n",
      "143/143 [==============================] - 89s 627ms/step - loss: 64.6957 - root_mean_squared_error: 8.0264 - mean_absolute_error: 6.5020 - val_loss: 71.8699 - val_root_mean_squared_error: 8.4776 - val_mean_absolute_error: 6.9188\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 60.16933\n",
      "Epoch 114/2000\n",
      "143/143 [==============================] - 89s 624ms/step - loss: 65.0893 - root_mean_squared_error: 8.0636 - mean_absolute_error: 6.6045 - val_loss: 71.2098 - val_root_mean_squared_error: 8.4386 - val_mean_absolute_error: 6.6656\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 60.16933\n",
      "Epoch 115/2000\n",
      "143/143 [==============================] - 89s 626ms/step - loss: 67.3926 - root_mean_squared_error: 8.2038 - mean_absolute_error: 6.6643 - val_loss: 66.9928 - val_root_mean_squared_error: 8.1849 - val_mean_absolute_error: 6.5197\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 60.16933\n",
      "Epoch 116/2000\n",
      "143/143 [==============================] - 89s 623ms/step - loss: 58.6382 - root_mean_squared_error: 7.6516 - mean_absolute_error: 6.2710 - val_loss: 78.1945 - val_root_mean_squared_error: 8.8428 - val_mean_absolute_error: 6.9694\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 60.16933\n",
      "Epoch 117/2000\n",
      "143/143 [==============================] - 90s 629ms/step - loss: 67.6230 - root_mean_squared_error: 8.2165 - mean_absolute_error: 6.7298 - val_loss: 66.5942 - val_root_mean_squared_error: 8.1605 - val_mean_absolute_error: 6.5871\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 60.16933\n",
      "Epoch 118/2000\n",
      "143/143 [==============================] - 89s 621ms/step - loss: 55.8191 - root_mean_squared_error: 7.4696 - mean_absolute_error: 6.0365 - val_loss: 69.8551 - val_root_mean_squared_error: 8.3579 - val_mean_absolute_error: 6.6530\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 60.16933\n",
      "Epoch 119/2000\n",
      "143/143 [==============================] - 91s 638ms/step - loss: 61.0167 - root_mean_squared_error: 7.8093 - mean_absolute_error: 6.3682 - val_loss: 70.9766 - val_root_mean_squared_error: 8.4248 - val_mean_absolute_error: 6.8365\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 60.16933\n",
      "Epoch 120/2000\n",
      "143/143 [==============================] - 91s 634ms/step - loss: 61.3452 - root_mean_squared_error: 7.8245 - mean_absolute_error: 6.3736 - val_loss: 61.5579 - val_root_mean_squared_error: 7.8459 - val_mean_absolute_error: 6.3068\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 60.16933\n",
      "Epoch 121/2000\n",
      "143/143 [==============================] - 89s 625ms/step - loss: 58.8126 - root_mean_squared_error: 7.6647 - mean_absolute_error: 6.2394 - val_loss: 71.7977 - val_root_mean_squared_error: 8.4733 - val_mean_absolute_error: 7.0430\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 60.16933\n",
      "Epoch 122/2000\n",
      "143/143 [==============================] - 91s 635ms/step - loss: 58.4125 - root_mean_squared_error: 7.6396 - mean_absolute_error: 6.1894 - val_loss: 74.7708 - val_root_mean_squared_error: 8.6470 - val_mean_absolute_error: 6.6931\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 60.16933\n",
      "Epoch 123/2000\n",
      "143/143 [==============================] - 90s 632ms/step - loss: 60.1989 - root_mean_squared_error: 7.7560 - mean_absolute_error: 6.2806 - val_loss: 69.6481 - val_root_mean_squared_error: 8.3455 - val_mean_absolute_error: 6.3889\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 60.16933\n",
      "Epoch 124/2000\n",
      "143/143 [==============================] - 89s 627ms/step - loss: 59.3802 - root_mean_squared_error: 7.7043 - mean_absolute_error: 6.2666 - val_loss: 65.6970 - val_root_mean_squared_error: 8.1054 - val_mean_absolute_error: 6.5435\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 60.16933\n",
      "Epoch 125/2000\n",
      "143/143 [==============================] - 89s 623ms/step - loss: 59.2027 - root_mean_squared_error: 7.6920 - mean_absolute_error: 6.2187 - val_loss: 70.8304 - val_root_mean_squared_error: 8.4161 - val_mean_absolute_error: 6.9438\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 60.16933\n",
      "Epoch 126/2000\n",
      "143/143 [==============================] - 89s 623ms/step - loss: 61.0827 - root_mean_squared_error: 7.8132 - mean_absolute_error: 6.3152 - val_loss: 80.9762 - val_root_mean_squared_error: 8.9987 - val_mean_absolute_error: 7.5553\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 60.16933\n",
      "Epoch 127/2000\n",
      "143/143 [==============================] - 93s 648ms/step - loss: 63.4436 - root_mean_squared_error: 7.9621 - mean_absolute_error: 6.4629 - val_loss: 68.6750 - val_root_mean_squared_error: 8.2870 - val_mean_absolute_error: 6.8801\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 60.16933\n",
      "Epoch 128/2000\n",
      "143/143 [==============================] - 90s 633ms/step - loss: 59.3624 - root_mean_squared_error: 7.7037 - mean_absolute_error: 6.2231 - val_loss: 66.2474 - val_root_mean_squared_error: 8.1392 - val_mean_absolute_error: 6.5786\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 60.16933\n",
      "Epoch 129/2000\n",
      "143/143 [==============================] - 87s 612ms/step - loss: 58.0517 - root_mean_squared_error: 7.6181 - mean_absolute_error: 6.1605 - val_loss: 85.8976 - val_root_mean_squared_error: 9.2681 - val_mean_absolute_error: 7.3942\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 60.16933\n",
      "Epoch 130/2000\n",
      "143/143 [==============================] - 89s 624ms/step - loss: 62.4863 - root_mean_squared_error: 7.9018 - mean_absolute_error: 6.3359 - val_loss: 70.0466 - val_root_mean_squared_error: 8.3694 - val_mean_absolute_error: 6.7166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00130: val_loss did not improve from 60.16933\n",
      "Epoch 131/2000\n",
      "143/143 [==============================] - 89s 625ms/step - loss: 61.6942 - root_mean_squared_error: 7.8531 - mean_absolute_error: 6.3671 - val_loss: 76.5305 - val_root_mean_squared_error: 8.7482 - val_mean_absolute_error: 7.2403\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 60.16933\n",
      "Epoch 132/2000\n",
      "143/143 [==============================] - 88s 617ms/step - loss: 63.6344 - root_mean_squared_error: 7.9750 - mean_absolute_error: 6.5020 - val_loss: 64.0276 - val_root_mean_squared_error: 8.0017 - val_mean_absolute_error: 6.5223\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 60.16933\n",
      "Epoch 133/2000\n",
      "143/143 [==============================] - 88s 618ms/step - loss: 58.2803 - root_mean_squared_error: 7.6308 - mean_absolute_error: 6.0975 - val_loss: 71.5432 - val_root_mean_squared_error: 8.4583 - val_mean_absolute_error: 7.1619\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 60.16933\n",
      "Epoch 134/2000\n",
      "143/143 [==============================] - 88s 615ms/step - loss: 56.4100 - root_mean_squared_error: 7.5065 - mean_absolute_error: 6.0808 - val_loss: 73.3475 - val_root_mean_squared_error: 8.5643 - val_mean_absolute_error: 6.7088\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 60.16933\n",
      "Epoch 135/2000\n",
      "143/143 [==============================] - 89s 624ms/step - loss: 57.1825 - root_mean_squared_error: 7.5509 - mean_absolute_error: 6.1332 - val_loss: 72.5742 - val_root_mean_squared_error: 8.5190 - val_mean_absolute_error: 7.0370\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 60.16933\n",
      "Epoch 136/2000\n",
      "143/143 [==============================] - 89s 622ms/step - loss: 57.7543 - root_mean_squared_error: 7.5986 - mean_absolute_error: 6.1996 - val_loss: 72.2435 - val_root_mean_squared_error: 8.4996 - val_mean_absolute_error: 6.8576\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 60.16933\n",
      "Epoch 137/2000\n",
      "143/143 [==============================] - 89s 621ms/step - loss: 59.4857 - root_mean_squared_error: 7.7108 - mean_absolute_error: 6.3259 - val_loss: 62.0744 - val_root_mean_squared_error: 7.8787 - val_mean_absolute_error: 6.4235\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 60.16933\n",
      "Epoch 138/2000\n",
      "143/143 [==============================] - 88s 615ms/step - loss: 60.8169 - root_mean_squared_error: 7.7900 - mean_absolute_error: 6.3127 - val_loss: 82.1628 - val_root_mean_squared_error: 9.0644 - val_mean_absolute_error: 7.3737\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 60.16933\n",
      "Epoch 139/2000\n",
      "143/143 [==============================] - 87s 608ms/step - loss: 57.4156 - root_mean_squared_error: 7.5747 - mean_absolute_error: 6.1945 - val_loss: 65.8621 - val_root_mean_squared_error: 8.1155 - val_mean_absolute_error: 6.5405\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 60.16933\n",
      "Epoch 140/2000\n",
      "143/143 [==============================] - 83s 578ms/step - loss: 62.7649 - root_mean_squared_error: 7.9209 - mean_absolute_error: 6.5380 - val_loss: 69.3847 - val_root_mean_squared_error: 8.3297 - val_mean_absolute_error: 6.8690\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 60.16933\n",
      "Epoch 141/2000\n",
      "143/143 [==============================] - 92s 644ms/step - loss: 61.2796 - root_mean_squared_error: 7.8226 - mean_absolute_error: 6.3779 - val_loss: 71.2707 - val_root_mean_squared_error: 8.4422 - val_mean_absolute_error: 7.1764\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 60.16933\n",
      "Epoch 142/2000\n",
      "143/143 [==============================] - 88s 612ms/step - loss: 60.3982 - root_mean_squared_error: 7.7698 - mean_absolute_error: 6.2355 - val_loss: 64.6058 - val_root_mean_squared_error: 8.0378 - val_mean_absolute_error: 6.5916\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 60.16933\n",
      "Epoch 143/2000\n",
      "143/143 [==============================] - 84s 589ms/step - loss: 56.8374 - root_mean_squared_error: 7.5337 - mean_absolute_error: 6.1304 - val_loss: 97.0042 - val_root_mean_squared_error: 9.8491 - val_mean_absolute_error: 7.9248\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 60.16933\n",
      "Epoch 144/2000\n",
      "143/143 [==============================] - 87s 611ms/step - loss: 62.3048 - root_mean_squared_error: 7.8898 - mean_absolute_error: 6.3467 - val_loss: 69.1702 - val_root_mean_squared_error: 8.3169 - val_mean_absolute_error: 6.7449\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 60.16933\n",
      "Epoch 145/2000\n",
      "143/143 [==============================] - 90s 632ms/step - loss: 55.2510 - root_mean_squared_error: 7.4307 - mean_absolute_error: 6.1113 - val_loss: 67.0610 - val_root_mean_squared_error: 8.1891 - val_mean_absolute_error: 6.7037\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 60.16933\n",
      "Epoch 146/2000\n",
      "143/143 [==============================] - 85s 598ms/step - loss: 61.7602 - root_mean_squared_error: 7.8561 - mean_absolute_error: 6.2695 - val_loss: 69.0855 - val_root_mean_squared_error: 8.3118 - val_mean_absolute_error: 6.8376\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 60.16933\n",
      "Epoch 147/2000\n",
      "143/143 [==============================] - 87s 609ms/step - loss: 62.3120 - root_mean_squared_error: 7.8920 - mean_absolute_error: 6.4886 - val_loss: 58.8919 - val_root_mean_squared_error: 7.6741 - val_mean_absolute_error: 6.3281\n",
      "\n",
      "Epoch 00147: val_loss improved from 60.16933 to 58.89191, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/TimeCNN_regressor_01.hdf5\n",
      "Epoch 148/2000\n",
      "143/143 [==============================] - 90s 629ms/step - loss: 60.4916 - root_mean_squared_error: 7.7660 - mean_absolute_error: 6.3276 - val_loss: 84.9751 - val_root_mean_squared_error: 9.2182 - val_mean_absolute_error: 7.3539\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 58.89191\n",
      "Epoch 149/2000\n",
      "143/143 [==============================] - 89s 621ms/step - loss: 60.0946 - root_mean_squared_error: 7.7510 - mean_absolute_error: 6.2336 - val_loss: 80.7145 - val_root_mean_squared_error: 8.9841 - val_mean_absolute_error: 6.9843\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 58.89191\n",
      "Epoch 150/2000\n",
      "143/143 [==============================] - 85s 598ms/step - loss: 54.8490 - root_mean_squared_error: 7.3973 - mean_absolute_error: 5.9995 - val_loss: 60.8632 - val_root_mean_squared_error: 7.8015 - val_mean_absolute_error: 6.3885\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 58.89191\n",
      "Epoch 151/2000\n",
      "143/143 [==============================] - 90s 628ms/step - loss: 59.5395 - root_mean_squared_error: 7.7139 - mean_absolute_error: 6.2124 - val_loss: 73.5885 - val_root_mean_squared_error: 8.5784 - val_mean_absolute_error: 6.9620\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 58.89191\n",
      "Epoch 152/2000\n",
      "143/143 [==============================] - 81s 565ms/step - loss: 65.8589 - root_mean_squared_error: 8.1084 - mean_absolute_error: 6.5506 - val_loss: 73.2447 - val_root_mean_squared_error: 8.5583 - val_mean_absolute_error: 6.9849\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 58.89191\n",
      "Epoch 153/2000\n",
      "143/143 [==============================] - 82s 573ms/step - loss: 66.5458 - root_mean_squared_error: 8.1361 - mean_absolute_error: 6.6140 - val_loss: 71.0234 - val_root_mean_squared_error: 8.4275 - val_mean_absolute_error: 6.5725\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 58.89191\n",
      "Epoch 154/2000\n",
      "143/143 [==============================] - 87s 607ms/step - loss: 56.3808 - root_mean_squared_error: 7.5033 - mean_absolute_error: 5.9868 - val_loss: 80.9256 - val_root_mean_squared_error: 8.9959 - val_mean_absolute_error: 7.5024\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 58.89191\n",
      "Epoch 155/2000\n",
      "143/143 [==============================] - 95s 661ms/step - loss: 53.2041 - root_mean_squared_error: 7.2826 - mean_absolute_error: 5.8460 - val_loss: 80.5977 - val_root_mean_squared_error: 8.9776 - val_mean_absolute_error: 6.7868\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 58.89191\n",
      "Epoch 156/2000\n",
      "143/143 [==============================] - 84s 584ms/step - loss: 53.4302 - root_mean_squared_error: 7.3046 - mean_absolute_error: 5.9247 - val_loss: 91.7765 - val_root_mean_squared_error: 9.5800 - val_mean_absolute_error: 7.5425\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 58.89191\n",
      "Epoch 157/2000\n",
      "143/143 [==============================] - 84s 585ms/step - loss: 55.1891 - root_mean_squared_error: 7.4238 - mean_absolute_error: 5.9046 - val_loss: 64.1727 - val_root_mean_squared_error: 8.0108 - val_mean_absolute_error: 6.4890\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 58.89191\n",
      "Epoch 158/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 84s 588ms/step - loss: 56.8468 - root_mean_squared_error: 7.5335 - mean_absolute_error: 6.0720 - val_loss: 67.4329 - val_root_mean_squared_error: 8.2118 - val_mean_absolute_error: 6.3400\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 58.89191\n",
      "Epoch 159/2000\n",
      "143/143 [==============================] - 86s 604ms/step - loss: 61.2566 - root_mean_squared_error: 7.8251 - mean_absolute_error: 6.4088 - val_loss: 110.2732 - val_root_mean_squared_error: 10.5011 - val_mean_absolute_error: 8.7393\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 58.89191\n",
      "Epoch 160/2000\n",
      "143/143 [==============================] - 86s 600ms/step - loss: 56.1984 - root_mean_squared_error: 7.4957 - mean_absolute_error: 5.9987 - val_loss: 75.5192 - val_root_mean_squared_error: 8.6902 - val_mean_absolute_error: 6.9132\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 58.89191\n",
      "Epoch 161/2000\n",
      "143/143 [==============================] - 86s 604ms/step - loss: 64.0623 - root_mean_squared_error: 7.9994 - mean_absolute_error: 6.3595 - val_loss: 69.0303 - val_root_mean_squared_error: 8.3084 - val_mean_absolute_error: 6.8053\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 58.89191\n",
      "Epoch 162/2000\n",
      "143/143 [==============================] - 87s 606ms/step - loss: 58.1218 - root_mean_squared_error: 7.6181 - mean_absolute_error: 6.1761 - val_loss: 59.6836 - val_root_mean_squared_error: 7.7255 - val_mean_absolute_error: 6.3432\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 58.89191\n",
      "Epoch 163/2000\n",
      "143/143 [==============================] - 86s 600ms/step - loss: 65.4791 - root_mean_squared_error: 8.0795 - mean_absolute_error: 6.6248 - val_loss: 70.0660 - val_root_mean_squared_error: 8.3705 - val_mean_absolute_error: 6.6965\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 58.89191\n",
      "Epoch 164/2000\n",
      "143/143 [==============================] - 88s 615ms/step - loss: 58.4131 - root_mean_squared_error: 7.6407 - mean_absolute_error: 6.2830 - val_loss: 71.0997 - val_root_mean_squared_error: 8.4321 - val_mean_absolute_error: 6.9024\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 58.89191\n",
      "Epoch 165/2000\n",
      "143/143 [==============================] - 85s 596ms/step - loss: 56.5004 - root_mean_squared_error: 7.5144 - mean_absolute_error: 6.0561 - val_loss: 74.2655 - val_root_mean_squared_error: 8.6177 - val_mean_absolute_error: 6.9959\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 58.89191\n",
      "Epoch 166/2000\n",
      "143/143 [==============================] - 89s 620ms/step - loss: 53.3949 - root_mean_squared_error: 7.3040 - mean_absolute_error: 5.8836 - val_loss: 80.1012 - val_root_mean_squared_error: 8.9499 - val_mean_absolute_error: 7.0085\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 58.89191\n",
      "Epoch 167/2000\n",
      "143/143 [==============================] - 89s 623ms/step - loss: 57.3782 - root_mean_squared_error: 7.5731 - mean_absolute_error: 6.1162 - val_loss: 68.4734 - val_root_mean_squared_error: 8.2749 - val_mean_absolute_error: 6.4997\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 58.89191\n",
      "Epoch 168/2000\n",
      "143/143 [==============================] - 90s 628ms/step - loss: 59.5119 - root_mean_squared_error: 7.7105 - mean_absolute_error: 6.1955 - val_loss: 74.9130 - val_root_mean_squared_error: 8.6552 - val_mean_absolute_error: 6.9166\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 58.89191\n",
      "Epoch 169/2000\n",
      "143/143 [==============================] - 89s 625ms/step - loss: 56.4539 - root_mean_squared_error: 7.5111 - mean_absolute_error: 6.1181 - val_loss: 72.6718 - val_root_mean_squared_error: 8.5248 - val_mean_absolute_error: 7.1515\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 58.89191\n",
      "Epoch 170/2000\n",
      "143/143 [==============================] - 87s 610ms/step - loss: 57.1630 - root_mean_squared_error: 7.5591 - mean_absolute_error: 6.1272 - val_loss: 77.8238 - val_root_mean_squared_error: 8.8218 - val_mean_absolute_error: 7.2914\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 58.89191\n",
      "Epoch 171/2000\n",
      "143/143 [==============================] - 83s 582ms/step - loss: 64.5929 - root_mean_squared_error: 8.0335 - mean_absolute_error: 6.4238 - val_loss: 70.3619 - val_root_mean_squared_error: 8.3882 - val_mean_absolute_error: 6.8024\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 58.89191\n",
      "Epoch 172/2000\n",
      "143/143 [==============================] - 84s 585ms/step - loss: 52.7843 - root_mean_squared_error: 7.2637 - mean_absolute_error: 5.8694 - val_loss: 64.9421 - val_root_mean_squared_error: 8.0587 - val_mean_absolute_error: 6.2505\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 58.89191\n",
      "Epoch 173/2000\n",
      "143/143 [==============================] - 86s 602ms/step - loss: 58.8902 - root_mean_squared_error: 7.6695 - mean_absolute_error: 6.3011 - val_loss: 64.7039 - val_root_mean_squared_error: 8.0439 - val_mean_absolute_error: 6.4848\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 58.89191\n",
      "Epoch 174/2000\n",
      "143/143 [==============================] - 87s 609ms/step - loss: 55.0586 - root_mean_squared_error: 7.4166 - mean_absolute_error: 5.8964 - val_loss: 83.6832 - val_root_mean_squared_error: 9.1479 - val_mean_absolute_error: 7.0950\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 58.89191\n",
      "Epoch 175/2000\n",
      "143/143 [==============================] - 88s 618ms/step - loss: 62.3931 - root_mean_squared_error: 7.8943 - mean_absolute_error: 6.4048 - val_loss: 69.0930 - val_root_mean_squared_error: 8.3122 - val_mean_absolute_error: 6.7972\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 58.89191\n",
      "Epoch 176/2000\n",
      "143/143 [==============================] - 87s 607ms/step - loss: 50.8419 - root_mean_squared_error: 7.1265 - mean_absolute_error: 5.8133 - val_loss: 63.0610 - val_root_mean_squared_error: 7.9411 - val_mean_absolute_error: 6.2296\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 58.89191\n",
      "Epoch 177/2000\n",
      "143/143 [==============================] - 88s 614ms/step - loss: 56.4082 - root_mean_squared_error: 7.5077 - mean_absolute_error: 6.1074 - val_loss: 65.6350 - val_root_mean_squared_error: 8.1015 - val_mean_absolute_error: 6.2977\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 58.89191\n",
      "Epoch 178/2000\n",
      "143/143 [==============================] - 89s 624ms/step - loss: 57.6483 - root_mean_squared_error: 7.5874 - mean_absolute_error: 6.1436 - val_loss: 63.8048 - val_root_mean_squared_error: 7.9878 - val_mean_absolute_error: 6.2735\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 58.89191\n",
      "Epoch 179/2000\n",
      "143/143 [==============================] - 90s 628ms/step - loss: 52.9871 - root_mean_squared_error: 7.2775 - mean_absolute_error: 5.8727 - val_loss: 77.5897 - val_root_mean_squared_error: 8.8085 - val_mean_absolute_error: 6.8280\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 58.89191\n",
      "Epoch 180/2000\n",
      "143/143 [==============================] - 88s 619ms/step - loss: 61.9800 - root_mean_squared_error: 7.8704 - mean_absolute_error: 6.5140 - val_loss: 71.8598 - val_root_mean_squared_error: 8.4770 - val_mean_absolute_error: 6.7688\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 58.89191\n",
      "Epoch 181/2000\n",
      "143/143 [==============================] - 89s 626ms/step - loss: 54.9547 - root_mean_squared_error: 7.4101 - mean_absolute_error: 6.0839 - val_loss: 64.9785 - val_root_mean_squared_error: 8.0609 - val_mean_absolute_error: 6.3741\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 58.89191\n",
      "Epoch 182/2000\n",
      "143/143 [==============================] - 88s 619ms/step - loss: 56.1397 - root_mean_squared_error: 7.4843 - mean_absolute_error: 6.0213 - val_loss: 77.9645 - val_root_mean_squared_error: 8.8297 - val_mean_absolute_error: 7.3052\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 58.89191\n",
      "Epoch 183/2000\n",
      "143/143 [==============================] - 90s 633ms/step - loss: 57.2188 - root_mean_squared_error: 7.5625 - mean_absolute_error: 6.1416 - val_loss: 80.9414 - val_root_mean_squared_error: 8.9967 - val_mean_absolute_error: 7.0603\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 58.89191\n",
      "Epoch 184/2000\n",
      "143/143 [==============================] - 91s 637ms/step - loss: 57.2405 - root_mean_squared_error: 7.5623 - mean_absolute_error: 5.9945 - val_loss: 60.0000 - val_root_mean_squared_error: 7.7460 - val_mean_absolute_error: 6.0627\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 58.89191\n",
      "Epoch 185/2000\n",
      "143/143 [==============================] - 89s 620ms/step - loss: 58.1982 - root_mean_squared_error: 7.6252 - mean_absolute_error: 6.1733 - val_loss: 68.1775 - val_root_mean_squared_error: 8.2570 - val_mean_absolute_error: 6.8418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00185: val_loss did not improve from 58.89191\n",
      "Epoch 186/2000\n",
      "143/143 [==============================] - 91s 636ms/step - loss: 52.1603 - root_mean_squared_error: 7.2135 - mean_absolute_error: 5.8513 - val_loss: 85.9547 - val_root_mean_squared_error: 9.2712 - val_mean_absolute_error: 7.6935\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 58.89191\n",
      "Epoch 187/2000\n",
      "143/143 [==============================] - 86s 601ms/step - loss: 60.7500 - root_mean_squared_error: 7.7846 - mean_absolute_error: 6.2733 - val_loss: 70.7093 - val_root_mean_squared_error: 8.4089 - val_mean_absolute_error: 6.7480\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 58.89191\n",
      "Epoch 188/2000\n",
      "143/143 [==============================] - 89s 622ms/step - loss: 51.6986 - root_mean_squared_error: 7.1885 - mean_absolute_error: 5.8838 - val_loss: 67.2931 - val_root_mean_squared_error: 8.2032 - val_mean_absolute_error: 6.6366\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 58.89191\n",
      "Epoch 189/2000\n",
      "143/143 [==============================] - 89s 626ms/step - loss: 58.7741 - root_mean_squared_error: 7.6633 - mean_absolute_error: 6.2401 - val_loss: 71.3440 - val_root_mean_squared_error: 8.4465 - val_mean_absolute_error: 6.6777\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 58.89191\n",
      "Epoch 190/2000\n",
      "143/143 [==============================] - 91s 638ms/step - loss: 57.6015 - root_mean_squared_error: 7.5868 - mean_absolute_error: 6.0730 - val_loss: 63.9994 - val_root_mean_squared_error: 8.0000 - val_mean_absolute_error: 6.4338\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 58.89191\n",
      "Epoch 191/2000\n",
      "143/143 [==============================] - 90s 630ms/step - loss: 56.5620 - root_mean_squared_error: 7.5164 - mean_absolute_error: 6.1097 - val_loss: 68.4191 - val_root_mean_squared_error: 8.2716 - val_mean_absolute_error: 6.6808\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 58.89191\n",
      "Epoch 192/2000\n",
      "143/143 [==============================] - 90s 630ms/step - loss: 55.2102 - root_mean_squared_error: 7.4214 - mean_absolute_error: 5.9582 - val_loss: 77.2478 - val_root_mean_squared_error: 8.7891 - val_mean_absolute_error: 7.3613\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 58.89191\n",
      "Epoch 193/2000\n",
      "143/143 [==============================] - 89s 623ms/step - loss: 54.2849 - root_mean_squared_error: 7.3661 - mean_absolute_error: 6.0065 - val_loss: 55.9851 - val_root_mean_squared_error: 7.4823 - val_mean_absolute_error: 5.8014\n",
      "\n",
      "Epoch 00193: val_loss improved from 58.89191 to 55.98505, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/TimeCNN_regressor_01.hdf5\n",
      "Epoch 194/2000\n",
      "143/143 [==============================] - 87s 610ms/step - loss: 58.1829 - root_mean_squared_error: 7.6266 - mean_absolute_error: 6.1311 - val_loss: 89.3108 - val_root_mean_squared_error: 9.4504 - val_mean_absolute_error: 7.3719\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 55.98505\n",
      "Epoch 195/2000\n",
      "143/143 [==============================] - 86s 603ms/step - loss: 55.2002 - root_mean_squared_error: 7.4241 - mean_absolute_error: 5.9554 - val_loss: 70.2577 - val_root_mean_squared_error: 8.3820 - val_mean_absolute_error: 7.0636\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 55.98505\n",
      "Epoch 196/2000\n",
      "143/143 [==============================] - 89s 621ms/step - loss: 59.8334 - root_mean_squared_error: 7.7340 - mean_absolute_error: 6.3472 - val_loss: 68.0502 - val_root_mean_squared_error: 8.2493 - val_mean_absolute_error: 6.6916\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 55.98505\n",
      "Epoch 197/2000\n",
      "143/143 [==============================] - 89s 622ms/step - loss: 52.9556 - root_mean_squared_error: 7.2760 - mean_absolute_error: 5.8597 - val_loss: 79.0674 - val_root_mean_squared_error: 8.8920 - val_mean_absolute_error: 6.9729\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 55.98505\n",
      "Epoch 198/2000\n",
      "143/143 [==============================] - 93s 651ms/step - loss: 57.7090 - root_mean_squared_error: 7.5958 - mean_absolute_error: 6.1330 - val_loss: 78.8211 - val_root_mean_squared_error: 8.8781 - val_mean_absolute_error: 7.1388\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 55.98505\n",
      "Epoch 199/2000\n",
      "143/143 [==============================] - 88s 617ms/step - loss: 58.3414 - root_mean_squared_error: 7.6315 - mean_absolute_error: 6.1632 - val_loss: 87.2260 - val_root_mean_squared_error: 9.3395 - val_mean_absolute_error: 7.2364\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 55.98505\n",
      "Epoch 200/2000\n",
      "143/143 [==============================] - 90s 632ms/step - loss: 53.6908 - root_mean_squared_error: 7.3245 - mean_absolute_error: 5.8972 - val_loss: 69.8980 - val_root_mean_squared_error: 8.3605 - val_mean_absolute_error: 6.5783\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 55.98505\n",
      "Epoch 201/2000\n",
      "143/143 [==============================] - 84s 586ms/step - loss: 52.6504 - root_mean_squared_error: 7.2540 - mean_absolute_error: 5.9079 - val_loss: 76.7724 - val_root_mean_squared_error: 8.7620 - val_mean_absolute_error: 7.2826\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 55.98505\n",
      "Epoch 202/2000\n",
      "143/143 [==============================] - 91s 637ms/step - loss: 52.5048 - root_mean_squared_error: 7.2437 - mean_absolute_error: 5.8148 - val_loss: 52.8256 - val_root_mean_squared_error: 7.2681 - val_mean_absolute_error: 5.9352\n",
      "\n",
      "Epoch 00202: val_loss improved from 55.98505 to 52.82555, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/TimeCNN_regressor_01.hdf5\n",
      "Epoch 203/2000\n",
      "143/143 [==============================] - 89s 626ms/step - loss: 57.2797 - root_mean_squared_error: 7.5658 - mean_absolute_error: 6.1192 - val_loss: 97.9273 - val_root_mean_squared_error: 9.8958 - val_mean_absolute_error: 7.4261\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 52.82555\n",
      "Epoch 204/2000\n",
      "143/143 [==============================] - 89s 626ms/step - loss: 52.3016 - root_mean_squared_error: 7.2308 - mean_absolute_error: 5.9033 - val_loss: 75.3954 - val_root_mean_squared_error: 8.6831 - val_mean_absolute_error: 6.9762\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 52.82555\n",
      "Epoch 205/2000\n",
      "143/143 [==============================] - 91s 634ms/step - loss: 54.1868 - root_mean_squared_error: 7.3576 - mean_absolute_error: 5.9246 - val_loss: 61.3099 - val_root_mean_squared_error: 7.8301 - val_mean_absolute_error: 6.2264\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 52.82555\n",
      "Epoch 206/2000\n",
      "143/143 [==============================] - 90s 628ms/step - loss: 54.1752 - root_mean_squared_error: 7.3584 - mean_absolute_error: 6.0468 - val_loss: 60.1169 - val_root_mean_squared_error: 7.7535 - val_mean_absolute_error: 6.2386\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 52.82555\n",
      "Epoch 207/2000\n",
      "143/143 [==============================] - 90s 631ms/step - loss: 55.7380 - root_mean_squared_error: 7.4617 - mean_absolute_error: 6.0565 - val_loss: 92.4100 - val_root_mean_squared_error: 9.6130 - val_mean_absolute_error: 7.3536\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 52.82555\n",
      "Epoch 208/2000\n",
      "143/143 [==============================] - 88s 618ms/step - loss: 58.5089 - root_mean_squared_error: 7.6440 - mean_absolute_error: 6.2099 - val_loss: 69.9235 - val_root_mean_squared_error: 8.3620 - val_mean_absolute_error: 6.8865\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 52.82555\n",
      "Epoch 209/2000\n",
      "143/143 [==============================] - 89s 619ms/step - loss: 55.9266 - root_mean_squared_error: 7.4769 - mean_absolute_error: 6.1117 - val_loss: 74.3007 - val_root_mean_squared_error: 8.6198 - val_mean_absolute_error: 6.9365\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 52.82555\n",
      "Epoch 210/2000\n",
      "143/143 [==============================] - 91s 636ms/step - loss: 52.7135 - root_mean_squared_error: 7.2580 - mean_absolute_error: 5.8565 - val_loss: 62.7707 - val_root_mean_squared_error: 7.9228 - val_mean_absolute_error: 6.5396\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 52.82555\n",
      "Epoch 211/2000\n",
      "143/143 [==============================] - 88s 618ms/step - loss: 55.3160 - root_mean_squared_error: 7.4323 - mean_absolute_error: 5.9259 - val_loss: 87.8130 - val_root_mean_squared_error: 9.3709 - val_mean_absolute_error: 7.3082\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 52.82555\n",
      "Epoch 212/2000\n",
      "143/143 [==============================] - 90s 632ms/step - loss: 57.1541 - root_mean_squared_error: 7.5548 - mean_absolute_error: 6.1429 - val_loss: 76.5124 - val_root_mean_squared_error: 8.7471 - val_mean_absolute_error: 6.6871\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 52.82555\n",
      "Epoch 213/2000\n",
      "143/143 [==============================] - 89s 622ms/step - loss: 55.9828 - root_mean_squared_error: 7.4729 - mean_absolute_error: 6.0097 - val_loss: 91.5150 - val_root_mean_squared_error: 9.5663 - val_mean_absolute_error: 7.9260\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 52.82555\n",
      "Epoch 214/2000\n",
      "143/143 [==============================] - 90s 633ms/step - loss: 58.6296 - root_mean_squared_error: 7.6461 - mean_absolute_error: 6.2563 - val_loss: 66.6747 - val_root_mean_squared_error: 8.1655 - val_mean_absolute_error: 6.6435\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 52.82555\n",
      "Epoch 215/2000\n",
      "143/143 [==============================] - 90s 633ms/step - loss: 57.5285 - root_mean_squared_error: 7.5799 - mean_absolute_error: 6.1549 - val_loss: 70.6773 - val_root_mean_squared_error: 8.4070 - val_mean_absolute_error: 6.9671\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 52.82555\n",
      "Epoch 216/2000\n",
      "143/143 [==============================] - 90s 631ms/step - loss: 50.7750 - root_mean_squared_error: 7.1226 - mean_absolute_error: 5.7430 - val_loss: 70.9684 - val_root_mean_squared_error: 8.4243 - val_mean_absolute_error: 6.5799\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 52.82555\n",
      "Epoch 217/2000\n",
      "143/143 [==============================] - 90s 628ms/step - loss: 59.6152 - root_mean_squared_error: 7.7186 - mean_absolute_error: 6.1651 - val_loss: 66.4247 - val_root_mean_squared_error: 8.1501 - val_mean_absolute_error: 6.6771\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 52.82555\n",
      "Epoch 218/2000\n",
      "143/143 [==============================] - 84s 592ms/step - loss: 52.2143 - root_mean_squared_error: 7.2228 - mean_absolute_error: 5.8438 - val_loss: 68.3059 - val_root_mean_squared_error: 8.2647 - val_mean_absolute_error: 6.5800\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 52.82555\n",
      "Epoch 219/2000\n",
      "143/143 [==============================] - 83s 582ms/step - loss: 55.0236 - root_mean_squared_error: 7.3965 - mean_absolute_error: 5.9837 - val_loss: 65.7743 - val_root_mean_squared_error: 8.1101 - val_mean_absolute_error: 6.7267\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 52.82555\n",
      "Epoch 220/2000\n",
      "143/143 [==============================] - 86s 604ms/step - loss: 54.6793 - root_mean_squared_error: 7.3916 - mean_absolute_error: 6.0091 - val_loss: 72.6801 - val_root_mean_squared_error: 8.5253 - val_mean_absolute_error: 6.7925\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 52.82555\n",
      "Epoch 221/2000\n",
      "143/143 [==============================] - 86s 606ms/step - loss: 57.9839 - root_mean_squared_error: 7.6116 - mean_absolute_error: 6.2873 - val_loss: 78.6938 - val_root_mean_squared_error: 8.8710 - val_mean_absolute_error: 7.2130\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 52.82555\n",
      "Epoch 222/2000\n",
      "143/143 [==============================] - 87s 609ms/step - loss: 56.2737 - root_mean_squared_error: 7.4968 - mean_absolute_error: 6.0378 - val_loss: 61.4542 - val_root_mean_squared_error: 7.8393 - val_mean_absolute_error: 6.0840\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 52.82555\n",
      "Epoch 223/2000\n",
      "143/143 [==============================] - 86s 603ms/step - loss: 53.4432 - root_mean_squared_error: 7.2983 - mean_absolute_error: 5.8231 - val_loss: 68.0192 - val_root_mean_squared_error: 8.2474 - val_mean_absolute_error: 6.6320\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 52.82555\n",
      "Epoch 224/2000\n",
      "143/143 [==============================] - 86s 602ms/step - loss: 60.0434 - root_mean_squared_error: 7.7429 - mean_absolute_error: 6.2347 - val_loss: 69.5164 - val_root_mean_squared_error: 8.3377 - val_mean_absolute_error: 6.4916\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 52.82555\n",
      "Epoch 225/2000\n",
      "143/143 [==============================] - 91s 636ms/step - loss: 57.2795 - root_mean_squared_error: 7.5666 - mean_absolute_error: 6.1168 - val_loss: 71.5007 - val_root_mean_squared_error: 8.4558 - val_mean_absolute_error: 6.9272\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 52.82555\n",
      "Epoch 226/2000\n",
      "143/143 [==============================] - 89s 624ms/step - loss: 59.6497 - root_mean_squared_error: 7.7168 - mean_absolute_error: 6.2644 - val_loss: 65.9441 - val_root_mean_squared_error: 8.1206 - val_mean_absolute_error: 6.4223\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 52.82555\n",
      "Epoch 227/2000\n",
      "143/143 [==============================] - 89s 621ms/step - loss: 51.8796 - root_mean_squared_error: 7.1960 - mean_absolute_error: 5.7763 - val_loss: 68.0703 - val_root_mean_squared_error: 8.2505 - val_mean_absolute_error: 6.6245\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 52.82555\n",
      "Epoch 228/2000\n",
      "143/143 [==============================] - 88s 615ms/step - loss: 55.5282 - root_mean_squared_error: 7.4484 - mean_absolute_error: 5.9805 - val_loss: 67.9679 - val_root_mean_squared_error: 8.2443 - val_mean_absolute_error: 6.4131\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 52.82555\n",
      "Epoch 229/2000\n",
      "143/143 [==============================] - 90s 628ms/step - loss: 55.5883 - root_mean_squared_error: 7.4540 - mean_absolute_error: 5.9837 - val_loss: 74.9509 - val_root_mean_squared_error: 8.6574 - val_mean_absolute_error: 6.6451\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 52.82555\n",
      "Epoch 230/2000\n",
      "143/143 [==============================] - 91s 634ms/step - loss: 54.1659 - root_mean_squared_error: 7.3549 - mean_absolute_error: 5.8992 - val_loss: 55.4900 - val_root_mean_squared_error: 7.4492 - val_mean_absolute_error: 6.1756\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 52.82555\n",
      "Epoch 231/2000\n",
      "143/143 [==============================] - 92s 643ms/step - loss: 50.2062 - root_mean_squared_error: 7.0802 - mean_absolute_error: 5.7289 - val_loss: 72.1165 - val_root_mean_squared_error: 8.4921 - val_mean_absolute_error: 6.7896\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 52.82555\n",
      "Epoch 232/2000\n",
      "143/143 [==============================] - 90s 630ms/step - loss: 59.4876 - root_mean_squared_error: 7.7090 - mean_absolute_error: 6.3929 - val_loss: 77.9121 - val_root_mean_squared_error: 8.8268 - val_mean_absolute_error: 7.2884\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 52.82555\n",
      "Epoch 233/2000\n",
      "143/143 [==============================] - 89s 626ms/step - loss: 54.6212 - root_mean_squared_error: 7.3874 - mean_absolute_error: 5.9100 - val_loss: 73.1094 - val_root_mean_squared_error: 8.5504 - val_mean_absolute_error: 6.9330\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 52.82555\n",
      "Epoch 234/2000\n",
      "143/143 [==============================] - 89s 625ms/step - loss: 48.4366 - root_mean_squared_error: 6.9555 - mean_absolute_error: 5.5542 - val_loss: 63.2873 - val_root_mean_squared_error: 7.9553 - val_mean_absolute_error: 6.5355\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 52.82555\n",
      "Epoch 235/2000\n",
      "143/143 [==============================] - 89s 622ms/step - loss: 56.6592 - root_mean_squared_error: 7.5116 - mean_absolute_error: 5.9684 - val_loss: 70.4717 - val_root_mean_squared_error: 8.3947 - val_mean_absolute_error: 6.6106\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 52.82555\n",
      "Epoch 236/2000\n",
      "143/143 [==============================] - 91s 634ms/step - loss: 57.5953 - root_mean_squared_error: 7.5858 - mean_absolute_error: 6.0876 - val_loss: 60.6544 - val_root_mean_squared_error: 7.7881 - val_mean_absolute_error: 6.4128\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 52.82555\n",
      "Epoch 237/2000\n",
      "143/143 [==============================] - 91s 637ms/step - loss: 50.9653 - root_mean_squared_error: 7.1353 - mean_absolute_error: 5.6553 - val_loss: 69.7396 - val_root_mean_squared_error: 8.3510 - val_mean_absolute_error: 6.8534\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 52.82555\n",
      "Epoch 238/2000\n",
      "143/143 [==============================] - 89s 621ms/step - loss: 49.8475 - root_mean_squared_error: 7.0571 - mean_absolute_error: 5.6280 - val_loss: 80.2019 - val_root_mean_squared_error: 8.9556 - val_mean_absolute_error: 7.5539\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 52.82555\n",
      "Epoch 239/2000\n",
      "143/143 [==============================] - 91s 635ms/step - loss: 53.4701 - root_mean_squared_error: 7.3053 - mean_absolute_error: 5.8202 - val_loss: 73.4061 - val_root_mean_squared_error: 8.5677 - val_mean_absolute_error: 6.7258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00239: val_loss did not improve from 52.82555\n",
      "Epoch 240/2000\n",
      "143/143 [==============================] - 89s 624ms/step - loss: 53.3910 - root_mean_squared_error: 7.3041 - mean_absolute_error: 5.8367 - val_loss: 71.5651 - val_root_mean_squared_error: 8.4596 - val_mean_absolute_error: 6.6286\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 52.82555\n",
      "Epoch 241/2000\n",
      "143/143 [==============================] - 91s 639ms/step - loss: 52.7446 - root_mean_squared_error: 7.2601 - mean_absolute_error: 5.7534 - val_loss: 67.3476 - val_root_mean_squared_error: 8.2066 - val_mean_absolute_error: 6.6290\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 52.82555\n",
      "Epoch 242/2000\n",
      "143/143 [==============================] - 89s 624ms/step - loss: 47.1012 - root_mean_squared_error: 6.8582 - mean_absolute_error: 5.4684 - val_loss: 67.2039 - val_root_mean_squared_error: 8.1978 - val_mean_absolute_error: 6.6073\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 52.82555\n",
      "Epoch 243/2000\n",
      "143/143 [==============================] - 90s 627ms/step - loss: 52.6020 - root_mean_squared_error: 7.2465 - mean_absolute_error: 5.8426 - val_loss: 78.8137 - val_root_mean_squared_error: 8.8777 - val_mean_absolute_error: 6.8726\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 52.82555\n",
      "Epoch 244/2000\n",
      "143/143 [==============================] - 89s 627ms/step - loss: 62.6356 - root_mean_squared_error: 7.9072 - mean_absolute_error: 6.3628 - val_loss: 75.6928 - val_root_mean_squared_error: 8.7002 - val_mean_absolute_error: 7.2504\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 52.82555\n",
      "Epoch 245/2000\n",
      "143/143 [==============================] - 93s 652ms/step - loss: 55.5215 - root_mean_squared_error: 7.4499 - mean_absolute_error: 6.0109 - val_loss: 82.7481 - val_root_mean_squared_error: 9.0966 - val_mean_absolute_error: 7.3480\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 52.82555\n",
      "Epoch 246/2000\n",
      "143/143 [==============================] - 91s 637ms/step - loss: 56.6892 - root_mean_squared_error: 7.5218 - mean_absolute_error: 6.0219 - val_loss: 82.6044 - val_root_mean_squared_error: 9.0887 - val_mean_absolute_error: 6.8985\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 52.82555\n",
      "Epoch 247/2000\n",
      "143/143 [==============================] - 89s 625ms/step - loss: 56.3698 - root_mean_squared_error: 7.5060 - mean_absolute_error: 6.0293 - val_loss: 75.9354 - val_root_mean_squared_error: 8.7141 - val_mean_absolute_error: 6.8724\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 52.82555\n",
      "Epoch 248/2000\n",
      "143/143 [==============================] - 92s 642ms/step - loss: 52.2588 - root_mean_squared_error: 7.2246 - mean_absolute_error: 5.9013 - val_loss: 61.7316 - val_root_mean_squared_error: 7.8569 - val_mean_absolute_error: 6.2975\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 52.82555\n",
      "Epoch 249/2000\n",
      "143/143 [==============================] - 92s 646ms/step - loss: 46.6523 - root_mean_squared_error: 6.8269 - mean_absolute_error: 5.5104 - val_loss: 64.9986 - val_root_mean_squared_error: 8.0622 - val_mean_absolute_error: 6.5450\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 52.82555\n",
      "Epoch 250/2000\n",
      "143/143 [==============================] - 90s 631ms/step - loss: 57.2022 - root_mean_squared_error: 7.5612 - mean_absolute_error: 6.1446 - val_loss: 73.2878 - val_root_mean_squared_error: 8.5608 - val_mean_absolute_error: 6.7321\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 52.82555\n",
      "Epoch 251/2000\n",
      "143/143 [==============================] - 94s 655ms/step - loss: 54.9741 - root_mean_squared_error: 7.4095 - mean_absolute_error: 5.9587 - val_loss: 78.1426 - val_root_mean_squared_error: 8.8398 - val_mean_absolute_error: 6.7912\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 52.82555\n",
      "Epoch 252/2000\n",
      "143/143 [==============================] - 90s 627ms/step - loss: 53.6598 - root_mean_squared_error: 7.3131 - mean_absolute_error: 5.8226 - val_loss: 65.4895 - val_root_mean_squared_error: 8.0926 - val_mean_absolute_error: 6.7032\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 52.82555\n",
      "\n",
      "Epoch 00252: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "Epoch 253/2000\n",
      "143/143 [==============================] - 90s 627ms/step - loss: 55.5723 - root_mean_squared_error: 7.4536 - mean_absolute_error: 6.0145 - val_loss: 80.7202 - val_root_mean_squared_error: 8.9844 - val_mean_absolute_error: 7.2156\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 52.82555\n",
      "Epoch 254/2000\n",
      "143/143 [==============================] - 90s 631ms/step - loss: 53.7074 - root_mean_squared_error: 7.3275 - mean_absolute_error: 5.9312 - val_loss: 60.7231 - val_root_mean_squared_error: 7.7925 - val_mean_absolute_error: 6.3474\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 52.82555\n",
      "Epoch 255/2000\n",
      "143/143 [==============================] - 91s 638ms/step - loss: 53.2290 - root_mean_squared_error: 7.2937 - mean_absolute_error: 5.8731 - val_loss: 65.7188 - val_root_mean_squared_error: 8.1067 - val_mean_absolute_error: 6.3904\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 52.82555\n",
      "Epoch 256/2000\n",
      "143/143 [==============================] - 91s 638ms/step - loss: 51.6216 - root_mean_squared_error: 7.1819 - mean_absolute_error: 5.7642 - val_loss: 73.8398 - val_root_mean_squared_error: 8.5930 - val_mean_absolute_error: 6.7742\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 52.82555\n",
      "Epoch 257/2000\n",
      "143/143 [==============================] - 92s 647ms/step - loss: 51.8349 - root_mean_squared_error: 7.1970 - mean_absolute_error: 5.7143 - val_loss: 56.8492 - val_root_mean_squared_error: 7.5398 - val_mean_absolute_error: 5.9810\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 52.82555\n",
      "Epoch 258/2000\n",
      "143/143 [==============================] - 92s 640ms/step - loss: 51.6499 - root_mean_squared_error: 7.1853 - mean_absolute_error: 5.6919 - val_loss: 67.2588 - val_root_mean_squared_error: 8.2011 - val_mean_absolute_error: 6.7376\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 52.82555\n",
      "Epoch 259/2000\n",
      "143/143 [==============================] - 91s 639ms/step - loss: 54.0782 - root_mean_squared_error: 7.3477 - mean_absolute_error: 5.9526 - val_loss: 58.8135 - val_root_mean_squared_error: 7.6690 - val_mean_absolute_error: 6.2505\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 52.82555\n",
      "Epoch 260/2000\n",
      "143/143 [==============================] - 91s 639ms/step - loss: 52.2924 - root_mean_squared_error: 7.2282 - mean_absolute_error: 5.9820 - val_loss: 66.2013 - val_root_mean_squared_error: 8.1364 - val_mean_absolute_error: 6.5723\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 52.82555\n",
      "Epoch 261/2000\n",
      "143/143 [==============================] - 91s 635ms/step - loss: 54.5513 - root_mean_squared_error: 7.3800 - mean_absolute_error: 5.9210 - val_loss: 64.3248 - val_root_mean_squared_error: 8.0203 - val_mean_absolute_error: 6.4708\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 52.82555\n",
      "Epoch 262/2000\n",
      "143/143 [==============================] - 93s 648ms/step - loss: 53.7594 - root_mean_squared_error: 7.3292 - mean_absolute_error: 5.9095 - val_loss: 66.3200 - val_root_mean_squared_error: 8.1437 - val_mean_absolute_error: 6.4176\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 52.82555\n",
      "Epoch 263/2000\n",
      "143/143 [==============================] - 92s 642ms/step - loss: 52.8086 - root_mean_squared_error: 7.2649 - mean_absolute_error: 5.8615 - val_loss: 69.8313 - val_root_mean_squared_error: 8.3565 - val_mean_absolute_error: 6.9341\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 52.82555\n",
      "Epoch 264/2000\n",
      "143/143 [==============================] - 91s 640ms/step - loss: 50.5348 - root_mean_squared_error: 7.1022 - mean_absolute_error: 5.6780 - val_loss: 71.1530 - val_root_mean_squared_error: 8.4352 - val_mean_absolute_error: 6.7370\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 52.82555\n",
      "Epoch 265/2000\n",
      "143/143 [==============================] - 91s 638ms/step - loss: 49.4890 - root_mean_squared_error: 7.0307 - mean_absolute_error: 5.6610 - val_loss: 75.6648 - val_root_mean_squared_error: 8.6985 - val_mean_absolute_error: 6.9000\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 52.82555\n",
      "Epoch 266/2000\n",
      "143/143 [==============================] - 94s 660ms/step - loss: 54.2154 - root_mean_squared_error: 7.3617 - mean_absolute_error: 5.9847 - val_loss: 58.9488 - val_root_mean_squared_error: 7.6778 - val_mean_absolute_error: 6.0362\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 52.82555\n",
      "Epoch 267/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 90s 630ms/step - loss: 53.2775 - root_mean_squared_error: 7.2963 - mean_absolute_error: 5.7658 - val_loss: 63.6100 - val_root_mean_squared_error: 7.9756 - val_mean_absolute_error: 6.4189\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 52.82555\n",
      "Epoch 268/2000\n",
      "143/143 [==============================] - 91s 640ms/step - loss: 50.6666 - root_mean_squared_error: 7.1163 - mean_absolute_error: 5.7763 - val_loss: 63.7513 - val_root_mean_squared_error: 7.9844 - val_mean_absolute_error: 6.4787\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 52.82555\n",
      "Epoch 269/2000\n",
      "143/143 [==============================] - 91s 639ms/step - loss: 57.2071 - root_mean_squared_error: 7.5595 - mean_absolute_error: 6.1555 - val_loss: 67.9855 - val_root_mean_squared_error: 8.2453 - val_mean_absolute_error: 6.5656\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 52.82555\n",
      "Epoch 270/2000\n",
      "143/143 [==============================] - 91s 636ms/step - loss: 49.2886 - root_mean_squared_error: 7.0196 - mean_absolute_error: 5.7295 - val_loss: 59.1431 - val_root_mean_squared_error: 7.6905 - val_mean_absolute_error: 6.1486\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 52.82555\n",
      "Epoch 271/2000\n",
      "143/143 [==============================] - 92s 644ms/step - loss: 48.2970 - root_mean_squared_error: 6.9465 - mean_absolute_error: 5.6925 - val_loss: 60.4736 - val_root_mean_squared_error: 7.7765 - val_mean_absolute_error: 6.1954\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 52.82555\n",
      "Epoch 272/2000\n",
      "143/143 [==============================] - 92s 647ms/step - loss: 55.3602 - root_mean_squared_error: 7.4358 - mean_absolute_error: 5.9122 - val_loss: 62.2507 - val_root_mean_squared_error: 7.8899 - val_mean_absolute_error: 6.4454\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 52.82555\n",
      "Epoch 273/2000\n",
      "143/143 [==============================] - 92s 642ms/step - loss: 51.0253 - root_mean_squared_error: 7.1400 - mean_absolute_error: 5.7907 - val_loss: 53.7786 - val_root_mean_squared_error: 7.3334 - val_mean_absolute_error: 5.9517\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 52.82555\n",
      "Epoch 274/2000\n",
      "143/143 [==============================] - 93s 652ms/step - loss: 49.2687 - root_mean_squared_error: 7.0174 - mean_absolute_error: 5.5922 - val_loss: 69.4075 - val_root_mean_squared_error: 8.3311 - val_mean_absolute_error: 6.3602\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 52.82555\n",
      "Epoch 275/2000\n",
      "143/143 [==============================] - 93s 652ms/step - loss: 48.6485 - root_mean_squared_error: 6.9705 - mean_absolute_error: 5.6658 - val_loss: 68.4002 - val_root_mean_squared_error: 8.2704 - val_mean_absolute_error: 6.8178\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 52.82555\n",
      "Epoch 276/2000\n",
      "143/143 [==============================] - 91s 636ms/step - loss: 49.9528 - root_mean_squared_error: 7.0650 - mean_absolute_error: 5.6855 - val_loss: 69.0956 - val_root_mean_squared_error: 8.3124 - val_mean_absolute_error: 6.6072\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 52.82555\n",
      "Epoch 277/2000\n",
      "143/143 [==============================] - 92s 647ms/step - loss: 47.9719 - root_mean_squared_error: 6.9223 - mean_absolute_error: 5.6297 - val_loss: 68.7968 - val_root_mean_squared_error: 8.2944 - val_mean_absolute_error: 6.7525\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 52.82555\n",
      "Epoch 278/2000\n",
      "143/143 [==============================] - 92s 646ms/step - loss: 53.1804 - root_mean_squared_error: 7.2858 - mean_absolute_error: 5.8188 - val_loss: 73.9939 - val_root_mean_squared_error: 8.6020 - val_mean_absolute_error: 7.2170\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 52.82555\n",
      "Epoch 279/2000\n",
      "143/143 [==============================] - 92s 646ms/step - loss: 48.3071 - root_mean_squared_error: 6.9477 - mean_absolute_error: 5.5685 - val_loss: 67.0992 - val_root_mean_squared_error: 8.1914 - val_mean_absolute_error: 6.5399\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 52.82555\n",
      "Epoch 280/2000\n",
      "143/143 [==============================] - 91s 640ms/step - loss: 52.5844 - root_mean_squared_error: 7.2502 - mean_absolute_error: 5.9085 - val_loss: 66.7523 - val_root_mean_squared_error: 8.1702 - val_mean_absolute_error: 6.3349\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 52.82555\n",
      "Epoch 281/2000\n",
      "143/143 [==============================] - 92s 640ms/step - loss: 53.8373 - root_mean_squared_error: 7.3340 - mean_absolute_error: 5.9080 - val_loss: 72.9352 - val_root_mean_squared_error: 8.5402 - val_mean_absolute_error: 6.7989\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 52.82555\n",
      "Epoch 282/2000\n",
      "143/143 [==============================] - 92s 647ms/step - loss: 50.2129 - root_mean_squared_error: 7.0792 - mean_absolute_error: 5.7009 - val_loss: 74.3673 - val_root_mean_squared_error: 8.6236 - val_mean_absolute_error: 7.0181\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 52.82555\n",
      "Epoch 283/2000\n",
      "143/143 [==============================] - 92s 646ms/step - loss: 49.3646 - root_mean_squared_error: 7.0226 - mean_absolute_error: 5.6288 - val_loss: 67.6080 - val_root_mean_squared_error: 8.2224 - val_mean_absolute_error: 6.6981\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 52.82555\n",
      "Epoch 284/2000\n",
      "143/143 [==============================] - 92s 646ms/step - loss: 52.7572 - root_mean_squared_error: 7.2595 - mean_absolute_error: 5.8820 - val_loss: 66.7799 - val_root_mean_squared_error: 8.1719 - val_mean_absolute_error: 6.2673\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 52.82555\n",
      "Epoch 285/2000\n",
      "143/143 [==============================] - 93s 650ms/step - loss: 49.7111 - root_mean_squared_error: 7.0470 - mean_absolute_error: 5.6993 - val_loss: 73.4112 - val_root_mean_squared_error: 8.5680 - val_mean_absolute_error: 6.8022\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 52.82555\n",
      "Epoch 286/2000\n",
      "143/143 [==============================] - 92s 641ms/step - loss: 46.1889 - root_mean_squared_error: 6.7919 - mean_absolute_error: 5.3892 - val_loss: 80.7803 - val_root_mean_squared_error: 8.9878 - val_mean_absolute_error: 7.4546\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 52.82555\n",
      "Epoch 287/2000\n",
      "143/143 [==============================] - 92s 647ms/step - loss: 53.0803 - root_mean_squared_error: 7.2719 - mean_absolute_error: 5.8200 - val_loss: 62.2279 - val_root_mean_squared_error: 7.8885 - val_mean_absolute_error: 6.2849\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 52.82555\n",
      "Epoch 288/2000\n",
      "143/143 [==============================] - 92s 646ms/step - loss: 52.4669 - root_mean_squared_error: 7.2414 - mean_absolute_error: 5.8843 - val_loss: 72.0126 - val_root_mean_squared_error: 8.4860 - val_mean_absolute_error: 6.6732\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 52.82555\n",
      "Epoch 289/2000\n",
      "143/143 [==============================] - 92s 647ms/step - loss: 50.0017 - root_mean_squared_error: 7.0675 - mean_absolute_error: 5.6502 - val_loss: 68.6455 - val_root_mean_squared_error: 8.2853 - val_mean_absolute_error: 6.8092\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 52.82555\n",
      "Epoch 290/2000\n",
      "143/143 [==============================] - 90s 629ms/step - loss: 48.9349 - root_mean_squared_error: 6.9912 - mean_absolute_error: 5.6765 - val_loss: 69.6632 - val_root_mean_squared_error: 8.3464 - val_mean_absolute_error: 6.6732\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 52.82555\n",
      "Epoch 291/2000\n",
      "143/143 [==============================] - 92s 647ms/step - loss: 49.3406 - root_mean_squared_error: 7.0203 - mean_absolute_error: 5.4990 - val_loss: 67.5666 - val_root_mean_squared_error: 8.2199 - val_mean_absolute_error: 6.6601\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 52.82555\n",
      "Epoch 292/2000\n",
      "143/143 [==============================] - 92s 641ms/step - loss: 51.1334 - root_mean_squared_error: 7.1476 - mean_absolute_error: 5.7760 - val_loss: 65.2257 - val_root_mean_squared_error: 8.0762 - val_mean_absolute_error: 6.5775\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 52.82555\n",
      "Epoch 293/2000\n",
      "143/143 [==============================] - 91s 638ms/step - loss: 48.0969 - root_mean_squared_error: 6.9301 - mean_absolute_error: 5.5286 - val_loss: 66.7844 - val_root_mean_squared_error: 8.1722 - val_mean_absolute_error: 6.3267\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 52.82555\n",
      "Epoch 294/2000\n",
      "143/143 [==============================] - 90s 632ms/step - loss: 54.1596 - root_mean_squared_error: 7.3476 - mean_absolute_error: 5.8083 - val_loss: 69.6176 - val_root_mean_squared_error: 8.3437 - val_mean_absolute_error: 6.5310\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00294: val_loss did not improve from 52.82555\n",
      "Epoch 295/2000\n",
      "143/143 [==============================] - 90s 632ms/step - loss: 50.3966 - root_mean_squared_error: 7.0969 - mean_absolute_error: 5.7320 - val_loss: 62.8722 - val_root_mean_squared_error: 7.9292 - val_mean_absolute_error: 6.3905\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 52.82555\n",
      "Epoch 296/2000\n",
      "143/143 [==============================] - 91s 637ms/step - loss: 45.0634 - root_mean_squared_error: 6.7113 - mean_absolute_error: 5.4304 - val_loss: 59.5718 - val_root_mean_squared_error: 7.7183 - val_mean_absolute_error: 6.2219\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 52.82555\n",
      "Epoch 297/2000\n",
      "143/143 [==============================] - 91s 639ms/step - loss: 51.6080 - root_mean_squared_error: 7.1761 - mean_absolute_error: 5.7298 - val_loss: 65.1319 - val_root_mean_squared_error: 8.0704 - val_mean_absolute_error: 6.4828\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 52.82555\n",
      "Epoch 298/2000\n",
      "143/143 [==============================] - 91s 639ms/step - loss: 49.4605 - root_mean_squared_error: 7.0314 - mean_absolute_error: 5.6351 - val_loss: 58.0015 - val_root_mean_squared_error: 7.6159 - val_mean_absolute_error: 6.1278\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 52.82555\n",
      "Epoch 299/2000\n",
      "143/143 [==============================] - 90s 632ms/step - loss: 49.9361 - root_mean_squared_error: 7.0534 - mean_absolute_error: 5.6652 - val_loss: 81.0781 - val_root_mean_squared_error: 9.0043 - val_mean_absolute_error: 7.2310\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 52.82555\n",
      "Epoch 300/2000\n",
      "143/143 [==============================] - 90s 628ms/step - loss: 48.9105 - root_mean_squared_error: 6.9924 - mean_absolute_error: 5.5758 - val_loss: 72.3598 - val_root_mean_squared_error: 8.5065 - val_mean_absolute_error: 6.6138\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 52.82555\n",
      "Epoch 301/2000\n",
      "143/143 [==============================] - 92s 641ms/step - loss: 50.7174 - root_mean_squared_error: 7.1156 - mean_absolute_error: 5.6922 - val_loss: 63.3398 - val_root_mean_squared_error: 7.9586 - val_mean_absolute_error: 6.2672\n",
      "\n",
      "Epoch 00301: val_loss did not improve from 52.82555\n",
      "Epoch 302/2000\n",
      "143/143 [==============================] - 91s 634ms/step - loss: 49.9579 - root_mean_squared_error: 7.0663 - mean_absolute_error: 5.7377 - val_loss: 54.2747 - val_root_mean_squared_error: 7.3671 - val_mean_absolute_error: 5.9048\n",
      "\n",
      "Epoch 00302: val_loss did not improve from 52.82555\n",
      "\n",
      "Epoch 00302: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "Epoch 303/2000\n",
      "143/143 [==============================] - 91s 635ms/step - loss: 51.2168 - root_mean_squared_error: 7.1438 - mean_absolute_error: 5.6874 - val_loss: 59.8893 - val_root_mean_squared_error: 7.7388 - val_mean_absolute_error: 6.2968\n",
      "\n",
      "Epoch 00303: val_loss did not improve from 52.82555\n",
      "Epoch 304/2000\n",
      "143/143 [==============================] - 93s 648ms/step - loss: 51.4351 - root_mean_squared_error: 7.1674 - mean_absolute_error: 5.7316 - val_loss: 55.4688 - val_root_mean_squared_error: 7.4477 - val_mean_absolute_error: 6.1511\n",
      "\n",
      "Epoch 00304: val_loss did not improve from 52.82555\n",
      "Epoch 305/2000\n",
      "143/143 [==============================] - 92s 641ms/step - loss: 49.1246 - root_mean_squared_error: 7.0079 - mean_absolute_error: 5.6639 - val_loss: 61.6893 - val_root_mean_squared_error: 7.8543 - val_mean_absolute_error: 6.1860\n",
      "\n",
      "Epoch 00305: val_loss did not improve from 52.82555\n",
      "Epoch 306/2000\n",
      "143/143 [==============================] - 89s 621ms/step - loss: 50.0697 - root_mean_squared_error: 7.0581 - mean_absolute_error: 5.7669 - val_loss: 66.7827 - val_root_mean_squared_error: 8.1721 - val_mean_absolute_error: 6.6219\n",
      "\n",
      "Epoch 00306: val_loss did not improve from 52.82555\n",
      "Epoch 307/2000\n",
      "143/143 [==============================] - 88s 620ms/step - loss: 42.9151 - root_mean_squared_error: 6.5452 - mean_absolute_error: 5.2474 - val_loss: 60.2951 - val_root_mean_squared_error: 7.7650 - val_mean_absolute_error: 6.2146\n",
      "\n",
      "Epoch 00307: val_loss did not improve from 52.82555\n",
      "Epoch 308/2000\n",
      "143/143 [==============================] - 92s 643ms/step - loss: 51.9265 - root_mean_squared_error: 7.2046 - mean_absolute_error: 5.7658 - val_loss: 57.8987 - val_root_mean_squared_error: 7.6091 - val_mean_absolute_error: 6.1789\n",
      "\n",
      "Epoch 00308: val_loss did not improve from 52.82555\n",
      "Epoch 309/2000\n",
      "143/143 [==============================] - 91s 635ms/step - loss: 48.9387 - root_mean_squared_error: 6.9937 - mean_absolute_error: 5.6014 - val_loss: 57.7708 - val_root_mean_squared_error: 7.6007 - val_mean_absolute_error: 6.2029\n",
      "\n",
      "Epoch 00309: val_loss did not improve from 52.82555\n",
      "Epoch 310/2000\n",
      "143/143 [==============================] - 91s 635ms/step - loss: 49.5529 - root_mean_squared_error: 7.0385 - mean_absolute_error: 5.6550 - val_loss: 59.7063 - val_root_mean_squared_error: 7.7270 - val_mean_absolute_error: 6.1586\n",
      "\n",
      "Epoch 00310: val_loss did not improve from 52.82555\n",
      "Epoch 311/2000\n",
      "143/143 [==============================] - 92s 642ms/step - loss: 50.3213 - root_mean_squared_error: 7.0903 - mean_absolute_error: 5.6705 - val_loss: 67.0953 - val_root_mean_squared_error: 8.1912 - val_mean_absolute_error: 6.6199\n",
      "\n",
      "Epoch 00311: val_loss did not improve from 52.82555\n",
      "Epoch 312/2000\n",
      "143/143 [==============================] - 92s 644ms/step - loss: 51.2524 - root_mean_squared_error: 7.1506 - mean_absolute_error: 5.6460 - val_loss: 65.7365 - val_root_mean_squared_error: 8.1078 - val_mean_absolute_error: 6.5444\n",
      "\n",
      "Epoch 00312: val_loss did not improve from 52.82555\n",
      "Epoch 313/2000\n",
      "143/143 [==============================] - 91s 637ms/step - loss: 46.4256 - root_mean_squared_error: 6.8097 - mean_absolute_error: 5.5135 - val_loss: 77.5853 - val_root_mean_squared_error: 8.8082 - val_mean_absolute_error: 7.2692\n",
      "\n",
      "Epoch 00313: val_loss did not improve from 52.82555\n",
      "Epoch 314/2000\n",
      "143/143 [==============================] - 90s 628ms/step - loss: 46.3922 - root_mean_squared_error: 6.8096 - mean_absolute_error: 5.5588 - val_loss: 68.9717 - val_root_mean_squared_error: 8.3049 - val_mean_absolute_error: 6.5506\n",
      "\n",
      "Epoch 00314: val_loss did not improve from 52.82555\n",
      "Epoch 315/2000\n",
      "143/143 [==============================] - 91s 634ms/step - loss: 52.1752 - root_mean_squared_error: 7.2211 - mean_absolute_error: 5.7442 - val_loss: 64.0532 - val_root_mean_squared_error: 8.0033 - val_mean_absolute_error: 6.2874\n",
      "\n",
      "Epoch 00315: val_loss did not improve from 52.82555\n",
      "Epoch 316/2000\n",
      "143/143 [==============================] - 90s 632ms/step - loss: 49.6579 - root_mean_squared_error: 7.0457 - mean_absolute_error: 5.6116 - val_loss: 51.9006 - val_root_mean_squared_error: 7.2042 - val_mean_absolute_error: 5.7634\n",
      "\n",
      "Epoch 00316: val_loss improved from 52.82555 to 51.90059, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/TimeCNN_regressor_01.hdf5\n",
      "Epoch 317/2000\n",
      "143/143 [==============================] - 92s 644ms/step - loss: 49.1790 - root_mean_squared_error: 7.0119 - mean_absolute_error: 5.5697 - val_loss: 60.8364 - val_root_mean_squared_error: 7.7998 - val_mean_absolute_error: 6.2808\n",
      "\n",
      "Epoch 00317: val_loss did not improve from 51.90059\n",
      "Epoch 318/2000\n",
      "143/143 [==============================] - 90s 631ms/step - loss: 48.0544 - root_mean_squared_error: 6.9184 - mean_absolute_error: 5.5632 - val_loss: 59.2697 - val_root_mean_squared_error: 7.6987 - val_mean_absolute_error: 6.1126\n",
      "\n",
      "Epoch 00318: val_loss did not improve from 51.90059\n",
      "Epoch 319/2000\n",
      "143/143 [==============================] - 91s 637ms/step - loss: 50.5193 - root_mean_squared_error: 7.0898 - mean_absolute_error: 5.6356 - val_loss: 66.0860 - val_root_mean_squared_error: 8.1293 - val_mean_absolute_error: 6.3269\n",
      "\n",
      "Epoch 00319: val_loss did not improve from 51.90059\n",
      "Epoch 320/2000\n",
      "143/143 [==============================] - 90s 631ms/step - loss: 48.4717 - root_mean_squared_error: 6.9591 - mean_absolute_error: 5.5578 - val_loss: 61.0049 - val_root_mean_squared_error: 7.8106 - val_mean_absolute_error: 6.0729\n",
      "\n",
      "Epoch 00320: val_loss did not improve from 51.90059\n",
      "Epoch 321/2000\n",
      "143/143 [==============================] - 92s 640ms/step - loss: 48.2895 - root_mean_squared_error: 6.9386 - mean_absolute_error: 5.5225 - val_loss: 59.2985 - val_root_mean_squared_error: 7.7006 - val_mean_absolute_error: 6.1218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00321: val_loss did not improve from 51.90059\n",
      "Epoch 322/2000\n",
      "143/143 [==============================] - 92s 644ms/step - loss: 48.6022 - root_mean_squared_error: 6.9704 - mean_absolute_error: 5.6443 - val_loss: 56.8475 - val_root_mean_squared_error: 7.5397 - val_mean_absolute_error: 6.0544\n",
      "\n",
      "Epoch 00322: val_loss did not improve from 51.90059\n",
      "Epoch 323/2000\n",
      "143/143 [==============================] - 90s 632ms/step - loss: 48.5693 - root_mean_squared_error: 6.9622 - mean_absolute_error: 5.5819 - val_loss: 57.8626 - val_root_mean_squared_error: 7.6067 - val_mean_absolute_error: 6.1269\n",
      "\n",
      "Epoch 00323: val_loss did not improve from 51.90059\n",
      "Epoch 324/2000\n",
      "143/143 [==============================] - 92s 645ms/step - loss: 50.2688 - root_mean_squared_error: 7.0870 - mean_absolute_error: 5.7265 - val_loss: 50.7575 - val_root_mean_squared_error: 7.1244 - val_mean_absolute_error: 5.9099\n",
      "\n",
      "Epoch 00324: val_loss improved from 51.90059 to 50.75751, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/TimeCNN_regressor_01.hdf5\n",
      "Epoch 325/2000\n",
      "143/143 [==============================] - 92s 642ms/step - loss: 48.0937 - root_mean_squared_error: 6.9289 - mean_absolute_error: 5.5831 - val_loss: 56.3210 - val_root_mean_squared_error: 7.5047 - val_mean_absolute_error: 6.0529\n",
      "\n",
      "Epoch 00325: val_loss did not improve from 50.75751\n",
      "Epoch 326/2000\n",
      "143/143 [==============================] - 92s 642ms/step - loss: 48.4815 - root_mean_squared_error: 6.9606 - mean_absolute_error: 5.5914 - val_loss: 62.1633 - val_root_mean_squared_error: 7.8844 - val_mean_absolute_error: 6.3537\n",
      "\n",
      "Epoch 00326: val_loss did not improve from 50.75751\n",
      "Epoch 327/2000\n",
      "143/143 [==============================] - 92s 644ms/step - loss: 50.4464 - root_mean_squared_error: 7.0998 - mean_absolute_error: 5.7410 - val_loss: 61.5935 - val_root_mean_squared_error: 7.8482 - val_mean_absolute_error: 6.1440\n",
      "\n",
      "Epoch 00327: val_loss did not improve from 50.75751\n",
      "Epoch 328/2000\n",
      "143/143 [==============================] - 89s 622ms/step - loss: 51.2162 - root_mean_squared_error: 7.1540 - mean_absolute_error: 5.6657 - val_loss: 55.9027 - val_root_mean_squared_error: 7.4768 - val_mean_absolute_error: 6.0914\n",
      "\n",
      "Epoch 00328: val_loss did not improve from 50.75751\n",
      "Epoch 329/2000\n",
      "143/143 [==============================] - 88s 618ms/step - loss: 44.4919 - root_mean_squared_error: 6.6602 - mean_absolute_error: 5.3855 - val_loss: 65.3339 - val_root_mean_squared_error: 8.0829 - val_mean_absolute_error: 6.4628\n",
      "\n",
      "Epoch 00329: val_loss did not improve from 50.75751\n",
      "Epoch 330/2000\n",
      "143/143 [==============================] - 87s 612ms/step - loss: 49.0030 - root_mean_squared_error: 6.9983 - mean_absolute_error: 5.6719 - val_loss: 59.0993 - val_root_mean_squared_error: 7.6876 - val_mean_absolute_error: 6.0707\n",
      "\n",
      "Epoch 00330: val_loss did not improve from 50.75751\n",
      "Epoch 331/2000\n",
      "143/143 [==============================] - 88s 613ms/step - loss: 51.7089 - root_mean_squared_error: 7.1872 - mean_absolute_error: 5.8070 - val_loss: 67.5786 - val_root_mean_squared_error: 8.2206 - val_mean_absolute_error: 6.5200\n",
      "\n",
      "Epoch 00331: val_loss did not improve from 50.75751\n",
      "Epoch 332/2000\n",
      "143/143 [==============================] - 87s 609ms/step - loss: 48.0628 - root_mean_squared_error: 6.9288 - mean_absolute_error: 5.7306 - val_loss: 65.6107 - val_root_mean_squared_error: 8.1000 - val_mean_absolute_error: 6.5092\n",
      "\n",
      "Epoch 00332: val_loss did not improve from 50.75751\n",
      "Epoch 333/2000\n",
      "143/143 [==============================] - 83s 578ms/step - loss: 44.6846 - root_mean_squared_error: 6.6814 - mean_absolute_error: 5.3693 - val_loss: 60.4228 - val_root_mean_squared_error: 7.7732 - val_mean_absolute_error: 6.1739\n",
      "\n",
      "Epoch 00333: val_loss did not improve from 50.75751\n",
      "Epoch 334/2000\n",
      "143/143 [==============================] - 87s 609ms/step - loss: 49.3328 - root_mean_squared_error: 7.0214 - mean_absolute_error: 5.7217 - val_loss: 55.0134 - val_root_mean_squared_error: 7.4171 - val_mean_absolute_error: 5.9081\n",
      "\n",
      "Epoch 00334: val_loss did not improve from 50.75751\n",
      "Epoch 335/2000\n",
      "143/143 [==============================] - 88s 617ms/step - loss: 43.9242 - root_mean_squared_error: 6.6223 - mean_absolute_error: 5.3046 - val_loss: 55.5597 - val_root_mean_squared_error: 7.4538 - val_mean_absolute_error: 5.9760\n",
      "\n",
      "Epoch 00335: val_loss did not improve from 50.75751\n",
      "Epoch 336/2000\n",
      "143/143 [==============================] - 90s 627ms/step - loss: 52.7092 - root_mean_squared_error: 7.2499 - mean_absolute_error: 5.7697 - val_loss: 61.7922 - val_root_mean_squared_error: 7.8608 - val_mean_absolute_error: 6.2119\n",
      "\n",
      "Epoch 00336: val_loss did not improve from 50.75751\n",
      "Epoch 337/2000\n",
      "143/143 [==============================] - 89s 622ms/step - loss: 48.2193 - root_mean_squared_error: 6.9423 - mean_absolute_error: 5.5358 - val_loss: 58.0491 - val_root_mean_squared_error: 7.6190 - val_mean_absolute_error: 6.1278\n",
      "\n",
      "Epoch 00337: val_loss did not improve from 50.75751\n",
      "Epoch 338/2000\n",
      "143/143 [==============================] - 90s 630ms/step - loss: 46.9235 - root_mean_squared_error: 6.8427 - mean_absolute_error: 5.4088 - val_loss: 68.3104 - val_root_mean_squared_error: 8.2650 - val_mean_absolute_error: 6.5873\n",
      "\n",
      "Epoch 00338: val_loss did not improve from 50.75751\n",
      "Epoch 339/2000\n",
      "143/143 [==============================] - 88s 619ms/step - loss: 49.4162 - root_mean_squared_error: 7.0251 - mean_absolute_error: 5.6710 - val_loss: 57.1109 - val_root_mean_squared_error: 7.5572 - val_mean_absolute_error: 6.0503\n",
      "\n",
      "Epoch 00339: val_loss did not improve from 50.75751\n",
      "Epoch 340/2000\n",
      "143/143 [==============================] - 88s 617ms/step - loss: 52.5606 - root_mean_squared_error: 7.2418 - mean_absolute_error: 5.7925 - val_loss: 58.0790 - val_root_mean_squared_error: 7.6210 - val_mean_absolute_error: 6.1925\n",
      "\n",
      "Epoch 00340: val_loss did not improve from 50.75751\n",
      "Epoch 341/2000\n",
      "143/143 [==============================] - 88s 614ms/step - loss: 48.4190 - root_mean_squared_error: 6.9516 - mean_absolute_error: 5.5380 - val_loss: 53.8568 - val_root_mean_squared_error: 7.3387 - val_mean_absolute_error: 5.9290\n",
      "\n",
      "Epoch 00341: val_loss did not improve from 50.75751\n",
      "Epoch 342/2000\n",
      "143/143 [==============================] - 89s 624ms/step - loss: 47.9333 - root_mean_squared_error: 6.9162 - mean_absolute_error: 5.6366 - val_loss: 61.6783 - val_root_mean_squared_error: 7.8536 - val_mean_absolute_error: 6.3647\n",
      "\n",
      "Epoch 00342: val_loss did not improve from 50.75751\n",
      "Epoch 343/2000\n",
      "143/143 [==============================] - 89s 625ms/step - loss: 49.3164 - root_mean_squared_error: 7.0093 - mean_absolute_error: 5.6022 - val_loss: 56.8406 - val_root_mean_squared_error: 7.5393 - val_mean_absolute_error: 6.0129\n",
      "\n",
      "Epoch 00343: val_loss did not improve from 50.75751\n",
      "Epoch 344/2000\n",
      "143/143 [==============================] - 89s 620ms/step - loss: 52.6732 - root_mean_squared_error: 7.2555 - mean_absolute_error: 5.8153 - val_loss: 51.2981 - val_root_mean_squared_error: 7.1623 - val_mean_absolute_error: 5.8841\n",
      "\n",
      "Epoch 00344: val_loss did not improve from 50.75751\n",
      "Epoch 345/2000\n",
      "143/143 [==============================] - 88s 618ms/step - loss: 48.6844 - root_mean_squared_error: 6.9730 - mean_absolute_error: 5.5431 - val_loss: 66.8108 - val_root_mean_squared_error: 8.1738 - val_mean_absolute_error: 6.4340\n",
      "\n",
      "Epoch 00345: val_loss did not improve from 50.75751\n",
      "Epoch 346/2000\n",
      "143/143 [==============================] - 89s 622ms/step - loss: 52.6222 - root_mean_squared_error: 7.2523 - mean_absolute_error: 5.9192 - val_loss: 68.6395 - val_root_mean_squared_error: 8.2849 - val_mean_absolute_error: 6.6633\n",
      "\n",
      "Epoch 00346: val_loss did not improve from 50.75751\n",
      "Epoch 347/2000\n",
      "143/143 [==============================] - 86s 602ms/step - loss: 45.4027 - root_mean_squared_error: 6.7362 - mean_absolute_error: 5.4282 - val_loss: 59.2272 - val_root_mean_squared_error: 7.6959 - val_mean_absolute_error: 6.2119\n",
      "\n",
      "Epoch 00347: val_loss did not improve from 50.75751\n",
      "Epoch 348/2000\n",
      "143/143 [==============================] - 89s 626ms/step - loss: 47.5740 - root_mean_squared_error: 6.8950 - mean_absolute_error: 5.5438 - val_loss: 68.0141 - val_root_mean_squared_error: 8.2471 - val_mean_absolute_error: 6.3276\n",
      "\n",
      "Epoch 00348: val_loss did not improve from 50.75751\n",
      "Epoch 349/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 88s 615ms/step - loss: 50.7562 - root_mean_squared_error: 7.1175 - mean_absolute_error: 5.6984 - val_loss: 64.6408 - val_root_mean_squared_error: 8.0399 - val_mean_absolute_error: 6.3157\n",
      "\n",
      "Epoch 00349: val_loss did not improve from 50.75751\n",
      "Epoch 350/2000\n",
      "143/143 [==============================] - 78s 547ms/step - loss: 49.4150 - root_mean_squared_error: 7.0279 - mean_absolute_error: 5.7000 - val_loss: 68.3142 - val_root_mean_squared_error: 8.2652 - val_mean_absolute_error: 6.8393\n",
      "\n",
      "Epoch 00350: val_loss did not improve from 50.75751\n",
      "Epoch 351/2000\n",
      "143/143 [==============================] - 79s 551ms/step - loss: 50.6283 - root_mean_squared_error: 7.1120 - mean_absolute_error: 5.8073 - val_loss: 64.5066 - val_root_mean_squared_error: 8.0316 - val_mean_absolute_error: 6.3855\n",
      "\n",
      "Epoch 00351: val_loss did not improve from 50.75751\n",
      "Epoch 352/2000\n",
      "143/143 [==============================] - 79s 554ms/step - loss: 54.0125 - root_mean_squared_error: 7.3461 - mean_absolute_error: 5.8569 - val_loss: 51.0116 - val_root_mean_squared_error: 7.1422 - val_mean_absolute_error: 5.7224\n",
      "\n",
      "Epoch 00352: val_loss did not improve from 50.75751\n",
      "Epoch 353/2000\n",
      "143/143 [==============================] - 82s 575ms/step - loss: 52.1517 - root_mean_squared_error: 7.2203 - mean_absolute_error: 5.8523 - val_loss: 67.8237 - val_root_mean_squared_error: 8.2355 - val_mean_absolute_error: 6.5922\n",
      "\n",
      "Epoch 00353: val_loss did not improve from 50.75751\n",
      "Epoch 354/2000\n",
      "143/143 [==============================] - 91s 638ms/step - loss: 50.2152 - root_mean_squared_error: 7.0840 - mean_absolute_error: 5.7750 - val_loss: 60.2240 - val_root_mean_squared_error: 7.7604 - val_mean_absolute_error: 6.2622\n",
      "\n",
      "Epoch 00354: val_loss did not improve from 50.75751\n",
      "Epoch 355/2000\n",
      "143/143 [==============================] - 92s 642ms/step - loss: 49.6660 - root_mean_squared_error: 7.0416 - mean_absolute_error: 5.7676 - val_loss: 62.3972 - val_root_mean_squared_error: 7.8992 - val_mean_absolute_error: 6.3447\n",
      "\n",
      "Epoch 00355: val_loss did not improve from 50.75751\n",
      "Epoch 356/2000\n",
      "143/143 [==============================] - 95s 665ms/step - loss: 50.7671 - root_mean_squared_error: 7.1197 - mean_absolute_error: 5.7532 - val_loss: 53.8017 - val_root_mean_squared_error: 7.3350 - val_mean_absolute_error: 5.7627\n",
      "\n",
      "Epoch 00356: val_loss did not improve from 50.75751\n",
      "Epoch 357/2000\n",
      "143/143 [==============================] - 93s 651ms/step - loss: 50.2634 - root_mean_squared_error: 7.0874 - mean_absolute_error: 5.6188 - val_loss: 68.3102 - val_root_mean_squared_error: 8.2650 - val_mean_absolute_error: 6.8140\n",
      "\n",
      "Epoch 00357: val_loss did not improve from 50.75751\n",
      "Epoch 358/2000\n",
      "143/143 [==============================] - 92s 646ms/step - loss: 48.4614 - root_mean_squared_error: 6.9545 - mean_absolute_error: 5.5774 - val_loss: 69.1256 - val_root_mean_squared_error: 8.3142 - val_mean_absolute_error: 6.4438\n",
      "\n",
      "Epoch 00358: val_loss did not improve from 50.75751\n",
      "Epoch 359/2000\n",
      "143/143 [==============================] - 92s 642ms/step - loss: 48.0344 - root_mean_squared_error: 6.9291 - mean_absolute_error: 5.5658 - val_loss: 58.5688 - val_root_mean_squared_error: 7.6530 - val_mean_absolute_error: 6.2989\n",
      "\n",
      "Epoch 00359: val_loss did not improve from 50.75751\n",
      "Epoch 360/2000\n",
      "143/143 [==============================] - 91s 641ms/step - loss: 45.8780 - root_mean_squared_error: 6.7724 - mean_absolute_error: 5.2908 - val_loss: 65.5853 - val_root_mean_squared_error: 8.0985 - val_mean_absolute_error: 6.3778\n",
      "\n",
      "Epoch 00360: val_loss did not improve from 50.75751\n",
      "Epoch 361/2000\n",
      "143/143 [==============================] - 87s 607ms/step - loss: 53.6043 - root_mean_squared_error: 7.3156 - mean_absolute_error: 5.7035 - val_loss: 59.3942 - val_root_mean_squared_error: 7.7068 - val_mean_absolute_error: 6.0972\n",
      "\n",
      "Epoch 00361: val_loss did not improve from 50.75751\n",
      "Epoch 362/2000\n",
      "143/143 [==============================] - 92s 644ms/step - loss: 53.0676 - root_mean_squared_error: 7.2820 - mean_absolute_error: 5.9126 - val_loss: 58.1796 - val_root_mean_squared_error: 7.6276 - val_mean_absolute_error: 5.9795\n",
      "\n",
      "Epoch 00362: val_loss did not improve from 50.75751\n",
      "Epoch 363/2000\n",
      "143/143 [==============================] - 91s 640ms/step - loss: 47.3214 - root_mean_squared_error: 6.8778 - mean_absolute_error: 5.5610 - val_loss: 65.0057 - val_root_mean_squared_error: 8.0626 - val_mean_absolute_error: 6.6060\n",
      "\n",
      "Epoch 00363: val_loss did not improve from 50.75751\n",
      "Epoch 364/2000\n",
      "143/143 [==============================] - 91s 635ms/step - loss: 52.1738 - root_mean_squared_error: 7.2217 - mean_absolute_error: 5.8816 - val_loss: 56.2881 - val_root_mean_squared_error: 7.5025 - val_mean_absolute_error: 5.7482\n",
      "\n",
      "Epoch 00364: val_loss did not improve from 50.75751\n",
      "Epoch 365/2000\n",
      "143/143 [==============================] - 90s 627ms/step - loss: 47.5972 - root_mean_squared_error: 6.8969 - mean_absolute_error: 5.5698 - val_loss: 61.9036 - val_root_mean_squared_error: 7.8679 - val_mean_absolute_error: 6.5044\n",
      "\n",
      "Epoch 00365: val_loss did not improve from 50.75751\n",
      "Epoch 366/2000\n",
      "143/143 [==============================] - 94s 661ms/step - loss: 51.4802 - root_mean_squared_error: 7.1725 - mean_absolute_error: 5.8270 - val_loss: 71.8059 - val_root_mean_squared_error: 8.4738 - val_mean_absolute_error: 6.5917\n",
      "\n",
      "Epoch 00366: val_loss did not improve from 50.75751\n",
      "Epoch 367/2000\n",
      "143/143 [==============================] - 91s 636ms/step - loss: 45.7022 - root_mean_squared_error: 6.7414 - mean_absolute_error: 5.3102 - val_loss: 58.4368 - val_root_mean_squared_error: 7.6444 - val_mean_absolute_error: 6.0240\n",
      "\n",
      "Epoch 00367: val_loss did not improve from 50.75751\n",
      "Epoch 368/2000\n",
      "143/143 [==============================] - 91s 639ms/step - loss: 51.2991 - root_mean_squared_error: 7.1514 - mean_absolute_error: 5.6710 - val_loss: 59.9743 - val_root_mean_squared_error: 7.7443 - val_mean_absolute_error: 6.2351\n",
      "\n",
      "Epoch 00368: val_loss did not improve from 50.75751\n",
      "Epoch 369/2000\n",
      "143/143 [==============================] - 90s 633ms/step - loss: 48.2714 - root_mean_squared_error: 6.9416 - mean_absolute_error: 5.5438 - val_loss: 65.7035 - val_root_mean_squared_error: 8.1058 - val_mean_absolute_error: 6.6025\n",
      "\n",
      "Epoch 00369: val_loss did not improve from 50.75751\n",
      "Epoch 370/2000\n",
      "143/143 [==============================] - 91s 638ms/step - loss: 52.7939 - root_mean_squared_error: 7.2596 - mean_absolute_error: 5.8763 - val_loss: 60.0281 - val_root_mean_squared_error: 7.7478 - val_mean_absolute_error: 6.2672\n",
      "\n",
      "Epoch 00370: val_loss did not improve from 50.75751\n",
      "Epoch 371/2000\n",
      "143/143 [==============================] - 89s 621ms/step - loss: 47.4577 - root_mean_squared_error: 6.8842 - mean_absolute_error: 5.5393 - val_loss: 62.2853 - val_root_mean_squared_error: 7.8921 - val_mean_absolute_error: 6.2932\n",
      "\n",
      "Epoch 00371: val_loss did not improve from 50.75751\n",
      "Epoch 372/2000\n",
      "143/143 [==============================] - 92s 645ms/step - loss: 49.1624 - root_mean_squared_error: 6.9930 - mean_absolute_error: 5.5544 - val_loss: 68.9796 - val_root_mean_squared_error: 8.3054 - val_mean_absolute_error: 6.4809\n",
      "\n",
      "Epoch 00372: val_loss did not improve from 50.75751\n",
      "Epoch 373/2000\n",
      "143/143 [==============================] - 91s 640ms/step - loss: 53.1204 - root_mean_squared_error: 7.2827 - mean_absolute_error: 5.7787 - val_loss: 60.9109 - val_root_mean_squared_error: 7.8045 - val_mean_absolute_error: 6.2799\n",
      "\n",
      "Epoch 00373: val_loss did not improve from 50.75751\n",
      "Epoch 374/2000\n",
      "143/143 [==============================] - 91s 636ms/step - loss: 53.1688 - root_mean_squared_error: 7.2849 - mean_absolute_error: 5.8180 - val_loss: 58.8538 - val_root_mean_squared_error: 7.6716 - val_mean_absolute_error: 6.0773\n",
      "\n",
      "Epoch 00374: val_loss did not improve from 50.75751\n",
      "\n",
      "Epoch 00374: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "Epoch 375/2000\n",
      "143/143 [==============================] - 93s 651ms/step - loss: 47.6214 - root_mean_squared_error: 6.8931 - mean_absolute_error: 5.5219 - val_loss: 69.4518 - val_root_mean_squared_error: 8.3338 - val_mean_absolute_error: 6.5425\n",
      "\n",
      "Epoch 00375: val_loss did not improve from 50.75751\n",
      "Epoch 376/2000\n",
      "143/143 [==============================] - 90s 632ms/step - loss: 46.5848 - root_mean_squared_error: 6.8226 - mean_absolute_error: 5.4524 - val_loss: 69.9653 - val_root_mean_squared_error: 8.3645 - val_mean_absolute_error: 6.7047\n",
      "\n",
      "Epoch 00376: val_loss did not improve from 50.75751\n",
      "Epoch 377/2000\n",
      "143/143 [==============================] - 90s 630ms/step - loss: 48.3748 - root_mean_squared_error: 6.9523 - mean_absolute_error: 5.6290 - val_loss: 63.9092 - val_root_mean_squared_error: 7.9943 - val_mean_absolute_error: 6.3878\n",
      "\n",
      "Epoch 00377: val_loss did not improve from 50.75751\n",
      "Epoch 378/2000\n",
      "143/143 [==============================] - 91s 641ms/step - loss: 48.1456 - root_mean_squared_error: 6.9312 - mean_absolute_error: 5.5650 - val_loss: 55.3561 - val_root_mean_squared_error: 7.4402 - val_mean_absolute_error: 6.0112\n",
      "\n",
      "Epoch 00378: val_loss did not improve from 50.75751\n",
      "Epoch 379/2000\n",
      "143/143 [==============================] - 93s 649ms/step - loss: 43.2034 - root_mean_squared_error: 6.5675 - mean_absolute_error: 5.2612 - val_loss: 64.7234 - val_root_mean_squared_error: 8.0451 - val_mean_absolute_error: 6.3853\n",
      "\n",
      "Epoch 00379: val_loss did not improve from 50.75751\n",
      "Epoch 380/2000\n",
      "143/143 [==============================] - 91s 640ms/step - loss: 50.6424 - root_mean_squared_error: 7.1023 - mean_absolute_error: 5.6239 - val_loss: 58.7695 - val_root_mean_squared_error: 7.6661 - val_mean_absolute_error: 6.0209\n",
      "\n",
      "Epoch 00380: val_loss did not improve from 50.75751\n",
      "Epoch 381/2000\n",
      "143/143 [==============================] - 90s 630ms/step - loss: 48.9557 - root_mean_squared_error: 6.9934 - mean_absolute_error: 5.6422 - val_loss: 72.0980 - val_root_mean_squared_error: 8.4911 - val_mean_absolute_error: 6.8863\n",
      "\n",
      "Epoch 00381: val_loss did not improve from 50.75751\n",
      "Epoch 382/2000\n",
      "143/143 [==============================] - 91s 639ms/step - loss: 46.1546 - root_mean_squared_error: 6.7915 - mean_absolute_error: 5.4714 - val_loss: 67.1033 - val_root_mean_squared_error: 8.1917 - val_mean_absolute_error: 6.5658\n",
      "\n",
      "Epoch 00382: val_loss did not improve from 50.75751\n",
      "Epoch 383/2000\n",
      "143/143 [==============================] - 93s 647ms/step - loss: 51.0221 - root_mean_squared_error: 7.1385 - mean_absolute_error: 5.7397 - val_loss: 62.2466 - val_root_mean_squared_error: 7.8896 - val_mean_absolute_error: 6.3368\n",
      "\n",
      "Epoch 00383: val_loss did not improve from 50.75751\n",
      "Epoch 384/2000\n",
      "143/143 [==============================] - 89s 627ms/step - loss: 51.3645 - root_mean_squared_error: 7.1595 - mean_absolute_error: 5.7613 - val_loss: 55.2968 - val_root_mean_squared_error: 7.4362 - val_mean_absolute_error: 5.9442\n",
      "\n",
      "Epoch 00384: val_loss did not improve from 50.75751\n",
      "Epoch 385/2000\n",
      "143/143 [==============================] - 87s 612ms/step - loss: 50.5749 - root_mean_squared_error: 7.1068 - mean_absolute_error: 5.6500 - val_loss: 69.1802 - val_root_mean_squared_error: 8.3175 - val_mean_absolute_error: 6.6354\n",
      "\n",
      "Epoch 00385: val_loss did not improve from 50.75751\n",
      "Epoch 386/2000\n",
      "143/143 [==============================] - 90s 630ms/step - loss: 49.8462 - root_mean_squared_error: 7.0496 - mean_absolute_error: 5.5772 - val_loss: 65.1661 - val_root_mean_squared_error: 8.0726 - val_mean_absolute_error: 6.6122\n",
      "\n",
      "Epoch 00386: val_loss did not improve from 50.75751\n",
      "Epoch 387/2000\n",
      "143/143 [==============================] - 89s 623ms/step - loss: 48.3410 - root_mean_squared_error: 6.9510 - mean_absolute_error: 5.5114 - val_loss: 57.1984 - val_root_mean_squared_error: 7.5630 - val_mean_absolute_error: 6.1336\n",
      "\n",
      "Epoch 00387: val_loss did not improve from 50.75751\n",
      "Epoch 388/2000\n",
      "143/143 [==============================] - 92s 641ms/step - loss: 43.3016 - root_mean_squared_error: 6.5680 - mean_absolute_error: 5.2277 - val_loss: 57.3579 - val_root_mean_squared_error: 7.5735 - val_mean_absolute_error: 6.0697\n",
      "\n",
      "Epoch 00388: val_loss did not improve from 50.75751\n",
      "Epoch 389/2000\n",
      "143/143 [==============================] - 92s 645ms/step - loss: 46.7594 - root_mean_squared_error: 6.8344 - mean_absolute_error: 5.4933 - val_loss: 59.3894 - val_root_mean_squared_error: 7.7065 - val_mean_absolute_error: 6.3107\n",
      "\n",
      "Epoch 00389: val_loss did not improve from 50.75751\n",
      "Epoch 390/2000\n",
      "143/143 [==============================] - 91s 635ms/step - loss: 45.8756 - root_mean_squared_error: 6.7711 - mean_absolute_error: 5.4679 - val_loss: 61.1664 - val_root_mean_squared_error: 7.8209 - val_mean_absolute_error: 6.3392\n",
      "\n",
      "Epoch 00390: val_loss did not improve from 50.75751\n",
      "Epoch 391/2000\n",
      "143/143 [==============================] - 90s 631ms/step - loss: 46.8894 - root_mean_squared_error: 6.8390 - mean_absolute_error: 5.3861 - val_loss: 58.9313 - val_root_mean_squared_error: 7.6767 - val_mean_absolute_error: 5.9987\n",
      "\n",
      "Epoch 00391: val_loss did not improve from 50.75751\n",
      "Epoch 392/2000\n",
      "143/143 [==============================] - 90s 629ms/step - loss: 47.9513 - root_mean_squared_error: 6.9229 - mean_absolute_error: 5.6260 - val_loss: 66.8812 - val_root_mean_squared_error: 8.1781 - val_mean_absolute_error: 6.3789\n",
      "\n",
      "Epoch 00392: val_loss did not improve from 50.75751\n",
      "Epoch 393/2000\n",
      "143/143 [==============================] - 92s 643ms/step - loss: 47.4363 - root_mean_squared_error: 6.8859 - mean_absolute_error: 5.5058 - val_loss: 76.2393 - val_root_mean_squared_error: 8.7315 - val_mean_absolute_error: 6.8889\n",
      "\n",
      "Epoch 00393: val_loss did not improve from 50.75751\n",
      "Epoch 394/2000\n",
      "143/143 [==============================] - 91s 636ms/step - loss: 48.0665 - root_mean_squared_error: 6.9299 - mean_absolute_error: 5.5625 - val_loss: 59.0587 - val_root_mean_squared_error: 7.6850 - val_mean_absolute_error: 6.2918\n",
      "\n",
      "Epoch 00394: val_loss did not improve from 50.75751\n",
      "Epoch 395/2000\n",
      "143/143 [==============================] - 91s 633ms/step - loss: 46.9637 - root_mean_squared_error: 6.8514 - mean_absolute_error: 5.5495 - val_loss: 70.5651 - val_root_mean_squared_error: 8.4003 - val_mean_absolute_error: 6.8420\n",
      "\n",
      "Epoch 00395: val_loss did not improve from 50.75751\n",
      "Epoch 396/2000\n",
      "143/143 [==============================] - 89s 623ms/step - loss: 48.2149 - root_mean_squared_error: 6.9434 - mean_absolute_error: 5.6178 - val_loss: 51.2141 - val_root_mean_squared_error: 7.1564 - val_mean_absolute_error: 5.6607\n",
      "\n",
      "Epoch 00396: val_loss did not improve from 50.75751\n",
      "Epoch 397/2000\n",
      "143/143 [==============================] - 89s 622ms/step - loss: 49.8329 - root_mean_squared_error: 7.0548 - mean_absolute_error: 5.6925 - val_loss: 62.1931 - val_root_mean_squared_error: 7.8863 - val_mean_absolute_error: 6.5109\n",
      "\n",
      "Epoch 00397: val_loss did not improve from 50.75751\n",
      "Epoch 398/2000\n",
      "143/143 [==============================] - 91s 638ms/step - loss: 46.4286 - root_mean_squared_error: 6.8096 - mean_absolute_error: 5.5088 - val_loss: 58.9859 - val_root_mean_squared_error: 7.6802 - val_mean_absolute_error: 6.1677\n",
      "\n",
      "Epoch 00398: val_loss did not improve from 50.75751\n",
      "Epoch 399/2000\n",
      "143/143 [==============================] - 90s 631ms/step - loss: 50.7496 - root_mean_squared_error: 7.1190 - mean_absolute_error: 5.6857 - val_loss: 69.7255 - val_root_mean_squared_error: 8.3502 - val_mean_absolute_error: 6.5445\n",
      "\n",
      "Epoch 00399: val_loss did not improve from 50.75751\n",
      "Epoch 400/2000\n",
      "143/143 [==============================] - 92s 643ms/step - loss: 50.1175 - root_mean_squared_error: 7.0773 - mean_absolute_error: 5.7544 - val_loss: 66.1673 - val_root_mean_squared_error: 8.1343 - val_mean_absolute_error: 6.4308\n",
      "\n",
      "Epoch 00400: val_loss did not improve from 50.75751\n",
      "Epoch 401/2000\n",
      "143/143 [==============================] - 91s 635ms/step - loss: 44.7770 - root_mean_squared_error: 6.6869 - mean_absolute_error: 5.3174 - val_loss: 57.0583 - val_root_mean_squared_error: 7.5537 - val_mean_absolute_error: 6.1627\n",
      "\n",
      "Epoch 00401: val_loss did not improve from 50.75751\n",
      "Epoch 402/2000\n",
      "143/143 [==============================] - 92s 644ms/step - loss: 44.9612 - root_mean_squared_error: 6.7027 - mean_absolute_error: 5.4286 - val_loss: 64.6023 - val_root_mean_squared_error: 8.0376 - val_mean_absolute_error: 6.3925\n",
      "\n",
      "Epoch 00402: val_loss did not improve from 50.75751\n",
      "Epoch 403/2000\n",
      "143/143 [==============================] - 92s 644ms/step - loss: 50.4635 - root_mean_squared_error: 7.0927 - mean_absolute_error: 5.6330 - val_loss: 70.3697 - val_root_mean_squared_error: 8.3887 - val_mean_absolute_error: 6.6885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00403: val_loss did not improve from 50.75751\n",
      "Epoch 404/2000\n",
      "143/143 [==============================] - 90s 633ms/step - loss: 49.8492 - root_mean_squared_error: 7.0528 - mean_absolute_error: 5.6238 - val_loss: 59.5973 - val_root_mean_squared_error: 7.7199 - val_mean_absolute_error: 6.1327\n",
      "\n",
      "Epoch 00404: val_loss did not improve from 50.75751\n",
      "Epoch 405/2000\n",
      "143/143 [==============================] - 90s 630ms/step - loss: 47.6424 - root_mean_squared_error: 6.9014 - mean_absolute_error: 5.5134 - val_loss: 74.2427 - val_root_mean_squared_error: 8.6164 - val_mean_absolute_error: 6.7171\n",
      "\n",
      "Epoch 00405: val_loss did not improve from 50.75751\n",
      "Epoch 406/2000\n",
      "143/143 [==============================] - 91s 639ms/step - loss: 47.0558 - root_mean_squared_error: 6.8538 - mean_absolute_error: 5.5119 - val_loss: 50.4317 - val_root_mean_squared_error: 7.1015 - val_mean_absolute_error: 5.7122\n",
      "\n",
      "Epoch 00406: val_loss improved from 50.75751 to 50.43166, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/TimeCNN_regressor_01.hdf5\n",
      "Epoch 407/2000\n",
      "143/143 [==============================] - 91s 634ms/step - loss: 46.8111 - root_mean_squared_error: 6.8309 - mean_absolute_error: 5.4053 - val_loss: 63.6188 - val_root_mean_squared_error: 7.9761 - val_mean_absolute_error: 6.3368\n",
      "\n",
      "Epoch 00407: val_loss did not improve from 50.43166\n",
      "Epoch 408/2000\n",
      "143/143 [==============================] - 90s 630ms/step - loss: 46.3835 - root_mean_squared_error: 6.8095 - mean_absolute_error: 5.4815 - val_loss: 59.8247 - val_root_mean_squared_error: 7.7346 - val_mean_absolute_error: 6.4078\n",
      "\n",
      "Epoch 00408: val_loss did not improve from 50.43166\n",
      "Epoch 409/2000\n",
      "143/143 [==============================] - 89s 625ms/step - loss: 49.9584 - root_mean_squared_error: 7.0611 - mean_absolute_error: 5.5880 - val_loss: 65.7748 - val_root_mean_squared_error: 8.1102 - val_mean_absolute_error: 6.5727\n",
      "\n",
      "Epoch 00409: val_loss did not improve from 50.43166\n",
      "Epoch 410/2000\n",
      "143/143 [==============================] - 92s 644ms/step - loss: 52.6583 - root_mean_squared_error: 7.2452 - mean_absolute_error: 5.7605 - val_loss: 64.8449 - val_root_mean_squared_error: 8.0526 - val_mean_absolute_error: 6.3914\n",
      "\n",
      "Epoch 00410: val_loss did not improve from 50.43166\n",
      "Epoch 411/2000\n",
      "143/143 [==============================] - 90s 631ms/step - loss: 49.5634 - root_mean_squared_error: 7.0381 - mean_absolute_error: 5.5873 - val_loss: 64.8346 - val_root_mean_squared_error: 8.0520 - val_mean_absolute_error: 6.5243\n",
      "\n",
      "Epoch 00411: val_loss did not improve from 50.43166\n",
      "Epoch 412/2000\n",
      "143/143 [==============================] - 90s 633ms/step - loss: 46.3504 - root_mean_squared_error: 6.8056 - mean_absolute_error: 5.4978 - val_loss: 61.3357 - val_root_mean_squared_error: 7.8317 - val_mean_absolute_error: 6.1368\n",
      "\n",
      "Epoch 00412: val_loss did not improve from 50.43166\n",
      "Epoch 413/2000\n",
      "143/143 [==============================] - 89s 624ms/step - loss: 47.7966 - root_mean_squared_error: 6.9120 - mean_absolute_error: 5.5757 - val_loss: 54.9708 - val_root_mean_squared_error: 7.4142 - val_mean_absolute_error: 5.7647\n",
      "\n",
      "Epoch 00413: val_loss did not improve from 50.43166\n",
      "Epoch 414/2000\n",
      "143/143 [==============================] - 91s 638ms/step - loss: 50.0375 - root_mean_squared_error: 7.0678 - mean_absolute_error: 5.6983 - val_loss: 64.1624 - val_root_mean_squared_error: 8.0101 - val_mean_absolute_error: 6.4370\n",
      "\n",
      "Epoch 00414: val_loss did not improve from 50.43166\n",
      "Epoch 415/2000\n",
      "143/143 [==============================] - 90s 631ms/step - loss: 44.3915 - root_mean_squared_error: 6.6610 - mean_absolute_error: 5.3550 - val_loss: 58.8034 - val_root_mean_squared_error: 7.6683 - val_mean_absolute_error: 5.9849\n",
      "\n",
      "Epoch 00415: val_loss did not improve from 50.43166\n",
      "Epoch 416/2000\n",
      "143/143 [==============================] - 90s 630ms/step - loss: 49.6066 - root_mean_squared_error: 7.0405 - mean_absolute_error: 5.6681 - val_loss: 56.1582 - val_root_mean_squared_error: 7.4939 - val_mean_absolute_error: 5.9874\n",
      "\n",
      "Epoch 00416: val_loss did not improve from 50.43166\n",
      "Epoch 417/2000\n",
      "143/143 [==============================] - 92s 642ms/step - loss: 48.4272 - root_mean_squared_error: 6.9559 - mean_absolute_error: 5.6445 - val_loss: 68.4424 - val_root_mean_squared_error: 8.2730 - val_mean_absolute_error: 6.6214\n",
      "\n",
      "Epoch 00417: val_loss did not improve from 50.43166\n",
      "Epoch 418/2000\n",
      "143/143 [==============================] - 89s 623ms/step - loss: 52.5186 - root_mean_squared_error: 7.2446 - mean_absolute_error: 5.8740 - val_loss: 61.0023 - val_root_mean_squared_error: 7.8104 - val_mean_absolute_error: 6.2675\n",
      "\n",
      "Epoch 00418: val_loss did not improve from 50.43166\n",
      "Epoch 419/2000\n",
      "143/143 [==============================] - 91s 638ms/step - loss: 50.7619 - root_mean_squared_error: 7.1235 - mean_absolute_error: 5.7505 - val_loss: 75.0039 - val_root_mean_squared_error: 8.6605 - val_mean_absolute_error: 6.8462\n",
      "\n",
      "Epoch 00419: val_loss did not improve from 50.43166\n",
      "Epoch 420/2000\n",
      "143/143 [==============================] - 89s 623ms/step - loss: 47.5352 - root_mean_squared_error: 6.8933 - mean_absolute_error: 5.6281 - val_loss: 61.3463 - val_root_mean_squared_error: 7.8324 - val_mean_absolute_error: 6.4102\n",
      "\n",
      "Epoch 00420: val_loss did not improve from 50.43166\n",
      "Epoch 421/2000\n",
      "143/143 [==============================] - 85s 593ms/step - loss: 47.9713 - root_mean_squared_error: 6.9241 - mean_absolute_error: 5.6300 - val_loss: 54.9653 - val_root_mean_squared_error: 7.4139 - val_mean_absolute_error: 5.8473\n",
      "\n",
      "Epoch 00421: val_loss did not improve from 50.43166\n",
      "Epoch 422/2000\n",
      "143/143 [==============================] - 85s 594ms/step - loss: 51.5658 - root_mean_squared_error: 7.1738 - mean_absolute_error: 5.6590 - val_loss: 59.7785 - val_root_mean_squared_error: 7.7317 - val_mean_absolute_error: 6.2019\n",
      "\n",
      "Epoch 00422: val_loss did not improve from 50.43166\n",
      "Epoch 423/2000\n",
      "143/143 [==============================] - 86s 604ms/step - loss: 45.3332 - root_mean_squared_error: 6.7271 - mean_absolute_error: 5.2555 - val_loss: 66.4331 - val_root_mean_squared_error: 8.1507 - val_mean_absolute_error: 6.5604\n",
      "\n",
      "Epoch 00423: val_loss did not improve from 50.43166\n",
      "Epoch 424/2000\n",
      "143/143 [==============================] - 87s 612ms/step - loss: 45.8693 - root_mean_squared_error: 6.7700 - mean_absolute_error: 5.3431 - val_loss: 54.2680 - val_root_mean_squared_error: 7.3667 - val_mean_absolute_error: 5.9619\n",
      "\n",
      "Epoch 00424: val_loss did not improve from 50.43166\n",
      "Epoch 425/2000\n",
      "143/143 [==============================] - 89s 623ms/step - loss: 46.8559 - root_mean_squared_error: 6.8429 - mean_absolute_error: 5.5423 - val_loss: 58.5619 - val_root_mean_squared_error: 7.6526 - val_mean_absolute_error: 6.0011\n",
      "\n",
      "Epoch 00425: val_loss did not improve from 50.43166\n",
      "Epoch 426/2000\n",
      "143/143 [==============================] - 92s 642ms/step - loss: 46.3660 - root_mean_squared_error: 6.8060 - mean_absolute_error: 5.5161 - val_loss: 55.1211 - val_root_mean_squared_error: 7.4244 - val_mean_absolute_error: 6.0081\n",
      "\n",
      "Epoch 00426: val_loss did not improve from 50.43166\n",
      "Epoch 427/2000\n",
      "143/143 [==============================] - 89s 621ms/step - loss: 48.8361 - root_mean_squared_error: 6.9865 - mean_absolute_error: 5.5633 - val_loss: 71.7860 - val_root_mean_squared_error: 8.4727 - val_mean_absolute_error: 6.7335\n",
      "\n",
      "Epoch 00427: val_loss did not improve from 50.43166\n",
      "Epoch 428/2000\n",
      "143/143 [==============================] - 90s 629ms/step - loss: 50.5530 - root_mean_squared_error: 7.1082 - mean_absolute_error: 5.7802 - val_loss: 67.8039 - val_root_mean_squared_error: 8.2343 - val_mean_absolute_error: 6.6140\n",
      "\n",
      "Epoch 00428: val_loss did not improve from 50.43166\n",
      "Epoch 429/2000\n",
      "143/143 [==============================] - 88s 613ms/step - loss: 48.4126 - root_mean_squared_error: 6.9563 - mean_absolute_error: 5.6265 - val_loss: 59.5409 - val_root_mean_squared_error: 7.7163 - val_mean_absolute_error: 6.1755\n",
      "\n",
      "Epoch 00429: val_loss did not improve from 50.43166\n",
      "Epoch 430/2000\n",
      "143/143 [==============================] - 89s 624ms/step - loss: 51.9407 - root_mean_squared_error: 7.2042 - mean_absolute_error: 5.7494 - val_loss: 56.4338 - val_root_mean_squared_error: 7.5122 - val_mean_absolute_error: 5.8478\n",
      "\n",
      "Epoch 00430: val_loss did not improve from 50.43166\n",
      "Epoch 431/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 90s 629ms/step - loss: 47.7175 - root_mean_squared_error: 6.9022 - mean_absolute_error: 5.4615 - val_loss: 65.4571 - val_root_mean_squared_error: 8.0906 - val_mean_absolute_error: 6.5373\n",
      "\n",
      "Epoch 00431: val_loss did not improve from 50.43166\n",
      "Epoch 432/2000\n",
      "143/143 [==============================] - 89s 624ms/step - loss: 46.3438 - root_mean_squared_error: 6.8000 - mean_absolute_error: 5.3898 - val_loss: 65.8487 - val_root_mean_squared_error: 8.1147 - val_mean_absolute_error: 6.4410\n",
      "\n",
      "Epoch 00432: val_loss did not improve from 50.43166\n",
      "Epoch 433/2000\n",
      "143/143 [==============================] - 90s 630ms/step - loss: 48.9694 - root_mean_squared_error: 6.9962 - mean_absolute_error: 5.5704 - val_loss: 61.1195 - val_root_mean_squared_error: 7.8179 - val_mean_absolute_error: 6.1633\n",
      "\n",
      "Epoch 00433: val_loss did not improve from 50.43166\n",
      "Epoch 434/2000\n",
      "143/143 [==============================] - 87s 610ms/step - loss: 50.8045 - root_mean_squared_error: 7.1245 - mean_absolute_error: 5.7513 - val_loss: 63.8228 - val_root_mean_squared_error: 7.9889 - val_mean_absolute_error: 6.1747\n",
      "\n",
      "Epoch 00434: val_loss did not improve from 50.43166\n",
      "Epoch 435/2000\n",
      "143/143 [==============================] - 80s 559ms/step - loss: 50.6469 - root_mean_squared_error: 7.1098 - mean_absolute_error: 5.5812 - val_loss: 59.1672 - val_root_mean_squared_error: 7.6920 - val_mean_absolute_error: 6.1517\n",
      "\n",
      "Epoch 00435: val_loss did not improve from 50.43166\n",
      "Epoch 436/2000\n",
      "143/143 [==============================] - 79s 555ms/step - loss: 47.9677 - root_mean_squared_error: 6.9228 - mean_absolute_error: 5.5658 - val_loss: 72.2185 - val_root_mean_squared_error: 8.4981 - val_mean_absolute_error: 6.8767\n",
      "\n",
      "Epoch 00436: val_loss did not improve from 50.43166\n",
      "Epoch 437/2000\n",
      "143/143 [==============================] - 80s 557ms/step - loss: 49.7383 - root_mean_squared_error: 7.0473 - mean_absolute_error: 5.6444 - val_loss: 69.2792 - val_root_mean_squared_error: 8.3234 - val_mean_absolute_error: 6.5691\n",
      "\n",
      "Epoch 00437: val_loss did not improve from 50.43166\n",
      "Epoch 438/2000\n",
      "143/143 [==============================] - 85s 597ms/step - loss: 50.3962 - root_mean_squared_error: 7.0926 - mean_absolute_error: 5.6850 - val_loss: 58.4983 - val_root_mean_squared_error: 7.6484 - val_mean_absolute_error: 6.1842\n",
      "\n",
      "Epoch 00438: val_loss did not improve from 50.43166\n",
      "Epoch 439/2000\n",
      "143/143 [==============================] - 91s 634ms/step - loss: 47.6937 - root_mean_squared_error: 6.9022 - mean_absolute_error: 5.5779 - val_loss: 62.5704 - val_root_mean_squared_error: 7.9101 - val_mean_absolute_error: 6.4535\n",
      "\n",
      "Epoch 00439: val_loss did not improve from 50.43166\n",
      "Epoch 440/2000\n",
      "143/143 [==============================] - 94s 659ms/step - loss: 47.2573 - root_mean_squared_error: 6.8737 - mean_absolute_error: 5.5109 - val_loss: 59.2516 - val_root_mean_squared_error: 7.6975 - val_mean_absolute_error: 6.3233\n",
      "\n",
      "Epoch 00440: val_loss did not improve from 50.43166\n",
      "Epoch 441/2000\n",
      "143/143 [==============================] - 93s 648ms/step - loss: 49.9727 - root_mean_squared_error: 7.0678 - mean_absolute_error: 5.6130 - val_loss: 65.0822 - val_root_mean_squared_error: 8.0674 - val_mean_absolute_error: 6.6026\n",
      "\n",
      "Epoch 00441: val_loss did not improve from 50.43166\n",
      "Epoch 442/2000\n",
      "143/143 [==============================] - 93s 651ms/step - loss: 46.0071 - root_mean_squared_error: 6.7800 - mean_absolute_error: 5.3973 - val_loss: 69.4442 - val_root_mean_squared_error: 8.3333 - val_mean_absolute_error: 6.7696\n",
      "\n",
      "Epoch 00442: val_loss did not improve from 50.43166\n",
      "Epoch 443/2000\n",
      "143/143 [==============================] - 93s 648ms/step - loss: 45.7949 - root_mean_squared_error: 6.7659 - mean_absolute_error: 5.4832 - val_loss: 63.9814 - val_root_mean_squared_error: 7.9988 - val_mean_absolute_error: 6.0431\n",
      "\n",
      "Epoch 00443: val_loss did not improve from 50.43166\n",
      "Epoch 444/2000\n",
      "143/143 [==============================] - 93s 653ms/step - loss: 44.6467 - root_mean_squared_error: 6.6751 - mean_absolute_error: 5.3691 - val_loss: 66.4824 - val_root_mean_squared_error: 8.1537 - val_mean_absolute_error: 6.5249\n",
      "\n",
      "Epoch 00444: val_loss did not improve from 50.43166\n",
      "Epoch 445/2000\n",
      "143/143 [==============================] - 92s 643ms/step - loss: 48.8155 - root_mean_squared_error: 6.9855 - mean_absolute_error: 5.6345 - val_loss: 65.9092 - val_root_mean_squared_error: 8.1185 - val_mean_absolute_error: 6.5000\n",
      "\n",
      "Epoch 00445: val_loss did not improve from 50.43166\n",
      "Epoch 446/2000\n",
      "143/143 [==============================] - 95s 662ms/step - loss: 47.7936 - root_mean_squared_error: 6.9120 - mean_absolute_error: 5.5783 - val_loss: 66.8386 - val_root_mean_squared_error: 8.1755 - val_mean_absolute_error: 6.4649\n",
      "\n",
      "Epoch 00446: val_loss did not improve from 50.43166\n",
      "Epoch 447/2000\n",
      "143/143 [==============================] - 93s 649ms/step - loss: 44.9798 - root_mean_squared_error: 6.7054 - mean_absolute_error: 5.3386 - val_loss: 64.2934 - val_root_mean_squared_error: 8.0183 - val_mean_absolute_error: 6.6749\n",
      "\n",
      "Epoch 00447: val_loss did not improve from 50.43166\n",
      "Epoch 448/2000\n",
      "143/143 [==============================] - 91s 640ms/step - loss: 46.7148 - root_mean_squared_error: 6.8297 - mean_absolute_error: 5.4466 - val_loss: 69.5152 - val_root_mean_squared_error: 8.3376 - val_mean_absolute_error: 6.4794\n",
      "\n",
      "Epoch 00448: val_loss did not improve from 50.43166\n",
      "Epoch 449/2000\n",
      "143/143 [==============================] - 93s 652ms/step - loss: 44.0707 - root_mean_squared_error: 6.6316 - mean_absolute_error: 5.2303 - val_loss: 60.0630 - val_root_mean_squared_error: 7.7500 - val_mean_absolute_error: 6.0843\n",
      "\n",
      "Epoch 00449: val_loss did not improve from 50.43166\n",
      "Epoch 450/2000\n",
      "143/143 [==============================] - 92s 645ms/step - loss: 48.4055 - root_mean_squared_error: 6.9547 - mean_absolute_error: 5.4564 - val_loss: 64.0819 - val_root_mean_squared_error: 8.0051 - val_mean_absolute_error: 6.4403\n",
      "\n",
      "Epoch 00450: val_loss did not improve from 50.43166\n",
      "Epoch 451/2000\n",
      "143/143 [==============================] - 91s 638ms/step - loss: 47.3986 - root_mean_squared_error: 6.8820 - mean_absolute_error: 5.5494 - val_loss: 60.3050 - val_root_mean_squared_error: 7.7656 - val_mean_absolute_error: 6.3214\n",
      "\n",
      "Epoch 00451: val_loss did not improve from 50.43166\n",
      "Epoch 452/2000\n",
      "143/143 [==============================] - 92s 643ms/step - loss: 52.1888 - root_mean_squared_error: 7.2203 - mean_absolute_error: 5.8808 - val_loss: 49.4721 - val_root_mean_squared_error: 7.0336 - val_mean_absolute_error: 5.8549\n",
      "\n",
      "Epoch 00452: val_loss improved from 50.43166 to 49.47214, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/TimeCNN_regressor_01.hdf5\n",
      "Epoch 453/2000\n",
      "143/143 [==============================] - 91s 640ms/step - loss: 42.4289 - root_mean_squared_error: 6.5117 - mean_absolute_error: 5.1897 - val_loss: 63.3172 - val_root_mean_squared_error: 7.9572 - val_mean_absolute_error: 6.4106\n",
      "\n",
      "Epoch 00453: val_loss did not improve from 49.47214\n",
      "Epoch 454/2000\n",
      "143/143 [==============================] - 91s 639ms/step - loss: 48.8152 - root_mean_squared_error: 6.9842 - mean_absolute_error: 5.5501 - val_loss: 67.4985 - val_root_mean_squared_error: 8.2157 - val_mean_absolute_error: 6.6098\n",
      "\n",
      "Epoch 00454: val_loss did not improve from 49.47214\n",
      "Epoch 455/2000\n",
      "143/143 [==============================] - 91s 637ms/step - loss: 45.7241 - root_mean_squared_error: 6.7601 - mean_absolute_error: 5.2972 - val_loss: 61.8605 - val_root_mean_squared_error: 7.8651 - val_mean_absolute_error: 6.4529\n",
      "\n",
      "Epoch 00455: val_loss did not improve from 49.47214\n",
      "Epoch 456/2000\n",
      "143/143 [==============================] - 93s 649ms/step - loss: 47.6428 - root_mean_squared_error: 6.8985 - mean_absolute_error: 5.5217 - val_loss: 65.1107 - val_root_mean_squared_error: 8.0691 - val_mean_absolute_error: 6.3076\n",
      "\n",
      "Epoch 00456: val_loss did not improve from 49.47214\n",
      "Epoch 457/2000\n",
      "143/143 [==============================] - 93s 651ms/step - loss: 45.8947 - root_mean_squared_error: 6.7732 - mean_absolute_error: 5.4092 - val_loss: 70.7734 - val_root_mean_squared_error: 8.4127 - val_mean_absolute_error: 6.6773\n",
      "\n",
      "Epoch 00457: val_loss did not improve from 49.47214\n",
      "Epoch 458/2000\n",
      "143/143 [==============================] - 91s 635ms/step - loss: 50.1563 - root_mean_squared_error: 7.0786 - mean_absolute_error: 5.7750 - val_loss: 63.2380 - val_root_mean_squared_error: 7.9522 - val_mean_absolute_error: 6.4214\n",
      "\n",
      "Epoch 00458: val_loss did not improve from 49.47214\n",
      "Epoch 459/2000\n",
      "143/143 [==============================] - 93s 653ms/step - loss: 48.0662 - root_mean_squared_error: 6.9302 - mean_absolute_error: 5.5711 - val_loss: 64.8536 - val_root_mean_squared_error: 8.0532 - val_mean_absolute_error: 6.6437\n",
      "\n",
      "Epoch 00459: val_loss did not improve from 49.47214\n",
      "Epoch 460/2000\n",
      "143/143 [==============================] - 92s 646ms/step - loss: 50.9353 - root_mean_squared_error: 7.1114 - mean_absolute_error: 5.6434 - val_loss: 52.2900 - val_root_mean_squared_error: 7.2312 - val_mean_absolute_error: 5.8047\n",
      "\n",
      "Epoch 00460: val_loss did not improve from 49.47214\n",
      "Epoch 461/2000\n",
      "143/143 [==============================] - 91s 638ms/step - loss: 44.7645 - root_mean_squared_error: 6.6882 - mean_absolute_error: 5.2808 - val_loss: 57.5878 - val_root_mean_squared_error: 7.5887 - val_mean_absolute_error: 6.1571\n",
      "\n",
      "Epoch 00461: val_loss did not improve from 49.47214\n",
      "Epoch 462/2000\n",
      "143/143 [==============================] - 89s 622ms/step - loss: 45.0932 - root_mean_squared_error: 6.7093 - mean_absolute_error: 5.4059 - val_loss: 66.8752 - val_root_mean_squared_error: 8.1777 - val_mean_absolute_error: 6.4829\n",
      "\n",
      "Epoch 00462: val_loss did not improve from 49.47214\n",
      "Epoch 463/2000\n",
      "143/143 [==============================] - 94s 659ms/step - loss: 44.3611 - root_mean_squared_error: 6.6582 - mean_absolute_error: 5.3005 - val_loss: 60.3292 - val_root_mean_squared_error: 7.7672 - val_mean_absolute_error: 6.1687\n",
      "\n",
      "Epoch 00463: val_loss did not improve from 49.47214\n",
      "Epoch 464/2000\n",
      "143/143 [==============================] - 93s 652ms/step - loss: 54.0069 - root_mean_squared_error: 7.3322 - mean_absolute_error: 5.8936 - val_loss: 64.7291 - val_root_mean_squared_error: 8.0454 - val_mean_absolute_error: 6.5271\n",
      "\n",
      "Epoch 00464: val_loss did not improve from 49.47214\n",
      "Epoch 465/2000\n",
      "143/143 [==============================] - 91s 641ms/step - loss: 48.0718 - root_mean_squared_error: 6.9298 - mean_absolute_error: 5.5976 - val_loss: 49.5691 - val_root_mean_squared_error: 7.0405 - val_mean_absolute_error: 5.6579\n",
      "\n",
      "Epoch 00465: val_loss did not improve from 49.47214\n",
      "Epoch 466/2000\n",
      "143/143 [==============================] - 93s 647ms/step - loss: 47.6004 - root_mean_squared_error: 6.8968 - mean_absolute_error: 5.5575 - val_loss: 62.1651 - val_root_mean_squared_error: 7.8845 - val_mean_absolute_error: 6.1066\n",
      "\n",
      "Epoch 00466: val_loss did not improve from 49.47214\n",
      "Epoch 467/2000\n",
      "143/143 [==============================] - 89s 624ms/step - loss: 47.4709 - root_mean_squared_error: 6.8818 - mean_absolute_error: 5.4768 - val_loss: 66.2182 - val_root_mean_squared_error: 8.1375 - val_mean_absolute_error: 6.4549\n",
      "\n",
      "Epoch 00467: val_loss did not improve from 49.47214\n",
      "Epoch 468/2000\n",
      "143/143 [==============================] - 91s 638ms/step - loss: 43.9260 - root_mean_squared_error: 6.6217 - mean_absolute_error: 5.3298 - val_loss: 57.0207 - val_root_mean_squared_error: 7.5512 - val_mean_absolute_error: 6.0239\n",
      "\n",
      "Epoch 00468: val_loss did not improve from 49.47214\n",
      "Epoch 469/2000\n",
      "143/143 [==============================] - 91s 640ms/step - loss: 48.0766 - root_mean_squared_error: 6.9306 - mean_absolute_error: 5.6085 - val_loss: 67.5455 - val_root_mean_squared_error: 8.2186 - val_mean_absolute_error: 6.4195\n",
      "\n",
      "Epoch 00469: val_loss did not improve from 49.47214\n",
      "Epoch 470/2000\n",
      "143/143 [==============================] - 91s 633ms/step - loss: 50.4440 - root_mean_squared_error: 7.0999 - mean_absolute_error: 5.6634 - val_loss: 62.2710 - val_root_mean_squared_error: 7.8912 - val_mean_absolute_error: 6.1547\n",
      "\n",
      "Epoch 00470: val_loss did not improve from 49.47214\n",
      "Epoch 471/2000\n",
      "143/143 [==============================] - 92s 643ms/step - loss: 42.5830 - root_mean_squared_error: 6.5131 - mean_absolute_error: 5.2720 - val_loss: 59.8700 - val_root_mean_squared_error: 7.7376 - val_mean_absolute_error: 6.1834\n",
      "\n",
      "Epoch 00471: val_loss did not improve from 49.47214\n",
      "Epoch 472/2000\n",
      "143/143 [==============================] - 89s 622ms/step - loss: 46.3749 - root_mean_squared_error: 6.8053 - mean_absolute_error: 5.5478 - val_loss: 63.3880 - val_root_mean_squared_error: 7.9617 - val_mean_absolute_error: 6.3643\n",
      "\n",
      "Epoch 00472: val_loss did not improve from 49.47214\n",
      "Epoch 473/2000\n",
      "143/143 [==============================] - 90s 633ms/step - loss: 47.4172 - root_mean_squared_error: 6.8848 - mean_absolute_error: 5.6805 - val_loss: 73.8409 - val_root_mean_squared_error: 8.5931 - val_mean_absolute_error: 6.8200\n",
      "\n",
      "Epoch 00473: val_loss did not improve from 49.47214\n",
      "Epoch 474/2000\n",
      "143/143 [==============================] - 92s 641ms/step - loss: 52.2353 - root_mean_squared_error: 7.2193 - mean_absolute_error: 5.8292 - val_loss: 55.2309 - val_root_mean_squared_error: 7.4317 - val_mean_absolute_error: 6.0623\n",
      "\n",
      "Epoch 00474: val_loss did not improve from 49.47214\n",
      "Epoch 475/2000\n",
      "143/143 [==============================] - 91s 636ms/step - loss: 50.1897 - root_mean_squared_error: 7.0837 - mean_absolute_error: 5.6500 - val_loss: 57.4834 - val_root_mean_squared_error: 7.5818 - val_mean_absolute_error: 6.0704\n",
      "\n",
      "Epoch 00475: val_loss did not improve from 49.47214\n",
      "Epoch 476/2000\n",
      "143/143 [==============================] - 90s 633ms/step - loss: 48.5279 - root_mean_squared_error: 6.9633 - mean_absolute_error: 5.5811 - val_loss: 58.5826 - val_root_mean_squared_error: 7.6539 - val_mean_absolute_error: 6.1065\n",
      "\n",
      "Epoch 00476: val_loss did not improve from 49.47214\n",
      "Epoch 477/2000\n",
      "143/143 [==============================] - 93s 649ms/step - loss: 46.7306 - root_mean_squared_error: 6.8294 - mean_absolute_error: 5.5506 - val_loss: 67.1238 - val_root_mean_squared_error: 8.1929 - val_mean_absolute_error: 6.7537\n",
      "\n",
      "Epoch 00477: val_loss did not improve from 49.47214\n",
      "Epoch 478/2000\n",
      "143/143 [==============================] - 90s 629ms/step - loss: 48.9158 - root_mean_squared_error: 6.9933 - mean_absolute_error: 5.5412 - val_loss: 57.5332 - val_root_mean_squared_error: 7.5851 - val_mean_absolute_error: 6.1142\n",
      "\n",
      "Epoch 00478: val_loss did not improve from 49.47214\n",
      "Epoch 479/2000\n",
      "143/143 [==============================] - 92s 647ms/step - loss: 47.2620 - root_mean_squared_error: 6.8719 - mean_absolute_error: 5.4767 - val_loss: 60.4768 - val_root_mean_squared_error: 7.7767 - val_mean_absolute_error: 6.2988\n",
      "\n",
      "Epoch 00479: val_loss did not improve from 49.47214\n",
      "Epoch 480/2000\n",
      "143/143 [==============================] - 94s 660ms/step - loss: 45.3521 - root_mean_squared_error: 6.7248 - mean_absolute_error: 5.3848 - val_loss: 65.6343 - val_root_mean_squared_error: 8.1015 - val_mean_absolute_error: 6.4648\n",
      "\n",
      "Epoch 00480: val_loss did not improve from 49.47214\n",
      "Epoch 481/2000\n",
      "143/143 [==============================] - 93s 651ms/step - loss: 50.0691 - root_mean_squared_error: 7.0730 - mean_absolute_error: 5.6215 - val_loss: 57.2684 - val_root_mean_squared_error: 7.5676 - val_mean_absolute_error: 6.0440\n",
      "\n",
      "Epoch 00481: val_loss did not improve from 49.47214\n",
      "Epoch 482/2000\n",
      "143/143 [==============================] - 90s 631ms/step - loss: 48.5354 - root_mean_squared_error: 6.9637 - mean_absolute_error: 5.5178 - val_loss: 64.5808 - val_root_mean_squared_error: 8.0362 - val_mean_absolute_error: 6.3222\n",
      "\n",
      "Epoch 00482: val_loss did not improve from 49.47214\n",
      "Epoch 483/2000\n",
      "143/143 [==============================] - 92s 647ms/step - loss: 48.4125 - root_mean_squared_error: 6.9546 - mean_absolute_error: 5.5558 - val_loss: 64.9480 - val_root_mean_squared_error: 8.0590 - val_mean_absolute_error: 6.3687\n",
      "\n",
      "Epoch 00483: val_loss did not improve from 49.47214\n",
      "Epoch 484/2000\n",
      "143/143 [==============================] - 91s 638ms/step - loss: 48.3199 - root_mean_squared_error: 6.9496 - mean_absolute_error: 5.6246 - val_loss: 68.6691 - val_root_mean_squared_error: 8.2867 - val_mean_absolute_error: 6.5089\n",
      "\n",
      "Epoch 00484: val_loss did not improve from 49.47214\n",
      "Epoch 485/2000\n",
      "143/143 [==============================] - 93s 650ms/step - loss: 49.7098 - root_mean_squared_error: 7.0479 - mean_absolute_error: 5.6361 - val_loss: 59.3128 - val_root_mean_squared_error: 7.7015 - val_mean_absolute_error: 6.0552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00485: val_loss did not improve from 49.47214\n",
      "Epoch 486/2000\n",
      "143/143 [==============================] - 92s 645ms/step - loss: 47.3663 - root_mean_squared_error: 6.8802 - mean_absolute_error: 5.5974 - val_loss: 60.3234 - val_root_mean_squared_error: 7.7668 - val_mean_absolute_error: 6.1548\n",
      "\n",
      "Epoch 00486: val_loss did not improve from 49.47214\n",
      "Epoch 487/2000\n",
      "143/143 [==============================] - 93s 651ms/step - loss: 45.8321 - root_mean_squared_error: 6.7682 - mean_absolute_error: 5.5244 - val_loss: 65.9065 - val_root_mean_squared_error: 8.1183 - val_mean_absolute_error: 6.3592\n",
      "\n",
      "Epoch 00487: val_loss did not improve from 49.47214\n",
      "Epoch 488/2000\n",
      "143/143 [==============================] - 92s 641ms/step - loss: 47.7251 - root_mean_squared_error: 6.9071 - mean_absolute_error: 5.4640 - val_loss: 66.2656 - val_root_mean_squared_error: 8.1404 - val_mean_absolute_error: 6.4182\n",
      "\n",
      "Epoch 00488: val_loss did not improve from 49.47214\n",
      "Epoch 489/2000\n",
      "143/143 [==============================] - 92s 648ms/step - loss: 50.2591 - root_mean_squared_error: 7.0864 - mean_absolute_error: 5.7205 - val_loss: 61.2414 - val_root_mean_squared_error: 7.8257 - val_mean_absolute_error: 6.1858\n",
      "\n",
      "Epoch 00489: val_loss did not improve from 49.47214\n",
      "Epoch 490/2000\n",
      "143/143 [==============================] - 93s 651ms/step - loss: 43.7824 - root_mean_squared_error: 6.6116 - mean_absolute_error: 5.3023 - val_loss: 58.6445 - val_root_mean_squared_error: 7.6580 - val_mean_absolute_error: 6.0791\n",
      "\n",
      "Epoch 00490: val_loss did not improve from 49.47214\n",
      "Epoch 491/2000\n",
      "143/143 [==============================] - 92s 643ms/step - loss: 46.1807 - root_mean_squared_error: 6.7929 - mean_absolute_error: 5.4033 - val_loss: 59.7876 - val_root_mean_squared_error: 7.7322 - val_mean_absolute_error: 6.1938\n",
      "\n",
      "Epoch 00491: val_loss did not improve from 49.47214\n",
      "Epoch 492/2000\n",
      "143/143 [==============================] - 91s 637ms/step - loss: 45.9630 - root_mean_squared_error: 6.7744 - mean_absolute_error: 5.4193 - val_loss: 57.3279 - val_root_mean_squared_error: 7.5715 - val_mean_absolute_error: 5.8335\n",
      "\n",
      "Epoch 00492: val_loss did not improve from 49.47214\n",
      "Epoch 493/2000\n",
      "143/143 [==============================] - 93s 653ms/step - loss: 45.7841 - root_mean_squared_error: 6.7630 - mean_absolute_error: 5.4500 - val_loss: 61.0160 - val_root_mean_squared_error: 7.8113 - val_mean_absolute_error: 6.1755\n",
      "\n",
      "Epoch 00493: val_loss did not improve from 49.47214\n",
      "Epoch 494/2000\n",
      "143/143 [==============================] - 93s 649ms/step - loss: 48.7664 - root_mean_squared_error: 6.9798 - mean_absolute_error: 5.4855 - val_loss: 70.4395 - val_root_mean_squared_error: 8.3928 - val_mean_absolute_error: 6.8081\n",
      "\n",
      "Epoch 00494: val_loss did not improve from 49.47214\n",
      "Epoch 495/2000\n",
      "143/143 [==============================] - 92s 641ms/step - loss: 48.2372 - root_mean_squared_error: 6.9428 - mean_absolute_error: 5.6664 - val_loss: 65.4824 - val_root_mean_squared_error: 8.0921 - val_mean_absolute_error: 6.2955\n",
      "\n",
      "Epoch 00495: val_loss did not improve from 49.47214\n",
      "Epoch 496/2000\n",
      "143/143 [==============================] - 91s 639ms/step - loss: 46.9542 - root_mean_squared_error: 6.8479 - mean_absolute_error: 5.4788 - val_loss: 56.3713 - val_root_mean_squared_error: 7.5081 - val_mean_absolute_error: 6.0630\n",
      "\n",
      "Epoch 00496: val_loss did not improve from 49.47214\n",
      "Epoch 497/2000\n",
      "143/143 [==============================] - 93s 654ms/step - loss: 46.6499 - root_mean_squared_error: 6.8252 - mean_absolute_error: 5.5007 - val_loss: 68.5044 - val_root_mean_squared_error: 8.2767 - val_mean_absolute_error: 6.3615\n",
      "\n",
      "Epoch 00497: val_loss did not improve from 49.47214\n",
      "Epoch 498/2000\n",
      "143/143 [==============================] - 92s 641ms/step - loss: 50.6101 - root_mean_squared_error: 7.1090 - mean_absolute_error: 5.6899 - val_loss: 73.4071 - val_root_mean_squared_error: 8.5678 - val_mean_absolute_error: 6.7984\n",
      "\n",
      "Epoch 00498: val_loss did not improve from 49.47214\n",
      "Epoch 499/2000\n",
      "143/143 [==============================] - 92s 642ms/step - loss: 45.7176 - root_mean_squared_error: 6.7543 - mean_absolute_error: 5.4745 - val_loss: 58.8790 - val_root_mean_squared_error: 7.6733 - val_mean_absolute_error: 6.0285\n",
      "\n",
      "Epoch 00499: val_loss did not improve from 49.47214\n",
      "Epoch 500/2000\n",
      "143/143 [==============================] - 90s 630ms/step - loss: 44.6142 - root_mean_squared_error: 6.6774 - mean_absolute_error: 5.3723 - val_loss: 61.1196 - val_root_mean_squared_error: 7.8179 - val_mean_absolute_error: 6.1096\n",
      "\n",
      "Epoch 00500: val_loss did not improve from 49.47214\n",
      "Epoch 501/2000\n",
      "143/143 [==============================] - 91s 640ms/step - loss: 45.0702 - root_mean_squared_error: 6.7061 - mean_absolute_error: 5.3434 - val_loss: 61.0373 - val_root_mean_squared_error: 7.8126 - val_mean_absolute_error: 6.1705\n",
      "\n",
      "Epoch 00501: val_loss did not improve from 49.47214\n",
      "Epoch 502/2000\n",
      "143/143 [==============================] - 92s 648ms/step - loss: 46.5618 - root_mean_squared_error: 6.8232 - mean_absolute_error: 5.5330 - val_loss: 50.4243 - val_root_mean_squared_error: 7.1010 - val_mean_absolute_error: 5.5831\n",
      "\n",
      "Epoch 00502: val_loss did not improve from 49.47214\n",
      "\n",
      "Epoch 00502: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "Epoch 503/2000\n",
      "143/143 [==============================] - 90s 632ms/step - loss: 48.0062 - root_mean_squared_error: 6.9274 - mean_absolute_error: 5.5795 - val_loss: 67.5078 - val_root_mean_squared_error: 8.2163 - val_mean_absolute_error: 6.4676\n",
      "\n",
      "Epoch 00503: val_loss did not improve from 49.47214\n",
      "Epoch 504/2000\n",
      "143/143 [==============================] - 90s 630ms/step - loss: 46.6853 - root_mean_squared_error: 6.8272 - mean_absolute_error: 5.5126 - val_loss: 63.6156 - val_root_mean_squared_error: 7.9759 - val_mean_absolute_error: 6.3122\n",
      "\n",
      "Epoch 00504: val_loss did not improve from 49.47214\n",
      "Epoch 505/2000\n",
      "143/143 [==============================] - 91s 636ms/step - loss: 48.0661 - root_mean_squared_error: 6.9289 - mean_absolute_error: 5.4958 - val_loss: 62.4602 - val_root_mean_squared_error: 7.9032 - val_mean_absolute_error: 6.1377\n",
      "\n",
      "Epoch 00505: val_loss did not improve from 49.47214\n",
      "Epoch 506/2000\n",
      "143/143 [==============================] - 91s 634ms/step - loss: 49.3968 - root_mean_squared_error: 7.0260 - mean_absolute_error: 5.5127 - val_loss: 54.0896 - val_root_mean_squared_error: 7.3546 - val_mean_absolute_error: 5.9393\n",
      "\n",
      "Epoch 00506: val_loss did not improve from 49.47214\n",
      "Epoch 507/2000\n",
      "143/143 [==============================] - 91s 639ms/step - loss: 49.4683 - root_mean_squared_error: 7.0299 - mean_absolute_error: 5.7509 - val_loss: 59.1215 - val_root_mean_squared_error: 7.6891 - val_mean_absolute_error: 6.0435\n",
      "\n",
      "Epoch 00507: val_loss did not improve from 49.47214\n",
      "Epoch 508/2000\n",
      "143/143 [==============================] - 90s 630ms/step - loss: 48.1055 - root_mean_squared_error: 6.9336 - mean_absolute_error: 5.6518 - val_loss: 66.6042 - val_root_mean_squared_error: 8.1611 - val_mean_absolute_error: 6.4000\n",
      "\n",
      "Epoch 00508: val_loss did not improve from 49.47214\n",
      "Epoch 509/2000\n",
      "143/143 [==============================] - 91s 638ms/step - loss: 51.6601 - root_mean_squared_error: 7.1685 - mean_absolute_error: 5.7940 - val_loss: 66.8032 - val_root_mean_squared_error: 8.1733 - val_mean_absolute_error: 6.3847\n",
      "\n",
      "Epoch 00509: val_loss did not improve from 49.47214\n",
      "Epoch 510/2000\n",
      "143/143 [==============================] - 91s 636ms/step - loss: 49.3324 - root_mean_squared_error: 7.0158 - mean_absolute_error: 5.6601 - val_loss: 63.5108 - val_root_mean_squared_error: 7.9694 - val_mean_absolute_error: 6.3567\n",
      "\n",
      "Epoch 00510: val_loss did not improve from 49.47214\n",
      "Epoch 511/2000\n",
      "143/143 [==============================] - 91s 637ms/step - loss: 45.4961 - root_mean_squared_error: 6.7415 - mean_absolute_error: 5.4520 - val_loss: 66.0847 - val_root_mean_squared_error: 8.1292 - val_mean_absolute_error: 6.3499\n",
      "\n",
      "Epoch 00511: val_loss did not improve from 49.47214\n",
      "Epoch 512/2000\n",
      "143/143 [==============================] - 90s 632ms/step - loss: 47.8352 - root_mean_squared_error: 6.9059 - mean_absolute_error: 5.5006 - val_loss: 56.3468 - val_root_mean_squared_error: 7.5065 - val_mean_absolute_error: 5.9138\n",
      "\n",
      "Epoch 00512: val_loss did not improve from 49.47214\n",
      "Epoch 513/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 91s 635ms/step - loss: 42.2176 - root_mean_squared_error: 6.4937 - mean_absolute_error: 5.2039 - val_loss: 66.2640 - val_root_mean_squared_error: 8.1403 - val_mean_absolute_error: 6.4703\n",
      "\n",
      "Epoch 00513: val_loss did not improve from 49.47214\n",
      "Epoch 514/2000\n",
      "143/143 [==============================] - 91s 637ms/step - loss: 46.1012 - root_mean_squared_error: 6.7888 - mean_absolute_error: 5.4826 - val_loss: 64.6083 - val_root_mean_squared_error: 8.0379 - val_mean_absolute_error: 6.4880\n",
      "\n",
      "Epoch 00514: val_loss did not improve from 49.47214\n",
      "Epoch 515/2000\n",
      "143/143 [==============================] - 91s 638ms/step - loss: 42.5749 - root_mean_squared_error: 6.5228 - mean_absolute_error: 5.1973 - val_loss: 79.0146 - val_root_mean_squared_error: 8.8890 - val_mean_absolute_error: 7.0643\n",
      "\n",
      "Epoch 00515: val_loss did not improve from 49.47214\n",
      "Epoch 516/2000\n",
      "143/143 [==============================] - 92s 647ms/step - loss: 46.7439 - root_mean_squared_error: 6.8332 - mean_absolute_error: 5.4949 - val_loss: 67.7264 - val_root_mean_squared_error: 8.2296 - val_mean_absolute_error: 6.4345\n",
      "\n",
      "Epoch 00516: val_loss did not improve from 49.47214\n",
      "Epoch 517/2000\n",
      "143/143 [==============================] - 92s 645ms/step - loss: 47.7230 - root_mean_squared_error: 6.9031 - mean_absolute_error: 5.4772 - val_loss: 53.8306 - val_root_mean_squared_error: 7.3369 - val_mean_absolute_error: 5.8796\n",
      "\n",
      "Epoch 00517: val_loss did not improve from 49.47214\n",
      "Epoch 518/2000\n",
      "143/143 [==============================] - 93s 651ms/step - loss: 45.4722 - root_mean_squared_error: 6.7416 - mean_absolute_error: 5.3920 - val_loss: 58.4751 - val_root_mean_squared_error: 7.6469 - val_mean_absolute_error: 6.0863\n",
      "\n",
      "Epoch 00518: val_loss did not improve from 49.47214\n",
      "Epoch 519/2000\n",
      "143/143 [==============================] - 91s 638ms/step - loss: 46.6239 - root_mean_squared_error: 6.8207 - mean_absolute_error: 5.4209 - val_loss: 64.4574 - val_root_mean_squared_error: 8.0285 - val_mean_absolute_error: 6.1407\n",
      "\n",
      "Epoch 00519: val_loss did not improve from 49.47214\n",
      "Epoch 520/2000\n",
      "143/143 [==============================] - 90s 629ms/step - loss: 49.2278 - root_mean_squared_error: 7.0126 - mean_absolute_error: 5.5712 - val_loss: 61.7653 - val_root_mean_squared_error: 7.8591 - val_mean_absolute_error: 6.2845\n",
      "\n",
      "Epoch 00520: val_loss did not improve from 49.47214\n",
      "Epoch 521/2000\n",
      "143/143 [==============================] - 90s 631ms/step - loss: 49.0057 - root_mean_squared_error: 6.9982 - mean_absolute_error: 5.6095 - val_loss: 64.1668 - val_root_mean_squared_error: 8.0104 - val_mean_absolute_error: 6.2940\n",
      "\n",
      "Epoch 00521: val_loss did not improve from 49.47214\n",
      "Epoch 522/2000\n",
      "143/143 [==============================] - 92s 646ms/step - loss: 44.9199 - root_mean_squared_error: 6.7010 - mean_absolute_error: 5.3671 - val_loss: 74.5681 - val_root_mean_squared_error: 8.6353 - val_mean_absolute_error: 6.6907\n",
      "\n",
      "Epoch 00522: val_loss did not improve from 49.47214\n",
      "Epoch 523/2000\n",
      "143/143 [==============================] - 93s 652ms/step - loss: 47.9421 - root_mean_squared_error: 6.9187 - mean_absolute_error: 5.4542 - val_loss: 53.9127 - val_root_mean_squared_error: 7.3425 - val_mean_absolute_error: 5.9680\n",
      "\n",
      "Epoch 00523: val_loss did not improve from 49.47214\n",
      "Epoch 524/2000\n",
      "143/143 [==============================] - 91s 636ms/step - loss: 43.0588 - root_mean_squared_error: 6.5584 - mean_absolute_error: 5.2749 - val_loss: 57.6788 - val_root_mean_squared_error: 7.5947 - val_mean_absolute_error: 6.0606\n",
      "\n",
      "Epoch 00524: val_loss did not improve from 49.47214\n",
      "Epoch 525/2000\n",
      "143/143 [==============================] - 90s 631ms/step - loss: 51.1197 - root_mean_squared_error: 7.1451 - mean_absolute_error: 5.6242 - val_loss: 57.7634 - val_root_mean_squared_error: 7.6002 - val_mean_absolute_error: 6.0265\n",
      "\n",
      "Epoch 00525: val_loss did not improve from 49.47214\n",
      "Epoch 526/2000\n",
      "143/143 [==============================] - 91s 637ms/step - loss: 47.1067 - root_mean_squared_error: 6.8609 - mean_absolute_error: 5.5514 - val_loss: 60.9498 - val_root_mean_squared_error: 7.8070 - val_mean_absolute_error: 6.2004\n",
      "\n",
      "Epoch 00526: val_loss did not improve from 49.47214\n",
      "Epoch 527/2000\n",
      "143/143 [==============================] - 90s 629ms/step - loss: 46.0519 - root_mean_squared_error: 6.7852 - mean_absolute_error: 5.3673 - val_loss: 64.9374 - val_root_mean_squared_error: 8.0584 - val_mean_absolute_error: 6.4379\n",
      "\n",
      "Epoch 00527: val_loss did not improve from 49.47214\n",
      "Epoch 528/2000\n",
      "143/143 [==============================] - 92s 641ms/step - loss: 45.1777 - root_mean_squared_error: 6.7180 - mean_absolute_error: 5.4254 - val_loss: 54.2395 - val_root_mean_squared_error: 7.3647 - val_mean_absolute_error: 5.7865\n",
      "\n",
      "Epoch 00528: val_loss did not improve from 49.47214\n",
      "Epoch 529/2000\n",
      "143/143 [==============================] - 92s 646ms/step - loss: 45.3003 - root_mean_squared_error: 6.7264 - mean_absolute_error: 5.3627 - val_loss: 61.1722 - val_root_mean_squared_error: 7.8213 - val_mean_absolute_error: 6.2803\n",
      "\n",
      "Epoch 00529: val_loss did not improve from 49.47214\n",
      "Epoch 530/2000\n",
      "143/143 [==============================] - 91s 634ms/step - loss: 42.5247 - root_mean_squared_error: 6.5159 - mean_absolute_error: 5.2499 - val_loss: 57.0356 - val_root_mean_squared_error: 7.5522 - val_mean_absolute_error: 5.9823\n",
      "\n",
      "Epoch 00530: val_loss did not improve from 49.47214\n",
      "Epoch 531/2000\n",
      "143/143 [==============================] - 91s 641ms/step - loss: 43.8178 - root_mean_squared_error: 6.6184 - mean_absolute_error: 5.3630 - val_loss: 63.9434 - val_root_mean_squared_error: 7.9965 - val_mean_absolute_error: 6.4163\n",
      "\n",
      "Epoch 00531: val_loss did not improve from 49.47214\n",
      "Epoch 532/2000\n",
      "143/143 [==============================] - 91s 636ms/step - loss: 47.4569 - root_mean_squared_error: 6.8855 - mean_absolute_error: 5.4609 - val_loss: 58.7902 - val_root_mean_squared_error: 7.6675 - val_mean_absolute_error: 5.8207\n",
      "\n",
      "Epoch 00532: val_loss did not improve from 49.47214\n",
      "Epoch 533/2000\n",
      "143/143 [==============================] - 93s 648ms/step - loss: 47.8450 - root_mean_squared_error: 6.9158 - mean_absolute_error: 5.5510 - val_loss: 64.6006 - val_root_mean_squared_error: 8.0374 - val_mean_absolute_error: 6.3958\n",
      "\n",
      "Epoch 00533: val_loss did not improve from 49.47214\n",
      "Epoch 534/2000\n",
      "143/143 [==============================] - 90s 632ms/step - loss: 44.8430 - root_mean_squared_error: 6.6935 - mean_absolute_error: 5.3156 - val_loss: 63.1008 - val_root_mean_squared_error: 7.9436 - val_mean_absolute_error: 6.3697\n",
      "\n",
      "Epoch 00534: val_loss did not improve from 49.47214\n",
      "Epoch 535/2000\n",
      "143/143 [==============================] - 93s 653ms/step - loss: 49.2996 - root_mean_squared_error: 7.0190 - mean_absolute_error: 5.6796 - val_loss: 68.8626 - val_root_mean_squared_error: 8.2984 - val_mean_absolute_error: 6.6494\n",
      "\n",
      "Epoch 00535: val_loss did not improve from 49.47214\n",
      "Epoch 536/2000\n",
      "143/143 [==============================] - 92s 644ms/step - loss: 49.2262 - root_mean_squared_error: 7.0143 - mean_absolute_error: 5.6611 - val_loss: 60.1701 - val_root_mean_squared_error: 7.7569 - val_mean_absolute_error: 6.1236\n",
      "\n",
      "Epoch 00536: val_loss did not improve from 49.47214\n",
      "Epoch 537/2000\n",
      "143/143 [==============================] - 91s 639ms/step - loss: 49.4139 - root_mean_squared_error: 7.0175 - mean_absolute_error: 5.5439 - val_loss: 66.5985 - val_root_mean_squared_error: 8.1608 - val_mean_absolute_error: 6.5432\n",
      "\n",
      "Epoch 00537: val_loss did not improve from 49.47214\n",
      "Epoch 538/2000\n",
      "143/143 [==============================] - 92s 645ms/step - loss: 48.1016 - root_mean_squared_error: 6.9327 - mean_absolute_error: 5.5861 - val_loss: 68.6332 - val_root_mean_squared_error: 8.2845 - val_mean_absolute_error: 6.6755\n",
      "\n",
      "Epoch 00538: val_loss did not improve from 49.47214\n",
      "Epoch 539/2000\n",
      "143/143 [==============================] - 94s 655ms/step - loss: 44.0546 - root_mean_squared_error: 6.6346 - mean_absolute_error: 5.3636 - val_loss: 54.8468 - val_root_mean_squared_error: 7.4059 - val_mean_absolute_error: 5.9336\n",
      "\n",
      "Epoch 00539: val_loss did not improve from 49.47214\n",
      "Epoch 540/2000\n",
      "143/143 [==============================] - 92s 642ms/step - loss: 46.0240 - root_mean_squared_error: 6.7815 - mean_absolute_error: 5.4443 - val_loss: 64.8320 - val_root_mean_squared_error: 8.0518 - val_mean_absolute_error: 6.3641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00540: val_loss did not improve from 49.47214\n",
      "Epoch 541/2000\n",
      "143/143 [==============================] - 91s 638ms/step - loss: 47.7776 - root_mean_squared_error: 6.9091 - mean_absolute_error: 5.6233 - val_loss: 53.2104 - val_root_mean_squared_error: 7.2945 - val_mean_absolute_error: 5.8540\n",
      "\n",
      "Epoch 00541: val_loss did not improve from 49.47214\n",
      "Epoch 542/2000\n",
      "143/143 [==============================] - 94s 656ms/step - loss: 46.6056 - root_mean_squared_error: 6.8227 - mean_absolute_error: 5.4853 - val_loss: 61.7233 - val_root_mean_squared_error: 7.8564 - val_mean_absolute_error: 6.1182\n",
      "\n",
      "Epoch 00542: val_loss did not improve from 49.47214\n",
      "Epoch 543/2000\n",
      "143/143 [==============================] - 92s 644ms/step - loss: 46.0241 - root_mean_squared_error: 6.7807 - mean_absolute_error: 5.4944 - val_loss: 49.4565 - val_root_mean_squared_error: 7.0325 - val_mean_absolute_error: 5.6044\n",
      "\n",
      "Epoch 00543: val_loss improved from 49.47214 to 49.45648, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/TimeCNN_regressor_01.hdf5\n",
      "Epoch 544/2000\n",
      "143/143 [==============================] - 87s 609ms/step - loss: 48.3150 - root_mean_squared_error: 6.9471 - mean_absolute_error: 5.5231 - val_loss: 70.1831 - val_root_mean_squared_error: 8.3775 - val_mean_absolute_error: 6.4144\n",
      "\n",
      "Epoch 00544: val_loss did not improve from 49.45648\n",
      "Epoch 545/2000\n",
      "143/143 [==============================] - 85s 594ms/step - loss: 49.5777 - root_mean_squared_error: 7.0393 - mean_absolute_error: 5.6072 - val_loss: 62.2102 - val_root_mean_squared_error: 7.8873 - val_mean_absolute_error: 6.3370\n",
      "\n",
      "Epoch 00545: val_loss did not improve from 49.45648\n",
      "Epoch 546/2000\n",
      "143/143 [==============================] - 90s 629ms/step - loss: 48.6438 - root_mean_squared_error: 6.9741 - mean_absolute_error: 5.6619 - val_loss: 59.2997 - val_root_mean_squared_error: 7.7006 - val_mean_absolute_error: 6.0698\n",
      "\n",
      "Epoch 00546: val_loss did not improve from 49.45648\n",
      "Epoch 547/2000\n",
      "143/143 [==============================] - 88s 617ms/step - loss: 49.4535 - root_mean_squared_error: 7.0275 - mean_absolute_error: 5.6852 - val_loss: 55.5508 - val_root_mean_squared_error: 7.4532 - val_mean_absolute_error: 5.8981\n",
      "\n",
      "Epoch 00547: val_loss did not improve from 49.45648\n",
      "Epoch 548/2000\n",
      "143/143 [==============================] - 90s 631ms/step - loss: 49.8325 - root_mean_squared_error: 7.0556 - mean_absolute_error: 5.6854 - val_loss: 56.9725 - val_root_mean_squared_error: 7.5480 - val_mean_absolute_error: 6.0344\n",
      "\n",
      "Epoch 00548: val_loss did not improve from 49.45648\n",
      "Epoch 549/2000\n",
      "143/143 [==============================] - 88s 617ms/step - loss: 43.1774 - root_mean_squared_error: 6.5695 - mean_absolute_error: 5.2720 - val_loss: 55.3233 - val_root_mean_squared_error: 7.4380 - val_mean_absolute_error: 5.8366\n",
      "\n",
      "Epoch 00549: val_loss did not improve from 49.45648\n",
      "Epoch 550/2000\n",
      "143/143 [==============================] - 89s 621ms/step - loss: 48.7320 - root_mean_squared_error: 6.9775 - mean_absolute_error: 5.6303 - val_loss: 73.9705 - val_root_mean_squared_error: 8.6006 - val_mean_absolute_error: 6.7751\n",
      "\n",
      "Epoch 00550: val_loss did not improve from 49.45648\n",
      "Epoch 551/2000\n",
      "143/143 [==============================] - 89s 620ms/step - loss: 51.9901 - root_mean_squared_error: 7.2065 - mean_absolute_error: 5.7878 - val_loss: 65.1341 - val_root_mean_squared_error: 8.0706 - val_mean_absolute_error: 6.1972\n",
      "\n",
      "Epoch 00551: val_loss did not improve from 49.45648\n",
      "Epoch 552/2000\n",
      "143/143 [==============================] - 90s 626ms/step - loss: 47.8256 - root_mean_squared_error: 6.9031 - mean_absolute_error: 5.4335 - val_loss: 61.5304 - val_root_mean_squared_error: 7.8441 - val_mean_absolute_error: 6.1324\n",
      "\n",
      "Epoch 00552: val_loss did not improve from 49.45648\n",
      "Epoch 553/2000\n",
      "143/143 [==============================] - 90s 632ms/step - loss: 45.1254 - root_mean_squared_error: 6.7147 - mean_absolute_error: 5.4787 - val_loss: 59.8066 - val_root_mean_squared_error: 7.7335 - val_mean_absolute_error: 6.2242\n",
      "\n",
      "Epoch 00553: val_loss did not improve from 49.45648\n",
      "Epoch 554/2000\n",
      "143/143 [==============================] - 90s 631ms/step - loss: 42.7002 - root_mean_squared_error: 6.5329 - mean_absolute_error: 5.2672 - val_loss: 61.5491 - val_root_mean_squared_error: 7.8453 - val_mean_absolute_error: 6.3618\n",
      "\n",
      "Epoch 00554: val_loss did not improve from 49.45648\n",
      "Epoch 555/2000\n",
      "143/143 [==============================] - 92s 647ms/step - loss: 49.0109 - root_mean_squared_error: 6.9982 - mean_absolute_error: 5.5488 - val_loss: 57.6340 - val_root_mean_squared_error: 7.5917 - val_mean_absolute_error: 6.0582\n",
      "\n",
      "Epoch 00555: val_loss did not improve from 49.45648\n",
      "Epoch 556/2000\n",
      "143/143 [==============================] - 93s 648ms/step - loss: 43.4259 - root_mean_squared_error: 6.5856 - mean_absolute_error: 5.2623 - val_loss: 63.2002 - val_root_mean_squared_error: 7.9499 - val_mean_absolute_error: 6.3535\n",
      "\n",
      "Epoch 00556: val_loss did not improve from 49.45648\n",
      "Epoch 557/2000\n",
      "143/143 [==============================] - 91s 635ms/step - loss: 42.9138 - root_mean_squared_error: 6.5408 - mean_absolute_error: 5.3053 - val_loss: 60.3332 - val_root_mean_squared_error: 7.7674 - val_mean_absolute_error: 6.5153\n",
      "\n",
      "Epoch 00557: val_loss did not improve from 49.45648\n",
      "Epoch 558/2000\n",
      "143/143 [==============================] - 91s 636ms/step - loss: 48.9604 - root_mean_squared_error: 6.9938 - mean_absolute_error: 5.6423 - val_loss: 57.3443 - val_root_mean_squared_error: 7.5726 - val_mean_absolute_error: 5.9496\n",
      "\n",
      "Epoch 00558: val_loss did not improve from 49.45648\n",
      "Epoch 559/2000\n",
      "143/143 [==============================] - 92s 643ms/step - loss: 55.5137 - root_mean_squared_error: 7.4289 - mean_absolute_error: 5.8190 - val_loss: 68.7309 - val_root_mean_squared_error: 8.2904 - val_mean_absolute_error: 6.4994\n",
      "\n",
      "Epoch 00559: val_loss did not improve from 49.45648\n",
      "Epoch 560/2000\n",
      "143/143 [==============================] - 92s 642ms/step - loss: 50.0947 - root_mean_squared_error: 7.0757 - mean_absolute_error: 5.6638 - val_loss: 56.4763 - val_root_mean_squared_error: 7.5151 - val_mean_absolute_error: 6.1045\n",
      "\n",
      "Epoch 00560: val_loss did not improve from 49.45648\n",
      "Epoch 561/2000\n",
      "143/143 [==============================] - 92s 641ms/step - loss: 48.8501 - root_mean_squared_error: 6.9792 - mean_absolute_error: 5.5882 - val_loss: 61.9252 - val_root_mean_squared_error: 7.8693 - val_mean_absolute_error: 6.1919\n",
      "\n",
      "Epoch 00561: val_loss did not improve from 49.45648\n",
      "Epoch 562/2000\n",
      "143/143 [==============================] - 90s 632ms/step - loss: 49.0282 - root_mean_squared_error: 6.9988 - mean_absolute_error: 5.5442 - val_loss: 52.8195 - val_root_mean_squared_error: 7.2677 - val_mean_absolute_error: 5.8387\n",
      "\n",
      "Epoch 00562: val_loss did not improve from 49.45648\n",
      "Epoch 563/2000\n",
      "143/143 [==============================] - 92s 641ms/step - loss: 45.0452 - root_mean_squared_error: 6.7101 - mean_absolute_error: 5.3737 - val_loss: 63.5696 - val_root_mean_squared_error: 7.9731 - val_mean_absolute_error: 6.3179\n",
      "\n",
      "Epoch 00563: val_loss did not improve from 49.45648\n",
      "Epoch 564/2000\n",
      "143/143 [==============================] - 92s 647ms/step - loss: 46.0186 - root_mean_squared_error: 6.7801 - mean_absolute_error: 5.2940 - val_loss: 54.1103 - val_root_mean_squared_error: 7.3560 - val_mean_absolute_error: 5.9090\n",
      "\n",
      "Epoch 00564: val_loss did not improve from 49.45648\n",
      "Epoch 565/2000\n",
      "143/143 [==============================] - 91s 639ms/step - loss: 44.2892 - root_mean_squared_error: 6.6533 - mean_absolute_error: 5.4911 - val_loss: 65.5644 - val_root_mean_squared_error: 8.0972 - val_mean_absolute_error: 6.4186\n",
      "\n",
      "Epoch 00565: val_loss did not improve from 49.45648\n",
      "Epoch 566/2000\n",
      "143/143 [==============================] - 92s 642ms/step - loss: 50.8088 - root_mean_squared_error: 7.1217 - mean_absolute_error: 5.6972 - val_loss: 65.8502 - val_root_mean_squared_error: 8.1148 - val_mean_absolute_error: 6.4969\n",
      "\n",
      "Epoch 00566: val_loss did not improve from 49.45648\n",
      "Epoch 567/2000\n",
      "143/143 [==============================] - 92s 642ms/step - loss: 45.2077 - root_mean_squared_error: 6.7218 - mean_absolute_error: 5.4421 - val_loss: 52.0298 - val_root_mean_squared_error: 7.2132 - val_mean_absolute_error: 5.6917\n",
      "\n",
      "Epoch 00567: val_loss did not improve from 49.45648\n",
      "Epoch 568/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 95s 665ms/step - loss: 44.1353 - root_mean_squared_error: 6.6382 - mean_absolute_error: 5.2677 - val_loss: 64.8481 - val_root_mean_squared_error: 8.0528 - val_mean_absolute_error: 6.3770\n",
      "\n",
      "Epoch 00568: val_loss did not improve from 49.45648\n",
      "Epoch 569/2000\n",
      "143/143 [==============================] - 94s 659ms/step - loss: 44.7764 - root_mean_squared_error: 6.6905 - mean_absolute_error: 5.4051 - val_loss: 58.4900 - val_root_mean_squared_error: 7.6479 - val_mean_absolute_error: 6.0380\n",
      "\n",
      "Epoch 00569: val_loss did not improve from 49.45648\n",
      "Epoch 570/2000\n",
      "143/143 [==============================] - 90s 633ms/step - loss: 50.0666 - root_mean_squared_error: 7.0698 - mean_absolute_error: 5.7286 - val_loss: 58.9997 - val_root_mean_squared_error: 7.6811 - val_mean_absolute_error: 6.3031\n",
      "\n",
      "Epoch 00570: val_loss did not improve from 49.45648\n",
      "Epoch 571/2000\n",
      "143/143 [==============================] - 91s 634ms/step - loss: 47.8390 - root_mean_squared_error: 6.9132 - mean_absolute_error: 5.5860 - val_loss: 56.8889 - val_root_mean_squared_error: 7.5425 - val_mean_absolute_error: 5.9735\n",
      "\n",
      "Epoch 00571: val_loss did not improve from 49.45648\n",
      "Epoch 572/2000\n",
      "143/143 [==============================] - 92s 643ms/step - loss: 47.5024 - root_mean_squared_error: 6.8878 - mean_absolute_error: 5.4020 - val_loss: 63.7269 - val_root_mean_squared_error: 7.9829 - val_mean_absolute_error: 6.3687\n",
      "\n",
      "Epoch 00572: val_loss did not improve from 49.45648\n",
      "Epoch 573/2000\n",
      "143/143 [==============================] - 92s 645ms/step - loss: 45.2219 - root_mean_squared_error: 6.7232 - mean_absolute_error: 5.3540 - val_loss: 65.4219 - val_root_mean_squared_error: 8.0884 - val_mean_absolute_error: 6.4362\n",
      "\n",
      "Epoch 00573: val_loss did not improve from 49.45648\n",
      "Epoch 574/2000\n",
      "143/143 [==============================] - 92s 642ms/step - loss: 43.5089 - root_mean_squared_error: 6.5896 - mean_absolute_error: 5.2396 - val_loss: 65.0921 - val_root_mean_squared_error: 8.0680 - val_mean_absolute_error: 6.5088\n",
      "\n",
      "Epoch 00574: val_loss did not improve from 49.45648\n",
      "Epoch 575/2000\n",
      "143/143 [==============================] - 92s 645ms/step - loss: 50.4447 - root_mean_squared_error: 7.1003 - mean_absolute_error: 5.6731 - val_loss: 56.8971 - val_root_mean_squared_error: 7.5430 - val_mean_absolute_error: 6.0842\n",
      "\n",
      "Epoch 00575: val_loss did not improve from 49.45648\n",
      "Epoch 576/2000\n",
      "143/143 [==============================] - 93s 651ms/step - loss: 45.7933 - root_mean_squared_error: 6.7663 - mean_absolute_error: 5.4450 - val_loss: 63.0763 - val_root_mean_squared_error: 7.9421 - val_mean_absolute_error: 6.4106\n",
      "\n",
      "Epoch 00576: val_loss did not improve from 49.45648\n",
      "Epoch 577/2000\n",
      "143/143 [==============================] - 91s 638ms/step - loss: 45.5014 - root_mean_squared_error: 6.7417 - mean_absolute_error: 5.3553 - val_loss: 64.8950 - val_root_mean_squared_error: 8.0557 - val_mean_absolute_error: 6.3128\n",
      "\n",
      "Epoch 00577: val_loss did not improve from 49.45648\n",
      "Epoch 578/2000\n",
      "143/143 [==============================] - 92s 645ms/step - loss: 50.5926 - root_mean_squared_error: 7.1052 - mean_absolute_error: 5.7279 - val_loss: 54.0802 - val_root_mean_squared_error: 7.3539 - val_mean_absolute_error: 5.7898\n",
      "\n",
      "Epoch 00578: val_loss did not improve from 49.45648\n",
      "Epoch 579/2000\n",
      "143/143 [==============================] - 92s 644ms/step - loss: 46.0657 - root_mean_squared_error: 6.7842 - mean_absolute_error: 5.4793 - val_loss: 67.8167 - val_root_mean_squared_error: 8.2351 - val_mean_absolute_error: 6.5900\n",
      "\n",
      "Epoch 00579: val_loss did not improve from 49.45648\n",
      "Epoch 580/2000\n",
      "143/143 [==============================] - 93s 653ms/step - loss: 47.7473 - root_mean_squared_error: 6.9088 - mean_absolute_error: 5.5141 - val_loss: 55.7511 - val_root_mean_squared_error: 7.4667 - val_mean_absolute_error: 5.9777\n",
      "\n",
      "Epoch 00580: val_loss did not improve from 49.45648\n",
      "Epoch 581/2000\n",
      "143/143 [==============================] - 93s 649ms/step - loss: 47.4700 - root_mean_squared_error: 6.8819 - mean_absolute_error: 5.4704 - val_loss: 64.3265 - val_root_mean_squared_error: 8.0204 - val_mean_absolute_error: 6.1759\n",
      "\n",
      "Epoch 00581: val_loss did not improve from 49.45648\n",
      "Epoch 582/2000\n",
      "143/143 [==============================] - 92s 645ms/step - loss: 46.7372 - root_mean_squared_error: 6.8333 - mean_absolute_error: 5.5766 - val_loss: 62.7174 - val_root_mean_squared_error: 7.9194 - val_mean_absolute_error: 6.3071\n",
      "\n",
      "Epoch 00582: val_loss did not improve from 49.45648\n",
      "Epoch 583/2000\n",
      "143/143 [==============================] - 91s 635ms/step - loss: 47.4126 - root_mean_squared_error: 6.8835 - mean_absolute_error: 5.5491 - val_loss: 68.9819 - val_root_mean_squared_error: 8.3055 - val_mean_absolute_error: 6.4311\n",
      "\n",
      "Epoch 00583: val_loss did not improve from 49.45648\n",
      "Epoch 584/2000\n",
      "143/143 [==============================] - 93s 651ms/step - loss: 44.8828 - root_mean_squared_error: 6.6982 - mean_absolute_error: 5.4194 - val_loss: 59.4743 - val_root_mean_squared_error: 7.7120 - val_mean_absolute_error: 6.1497\n",
      "\n",
      "Epoch 00584: val_loss did not improve from 49.45648\n",
      "Epoch 585/2000\n",
      "143/143 [==============================] - 89s 622ms/step - loss: 42.7967 - root_mean_squared_error: 6.5392 - mean_absolute_error: 5.2128 - val_loss: 69.0127 - val_root_mean_squared_error: 8.3074 - val_mean_absolute_error: 6.5450\n",
      "\n",
      "Epoch 00585: val_loss did not improve from 49.45648\n",
      "Epoch 586/2000\n",
      "143/143 [==============================] - 94s 657ms/step - loss: 45.4482 - root_mean_squared_error: 6.7387 - mean_absolute_error: 5.4774 - val_loss: 64.1068 - val_root_mean_squared_error: 8.0067 - val_mean_absolute_error: 6.3120\n",
      "\n",
      "Epoch 00586: val_loss did not improve from 49.45648\n",
      "Epoch 587/2000\n",
      "143/143 [==============================] - 92s 640ms/step - loss: 45.8265 - root_mean_squared_error: 6.7684 - mean_absolute_error: 5.3898 - val_loss: 57.3863 - val_root_mean_squared_error: 7.5754 - val_mean_absolute_error: 6.2098\n",
      "\n",
      "Epoch 00587: val_loss did not improve from 49.45648\n",
      "Epoch 588/2000\n",
      "143/143 [==============================] - 92s 645ms/step - loss: 46.7044 - root_mean_squared_error: 6.8319 - mean_absolute_error: 5.4889 - val_loss: 59.0528 - val_root_mean_squared_error: 7.6846 - val_mean_absolute_error: 6.0578\n",
      "\n",
      "Epoch 00588: val_loss did not improve from 49.45648\n",
      "Epoch 589/2000\n",
      "143/143 [==============================] - 91s 638ms/step - loss: 45.1211 - root_mean_squared_error: 6.7162 - mean_absolute_error: 5.3715 - val_loss: 65.1167 - val_root_mean_squared_error: 8.0695 - val_mean_absolute_error: 6.3673\n",
      "\n",
      "Epoch 00589: val_loss did not improve from 49.45648\n",
      "Epoch 590/2000\n",
      "143/143 [==============================] - 91s 639ms/step - loss: 45.8332 - root_mean_squared_error: 6.7680 - mean_absolute_error: 5.3096 - val_loss: 57.3480 - val_root_mean_squared_error: 7.5728 - val_mean_absolute_error: 6.1285\n",
      "\n",
      "Epoch 00590: val_loss did not improve from 49.45648\n",
      "Epoch 591/2000\n",
      "143/143 [==============================] - 89s 625ms/step - loss: 48.3110 - root_mean_squared_error: 6.9366 - mean_absolute_error: 5.5524 - val_loss: 55.1513 - val_root_mean_squared_error: 7.4264 - val_mean_absolute_error: 6.0421\n",
      "\n",
      "Epoch 00591: val_loss did not improve from 49.45648\n",
      "Epoch 592/2000\n",
      "143/143 [==============================] - 90s 628ms/step - loss: 50.0942 - root_mean_squared_error: 7.0745 - mean_absolute_error: 5.6942 - val_loss: 71.8425 - val_root_mean_squared_error: 8.4760 - val_mean_absolute_error: 6.6269\n",
      "\n",
      "Epoch 00592: val_loss did not improve from 49.45648\n",
      "Epoch 593/2000\n",
      "143/143 [==============================] - 92s 647ms/step - loss: 48.1041 - root_mean_squared_error: 6.9290 - mean_absolute_error: 5.3992 - val_loss: 60.7699 - val_root_mean_squared_error: 7.7955 - val_mean_absolute_error: 6.2370\n",
      "\n",
      "Epoch 00593: val_loss did not improve from 49.45648\n",
      "\n",
      "Epoch 00593: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "Epoch 594/2000\n",
      "143/143 [==============================] - 91s 637ms/step - loss: 44.4121 - root_mean_squared_error: 6.6604 - mean_absolute_error: 5.2132 - val_loss: 59.7820 - val_root_mean_squared_error: 7.7319 - val_mean_absolute_error: 6.0763\n",
      "\n",
      "Epoch 00594: val_loss did not improve from 49.45648\n",
      "Epoch 595/2000\n",
      "143/143 [==============================] - 91s 638ms/step - loss: 47.6785 - root_mean_squared_error: 6.9017 - mean_absolute_error: 5.4886 - val_loss: 54.1146 - val_root_mean_squared_error: 7.3563 - val_mean_absolute_error: 5.8649\n",
      "\n",
      "Epoch 00595: val_loss did not improve from 49.45648\n",
      "Epoch 596/2000\n",
      "143/143 [==============================] - 91s 633ms/step - loss: 42.4894 - root_mean_squared_error: 6.5142 - mean_absolute_error: 5.1875 - val_loss: 57.4760 - val_root_mean_squared_error: 7.5813 - val_mean_absolute_error: 6.0780\n",
      "\n",
      "Epoch 00596: val_loss did not improve from 49.45648\n",
      "Epoch 597/2000\n",
      "143/143 [==============================] - 93s 650ms/step - loss: 45.5370 - root_mean_squared_error: 6.7355 - mean_absolute_error: 5.3248 - val_loss: 57.2103 - val_root_mean_squared_error: 7.5637 - val_mean_absolute_error: 6.2377\n",
      "\n",
      "Epoch 00597: val_loss did not improve from 49.45648\n",
      "Epoch 598/2000\n",
      "143/143 [==============================] - 91s 640ms/step - loss: 47.2560 - root_mean_squared_error: 6.8700 - mean_absolute_error: 5.5364 - val_loss: 66.2530 - val_root_mean_squared_error: 8.1396 - val_mean_absolute_error: 6.4676\n",
      "\n",
      "Epoch 00598: val_loss did not improve from 49.45648\n",
      "Epoch 599/2000\n",
      "143/143 [==============================] - 90s 628ms/step - loss: 48.6980 - root_mean_squared_error: 6.9714 - mean_absolute_error: 5.6409 - val_loss: 56.9201 - val_root_mean_squared_error: 7.5445 - val_mean_absolute_error: 5.8997\n",
      "\n",
      "Epoch 00599: val_loss did not improve from 49.45648\n",
      "Epoch 600/2000\n",
      "143/143 [==============================] - 89s 626ms/step - loss: 46.4250 - root_mean_squared_error: 6.8114 - mean_absolute_error: 5.5263 - val_loss: 56.3055 - val_root_mean_squared_error: 7.5037 - val_mean_absolute_error: 5.9943\n",
      "\n",
      "Epoch 00600: val_loss did not improve from 49.45648\n",
      "Epoch 601/2000\n",
      "143/143 [==============================] - 89s 625ms/step - loss: 45.5267 - root_mean_squared_error: 6.7465 - mean_absolute_error: 5.3991 - val_loss: 58.4373 - val_root_mean_squared_error: 7.6444 - val_mean_absolute_error: 6.1809\n",
      "\n",
      "Epoch 00601: val_loss did not improve from 49.45648\n",
      "Epoch 602/2000\n",
      "143/143 [==============================] - 88s 617ms/step - loss: 43.5785 - root_mean_squared_error: 6.5970 - mean_absolute_error: 5.2168 - val_loss: 64.5949 - val_root_mean_squared_error: 8.0371 - val_mean_absolute_error: 6.4431\n",
      "\n",
      "Epoch 00602: val_loss did not improve from 49.45648\n",
      "Epoch 603/2000\n",
      "143/143 [==============================] - 86s 602ms/step - loss: 47.0769 - root_mean_squared_error: 6.8599 - mean_absolute_error: 5.5481 - val_loss: 63.1586 - val_root_mean_squared_error: 7.9472 - val_mean_absolute_error: 6.3001\n",
      "\n",
      "Epoch 00603: val_loss did not improve from 49.45648\n",
      "Epoch 604/2000\n",
      "143/143 [==============================] - 85s 592ms/step - loss: 46.3554 - root_mean_squared_error: 6.8054 - mean_absolute_error: 5.4077 - val_loss: 66.2970 - val_root_mean_squared_error: 8.1423 - val_mean_absolute_error: 6.2453\n",
      "\n",
      "Epoch 00604: val_loss did not improve from 49.45648\n",
      "Epoch 605/2000\n",
      "143/143 [==============================] - 89s 619ms/step - loss: 45.3023 - root_mean_squared_error: 6.7286 - mean_absolute_error: 5.3780 - val_loss: 59.3333 - val_root_mean_squared_error: 7.7028 - val_mean_absolute_error: 6.2560\n",
      "\n",
      "Epoch 00605: val_loss did not improve from 49.45648\n",
      "Epoch 606/2000\n",
      "143/143 [==============================] - 86s 602ms/step - loss: 44.0153 - root_mean_squared_error: 6.6285 - mean_absolute_error: 5.2802 - val_loss: 51.4418 - val_root_mean_squared_error: 7.1723 - val_mean_absolute_error: 5.8249\n",
      "\n",
      "Epoch 00606: val_loss did not improve from 49.45648\n",
      "Epoch 607/2000\n",
      "143/143 [==============================] - 89s 622ms/step - loss: 44.2811 - root_mean_squared_error: 6.6479 - mean_absolute_error: 5.3159 - val_loss: 63.4809 - val_root_mean_squared_error: 7.9675 - val_mean_absolute_error: 6.3863\n",
      "\n",
      "Epoch 00607: val_loss did not improve from 49.45648\n",
      "Epoch 608/2000\n",
      "143/143 [==============================] - 88s 616ms/step - loss: 51.3424 - root_mean_squared_error: 7.1591 - mean_absolute_error: 5.7791 - val_loss: 59.1443 - val_root_mean_squared_error: 7.6905 - val_mean_absolute_error: 6.1988\n",
      "\n",
      "Epoch 00608: val_loss did not improve from 49.45648\n",
      "Epoch 609/2000\n",
      "143/143 [==============================] - 90s 631ms/step - loss: 42.8855 - root_mean_squared_error: 6.5436 - mean_absolute_error: 5.2947 - val_loss: 65.2881 - val_root_mean_squared_error: 8.0801 - val_mean_absolute_error: 6.3688\n",
      "\n",
      "Epoch 00609: val_loss did not improve from 49.45648\n",
      "Epoch 610/2000\n",
      "143/143 [==============================] - 89s 623ms/step - loss: 49.9498 - root_mean_squared_error: 7.0636 - mean_absolute_error: 5.6269 - val_loss: 59.7496 - val_root_mean_squared_error: 7.7298 - val_mean_absolute_error: 6.2969\n",
      "\n",
      "Epoch 00610: val_loss did not improve from 49.45648\n",
      "Epoch 611/2000\n",
      "143/143 [==============================] - 89s 620ms/step - loss: 48.3757 - root_mean_squared_error: 6.9511 - mean_absolute_error: 5.5932 - val_loss: 55.6319 - val_root_mean_squared_error: 7.4587 - val_mean_absolute_error: 5.7557\n",
      "\n",
      "Epoch 00611: val_loss did not improve from 49.45648\n",
      "Epoch 612/2000\n",
      "143/143 [==============================] - 87s 609ms/step - loss: 44.5444 - root_mean_squared_error: 6.6687 - mean_absolute_error: 5.3487 - val_loss: 59.4952 - val_root_mean_squared_error: 7.7133 - val_mean_absolute_error: 6.3566\n",
      "\n",
      "Epoch 00612: val_loss did not improve from 49.45648\n",
      "Epoch 613/2000\n",
      "143/143 [==============================] - 88s 616ms/step - loss: 45.1039 - root_mean_squared_error: 6.7118 - mean_absolute_error: 5.3485 - val_loss: 61.7562 - val_root_mean_squared_error: 7.8585 - val_mean_absolute_error: 6.1732\n",
      "\n",
      "Epoch 00613: val_loss did not improve from 49.45648\n",
      "Epoch 614/2000\n",
      "143/143 [==============================] - 88s 618ms/step - loss: 42.1450 - root_mean_squared_error: 6.4843 - mean_absolute_error: 5.2265 - val_loss: 63.5113 - val_root_mean_squared_error: 7.9694 - val_mean_absolute_error: 6.3231\n",
      "\n",
      "Epoch 00614: val_loss did not improve from 49.45648\n",
      "Epoch 615/2000\n",
      "143/143 [==============================] - 89s 624ms/step - loss: 44.9943 - root_mean_squared_error: 6.7068 - mean_absolute_error: 5.4020 - val_loss: 58.1996 - val_root_mean_squared_error: 7.6289 - val_mean_absolute_error: 6.1961\n",
      "\n",
      "Epoch 00615: val_loss did not improve from 49.45648\n",
      "Epoch 616/2000\n",
      "143/143 [==============================] - 89s 620ms/step - loss: 46.2705 - root_mean_squared_error: 6.7988 - mean_absolute_error: 5.5019 - val_loss: 56.9771 - val_root_mean_squared_error: 7.5483 - val_mean_absolute_error: 6.0297\n",
      "\n",
      "Epoch 00616: val_loss did not improve from 49.45648\n",
      "Epoch 617/2000\n",
      "143/143 [==============================] - 88s 617ms/step - loss: 46.5624 - root_mean_squared_error: 6.8221 - mean_absolute_error: 5.4388 - val_loss: 63.5244 - val_root_mean_squared_error: 7.9702 - val_mean_absolute_error: 6.1614\n",
      "\n",
      "Epoch 00617: val_loss did not improve from 49.45648\n",
      "Epoch 618/2000\n",
      "143/143 [==============================] - 89s 622ms/step - loss: 48.1410 - root_mean_squared_error: 6.9366 - mean_absolute_error: 5.5150 - val_loss: 58.5200 - val_root_mean_squared_error: 7.6498 - val_mean_absolute_error: 6.0734\n",
      "\n",
      "Epoch 00618: val_loss did not improve from 49.45648\n",
      "Epoch 619/2000\n",
      "143/143 [==============================] - 91s 638ms/step - loss: 49.9622 - root_mean_squared_error: 7.0640 - mean_absolute_error: 5.8062 - val_loss: 70.3064 - val_root_mean_squared_error: 8.3849 - val_mean_absolute_error: 6.9189\n",
      "\n",
      "Epoch 00619: val_loss did not improve from 49.45648\n",
      "Epoch 620/2000\n",
      "143/143 [==============================] - 90s 633ms/step - loss: 51.9496 - root_mean_squared_error: 7.1840 - mean_absolute_error: 5.7528 - val_loss: 62.2849 - val_root_mean_squared_error: 7.8921 - val_mean_absolute_error: 6.4019\n",
      "\n",
      "Epoch 00620: val_loss did not improve from 49.45648\n",
      "Epoch 621/2000\n",
      "143/143 [==============================] - 90s 629ms/step - loss: 47.0910 - root_mean_squared_error: 6.8587 - mean_absolute_error: 5.4784 - val_loss: 60.7073 - val_root_mean_squared_error: 7.7915 - val_mean_absolute_error: 6.2591\n",
      "\n",
      "Epoch 00621: val_loss did not improve from 49.45648\n",
      "Epoch 622/2000\n",
      "143/143 [==============================] - 90s 633ms/step - loss: 48.7253 - root_mean_squared_error: 6.9754 - mean_absolute_error: 5.6366 - val_loss: 56.8737 - val_root_mean_squared_error: 7.5415 - val_mean_absolute_error: 5.9707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00622: val_loss did not improve from 49.45648\n",
      "Epoch 623/2000\n",
      "143/143 [==============================] - 91s 637ms/step - loss: 47.4608 - root_mean_squared_error: 6.8882 - mean_absolute_error: 5.5318 - val_loss: 60.0210 - val_root_mean_squared_error: 7.7473 - val_mean_absolute_error: 6.3558\n",
      "\n",
      "Epoch 00623: val_loss did not improve from 49.45648\n",
      "Epoch 624/2000\n",
      "143/143 [==============================] - 91s 639ms/step - loss: 46.9811 - root_mean_squared_error: 6.8500 - mean_absolute_error: 5.6037 - val_loss: 64.1928 - val_root_mean_squared_error: 8.0120 - val_mean_absolute_error: 6.3704\n",
      "\n",
      "Epoch 00624: val_loss did not improve from 49.45648\n",
      "Epoch 625/2000\n",
      "143/143 [==============================] - 87s 613ms/step - loss: 46.0917 - root_mean_squared_error: 6.7862 - mean_absolute_error: 5.4237 - val_loss: 60.4105 - val_root_mean_squared_error: 7.7724 - val_mean_absolute_error: 6.1581\n",
      "\n",
      "Epoch 00625: val_loss did not improve from 49.45648\n",
      "Epoch 626/2000\n",
      "143/143 [==============================] - 90s 628ms/step - loss: 47.2802 - root_mean_squared_error: 6.8719 - mean_absolute_error: 5.4883 - val_loss: 69.9221 - val_root_mean_squared_error: 8.3619 - val_mean_absolute_error: 6.6186\n",
      "\n",
      "Epoch 00626: val_loss did not improve from 49.45648\n",
      "Epoch 627/2000\n",
      "143/143 [==============================] - 92s 643ms/step - loss: 43.8022 - root_mean_squared_error: 6.6165 - mean_absolute_error: 5.3296 - val_loss: 59.3090 - val_root_mean_squared_error: 7.7012 - val_mean_absolute_error: 6.2141\n",
      "\n",
      "Epoch 00627: val_loss did not improve from 49.45648\n",
      "Epoch 628/2000\n",
      "143/143 [==============================] - 90s 631ms/step - loss: 45.3565 - root_mean_squared_error: 6.7321 - mean_absolute_error: 5.3570 - val_loss: 51.2418 - val_root_mean_squared_error: 7.1583 - val_mean_absolute_error: 5.7684\n",
      "\n",
      "Epoch 00628: val_loss did not improve from 49.45648\n",
      "Epoch 629/2000\n",
      "143/143 [==============================] - 93s 653ms/step - loss: 48.2761 - root_mean_squared_error: 6.9378 - mean_absolute_error: 5.5665 - val_loss: 62.0185 - val_root_mean_squared_error: 7.8752 - val_mean_absolute_error: 6.3046\n",
      "\n",
      "Epoch 00629: val_loss did not improve from 49.45648\n",
      "Epoch 630/2000\n",
      "143/143 [==============================] - 90s 631ms/step - loss: 47.9318 - root_mean_squared_error: 6.9214 - mean_absolute_error: 5.5193 - val_loss: 61.9445 - val_root_mean_squared_error: 7.8705 - val_mean_absolute_error: 6.2720\n",
      "\n",
      "Epoch 00630: val_loss did not improve from 49.45648\n",
      "Epoch 631/2000\n",
      "143/143 [==============================] - 90s 630ms/step - loss: 50.5937 - root_mean_squared_error: 7.1103 - mean_absolute_error: 5.7412 - val_loss: 51.1071 - val_root_mean_squared_error: 7.1489 - val_mean_absolute_error: 5.8768\n",
      "\n",
      "Epoch 00631: val_loss did not improve from 49.45648\n",
      "Epoch 632/2000\n",
      "143/143 [==============================] - 89s 623ms/step - loss: 45.1049 - root_mean_squared_error: 6.7135 - mean_absolute_error: 5.3647 - val_loss: 64.2550 - val_root_mean_squared_error: 8.0159 - val_mean_absolute_error: 6.3405\n",
      "\n",
      "Epoch 00632: val_loss did not improve from 49.45648\n",
      "Epoch 633/2000\n",
      "143/143 [==============================] - 90s 633ms/step - loss: 45.8584 - root_mean_squared_error: 6.7682 - mean_absolute_error: 5.4585 - val_loss: 58.8542 - val_root_mean_squared_error: 7.6717 - val_mean_absolute_error: 6.0450\n",
      "\n",
      "Epoch 00633: val_loss did not improve from 49.45648\n",
      "Epoch 634/2000\n",
      "143/143 [==============================] - 90s 629ms/step - loss: 41.4002 - root_mean_squared_error: 6.4333 - mean_absolute_error: 5.1591 - val_loss: 62.0749 - val_root_mean_squared_error: 7.8788 - val_mean_absolute_error: 6.2936\n",
      "\n",
      "Epoch 00634: val_loss did not improve from 49.45648\n",
      "Epoch 635/2000\n",
      "143/143 [==============================] - 89s 624ms/step - loss: 48.3384 - root_mean_squared_error: 6.9500 - mean_absolute_error: 5.6670 - val_loss: 57.7241 - val_root_mean_squared_error: 7.5976 - val_mean_absolute_error: 5.9768\n",
      "\n",
      "Epoch 00635: val_loss did not improve from 49.45648\n",
      "Epoch 636/2000\n",
      "143/143 [==============================] - 89s 625ms/step - loss: 50.5074 - root_mean_squared_error: 7.1022 - mean_absolute_error: 5.7256 - val_loss: 60.6798 - val_root_mean_squared_error: 7.7897 - val_mean_absolute_error: 6.3211\n",
      "\n",
      "Epoch 00636: val_loss did not improve from 49.45648\n",
      "Epoch 637/2000\n",
      "143/143 [==============================] - 92s 645ms/step - loss: 41.4436 - root_mean_squared_error: 6.4324 - mean_absolute_error: 5.1743 - val_loss: 67.3151 - val_root_mean_squared_error: 8.2046 - val_mean_absolute_error: 6.3690\n",
      "\n",
      "Epoch 00637: val_loss did not improve from 49.45648\n",
      "Epoch 638/2000\n",
      "143/143 [==============================] - 91s 638ms/step - loss: 45.7607 - root_mean_squared_error: 6.7634 - mean_absolute_error: 5.3762 - val_loss: 59.8130 - val_root_mean_squared_error: 7.7339 - val_mean_absolute_error: 6.0839\n",
      "\n",
      "Epoch 00638: val_loss did not improve from 49.45648\n",
      "Epoch 639/2000\n",
      "143/143 [==============================] - 92s 641ms/step - loss: 47.5263 - root_mean_squared_error: 6.8895 - mean_absolute_error: 5.4571 - val_loss: 66.8190 - val_root_mean_squared_error: 8.1743 - val_mean_absolute_error: 6.2319\n",
      "\n",
      "Epoch 00639: val_loss did not improve from 49.45648\n",
      "Epoch 640/2000\n",
      "143/143 [==============================] - 90s 632ms/step - loss: 43.2156 - root_mean_squared_error: 6.5721 - mean_absolute_error: 5.2108 - val_loss: 61.7432 - val_root_mean_squared_error: 7.8577 - val_mean_absolute_error: 6.3198\n",
      "\n",
      "Epoch 00640: val_loss did not improve from 49.45648\n",
      "Epoch 641/2000\n",
      "143/143 [==============================] - 91s 635ms/step - loss: 46.6080 - root_mean_squared_error: 6.8255 - mean_absolute_error: 5.4697 - val_loss: 60.3553 - val_root_mean_squared_error: 7.7689 - val_mean_absolute_error: 6.1087\n",
      "\n",
      "Epoch 00641: val_loss did not improve from 49.45648\n",
      "Epoch 642/2000\n",
      "143/143 [==============================] - 90s 629ms/step - loss: 47.0399 - root_mean_squared_error: 6.8494 - mean_absolute_error: 5.3962 - val_loss: 49.9596 - val_root_mean_squared_error: 7.0682 - val_mean_absolute_error: 5.7417\n",
      "\n",
      "Epoch 00642: val_loss did not improve from 49.45648\n",
      "Epoch 643/2000\n",
      "143/143 [==============================] - 88s 614ms/step - loss: 45.3191 - root_mean_squared_error: 6.7266 - mean_absolute_error: 5.3581 - val_loss: 58.7771 - val_root_mean_squared_error: 7.6666 - val_mean_absolute_error: 6.2344\n",
      "\n",
      "Epoch 00643: val_loss did not improve from 49.45648\n",
      "\n",
      "Epoch 00643: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "Epoch 644/2000\n",
      "143/143 [==============================] - 92s 641ms/step - loss: 48.8282 - root_mean_squared_error: 6.9863 - mean_absolute_error: 5.6309 - val_loss: 58.7875 - val_root_mean_squared_error: 7.6673 - val_mean_absolute_error: 6.1127\n",
      "\n",
      "Epoch 00644: val_loss did not improve from 49.45648\n",
      "Epoch 645/2000\n",
      "143/143 [==============================] - 91s 640ms/step - loss: 47.2516 - root_mean_squared_error: 6.8712 - mean_absolute_error: 5.4911 - val_loss: 55.7995 - val_root_mean_squared_error: 7.4699 - val_mean_absolute_error: 5.9509\n",
      "\n",
      "Epoch 00645: val_loss did not improve from 49.45648\n",
      "Epoch 646/2000\n",
      "143/143 [==============================] - 90s 632ms/step - loss: 45.8591 - root_mean_squared_error: 6.7701 - mean_absolute_error: 5.4361 - val_loss: 61.3402 - val_root_mean_squared_error: 7.8320 - val_mean_absolute_error: 6.2502\n",
      "\n",
      "Epoch 00646: val_loss did not improve from 49.45648\n",
      "Epoch 647/2000\n",
      "143/143 [==============================] - 91s 640ms/step - loss: 43.6582 - root_mean_squared_error: 6.6036 - mean_absolute_error: 5.2921 - val_loss: 79.0813 - val_root_mean_squared_error: 8.8928 - val_mean_absolute_error: 7.1640\n",
      "\n",
      "Epoch 00647: val_loss did not improve from 49.45648\n",
      "Epoch 648/2000\n",
      "143/143 [==============================] - 90s 628ms/step - loss: 42.3930 - root_mean_squared_error: 6.5081 - mean_absolute_error: 5.2083 - val_loss: 55.7046 - val_root_mean_squared_error: 7.4635 - val_mean_absolute_error: 5.9323\n",
      "\n",
      "Epoch 00648: val_loss did not improve from 49.45648\n",
      "Epoch 649/2000\n",
      "143/143 [==============================] - 91s 635ms/step - loss: 47.4113 - root_mean_squared_error: 6.8798 - mean_absolute_error: 5.4661 - val_loss: 68.0805 - val_root_mean_squared_error: 8.2511 - val_mean_absolute_error: 6.5631\n",
      "\n",
      "Epoch 00649: val_loss did not improve from 49.45648\n",
      "Epoch 650/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 90s 629ms/step - loss: 47.4809 - root_mean_squared_error: 6.8848 - mean_absolute_error: 5.5477 - val_loss: 62.1320 - val_root_mean_squared_error: 7.8824 - val_mean_absolute_error: 6.0413\n",
      "\n",
      "Epoch 00650: val_loss did not improve from 49.45648\n",
      "Epoch 651/2000\n",
      "143/143 [==============================] - 91s 639ms/step - loss: 43.5357 - root_mean_squared_error: 6.5965 - mean_absolute_error: 5.3171 - val_loss: 68.9077 - val_root_mean_squared_error: 8.3011 - val_mean_absolute_error: 6.6066\n",
      "\n",
      "Epoch 00651: val_loss did not improve from 49.45648\n",
      "Epoch 652/2000\n",
      "143/143 [==============================] - 91s 638ms/step - loss: 50.3664 - root_mean_squared_error: 7.0861 - mean_absolute_error: 5.6728 - val_loss: 58.2800 - val_root_mean_squared_error: 7.6341 - val_mean_absolute_error: 5.9570\n",
      "\n",
      "Epoch 00652: val_loss did not improve from 49.45648\n",
      "Epoch 653/2000\n",
      "143/143 [==============================] - 91s 638ms/step - loss: 49.5845 - root_mean_squared_error: 7.0379 - mean_absolute_error: 5.6014 - val_loss: 59.8163 - val_root_mean_squared_error: 7.7341 - val_mean_absolute_error: 6.0921\n",
      "\n",
      "Epoch 00653: val_loss did not improve from 49.45648\n",
      "Epoch 654/2000\n",
      "143/143 [==============================] - 92s 642ms/step - loss: 48.6375 - root_mean_squared_error: 6.9702 - mean_absolute_error: 5.5575 - val_loss: 58.3780 - val_root_mean_squared_error: 7.6406 - val_mean_absolute_error: 6.1223\n",
      "\n",
      "Epoch 00654: val_loss did not improve from 49.45648\n",
      "Epoch 655/2000\n",
      "143/143 [==============================] - 92s 646ms/step - loss: 50.3952 - root_mean_squared_error: 7.0876 - mean_absolute_error: 5.6338 - val_loss: 65.4276 - val_root_mean_squared_error: 8.0887 - val_mean_absolute_error: 6.6610\n",
      "\n",
      "Epoch 00655: val_loss did not improve from 49.45648\n",
      "Epoch 656/2000\n",
      "143/143 [==============================] - 90s 628ms/step - loss: 44.3605 - root_mean_squared_error: 6.6582 - mean_absolute_error: 5.3549 - val_loss: 63.2784 - val_root_mean_squared_error: 7.9548 - val_mean_absolute_error: 6.4813\n",
      "\n",
      "Epoch 00656: val_loss did not improve from 49.45648\n",
      "Epoch 657/2000\n",
      "143/143 [==============================] - 92s 643ms/step - loss: 48.0381 - root_mean_squared_error: 6.9271 - mean_absolute_error: 5.5502 - val_loss: 57.3571 - val_root_mean_squared_error: 7.5734 - val_mean_absolute_error: 5.9386\n",
      "\n",
      "Epoch 00657: val_loss did not improve from 49.45648\n",
      "Epoch 658/2000\n",
      "143/143 [==============================] - 90s 629ms/step - loss: 48.0666 - root_mean_squared_error: 6.9311 - mean_absolute_error: 5.5957 - val_loss: 64.4395 - val_root_mean_squared_error: 8.0274 - val_mean_absolute_error: 6.3156\n",
      "\n",
      "Epoch 00658: val_loss did not improve from 49.45648\n",
      "Epoch 659/2000\n",
      "143/143 [==============================] - 91s 637ms/step - loss: 47.2588 - root_mean_squared_error: 6.8642 - mean_absolute_error: 5.5166 - val_loss: 61.7919 - val_root_mean_squared_error: 7.8608 - val_mean_absolute_error: 6.3411\n",
      "\n",
      "Epoch 00659: val_loss did not improve from 49.45648\n",
      "Epoch 660/2000\n",
      "143/143 [==============================] - 90s 631ms/step - loss: 44.9054 - root_mean_squared_error: 6.6991 - mean_absolute_error: 5.4034 - val_loss: 69.4183 - val_root_mean_squared_error: 8.3318 - val_mean_absolute_error: 6.4252\n",
      "\n",
      "Epoch 00660: val_loss did not improve from 49.45648\n",
      "Epoch 661/2000\n",
      "143/143 [==============================] - 93s 651ms/step - loss: 44.0589 - root_mean_squared_error: 6.6319 - mean_absolute_error: 5.3121 - val_loss: 59.8593 - val_root_mean_squared_error: 7.7369 - val_mean_absolute_error: 6.2088\n",
      "\n",
      "Epoch 00661: val_loss did not improve from 49.45648\n",
      "Epoch 662/2000\n",
      "143/143 [==============================] - 92s 641ms/step - loss: 49.3537 - root_mean_squared_error: 7.0234 - mean_absolute_error: 5.6423 - val_loss: 60.0356 - val_root_mean_squared_error: 7.7483 - val_mean_absolute_error: 6.1084\n",
      "\n",
      "Epoch 00662: val_loss did not improve from 49.45648\n",
      "Epoch 663/2000\n",
      "143/143 [==============================] - 91s 635ms/step - loss: 45.0002 - root_mean_squared_error: 6.6997 - mean_absolute_error: 5.4019 - val_loss: 66.6866 - val_root_mean_squared_error: 8.1662 - val_mean_absolute_error: 6.5005\n",
      "\n",
      "Epoch 00663: val_loss did not improve from 49.45648\n",
      "Epoch 664/2000\n",
      "143/143 [==============================] - 91s 638ms/step - loss: 45.8228 - root_mean_squared_error: 6.7640 - mean_absolute_error: 5.4462 - val_loss: 60.4788 - val_root_mean_squared_error: 7.7768 - val_mean_absolute_error: 6.3337\n",
      "\n",
      "Epoch 00664: val_loss did not improve from 49.45648\n",
      "Epoch 665/2000\n",
      "143/143 [==============================] - 90s 628ms/step - loss: 47.9402 - root_mean_squared_error: 6.9212 - mean_absolute_error: 5.6329 - val_loss: 54.5277 - val_root_mean_squared_error: 7.3843 - val_mean_absolute_error: 5.8071\n",
      "\n",
      "Epoch 00665: val_loss did not improve from 49.45648\n",
      "Epoch 666/2000\n",
      "143/143 [==============================] - 92s 641ms/step - loss: 50.9631 - root_mean_squared_error: 7.1344 - mean_absolute_error: 5.8012 - val_loss: 53.7438 - val_root_mean_squared_error: 7.3310 - val_mean_absolute_error: 5.6958\n",
      "\n",
      "Epoch 00666: val_loss did not improve from 49.45648\n",
      "Epoch 667/2000\n",
      "143/143 [==============================] - 90s 633ms/step - loss: 48.7567 - root_mean_squared_error: 6.9796 - mean_absolute_error: 5.5001 - val_loss: 57.4209 - val_root_mean_squared_error: 7.5777 - val_mean_absolute_error: 5.9752\n",
      "\n",
      "Epoch 00667: val_loss did not improve from 49.45648\n",
      "Epoch 668/2000\n",
      "143/143 [==============================] - 92s 646ms/step - loss: 51.2372 - root_mean_squared_error: 7.1514 - mean_absolute_error: 5.8079 - val_loss: 57.3748 - val_root_mean_squared_error: 7.5746 - val_mean_absolute_error: 5.9966\n",
      "\n",
      "Epoch 00668: val_loss did not improve from 49.45648\n",
      "Epoch 669/2000\n",
      "143/143 [==============================] - 91s 638ms/step - loss: 43.5904 - root_mean_squared_error: 6.5906 - mean_absolute_error: 5.3091 - val_loss: 57.2307 - val_root_mean_squared_error: 7.5651 - val_mean_absolute_error: 6.1543\n",
      "\n",
      "Epoch 00669: val_loss did not improve from 49.45648\n",
      "Epoch 670/2000\n",
      "143/143 [==============================] - 91s 636ms/step - loss: 45.7793 - root_mean_squared_error: 6.7591 - mean_absolute_error: 5.3706 - val_loss: 73.9291 - val_root_mean_squared_error: 8.5982 - val_mean_absolute_error: 6.5824\n",
      "\n",
      "Epoch 00670: val_loss did not improve from 49.45648\n",
      "Epoch 671/2000\n",
      "143/143 [==============================] - 93s 648ms/step - loss: 43.7840 - root_mean_squared_error: 6.6124 - mean_absolute_error: 5.3131 - val_loss: 55.9379 - val_root_mean_squared_error: 7.4792 - val_mean_absolute_error: 6.0485\n",
      "\n",
      "Epoch 00671: val_loss did not improve from 49.45648\n",
      "Epoch 672/2000\n",
      "143/143 [==============================] - 90s 629ms/step - loss: 45.7557 - root_mean_squared_error: 6.7586 - mean_absolute_error: 5.4663 - val_loss: 64.8174 - val_root_mean_squared_error: 8.0509 - val_mean_absolute_error: 6.5455\n",
      "\n",
      "Epoch 00672: val_loss did not improve from 49.45648\n",
      "Epoch 673/2000\n",
      "143/143 [==============================] - 91s 636ms/step - loss: 48.1741 - root_mean_squared_error: 6.9352 - mean_absolute_error: 5.4777 - val_loss: 59.2603 - val_root_mean_squared_error: 7.6981 - val_mean_absolute_error: 6.0561\n",
      "\n",
      "Epoch 00673: val_loss did not improve from 49.45648\n",
      "Epoch 674/2000\n",
      "143/143 [==============================] - 93s 654ms/step - loss: 44.1568 - root_mean_squared_error: 6.6420 - mean_absolute_error: 5.3634 - val_loss: 69.9052 - val_root_mean_squared_error: 8.3609 - val_mean_absolute_error: 6.5415\n",
      "\n",
      "Epoch 00674: val_loss did not improve from 49.45648\n",
      "Epoch 675/2000\n",
      "143/143 [==============================] - 91s 638ms/step - loss: 45.4403 - root_mean_squared_error: 6.7366 - mean_absolute_error: 5.3959 - val_loss: 65.3946 - val_root_mean_squared_error: 8.0867 - val_mean_absolute_error: 6.4674\n",
      "\n",
      "Epoch 00675: val_loss did not improve from 49.45648\n",
      "Epoch 676/2000\n",
      "143/143 [==============================] - 92s 642ms/step - loss: 47.7123 - root_mean_squared_error: 6.9028 - mean_absolute_error: 5.5258 - val_loss: 67.7571 - val_root_mean_squared_error: 8.2315 - val_mean_absolute_error: 6.5288\n",
      "\n",
      "Epoch 00676: val_loss did not improve from 49.45648\n",
      "Epoch 677/2000\n",
      "143/143 [==============================] - 91s 639ms/step - loss: 49.6089 - root_mean_squared_error: 7.0397 - mean_absolute_error: 5.6342 - val_loss: 54.6247 - val_root_mean_squared_error: 7.3908 - val_mean_absolute_error: 5.9517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00677: val_loss did not improve from 49.45648\n",
      "Epoch 678/2000\n",
      "143/143 [==============================] - 93s 652ms/step - loss: 50.4230 - root_mean_squared_error: 7.0977 - mean_absolute_error: 5.6780 - val_loss: 63.5413 - val_root_mean_squared_error: 7.9713 - val_mean_absolute_error: 6.3247\n",
      "\n",
      "Epoch 00678: val_loss did not improve from 49.45648\n",
      "Epoch 679/2000\n",
      "143/143 [==============================] - 91s 637ms/step - loss: 48.7606 - root_mean_squared_error: 6.9736 - mean_absolute_error: 5.5774 - val_loss: 62.4547 - val_root_mean_squared_error: 7.9028 - val_mean_absolute_error: 6.1945\n",
      "\n",
      "Epoch 00679: val_loss did not improve from 49.45648\n",
      "Epoch 680/2000\n",
      "143/143 [==============================] - 92s 647ms/step - loss: 49.6901 - root_mean_squared_error: 7.0473 - mean_absolute_error: 5.7381 - val_loss: 59.4377 - val_root_mean_squared_error: 7.7096 - val_mean_absolute_error: 6.0217\n",
      "\n",
      "Epoch 00680: val_loss did not improve from 49.45648\n",
      "Epoch 681/2000\n",
      "143/143 [==============================] - 92s 643ms/step - loss: 44.1127 - root_mean_squared_error: 6.6393 - mean_absolute_error: 5.4063 - val_loss: 63.7029 - val_root_mean_squared_error: 7.9814 - val_mean_absolute_error: 6.3465\n",
      "\n",
      "Epoch 00681: val_loss did not improve from 49.45648\n",
      "Epoch 682/2000\n",
      "143/143 [==============================] - 93s 653ms/step - loss: 47.8436 - root_mean_squared_error: 6.9143 - mean_absolute_error: 5.4288 - val_loss: 59.9441 - val_root_mean_squared_error: 7.7424 - val_mean_absolute_error: 5.9069\n",
      "\n",
      "Epoch 00682: val_loss did not improve from 49.45648\n",
      "Epoch 683/2000\n",
      "143/143 [==============================] - 91s 636ms/step - loss: 46.9836 - root_mean_squared_error: 6.8517 - mean_absolute_error: 5.5231 - val_loss: 63.1131 - val_root_mean_squared_error: 7.9444 - val_mean_absolute_error: 6.3756\n",
      "\n",
      "Epoch 00683: val_loss did not improve from 49.45648\n",
      "Epoch 684/2000\n",
      "143/143 [==============================] - 92s 647ms/step - loss: 43.9683 - root_mean_squared_error: 6.6293 - mean_absolute_error: 5.3676 - val_loss: 58.6923 - val_root_mean_squared_error: 7.6611 - val_mean_absolute_error: 6.2926\n",
      "\n",
      "Epoch 00684: val_loss did not improve from 49.45648\n",
      "Epoch 685/2000\n",
      "143/143 [==============================] - 91s 641ms/step - loss: 45.0003 - root_mean_squared_error: 6.7058 - mean_absolute_error: 5.3734 - val_loss: 57.3199 - val_root_mean_squared_error: 7.5710 - val_mean_absolute_error: 5.9246\n",
      "\n",
      "Epoch 00685: val_loss did not improve from 49.45648\n",
      "Epoch 686/2000\n",
      "143/143 [==============================] - 92s 647ms/step - loss: 47.6213 - root_mean_squared_error: 6.8971 - mean_absolute_error: 5.5098 - val_loss: 61.6035 - val_root_mean_squared_error: 7.8488 - val_mean_absolute_error: 6.3690\n",
      "\n",
      "Epoch 00686: val_loss did not improve from 49.45648\n",
      "Epoch 687/2000\n",
      "143/143 [==============================] - 92s 647ms/step - loss: 49.3284 - root_mean_squared_error: 7.0202 - mean_absolute_error: 5.6841 - val_loss: 61.9854 - val_root_mean_squared_error: 7.8731 - val_mean_absolute_error: 6.2609\n",
      "\n",
      "Epoch 00687: val_loss did not improve from 49.45648\n",
      "Epoch 688/2000\n",
      "143/143 [==============================] - 92s 647ms/step - loss: 46.2536 - root_mean_squared_error: 6.7964 - mean_absolute_error: 5.4576 - val_loss: 63.4006 - val_root_mean_squared_error: 7.9625 - val_mean_absolute_error: 6.2331\n",
      "\n",
      "Epoch 00688: val_loss did not improve from 49.45648\n",
      "Epoch 689/2000\n",
      "143/143 [==============================] - 90s 629ms/step - loss: 43.5190 - root_mean_squared_error: 6.5937 - mean_absolute_error: 5.3146 - val_loss: 59.5227 - val_root_mean_squared_error: 7.7151 - val_mean_absolute_error: 6.0937\n",
      "\n",
      "Epoch 00689: val_loss did not improve from 49.45648\n",
      "Epoch 690/2000\n",
      "143/143 [==============================] - 92s 643ms/step - loss: 45.5504 - root_mean_squared_error: 6.7470 - mean_absolute_error: 5.4200 - val_loss: 59.3139 - val_root_mean_squared_error: 7.7015 - val_mean_absolute_error: 6.1828\n",
      "\n",
      "Epoch 00690: val_loss did not improve from 49.45648\n",
      "Epoch 691/2000\n",
      "143/143 [==============================] - 92s 646ms/step - loss: 45.3969 - root_mean_squared_error: 6.7361 - mean_absolute_error: 5.4341 - val_loss: 64.8644 - val_root_mean_squared_error: 8.0538 - val_mean_absolute_error: 6.4378\n",
      "\n",
      "Epoch 00691: val_loss did not improve from 49.45648\n",
      "Epoch 692/2000\n",
      "143/143 [==============================] - 91s 641ms/step - loss: 50.9985 - root_mean_squared_error: 7.1388 - mean_absolute_error: 5.7476 - val_loss: 73.1179 - val_root_mean_squared_error: 8.5509 - val_mean_absolute_error: 6.6533\n",
      "\n",
      "Epoch 00692: val_loss did not improve from 49.45648\n",
      "Epoch 693/2000\n",
      "143/143 [==============================] - 91s 637ms/step - loss: 49.6468 - root_mean_squared_error: 7.0409 - mean_absolute_error: 5.6509 - val_loss: 54.2703 - val_root_mean_squared_error: 7.3668 - val_mean_absolute_error: 5.8755\n",
      "\n",
      "Epoch 00693: val_loss did not improve from 49.45648\n",
      "\n",
      "Epoch 00693: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "Epoch 694/2000\n",
      "143/143 [==============================] - 91s 638ms/step - loss: 44.4177 - root_mean_squared_error: 6.6594 - mean_absolute_error: 5.4557 - val_loss: 61.4219 - val_root_mean_squared_error: 7.8372 - val_mean_absolute_error: 6.3477\n",
      "\n",
      "Epoch 00694: val_loss did not improve from 49.45648\n",
      "Epoch 695/2000\n",
      "143/143 [==============================] - 91s 641ms/step - loss: 46.1917 - root_mean_squared_error: 6.7951 - mean_absolute_error: 5.5158 - val_loss: 65.0148 - val_root_mean_squared_error: 8.0632 - val_mean_absolute_error: 6.3955\n",
      "\n",
      "Epoch 00695: val_loss did not improve from 49.45648\n",
      "Epoch 696/2000\n",
      "143/143 [==============================] - 93s 649ms/step - loss: 48.5454 - root_mean_squared_error: 6.9647 - mean_absolute_error: 5.5967 - val_loss: 61.6768 - val_root_mean_squared_error: 7.8535 - val_mean_absolute_error: 6.1495\n",
      "\n",
      "Epoch 00696: val_loss did not improve from 49.45648\n",
      "Epoch 697/2000\n",
      "143/143 [==============================] - 91s 638ms/step - loss: 45.1259 - root_mean_squared_error: 6.7121 - mean_absolute_error: 5.4213 - val_loss: 69.1593 - val_root_mean_squared_error: 8.3162 - val_mean_absolute_error: 6.5433\n",
      "\n",
      "Epoch 00697: val_loss did not improve from 49.45648\n",
      "Epoch 698/2000\n",
      "143/143 [==============================] - 93s 649ms/step - loss: 49.1177 - root_mean_squared_error: 7.0076 - mean_absolute_error: 5.6443 - val_loss: 69.1054 - val_root_mean_squared_error: 8.3130 - val_mean_absolute_error: 6.4823\n",
      "\n",
      "Epoch 00698: val_loss did not improve from 49.45648\n",
      "Epoch 699/2000\n",
      "143/143 [==============================] - 94s 657ms/step - loss: 52.3191 - root_mean_squared_error: 7.2309 - mean_absolute_error: 5.7879 - val_loss: 67.6450 - val_root_mean_squared_error: 8.2247 - val_mean_absolute_error: 6.5769\n",
      "\n",
      "Epoch 00699: val_loss did not improve from 49.45648\n",
      "Epoch 700/2000\n",
      "143/143 [==============================] - 92s 646ms/step - loss: 43.5269 - root_mean_squared_error: 6.5941 - mean_absolute_error: 5.2981 - val_loss: 63.4726 - val_root_mean_squared_error: 7.9670 - val_mean_absolute_error: 6.3143\n",
      "\n",
      "Epoch 00700: val_loss did not improve from 49.45648\n",
      "Epoch 701/2000\n",
      "143/143 [==============================] - 91s 640ms/step - loss: 46.3288 - root_mean_squared_error: 6.8019 - mean_absolute_error: 5.4668 - val_loss: 67.1451 - val_root_mean_squared_error: 8.1942 - val_mean_absolute_error: 6.3531\n",
      "\n",
      "Epoch 00701: val_loss did not improve from 49.45648\n",
      "Epoch 702/2000\n",
      "143/143 [==============================] - 90s 629ms/step - loss: 44.8603 - root_mean_squared_error: 6.6966 - mean_absolute_error: 5.3312 - val_loss: 55.7012 - val_root_mean_squared_error: 7.4633 - val_mean_absolute_error: 5.9412\n",
      "\n",
      "Epoch 00702: val_loss did not improve from 49.45648\n",
      "Epoch 703/2000\n",
      "143/143 [==============================] - 92s 641ms/step - loss: 51.1273 - root_mean_squared_error: 7.1478 - mean_absolute_error: 5.7007 - val_loss: 60.3115 - val_root_mean_squared_error: 7.7660 - val_mean_absolute_error: 6.1652\n",
      "\n",
      "Epoch 00703: val_loss did not improve from 49.45648\n",
      "Epoch 704/2000\n",
      "143/143 [==============================] - 90s 630ms/step - loss: 42.2107 - root_mean_squared_error: 6.4940 - mean_absolute_error: 5.0763 - val_loss: 64.3057 - val_root_mean_squared_error: 8.0191 - val_mean_absolute_error: 6.3042\n",
      "\n",
      "Epoch 00704: val_loss did not improve from 49.45648\n",
      "Epoch 705/2000\n",
      "143/143 [==============================] - 90s 627ms/step - loss: 49.6133 - root_mean_squared_error: 7.0377 - mean_absolute_error: 5.6918 - val_loss: 54.9928 - val_root_mean_squared_error: 7.4157 - val_mean_absolute_error: 6.0034\n",
      "\n",
      "Epoch 00705: val_loss did not improve from 49.45648\n",
      "Epoch 706/2000\n",
      "143/143 [==============================] - 92s 646ms/step - loss: 47.6741 - root_mean_squared_error: 6.8992 - mean_absolute_error: 5.4534 - val_loss: 69.4708 - val_root_mean_squared_error: 8.3349 - val_mean_absolute_error: 6.6064\n",
      "\n",
      "Epoch 00706: val_loss did not improve from 49.45648\n",
      "Epoch 707/2000\n",
      "143/143 [==============================] - 94s 656ms/step - loss: 48.3560 - root_mean_squared_error: 6.9520 - mean_absolute_error: 5.6304 - val_loss: 52.7449 - val_root_mean_squared_error: 7.2626 - val_mean_absolute_error: 5.7453\n",
      "\n",
      "Epoch 00707: val_loss did not improve from 49.45648\n",
      "Epoch 708/2000\n",
      "143/143 [==============================] - 94s 655ms/step - loss: 46.7289 - root_mean_squared_error: 6.8343 - mean_absolute_error: 5.5154 - val_loss: 58.9260 - val_root_mean_squared_error: 7.6763 - val_mean_absolute_error: 6.1011\n",
      "\n",
      "Epoch 00708: val_loss did not improve from 49.45648\n",
      "Epoch 709/2000\n",
      "143/143 [==============================] - 91s 640ms/step - loss: 46.9133 - root_mean_squared_error: 6.8470 - mean_absolute_error: 5.4880 - val_loss: 56.8770 - val_root_mean_squared_error: 7.5417 - val_mean_absolute_error: 6.0059\n",
      "\n",
      "Epoch 00709: val_loss did not improve from 49.45648\n",
      "Epoch 710/2000\n",
      "143/143 [==============================] - 94s 656ms/step - loss: 44.4508 - root_mean_squared_error: 6.6640 - mean_absolute_error: 5.3920 - val_loss: 58.2405 - val_root_mean_squared_error: 7.6315 - val_mean_absolute_error: 6.0427\n",
      "\n",
      "Epoch 00710: val_loss did not improve from 49.45648\n",
      "Epoch 711/2000\n",
      "143/143 [==============================] - 92s 644ms/step - loss: 50.8237 - root_mean_squared_error: 7.1265 - mean_absolute_error: 5.6908 - val_loss: 58.6643 - val_root_mean_squared_error: 7.6593 - val_mean_absolute_error: 6.1518\n",
      "\n",
      "Epoch 00711: val_loss did not improve from 49.45648\n",
      "Epoch 712/2000\n",
      "143/143 [==============================] - 92s 644ms/step - loss: 49.9283 - root_mean_squared_error: 7.0594 - mean_absolute_error: 5.6330 - val_loss: 59.4882 - val_root_mean_squared_error: 7.7129 - val_mean_absolute_error: 6.2729\n",
      "\n",
      "Epoch 00712: val_loss did not improve from 49.45648\n",
      "Epoch 713/2000\n",
      "143/143 [==============================] - 92s 645ms/step - loss: 47.7698 - root_mean_squared_error: 6.9107 - mean_absolute_error: 5.5958 - val_loss: 54.4833 - val_root_mean_squared_error: 7.3813 - val_mean_absolute_error: 6.0548\n",
      "\n",
      "Epoch 00713: val_loss did not improve from 49.45648\n",
      "Epoch 714/2000\n",
      "143/143 [==============================] - 92s 647ms/step - loss: 49.4924 - root_mean_squared_error: 7.0244 - mean_absolute_error: 5.5284 - val_loss: 59.7671 - val_root_mean_squared_error: 7.7309 - val_mean_absolute_error: 6.1804\n",
      "\n",
      "Epoch 00714: val_loss did not improve from 49.45648\n",
      "Epoch 715/2000\n",
      "143/143 [==============================] - 91s 637ms/step - loss: 45.3432 - root_mean_squared_error: 6.7323 - mean_absolute_error: 5.3943 - val_loss: 61.9831 - val_root_mean_squared_error: 7.8729 - val_mean_absolute_error: 6.3281\n",
      "\n",
      "Epoch 00715: val_loss did not improve from 49.45648\n",
      "Epoch 716/2000\n",
      "143/143 [==============================] - 94s 660ms/step - loss: 46.6316 - root_mean_squared_error: 6.8258 - mean_absolute_error: 5.4448 - val_loss: 72.9302 - val_root_mean_squared_error: 8.5399 - val_mean_absolute_error: 6.3169\n",
      "\n",
      "Epoch 00716: val_loss did not improve from 49.45648\n",
      "Epoch 717/2000\n",
      "143/143 [==============================] - 94s 658ms/step - loss: 44.1492 - root_mean_squared_error: 6.6426 - mean_absolute_error: 5.3835 - val_loss: 60.4897 - val_root_mean_squared_error: 7.7775 - val_mean_absolute_error: 6.0898\n",
      "\n",
      "Epoch 00717: val_loss did not improve from 49.45648\n",
      "Epoch 718/2000\n",
      "143/143 [==============================] - 92s 643ms/step - loss: 47.4931 - root_mean_squared_error: 6.8894 - mean_absolute_error: 5.5742 - val_loss: 65.5996 - val_root_mean_squared_error: 8.0994 - val_mean_absolute_error: 6.3287\n",
      "\n",
      "Epoch 00718: val_loss did not improve from 49.45648\n",
      "Epoch 719/2000\n",
      "143/143 [==============================] - 93s 647ms/step - loss: 50.9116 - root_mean_squared_error: 7.1313 - mean_absolute_error: 5.6020 - val_loss: 74.1885 - val_root_mean_squared_error: 8.6133 - val_mean_absolute_error: 6.8999\n",
      "\n",
      "Epoch 00719: val_loss did not improve from 49.45648\n",
      "Epoch 720/2000\n",
      "143/143 [==============================] - 92s 641ms/step - loss: 44.4254 - root_mean_squared_error: 6.6627 - mean_absolute_error: 5.3803 - val_loss: 62.0652 - val_root_mean_squared_error: 7.8781 - val_mean_absolute_error: 6.3116\n",
      "\n",
      "Epoch 00720: val_loss did not improve from 49.45648\n",
      "Epoch 721/2000\n",
      "143/143 [==============================] - 94s 655ms/step - loss: 43.8415 - root_mean_squared_error: 6.6141 - mean_absolute_error: 5.2941 - val_loss: 60.5506 - val_root_mean_squared_error: 7.7814 - val_mean_absolute_error: 6.2784\n",
      "\n",
      "Epoch 00721: val_loss did not improve from 49.45648\n",
      "Epoch 722/2000\n",
      "143/143 [==============================] - 93s 651ms/step - loss: 42.4759 - root_mean_squared_error: 6.5137 - mean_absolute_error: 5.2834 - val_loss: 62.8066 - val_root_mean_squared_error: 7.9251 - val_mean_absolute_error: 6.3555\n",
      "\n",
      "Epoch 00722: val_loss did not improve from 49.45648\n",
      "Epoch 723/2000\n",
      "143/143 [==============================] - 94s 655ms/step - loss: 43.5187 - root_mean_squared_error: 6.5937 - mean_absolute_error: 5.3093 - val_loss: 54.0791 - val_root_mean_squared_error: 7.3539 - val_mean_absolute_error: 5.8511\n",
      "\n",
      "Epoch 00723: val_loss did not improve from 49.45648\n",
      "Epoch 724/2000\n",
      "143/143 [==============================] - 93s 653ms/step - loss: 41.3127 - root_mean_squared_error: 6.4170 - mean_absolute_error: 5.1478 - val_loss: 64.7431 - val_root_mean_squared_error: 8.0463 - val_mean_absolute_error: 6.2913\n",
      "\n",
      "Epoch 00724: val_loss did not improve from 49.45648\n",
      "Epoch 725/2000\n",
      "143/143 [==============================] - 94s 659ms/step - loss: 45.9332 - root_mean_squared_error: 6.7758 - mean_absolute_error: 5.5488 - val_loss: 60.2968 - val_root_mean_squared_error: 7.7651 - val_mean_absolute_error: 6.2289\n",
      "\n",
      "Epoch 00725: val_loss did not improve from 49.45648\n",
      "Epoch 726/2000\n",
      "143/143 [==============================] - 93s 654ms/step - loss: 46.3057 - root_mean_squared_error: 6.8036 - mean_absolute_error: 5.5260 - val_loss: 50.2446 - val_root_mean_squared_error: 7.0883 - val_mean_absolute_error: 5.5265\n",
      "\n",
      "Epoch 00726: val_loss did not improve from 49.45648\n",
      "Epoch 727/2000\n",
      "143/143 [==============================] - 92s 643ms/step - loss: 47.7258 - root_mean_squared_error: 6.9042 - mean_absolute_error: 5.4971 - val_loss: 57.8743 - val_root_mean_squared_error: 7.6075 - val_mean_absolute_error: 6.0655\n",
      "\n",
      "Epoch 00727: val_loss did not improve from 49.45648\n",
      "Epoch 728/2000\n",
      "143/143 [==============================] - 90s 632ms/step - loss: 46.7875 - root_mean_squared_error: 6.8385 - mean_absolute_error: 5.6109 - val_loss: 66.6628 - val_root_mean_squared_error: 8.1647 - val_mean_absolute_error: 6.4534\n",
      "\n",
      "Epoch 00728: val_loss did not improve from 49.45648\n",
      "Epoch 729/2000\n",
      "143/143 [==============================] - 92s 646ms/step - loss: 42.6978 - root_mean_squared_error: 6.5328 - mean_absolute_error: 5.2963 - val_loss: 63.8183 - val_root_mean_squared_error: 7.9886 - val_mean_absolute_error: 5.9002\n",
      "\n",
      "Epoch 00729: val_loss did not improve from 49.45648\n",
      "Epoch 730/2000\n",
      "143/143 [==============================] - 93s 648ms/step - loss: 46.3400 - root_mean_squared_error: 6.8038 - mean_absolute_error: 5.4596 - val_loss: 56.1571 - val_root_mean_squared_error: 7.4938 - val_mean_absolute_error: 6.0860\n",
      "\n",
      "Epoch 00730: val_loss did not improve from 49.45648\n",
      "Epoch 731/2000\n",
      "143/143 [==============================] - 91s 639ms/step - loss: 49.1592 - root_mean_squared_error: 6.9994 - mean_absolute_error: 5.5400 - val_loss: 51.9851 - val_root_mean_squared_error: 7.2101 - val_mean_absolute_error: 5.7496\n",
      "\n",
      "Epoch 00731: val_loss did not improve from 49.45648\n",
      "Epoch 732/2000\n",
      "143/143 [==============================] - 90s 630ms/step - loss: 47.4279 - root_mean_squared_error: 6.8808 - mean_absolute_error: 5.5200 - val_loss: 53.4875 - val_root_mean_squared_error: 7.3135 - val_mean_absolute_error: 6.0025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00732: val_loss did not improve from 49.45648\n",
      "Epoch 733/2000\n",
      "143/143 [==============================] - 93s 653ms/step - loss: 48.0429 - root_mean_squared_error: 6.9243 - mean_absolute_error: 5.5356 - val_loss: 48.5759 - val_root_mean_squared_error: 6.9696 - val_mean_absolute_error: 5.5120\n",
      "\n",
      "Epoch 00733: val_loss improved from 49.45648 to 48.57585, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/TimeCNN_regressor_01.hdf5\n",
      "Epoch 734/2000\n",
      "143/143 [==============================] - 94s 660ms/step - loss: 44.0910 - root_mean_squared_error: 6.6311 - mean_absolute_error: 5.3692 - val_loss: 60.9301 - val_root_mean_squared_error: 7.8058 - val_mean_absolute_error: 6.1553\n",
      "\n",
      "Epoch 00734: val_loss did not improve from 48.57585\n",
      "Epoch 735/2000\n",
      "143/143 [==============================] - 93s 648ms/step - loss: 45.6583 - root_mean_squared_error: 6.7554 - mean_absolute_error: 5.4201 - val_loss: 58.9869 - val_root_mean_squared_error: 7.6803 - val_mean_absolute_error: 6.1494\n",
      "\n",
      "Epoch 00735: val_loss did not improve from 48.57585\n",
      "Epoch 736/2000\n",
      "143/143 [==============================] - 92s 647ms/step - loss: 49.2468 - root_mean_squared_error: 7.0164 - mean_absolute_error: 5.6394 - val_loss: 66.2831 - val_root_mean_squared_error: 8.1414 - val_mean_absolute_error: 6.5733\n",
      "\n",
      "Epoch 00736: val_loss did not improve from 48.57585\n",
      "Epoch 737/2000\n",
      "143/143 [==============================] - 93s 651ms/step - loss: 47.7466 - root_mean_squared_error: 6.9067 - mean_absolute_error: 5.5182 - val_loss: 67.8391 - val_root_mean_squared_error: 8.2364 - val_mean_absolute_error: 6.5437\n",
      "\n",
      "Epoch 00737: val_loss did not improve from 48.57585\n",
      "Epoch 738/2000\n",
      "143/143 [==============================] - 91s 639ms/step - loss: 42.7314 - root_mean_squared_error: 6.5355 - mean_absolute_error: 5.2022 - val_loss: 62.7512 - val_root_mean_squared_error: 7.9216 - val_mean_absolute_error: 6.3878\n",
      "\n",
      "Epoch 00738: val_loss did not improve from 48.57585\n",
      "Epoch 739/2000\n",
      "143/143 [==============================] - 93s 650ms/step - loss: 40.3730 - root_mean_squared_error: 6.3524 - mean_absolute_error: 5.1186 - val_loss: 65.1281 - val_root_mean_squared_error: 8.0702 - val_mean_absolute_error: 6.3882\n",
      "\n",
      "Epoch 00739: val_loss did not improve from 48.57585\n",
      "Epoch 740/2000\n",
      "143/143 [==============================] - 92s 641ms/step - loss: 45.6065 - root_mean_squared_error: 6.7508 - mean_absolute_error: 5.3687 - val_loss: 64.5464 - val_root_mean_squared_error: 8.0341 - val_mean_absolute_error: 6.2605\n",
      "\n",
      "Epoch 00740: val_loss did not improve from 48.57585\n",
      "Epoch 741/2000\n",
      "143/143 [==============================] - 92s 644ms/step - loss: 47.8642 - root_mean_squared_error: 6.9147 - mean_absolute_error: 5.5551 - val_loss: 60.6365 - val_root_mean_squared_error: 7.7869 - val_mean_absolute_error: 6.0923\n",
      "\n",
      "Epoch 00741: val_loss did not improve from 48.57585\n",
      "Epoch 742/2000\n",
      "143/143 [==============================] - 93s 652ms/step - loss: 44.2681 - root_mean_squared_error: 6.6525 - mean_absolute_error: 5.3457 - val_loss: 57.9899 - val_root_mean_squared_error: 7.6151 - val_mean_absolute_error: 6.2434\n",
      "\n",
      "Epoch 00742: val_loss did not improve from 48.57585\n",
      "Epoch 743/2000\n",
      "143/143 [==============================] - 89s 620ms/step - loss: 44.4698 - root_mean_squared_error: 6.6622 - mean_absolute_error: 5.3976 - val_loss: 62.0356 - val_root_mean_squared_error: 7.8763 - val_mean_absolute_error: 6.0494\n",
      "\n",
      "Epoch 00743: val_loss did not improve from 48.57585\n",
      "Epoch 744/2000\n",
      "143/143 [==============================] - 91s 639ms/step - loss: 40.7684 - root_mean_squared_error: 6.3765 - mean_absolute_error: 5.1175 - val_loss: 56.4056 - val_root_mean_squared_error: 7.5104 - val_mean_absolute_error: 6.1070\n",
      "\n",
      "Epoch 00744: val_loss did not improve from 48.57585\n",
      "Epoch 745/2000\n",
      "143/143 [==============================] - 91s 639ms/step - loss: 40.5722 - root_mean_squared_error: 6.3680 - mean_absolute_error: 5.1427 - val_loss: 52.8931 - val_root_mean_squared_error: 7.2728 - val_mean_absolute_error: 5.8678\n",
      "\n",
      "Epoch 00745: val_loss did not improve from 48.57585\n",
      "Epoch 746/2000\n",
      "143/143 [==============================] - 91s 640ms/step - loss: 44.1470 - root_mean_squared_error: 6.6401 - mean_absolute_error: 5.2954 - val_loss: 55.7972 - val_root_mean_squared_error: 7.4698 - val_mean_absolute_error: 5.8647\n",
      "\n",
      "Epoch 00746: val_loss did not improve from 48.57585\n",
      "Epoch 747/2000\n",
      "143/143 [==============================] - 94s 661ms/step - loss: 45.7139 - root_mean_squared_error: 6.7571 - mean_absolute_error: 5.5499 - val_loss: 68.8054 - val_root_mean_squared_error: 8.2949 - val_mean_absolute_error: 6.6052\n",
      "\n",
      "Epoch 00747: val_loss did not improve from 48.57585\n",
      "Epoch 748/2000\n",
      "143/143 [==============================] - 90s 633ms/step - loss: 48.6718 - root_mean_squared_error: 6.9714 - mean_absolute_error: 5.6735 - val_loss: 59.1852 - val_root_mean_squared_error: 7.6932 - val_mean_absolute_error: 6.1245\n",
      "\n",
      "Epoch 00748: val_loss did not improve from 48.57585\n",
      "Epoch 749/2000\n",
      "143/143 [==============================] - 92s 647ms/step - loss: 47.1449 - root_mean_squared_error: 6.8630 - mean_absolute_error: 5.5285 - val_loss: 63.0500 - val_root_mean_squared_error: 7.9404 - val_mean_absolute_error: 6.2515\n",
      "\n",
      "Epoch 00749: val_loss did not improve from 48.57585\n",
      "Epoch 750/2000\n",
      "143/143 [==============================] - 93s 648ms/step - loss: 40.9184 - root_mean_squared_error: 6.3944 - mean_absolute_error: 5.2432 - val_loss: 63.6911 - val_root_mean_squared_error: 7.9807 - val_mean_absolute_error: 6.4099\n",
      "\n",
      "Epoch 00750: val_loss did not improve from 48.57585\n",
      "Epoch 751/2000\n",
      "143/143 [==============================] - 92s 643ms/step - loss: 47.5692 - root_mean_squared_error: 6.8961 - mean_absolute_error: 5.4350 - val_loss: 67.6534 - val_root_mean_squared_error: 8.2252 - val_mean_absolute_error: 6.2785\n",
      "\n",
      "Epoch 00751: val_loss did not improve from 48.57585\n",
      "Epoch 752/2000\n",
      "143/143 [==============================] - 92s 641ms/step - loss: 49.9120 - root_mean_squared_error: 7.0617 - mean_absolute_error: 5.7518 - val_loss: 72.0629 - val_root_mean_squared_error: 8.4890 - val_mean_absolute_error: 6.7247\n",
      "\n",
      "Epoch 00752: val_loss did not improve from 48.57585\n",
      "Epoch 753/2000\n",
      "143/143 [==============================] - 91s 639ms/step - loss: 45.3403 - root_mean_squared_error: 6.7278 - mean_absolute_error: 5.4278 - val_loss: 60.4910 - val_root_mean_squared_error: 7.7776 - val_mean_absolute_error: 6.2130\n",
      "\n",
      "Epoch 00753: val_loss did not improve from 48.57585\n",
      "Epoch 754/2000\n",
      "143/143 [==============================] - 91s 637ms/step - loss: 45.5559 - root_mean_squared_error: 6.7476 - mean_absolute_error: 5.3779 - val_loss: 64.8879 - val_root_mean_squared_error: 8.0553 - val_mean_absolute_error: 6.3595\n",
      "\n",
      "Epoch 00754: val_loss did not improve from 48.57585\n",
      "Epoch 755/2000\n",
      "143/143 [==============================] - 89s 624ms/step - loss: 43.8599 - root_mean_squared_error: 6.6169 - mean_absolute_error: 5.2974 - val_loss: 64.2379 - val_root_mean_squared_error: 8.0149 - val_mean_absolute_error: 6.3619\n",
      "\n",
      "Epoch 00755: val_loss did not improve from 48.57585\n",
      "Epoch 756/2000\n",
      "143/143 [==============================] - 91s 636ms/step - loss: 50.6647 - root_mean_squared_error: 7.1113 - mean_absolute_error: 5.7988 - val_loss: 59.2031 - val_root_mean_squared_error: 7.6944 - val_mean_absolute_error: 5.9933\n",
      "\n",
      "Epoch 00756: val_loss did not improve from 48.57585\n",
      "Epoch 757/2000\n",
      "143/143 [==============================] - 91s 640ms/step - loss: 46.0739 - root_mean_squared_error: 6.7855 - mean_absolute_error: 5.4629 - val_loss: 54.4267 - val_root_mean_squared_error: 7.3774 - val_mean_absolute_error: 5.9424\n",
      "\n",
      "Epoch 00757: val_loss did not improve from 48.57585\n",
      "Epoch 758/2000\n",
      "143/143 [==============================] - 91s 637ms/step - loss: 46.9531 - root_mean_squared_error: 6.8497 - mean_absolute_error: 5.5414 - val_loss: 59.1462 - val_root_mean_squared_error: 7.6907 - val_mean_absolute_error: 6.3636\n",
      "\n",
      "Epoch 00758: val_loss did not improve from 48.57585\n",
      "Epoch 759/2000\n",
      "143/143 [==============================] - 93s 654ms/step - loss: 45.8746 - root_mean_squared_error: 6.7707 - mean_absolute_error: 5.3582 - val_loss: 56.9977 - val_root_mean_squared_error: 7.5497 - val_mean_absolute_error: 5.9605\n",
      "\n",
      "Epoch 00759: val_loss did not improve from 48.57585\n",
      "Epoch 760/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 93s 651ms/step - loss: 46.5473 - root_mean_squared_error: 6.8148 - mean_absolute_error: 5.5335 - val_loss: 65.3938 - val_root_mean_squared_error: 8.0866 - val_mean_absolute_error: 6.4036\n",
      "\n",
      "Epoch 00760: val_loss did not improve from 48.57585\n",
      "Epoch 761/2000\n",
      "143/143 [==============================] - 91s 639ms/step - loss: 51.9924 - root_mean_squared_error: 7.2091 - mean_absolute_error: 5.7113 - val_loss: 59.9219 - val_root_mean_squared_error: 7.7409 - val_mean_absolute_error: 6.0618\n",
      "\n",
      "Epoch 00761: val_loss did not improve from 48.57585\n",
      "Epoch 762/2000\n",
      "143/143 [==============================] - 90s 632ms/step - loss: 47.6922 - root_mean_squared_error: 6.9001 - mean_absolute_error: 5.5959 - val_loss: 63.3959 - val_root_mean_squared_error: 7.9622 - val_mean_absolute_error: 6.2361\n",
      "\n",
      "Epoch 00762: val_loss did not improve from 48.57585\n",
      "Epoch 763/2000\n",
      "143/143 [==============================] - 90s 631ms/step - loss: 49.0940 - root_mean_squared_error: 7.0048 - mean_absolute_error: 5.5168 - val_loss: 58.6813 - val_root_mean_squared_error: 7.6604 - val_mean_absolute_error: 6.1952\n",
      "\n",
      "Epoch 00763: val_loss did not improve from 48.57585\n",
      "Epoch 764/2000\n",
      "143/143 [==============================] - 93s 649ms/step - loss: 48.3448 - root_mean_squared_error: 6.9499 - mean_absolute_error: 5.6183 - val_loss: 55.2709 - val_root_mean_squared_error: 7.4344 - val_mean_absolute_error: 5.9920\n",
      "\n",
      "Epoch 00764: val_loss did not improve from 48.57585\n",
      "Epoch 765/2000\n",
      "143/143 [==============================] - 90s 629ms/step - loss: 49.5563 - root_mean_squared_error: 7.0356 - mean_absolute_error: 5.5692 - val_loss: 60.1409 - val_root_mean_squared_error: 7.7551 - val_mean_absolute_error: 6.2243\n",
      "\n",
      "Epoch 00765: val_loss did not improve from 48.57585\n",
      "Epoch 766/2000\n",
      "143/143 [==============================] - 92s 641ms/step - loss: 45.7197 - root_mean_squared_error: 6.7574 - mean_absolute_error: 5.3957 - val_loss: 69.1674 - val_root_mean_squared_error: 8.3167 - val_mean_absolute_error: 6.6480\n",
      "\n",
      "Epoch 00766: val_loss did not improve from 48.57585\n",
      "Epoch 767/2000\n",
      "143/143 [==============================] - 89s 625ms/step - loss: 45.1913 - root_mean_squared_error: 6.7165 - mean_absolute_error: 5.4391 - val_loss: 54.1921 - val_root_mean_squared_error: 7.3615 - val_mean_absolute_error: 6.0134\n",
      "\n",
      "Epoch 00767: val_loss did not improve from 48.57585\n",
      "Epoch 768/2000\n",
      "143/143 [==============================] - 90s 632ms/step - loss: 47.5022 - root_mean_squared_error: 6.8859 - mean_absolute_error: 5.4718 - val_loss: 62.5042 - val_root_mean_squared_error: 7.9060 - val_mean_absolute_error: 6.3545\n",
      "\n",
      "Epoch 00768: val_loss did not improve from 48.57585\n",
      "Epoch 769/2000\n",
      "143/143 [==============================] - 91s 638ms/step - loss: 44.5265 - root_mean_squared_error: 6.6665 - mean_absolute_error: 5.3966 - val_loss: 53.8133 - val_root_mean_squared_error: 7.3358 - val_mean_absolute_error: 6.0168\n",
      "\n",
      "Epoch 00769: val_loss did not improve from 48.57585\n",
      "Epoch 770/2000\n",
      "143/143 [==============================] - 89s 625ms/step - loss: 50.4195 - root_mean_squared_error: 7.0954 - mean_absolute_error: 5.7163 - val_loss: 60.5783 - val_root_mean_squared_error: 7.7832 - val_mean_absolute_error: 6.1851\n",
      "\n",
      "Epoch 00770: val_loss did not improve from 48.57585\n",
      "Epoch 771/2000\n",
      "143/143 [==============================] - 89s 623ms/step - loss: 47.0156 - root_mean_squared_error: 6.8535 - mean_absolute_error: 5.5837 - val_loss: 62.5334 - val_root_mean_squared_error: 7.9078 - val_mean_absolute_error: 6.3867\n",
      "\n",
      "Epoch 00771: val_loss did not improve from 48.57585\n",
      "Epoch 772/2000\n",
      "143/143 [==============================] - 90s 632ms/step - loss: 48.2697 - root_mean_squared_error: 6.9460 - mean_absolute_error: 5.5798 - val_loss: 64.6388 - val_root_mean_squared_error: 8.0398 - val_mean_absolute_error: 6.3477\n",
      "\n",
      "Epoch 00772: val_loss did not improve from 48.57585\n",
      "Epoch 773/2000\n",
      "143/143 [==============================] - 91s 637ms/step - loss: 43.3872 - root_mean_squared_error: 6.5833 - mean_absolute_error: 5.2745 - val_loss: 63.0265 - val_root_mean_squared_error: 7.9389 - val_mean_absolute_error: 6.2816\n",
      "\n",
      "Epoch 00773: val_loss did not improve from 48.57585\n",
      "Epoch 774/2000\n",
      "143/143 [==============================] - 92s 646ms/step - loss: 44.8469 - root_mean_squared_error: 6.6939 - mean_absolute_error: 5.3608 - val_loss: 54.4390 - val_root_mean_squared_error: 7.3783 - val_mean_absolute_error: 5.7427\n",
      "\n",
      "Epoch 00774: val_loss did not improve from 48.57585\n",
      "Epoch 775/2000\n",
      "143/143 [==============================] - 92s 641ms/step - loss: 43.1621 - root_mean_squared_error: 6.5563 - mean_absolute_error: 5.2742 - val_loss: 55.7235 - val_root_mean_squared_error: 7.4648 - val_mean_absolute_error: 5.9927\n",
      "\n",
      "Epoch 00775: val_loss did not improve from 48.57585\n",
      "Epoch 776/2000\n",
      "143/143 [==============================] - 93s 650ms/step - loss: 45.0802 - root_mean_squared_error: 6.7114 - mean_absolute_error: 5.3844 - val_loss: 57.1535 - val_root_mean_squared_error: 7.5600 - val_mean_absolute_error: 5.9515\n",
      "\n",
      "Epoch 00776: val_loss did not improve from 48.57585\n",
      "Epoch 777/2000\n",
      "143/143 [==============================] - 89s 622ms/step - loss: 47.3785 - root_mean_squared_error: 6.8812 - mean_absolute_error: 5.3913 - val_loss: 69.2760 - val_root_mean_squared_error: 8.3232 - val_mean_absolute_error: 6.6729\n",
      "\n",
      "Epoch 00777: val_loss did not improve from 48.57585\n",
      "Epoch 778/2000\n",
      "143/143 [==============================] - 91s 636ms/step - loss: 45.9938 - root_mean_squared_error: 6.7800 - mean_absolute_error: 5.3565 - val_loss: 63.2728 - val_root_mean_squared_error: 7.9544 - val_mean_absolute_error: 6.2131\n",
      "\n",
      "Epoch 00778: val_loss did not improve from 48.57585\n",
      "Epoch 779/2000\n",
      "143/143 [==============================] - 91s 637ms/step - loss: 50.1648 - root_mean_squared_error: 7.0798 - mean_absolute_error: 5.6581 - val_loss: 59.9003 - val_root_mean_squared_error: 7.7395 - val_mean_absolute_error: 6.2873\n",
      "\n",
      "Epoch 00779: val_loss did not improve from 48.57585\n",
      "Epoch 780/2000\n",
      "143/143 [==============================] - 93s 651ms/step - loss: 42.4216 - root_mean_squared_error: 6.5102 - mean_absolute_error: 5.2287 - val_loss: 56.9105 - val_root_mean_squared_error: 7.5439 - val_mean_absolute_error: 6.0888\n",
      "\n",
      "Epoch 00780: val_loss did not improve from 48.57585\n",
      "Epoch 781/2000\n",
      "143/143 [==============================] - 91s 636ms/step - loss: 47.9222 - root_mean_squared_error: 6.9157 - mean_absolute_error: 5.4528 - val_loss: 56.3934 - val_root_mean_squared_error: 7.5096 - val_mean_absolute_error: 6.0137\n",
      "\n",
      "Epoch 00781: val_loss did not improve from 48.57585\n",
      "Epoch 782/2000\n",
      "143/143 [==============================] - 88s 616ms/step - loss: 44.9053 - root_mean_squared_error: 6.6986 - mean_absolute_error: 5.3223 - val_loss: 54.1836 - val_root_mean_squared_error: 7.3610 - val_mean_absolute_error: 5.8895\n",
      "\n",
      "Epoch 00782: val_loss did not improve from 48.57585\n",
      "Epoch 783/2000\n",
      "143/143 [==============================] - 89s 623ms/step - loss: 50.6327 - root_mean_squared_error: 7.1142 - mean_absolute_error: 5.7346 - val_loss: 60.2521 - val_root_mean_squared_error: 7.7622 - val_mean_absolute_error: 6.2975\n",
      "\n",
      "Epoch 00783: val_loss did not improve from 48.57585\n",
      "Epoch 784/2000\n",
      "143/143 [==============================] - 91s 638ms/step - loss: 51.8681 - root_mean_squared_error: 7.1968 - mean_absolute_error: 5.7061 - val_loss: 57.3497 - val_root_mean_squared_error: 7.5730 - val_mean_absolute_error: 6.0622\n",
      "\n",
      "Epoch 00784: val_loss did not improve from 48.57585\n",
      "Epoch 785/2000\n",
      "143/143 [==============================] - 91s 639ms/step - loss: 48.2363 - root_mean_squared_error: 6.9359 - mean_absolute_error: 5.4923 - val_loss: 63.7512 - val_root_mean_squared_error: 7.9844 - val_mean_absolute_error: 6.4807\n",
      "\n",
      "Epoch 00785: val_loss did not improve from 48.57585\n",
      "Epoch 786/2000\n",
      "143/143 [==============================] - 89s 625ms/step - loss: 44.1062 - root_mean_squared_error: 6.6384 - mean_absolute_error: 5.2786 - val_loss: 63.9916 - val_root_mean_squared_error: 7.9995 - val_mean_absolute_error: 6.5210\n",
      "\n",
      "Epoch 00786: val_loss did not improve from 48.57585\n",
      "Epoch 787/2000\n",
      "143/143 [==============================] - 90s 633ms/step - loss: 49.9538 - root_mean_squared_error: 7.0662 - mean_absolute_error: 5.7604 - val_loss: 67.3520 - val_root_mean_squared_error: 8.2068 - val_mean_absolute_error: 6.4903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00787: val_loss did not improve from 48.57585\n",
      "Epoch 788/2000\n",
      "143/143 [==============================] - 90s 633ms/step - loss: 42.3058 - root_mean_squared_error: 6.5030 - mean_absolute_error: 5.1744 - val_loss: 57.1928 - val_root_mean_squared_error: 7.5626 - val_mean_absolute_error: 6.1126\n",
      "\n",
      "Epoch 00788: val_loss did not improve from 48.57585\n",
      "Epoch 789/2000\n",
      "143/143 [==============================] - 91s 635ms/step - loss: 46.7806 - root_mean_squared_error: 6.8373 - mean_absolute_error: 5.6046 - val_loss: 71.4061 - val_root_mean_squared_error: 8.4502 - val_mean_absolute_error: 6.6661\n",
      "\n",
      "Epoch 00789: val_loss did not improve from 48.57585\n",
      "Epoch 790/2000\n",
      "143/143 [==============================] - 90s 626ms/step - loss: 43.1648 - root_mean_squared_error: 6.5648 - mean_absolute_error: 5.3594 - val_loss: 69.0603 - val_root_mean_squared_error: 8.3103 - val_mean_absolute_error: 6.6066\n",
      "\n",
      "Epoch 00790: val_loss did not improve from 48.57585\n",
      "Epoch 791/2000\n",
      "143/143 [==============================] - 91s 634ms/step - loss: 50.4081 - root_mean_squared_error: 7.0916 - mean_absolute_error: 5.6400 - val_loss: 55.8158 - val_root_mean_squared_error: 7.4710 - val_mean_absolute_error: 6.0654\n",
      "\n",
      "Epoch 00791: val_loss did not improve from 48.57585\n",
      "Epoch 792/2000\n",
      "143/143 [==============================] - 90s 628ms/step - loss: 52.1038 - root_mean_squared_error: 7.2161 - mean_absolute_error: 5.7206 - val_loss: 62.4780 - val_root_mean_squared_error: 7.9043 - val_mean_absolute_error: 6.2671\n",
      "\n",
      "Epoch 00792: val_loss did not improve from 48.57585\n",
      "Epoch 793/2000\n",
      "143/143 [==============================] - 91s 638ms/step - loss: 51.2396 - root_mean_squared_error: 7.1569 - mean_absolute_error: 5.7526 - val_loss: 59.3748 - val_root_mean_squared_error: 7.7055 - val_mean_absolute_error: 6.1226\n",
      "\n",
      "Epoch 00793: val_loss did not improve from 48.57585\n",
      "Epoch 794/2000\n",
      "143/143 [==============================] - 90s 628ms/step - loss: 45.7020 - root_mean_squared_error: 6.7567 - mean_absolute_error: 5.5118 - val_loss: 61.0450 - val_root_mean_squared_error: 7.8131 - val_mean_absolute_error: 6.2390\n",
      "\n",
      "Epoch 00794: val_loss did not improve from 48.57585\n",
      "Epoch 795/2000\n",
      "143/143 [==============================] - 89s 623ms/step - loss: 47.7033 - root_mean_squared_error: 6.9050 - mean_absolute_error: 5.4688 - val_loss: 63.0761 - val_root_mean_squared_error: 7.9420 - val_mean_absolute_error: 6.2563\n",
      "\n",
      "Epoch 00795: val_loss did not improve from 48.57585\n",
      "Epoch 796/2000\n",
      "143/143 [==============================] - 91s 638ms/step - loss: 42.2462 - root_mean_squared_error: 6.4931 - mean_absolute_error: 5.2005 - val_loss: 57.1763 - val_root_mean_squared_error: 7.5615 - val_mean_absolute_error: 6.0400\n",
      "\n",
      "Epoch 00796: val_loss did not improve from 48.57585\n",
      "Epoch 797/2000\n",
      "143/143 [==============================] - 91s 640ms/step - loss: 46.5181 - root_mean_squared_error: 6.8044 - mean_absolute_error: 5.4329 - val_loss: 70.1471 - val_root_mean_squared_error: 8.3754 - val_mean_absolute_error: 6.5775\n",
      "\n",
      "Epoch 00797: val_loss did not improve from 48.57585\n",
      "Epoch 798/2000\n",
      "143/143 [==============================] - 90s 630ms/step - loss: 46.4920 - root_mean_squared_error: 6.8141 - mean_absolute_error: 5.4055 - val_loss: 60.0438 - val_root_mean_squared_error: 7.7488 - val_mean_absolute_error: 6.2180\n",
      "\n",
      "Epoch 00798: val_loss did not improve from 48.57585\n",
      "Epoch 799/2000\n",
      "143/143 [==============================] - 91s 641ms/step - loss: 48.0079 - root_mean_squared_error: 6.9273 - mean_absolute_error: 5.5360 - val_loss: 56.0285 - val_root_mean_squared_error: 7.4852 - val_mean_absolute_error: 6.0193\n",
      "\n",
      "Epoch 00799: val_loss did not improve from 48.57585\n",
      "Epoch 800/2000\n",
      "143/143 [==============================] - 92s 641ms/step - loss: 38.8510 - root_mean_squared_error: 6.2290 - mean_absolute_error: 4.9387 - val_loss: 54.5909 - val_root_mean_squared_error: 7.3886 - val_mean_absolute_error: 5.8095\n",
      "\n",
      "Epoch 00800: val_loss did not improve from 48.57585\n",
      "Epoch 801/2000\n",
      "143/143 [==============================] - 92s 646ms/step - loss: 45.8765 - root_mean_squared_error: 6.7711 - mean_absolute_error: 5.4974 - val_loss: 51.9241 - val_root_mean_squared_error: 7.2058 - val_mean_absolute_error: 5.9237\n",
      "\n",
      "Epoch 00801: val_loss did not improve from 48.57585\n",
      "Epoch 802/2000\n",
      "143/143 [==============================] - 91s 635ms/step - loss: 45.7624 - root_mean_squared_error: 6.7599 - mean_absolute_error: 5.4080 - val_loss: 60.5819 - val_root_mean_squared_error: 7.7834 - val_mean_absolute_error: 6.0897\n",
      "\n",
      "Epoch 00802: val_loss did not improve from 48.57585\n",
      "Epoch 803/2000\n",
      "143/143 [==============================] - 91s 638ms/step - loss: 48.3893 - root_mean_squared_error: 6.9525 - mean_absolute_error: 5.6225 - val_loss: 65.7597 - val_root_mean_squared_error: 8.1092 - val_mean_absolute_error: 6.6200\n",
      "\n",
      "Epoch 00803: val_loss did not improve from 48.57585\n",
      "Epoch 804/2000\n",
      "143/143 [==============================] - 92s 647ms/step - loss: 47.5226 - root_mean_squared_error: 6.8887 - mean_absolute_error: 5.4114 - val_loss: 59.8614 - val_root_mean_squared_error: 7.7370 - val_mean_absolute_error: 6.2757\n",
      "\n",
      "Epoch 00804: val_loss did not improve from 48.57585\n",
      "Epoch 805/2000\n",
      "143/143 [==============================] - 90s 632ms/step - loss: 47.4377 - root_mean_squared_error: 6.8802 - mean_absolute_error: 5.5200 - val_loss: 49.4341 - val_root_mean_squared_error: 7.0309 - val_mean_absolute_error: 5.6156\n",
      "\n",
      "Epoch 00805: val_loss did not improve from 48.57585\n",
      "Epoch 806/2000\n",
      "143/143 [==============================] - 92s 646ms/step - loss: 44.8069 - root_mean_squared_error: 6.6914 - mean_absolute_error: 5.3446 - val_loss: 51.9747 - val_root_mean_squared_error: 7.2093 - val_mean_absolute_error: 5.8238\n",
      "\n",
      "Epoch 00806: val_loss did not improve from 48.57585\n",
      "Epoch 807/2000\n",
      "143/143 [==============================] - 90s 633ms/step - loss: 46.9615 - root_mean_squared_error: 6.8457 - mean_absolute_error: 5.5397 - val_loss: 65.7378 - val_root_mean_squared_error: 8.1079 - val_mean_absolute_error: 6.5807\n",
      "\n",
      "Epoch 00807: val_loss did not improve from 48.57585\n",
      "Epoch 808/2000\n",
      "143/143 [==============================] - 90s 627ms/step - loss: 45.9520 - root_mean_squared_error: 6.7760 - mean_absolute_error: 5.4061 - val_loss: 65.5208 - val_root_mean_squared_error: 8.0945 - val_mean_absolute_error: 6.4104\n",
      "\n",
      "Epoch 00808: val_loss did not improve from 48.57585\n",
      "Epoch 809/2000\n",
      "143/143 [==============================] - 93s 652ms/step - loss: 46.6498 - root_mean_squared_error: 6.8283 - mean_absolute_error: 5.3993 - val_loss: 63.4356 - val_root_mean_squared_error: 7.9646 - val_mean_absolute_error: 6.3858\n",
      "\n",
      "Epoch 00809: val_loss did not improve from 48.57585\n",
      "Epoch 810/2000\n",
      "143/143 [==============================] - 91s 636ms/step - loss: 47.1504 - root_mean_squared_error: 6.8653 - mean_absolute_error: 5.5983 - val_loss: 68.5664 - val_root_mean_squared_error: 8.2805 - val_mean_absolute_error: 6.5461\n",
      "\n",
      "Epoch 00810: val_loss did not improve from 48.57585\n",
      "Epoch 811/2000\n",
      "143/143 [==============================] - 92s 642ms/step - loss: 47.1475 - root_mean_squared_error: 6.8635 - mean_absolute_error: 5.4822 - val_loss: 64.4683 - val_root_mean_squared_error: 8.0292 - val_mean_absolute_error: 6.4912\n",
      "\n",
      "Epoch 00811: val_loss did not improve from 48.57585\n",
      "Epoch 812/2000\n",
      "143/143 [==============================] - 91s 635ms/step - loss: 47.6443 - root_mean_squared_error: 6.8980 - mean_absolute_error: 5.4922 - val_loss: 59.7857 - val_root_mean_squared_error: 7.7321 - val_mean_absolute_error: 6.2605\n",
      "\n",
      "Epoch 00812: val_loss did not improve from 48.57585\n",
      "Epoch 813/2000\n",
      "143/143 [==============================] - 92s 641ms/step - loss: 47.9932 - root_mean_squared_error: 6.9250 - mean_absolute_error: 5.4669 - val_loss: 64.0760 - val_root_mean_squared_error: 8.0047 - val_mean_absolute_error: 6.4288\n",
      "\n",
      "Epoch 00813: val_loss did not improve from 48.57585\n",
      "Epoch 814/2000\n",
      "143/143 [==============================] - 91s 638ms/step - loss: 48.6036 - root_mean_squared_error: 6.9678 - mean_absolute_error: 5.6082 - val_loss: 62.5598 - val_root_mean_squared_error: 7.9095 - val_mean_absolute_error: 6.3278\n",
      "\n",
      "Epoch 00814: val_loss did not improve from 48.57585\n",
      "Epoch 815/2000\n",
      "143/143 [==============================] - 89s 626ms/step - loss: 49.9690 - root_mean_squared_error: 7.0669 - mean_absolute_error: 5.7299 - val_loss: 62.9694 - val_root_mean_squared_error: 7.9353 - val_mean_absolute_error: 6.2798\n",
      "\n",
      "Epoch 00815: val_loss did not improve from 48.57585\n",
      "Epoch 816/2000\n",
      "143/143 [==============================] - 92s 642ms/step - loss: 48.2574 - root_mean_squared_error: 6.9455 - mean_absolute_error: 5.5646 - val_loss: 57.8978 - val_root_mean_squared_error: 7.6091 - val_mean_absolute_error: 6.1775\n",
      "\n",
      "Epoch 00816: val_loss did not improve from 48.57585\n",
      "Epoch 817/2000\n",
      "143/143 [==============================] - 92s 645ms/step - loss: 48.1835 - root_mean_squared_error: 6.9337 - mean_absolute_error: 5.5192 - val_loss: 68.9969 - val_root_mean_squared_error: 8.3064 - val_mean_absolute_error: 6.6913\n",
      "\n",
      "Epoch 00817: val_loss did not improve from 48.57585\n",
      "Epoch 818/2000\n",
      "143/143 [==============================] - 92s 640ms/step - loss: 46.0354 - root_mean_squared_error: 6.7762 - mean_absolute_error: 5.4453 - val_loss: 82.1250 - val_root_mean_squared_error: 9.0623 - val_mean_absolute_error: 7.1596\n",
      "\n",
      "Epoch 00818: val_loss did not improve from 48.57585\n",
      "Epoch 819/2000\n",
      "143/143 [==============================] - 91s 635ms/step - loss: 42.8490 - root_mean_squared_error: 6.5394 - mean_absolute_error: 5.2245 - val_loss: 63.8648 - val_root_mean_squared_error: 7.9915 - val_mean_absolute_error: 6.4242\n",
      "\n",
      "Epoch 00819: val_loss did not improve from 48.57585\n",
      "Epoch 820/2000\n",
      "143/143 [==============================] - 92s 641ms/step - loss: 48.2170 - root_mean_squared_error: 6.9303 - mean_absolute_error: 5.4869 - val_loss: 65.6873 - val_root_mean_squared_error: 8.1048 - val_mean_absolute_error: 6.4843\n",
      "\n",
      "Epoch 00820: val_loss did not improve from 48.57585\n",
      "Epoch 821/2000\n",
      "143/143 [==============================] - 86s 602ms/step - loss: 44.4165 - root_mean_squared_error: 6.6596 - mean_absolute_error: 5.3698 - val_loss: 54.8635 - val_root_mean_squared_error: 7.4070 - val_mean_absolute_error: 5.7782\n",
      "\n",
      "Epoch 00821: val_loss did not improve from 48.57585\n",
      "Epoch 822/2000\n",
      "143/143 [==============================] - 81s 569ms/step - loss: 48.4870 - root_mean_squared_error: 6.9592 - mean_absolute_error: 5.5387 - val_loss: 59.4705 - val_root_mean_squared_error: 7.7117 - val_mean_absolute_error: 6.1890\n",
      "\n",
      "Epoch 00822: val_loss did not improve from 48.57585\n",
      "Epoch 823/2000\n",
      "143/143 [==============================] - 84s 591ms/step - loss: 43.1772 - root_mean_squared_error: 6.5663 - mean_absolute_error: 5.2788 - val_loss: 53.6178 - val_root_mean_squared_error: 7.3224 - val_mean_absolute_error: 5.8100\n",
      "\n",
      "Epoch 00823: val_loss did not improve from 48.57585\n",
      "Epoch 824/2000\n",
      "143/143 [==============================] - 86s 602ms/step - loss: 46.3162 - root_mean_squared_error: 6.8018 - mean_absolute_error: 5.4510 - val_loss: 70.3936 - val_root_mean_squared_error: 8.3901 - val_mean_absolute_error: 6.6161\n",
      "\n",
      "Epoch 00824: val_loss did not improve from 48.57585\n",
      "Epoch 825/2000\n",
      "143/143 [==============================] - 87s 610ms/step - loss: 45.6955 - root_mean_squared_error: 6.7583 - mean_absolute_error: 5.3487 - val_loss: 63.7708 - val_root_mean_squared_error: 7.9857 - val_mean_absolute_error: 6.3647\n",
      "\n",
      "Epoch 00825: val_loss did not improve from 48.57585\n",
      "Epoch 826/2000\n",
      "143/143 [==============================] - 87s 609ms/step - loss: 41.9077 - root_mean_squared_error: 6.4692 - mean_absolute_error: 5.1480 - val_loss: 62.6915 - val_root_mean_squared_error: 7.9178 - val_mean_absolute_error: 6.2870\n",
      "\n",
      "Epoch 00826: val_loss did not improve from 48.57585\n",
      "Epoch 827/2000\n",
      "143/143 [==============================] - 87s 605ms/step - loss: 46.5466 - root_mean_squared_error: 6.8211 - mean_absolute_error: 5.5056 - val_loss: 49.9419 - val_root_mean_squared_error: 7.0670 - val_mean_absolute_error: 5.7974\n",
      "\n",
      "Epoch 00827: val_loss did not improve from 48.57585\n",
      "Epoch 828/2000\n",
      "143/143 [==============================] - 86s 601ms/step - loss: 50.2773 - root_mean_squared_error: 7.0843 - mean_absolute_error: 5.6046 - val_loss: 60.3539 - val_root_mean_squared_error: 7.7688 - val_mean_absolute_error: 6.2618\n",
      "\n",
      "Epoch 00828: val_loss did not improve from 48.57585\n",
      "Epoch 829/2000\n",
      "143/143 [==============================] - 90s 628ms/step - loss: 43.3746 - root_mean_squared_error: 6.5846 - mean_absolute_error: 5.2913 - val_loss: 59.4224 - val_root_mean_squared_error: 7.7086 - val_mean_absolute_error: 6.0708\n",
      "\n",
      "Epoch 00829: val_loss did not improve from 48.57585\n",
      "Epoch 830/2000\n",
      "143/143 [==============================] - 90s 633ms/step - loss: 46.4419 - root_mean_squared_error: 6.8129 - mean_absolute_error: 5.4322 - val_loss: 63.6219 - val_root_mean_squared_error: 7.9763 - val_mean_absolute_error: 6.2219\n",
      "\n",
      "Epoch 00830: val_loss did not improve from 48.57585\n",
      "Epoch 831/2000\n",
      "143/143 [==============================] - 2834s 20s/step - loss: 45.0169 - root_mean_squared_error: 6.7081 - mean_absolute_error: 5.4661 - val_loss: 50.6924 - val_root_mean_squared_error: 7.1199 - val_mean_absolute_error: 5.7006\n",
      "\n",
      "Epoch 00831: val_loss did not improve from 48.57585\n",
      "Epoch 832/2000\n",
      "143/143 [==============================] - 88s 613ms/step - loss: 43.3933 - root_mean_squared_error: 6.5858 - mean_absolute_error: 5.2036 - val_loss: 55.7326 - val_root_mean_squared_error: 7.4654 - val_mean_absolute_error: 6.0813\n",
      "\n",
      "Epoch 00832: val_loss did not improve from 48.57585\n",
      "Epoch 833/2000\n",
      "143/143 [==============================] - 87s 611ms/step - loss: 45.1503 - root_mean_squared_error: 6.7168 - mean_absolute_error: 5.3799 - val_loss: 62.0628 - val_root_mean_squared_error: 7.8780 - val_mean_absolute_error: 6.2604\n",
      "\n",
      "Epoch 00833: val_loss did not improve from 48.57585\n",
      "Epoch 834/2000\n",
      "143/143 [==============================] - 82s 575ms/step - loss: 44.4679 - root_mean_squared_error: 6.6642 - mean_absolute_error: 5.2951 - val_loss: 62.1171 - val_root_mean_squared_error: 7.8814 - val_mean_absolute_error: 6.3127\n",
      "\n",
      "Epoch 00834: val_loss did not improve from 48.57585\n",
      "Epoch 835/2000\n",
      "143/143 [==============================] - 83s 581ms/step - loss: 42.7228 - root_mean_squared_error: 6.5235 - mean_absolute_error: 5.2875 - val_loss: 67.9481 - val_root_mean_squared_error: 8.2431 - val_mean_absolute_error: 6.5245\n",
      "\n",
      "Epoch 00835: val_loss did not improve from 48.57585\n",
      "Epoch 836/2000\n",
      "143/143 [==============================] - 84s 591ms/step - loss: 44.2453 - root_mean_squared_error: 6.6504 - mean_absolute_error: 5.2681 - val_loss: 57.9779 - val_root_mean_squared_error: 7.6143 - val_mean_absolute_error: 6.0734\n",
      "\n",
      "Epoch 00836: val_loss did not improve from 48.57585\n",
      "Epoch 837/2000\n",
      "143/143 [==============================] - 86s 601ms/step - loss: 47.7258 - root_mean_squared_error: 6.8955 - mean_absolute_error: 5.4196 - val_loss: 60.8814 - val_root_mean_squared_error: 7.8027 - val_mean_absolute_error: 6.2190\n",
      "\n",
      "Epoch 00837: val_loss did not improve from 48.57585\n",
      "Epoch 838/2000\n",
      "143/143 [==============================] - 82s 575ms/step - loss: 48.0071 - root_mean_squared_error: 6.9281 - mean_absolute_error: 5.6161 - val_loss: 58.6386 - val_root_mean_squared_error: 7.6576 - val_mean_absolute_error: 6.0221\n",
      "\n",
      "Epoch 00838: val_loss did not improve from 48.57585\n",
      "Epoch 839/2000\n",
      "143/143 [==============================] - 82s 576ms/step - loss: 43.6796 - root_mean_squared_error: 6.6060 - mean_absolute_error: 5.3147 - val_loss: 55.8747 - val_root_mean_squared_error: 7.4749 - val_mean_absolute_error: 6.0450\n",
      "\n",
      "Epoch 00839: val_loss did not improve from 48.57585\n",
      "Epoch 840/2000\n",
      "143/143 [==============================] - 84s 585ms/step - loss: 49.8197 - root_mean_squared_error: 7.0489 - mean_absolute_error: 5.6236 - val_loss: 51.8178 - val_root_mean_squared_error: 7.1985 - val_mean_absolute_error: 5.8079\n",
      "\n",
      "Epoch 00840: val_loss did not improve from 48.57585\n",
      "Epoch 841/2000\n",
      "143/143 [==============================] - 82s 577ms/step - loss: 50.2404 - root_mean_squared_error: 7.0860 - mean_absolute_error: 5.7156 - val_loss: 74.2712 - val_root_mean_squared_error: 8.6181 - val_mean_absolute_error: 6.6696\n",
      "\n",
      "Epoch 00841: val_loss did not improve from 48.57585\n",
      "Epoch 842/2000\n",
      "143/143 [==============================] - 82s 574ms/step - loss: 51.1022 - root_mean_squared_error: 7.1413 - mean_absolute_error: 5.7024 - val_loss: 56.7755 - val_root_mean_squared_error: 7.5350 - val_mean_absolute_error: 6.1073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00842: val_loss did not improve from 48.57585\n",
      "Epoch 843/2000\n",
      "143/143 [==============================] - 83s 583ms/step - loss: 46.0476 - root_mean_squared_error: 6.7839 - mean_absolute_error: 5.5289 - val_loss: 69.3073 - val_root_mean_squared_error: 8.3251 - val_mean_absolute_error: 6.5033\n",
      "\n",
      "Epoch 00843: val_loss did not improve from 48.57585\n",
      "Epoch 844/2000\n",
      "143/143 [==============================] - 83s 581ms/step - loss: 48.2691 - root_mean_squared_error: 6.9458 - mean_absolute_error: 5.6355 - val_loss: 58.6813 - val_root_mean_squared_error: 7.6604 - val_mean_absolute_error: 6.1438\n",
      "\n",
      "Epoch 00844: val_loss did not improve from 48.57585\n",
      "Epoch 845/2000\n",
      "143/143 [==============================] - 83s 583ms/step - loss: 47.3390 - root_mean_squared_error: 6.8692 - mean_absolute_error: 5.5207 - val_loss: 70.1871 - val_root_mean_squared_error: 8.3778 - val_mean_absolute_error: 6.4513\n",
      "\n",
      "Epoch 00845: val_loss did not improve from 48.57585\n",
      "Epoch 846/2000\n",
      "143/143 [==============================] - 85s 593ms/step - loss: 44.1453 - root_mean_squared_error: 6.6402 - mean_absolute_error: 5.1859 - val_loss: 56.2219 - val_root_mean_squared_error: 7.4981 - val_mean_absolute_error: 5.8795\n",
      "\n",
      "Epoch 00846: val_loss did not improve from 48.57585\n",
      "Epoch 847/2000\n",
      "143/143 [==============================] - 89s 623ms/step - loss: 41.9508 - root_mean_squared_error: 6.4736 - mean_absolute_error: 5.2211 - val_loss: 54.5567 - val_root_mean_squared_error: 7.3862 - val_mean_absolute_error: 5.7722\n",
      "\n",
      "Epoch 00847: val_loss did not improve from 48.57585\n",
      "Epoch 848/2000\n",
      "143/143 [==============================] - 91s 640ms/step - loss: 47.3810 - root_mean_squared_error: 6.8818 - mean_absolute_error: 5.3747 - val_loss: 63.8331 - val_root_mean_squared_error: 7.9896 - val_mean_absolute_error: 6.2103\n",
      "\n",
      "Epoch 00848: val_loss did not improve from 48.57585\n",
      "Epoch 849/2000\n",
      "143/143 [==============================] - 91s 637ms/step - loss: 46.7506 - root_mean_squared_error: 6.8348 - mean_absolute_error: 5.5201 - val_loss: 72.4669 - val_root_mean_squared_error: 8.5127 - val_mean_absolute_error: 6.7553\n",
      "\n",
      "Epoch 00849: val_loss did not improve from 48.57585\n",
      "Epoch 850/2000\n",
      "143/143 [==============================] - 88s 615ms/step - loss: 44.0918 - root_mean_squared_error: 6.6384 - mean_absolute_error: 5.3676 - val_loss: 63.6351 - val_root_mean_squared_error: 7.9772 - val_mean_absolute_error: 6.3294\n",
      "\n",
      "Epoch 00850: val_loss did not improve from 48.57585\n",
      "Epoch 851/2000\n",
      "143/143 [==============================] - 87s 608ms/step - loss: 46.0726 - root_mean_squared_error: 6.7846 - mean_absolute_error: 5.3785 - val_loss: 54.1239 - val_root_mean_squared_error: 7.3569 - val_mean_absolute_error: 5.8181\n",
      "\n",
      "Epoch 00851: val_loss did not improve from 48.57585\n",
      "Epoch 852/2000\n",
      "143/143 [==============================] - 88s 613ms/step - loss: 46.1753 - root_mean_squared_error: 6.7934 - mean_absolute_error: 5.5258 - val_loss: 57.1919 - val_root_mean_squared_error: 7.5625 - val_mean_absolute_error: 6.0489\n",
      "\n",
      "Epoch 00852: val_loss did not improve from 48.57585\n",
      "Epoch 853/2000\n",
      "143/143 [==============================] - 84s 586ms/step - loss: 47.3636 - root_mean_squared_error: 6.8777 - mean_absolute_error: 5.4861 - val_loss: 63.6046 - val_root_mean_squared_error: 7.9753 - val_mean_absolute_error: 6.3117\n",
      "\n",
      "Epoch 00853: val_loss did not improve from 48.57585\n",
      "Epoch 854/2000\n",
      "143/143 [==============================] - 85s 592ms/step - loss: 48.7396 - root_mean_squared_error: 6.9774 - mean_absolute_error: 5.5670 - val_loss: 64.6189 - val_root_mean_squared_error: 8.0386 - val_mean_absolute_error: 6.2218\n",
      "\n",
      "Epoch 00854: val_loss did not improve from 48.57585\n",
      "Epoch 855/2000\n",
      "143/143 [==============================] - 93s 654ms/step - loss: 46.0982 - root_mean_squared_error: 6.7827 - mean_absolute_error: 5.4059 - val_loss: 62.3225 - val_root_mean_squared_error: 7.8945 - val_mean_absolute_error: 6.3743\n",
      "\n",
      "Epoch 00855: val_loss did not improve from 48.57585\n",
      "Epoch 856/2000\n",
      "143/143 [==============================] - 92s 644ms/step - loss: 49.2685 - root_mean_squared_error: 7.0176 - mean_absolute_error: 5.7272 - val_loss: 67.1421 - val_root_mean_squared_error: 8.1940 - val_mean_absolute_error: 6.4728\n",
      "\n",
      "Epoch 00856: val_loss did not improve from 48.57585\n",
      "Epoch 857/2000\n",
      "143/143 [==============================] - 94s 658ms/step - loss: 44.5011 - root_mean_squared_error: 6.6694 - mean_absolute_error: 5.3044 - val_loss: 63.8144 - val_root_mean_squared_error: 7.9884 - val_mean_absolute_error: 6.3768\n",
      "\n",
      "Epoch 00857: val_loss did not improve from 48.57585\n",
      "Epoch 858/2000\n",
      "143/143 [==============================] - 90s 633ms/step - loss: 49.3177 - root_mean_squared_error: 7.0184 - mean_absolute_error: 5.5769 - val_loss: 57.4309 - val_root_mean_squared_error: 7.5783 - val_mean_absolute_error: 6.1024\n",
      "\n",
      "Epoch 00858: val_loss did not improve from 48.57585\n",
      "Epoch 859/2000\n",
      "143/143 [==============================] - 89s 620ms/step - loss: 50.9238 - root_mean_squared_error: 7.1309 - mean_absolute_error: 5.6939 - val_loss: 68.8779 - val_root_mean_squared_error: 8.2993 - val_mean_absolute_error: 6.6729\n",
      "\n",
      "Epoch 00859: val_loss did not improve from 48.57585\n",
      "Epoch 860/2000\n",
      "143/143 [==============================] - 88s 613ms/step - loss: 46.9210 - root_mean_squared_error: 6.8449 - mean_absolute_error: 5.5228 - val_loss: 61.1467 - val_root_mean_squared_error: 7.8196 - val_mean_absolute_error: 6.4033\n",
      "\n",
      "Epoch 00860: val_loss did not improve from 48.57585\n",
      "Epoch 861/2000\n",
      "143/143 [==============================] - 85s 598ms/step - loss: 50.9134 - root_mean_squared_error: 7.1145 - mean_absolute_error: 5.6341 - val_loss: 54.3515 - val_root_mean_squared_error: 7.3723 - val_mean_absolute_error: 5.9940\n",
      "\n",
      "Epoch 00861: val_loss did not improve from 48.57585\n",
      "Epoch 862/2000\n",
      "143/143 [==============================] - 85s 596ms/step - loss: 45.9928 - root_mean_squared_error: 6.7780 - mean_absolute_error: 5.4521 - val_loss: 62.4597 - val_root_mean_squared_error: 7.9031 - val_mean_absolute_error: 6.2075\n",
      "\n",
      "Epoch 00862: val_loss did not improve from 48.57585\n",
      "Epoch 863/2000\n",
      "143/143 [==============================] - 90s 633ms/step - loss: 41.8940 - root_mean_squared_error: 6.4616 - mean_absolute_error: 5.1105 - val_loss: 54.8862 - val_root_mean_squared_error: 7.4085 - val_mean_absolute_error: 5.8474\n",
      "\n",
      "Epoch 00863: val_loss did not improve from 48.57585\n",
      "Epoch 864/2000\n",
      "143/143 [==============================] - 83s 583ms/step - loss: 48.6701 - root_mean_squared_error: 6.9752 - mean_absolute_error: 5.5788 - val_loss: 59.4570 - val_root_mean_squared_error: 7.7108 - val_mean_absolute_error: 6.2159\n",
      "\n",
      "Epoch 00864: val_loss did not improve from 48.57585\n",
      "Epoch 865/2000\n",
      "143/143 [==============================] - 79s 552ms/step - loss: 49.0338 - root_mean_squared_error: 6.9961 - mean_absolute_error: 5.5742 - val_loss: 58.5060 - val_root_mean_squared_error: 7.6489 - val_mean_absolute_error: 6.1975\n",
      "\n",
      "Epoch 00865: val_loss did not improve from 48.57585\n",
      "Epoch 866/2000\n",
      "143/143 [==============================] - 85s 597ms/step - loss: 46.1661 - root_mean_squared_error: 6.7929 - mean_absolute_error: 5.4274 - val_loss: 59.8476 - val_root_mean_squared_error: 7.7361 - val_mean_absolute_error: 6.3197\n",
      "\n",
      "Epoch 00866: val_loss did not improve from 48.57585\n",
      "Epoch 867/2000\n",
      "143/143 [==============================] - 86s 600ms/step - loss: 42.2949 - root_mean_squared_error: 6.4874 - mean_absolute_error: 5.3031 - val_loss: 67.9659 - val_root_mean_squared_error: 8.2441 - val_mean_absolute_error: 6.5114\n",
      "\n",
      "Epoch 00867: val_loss did not improve from 48.57585\n",
      "Epoch 868/2000\n",
      "143/143 [==============================] - 93s 648ms/step - loss: 46.1885 - root_mean_squared_error: 6.7930 - mean_absolute_error: 5.4936 - val_loss: 68.3715 - val_root_mean_squared_error: 8.2687 - val_mean_absolute_error: 6.6417\n",
      "\n",
      "Epoch 00868: val_loss did not improve from 48.57585\n",
      "Epoch 869/2000\n",
      "143/143 [==============================] - 88s 615ms/step - loss: 44.9536 - root_mean_squared_error: 6.7026 - mean_absolute_error: 5.3750 - val_loss: 64.4903 - val_root_mean_squared_error: 8.0306 - val_mean_absolute_error: 6.3891\n",
      "\n",
      "Epoch 00869: val_loss did not improve from 48.57585\n",
      "Epoch 870/2000\n",
      "143/143 [==============================] - 90s 629ms/step - loss: 43.3943 - root_mean_squared_error: 6.5852 - mean_absolute_error: 5.3294 - val_loss: 56.9568 - val_root_mean_squared_error: 7.5470 - val_mean_absolute_error: 6.1108\n",
      "\n",
      "Epoch 00870: val_loss did not improve from 48.57585\n",
      "Epoch 871/2000\n",
      "143/143 [==============================] - 91s 635ms/step - loss: 45.2116 - root_mean_squared_error: 6.7231 - mean_absolute_error: 5.4107 - val_loss: 65.5145 - val_root_mean_squared_error: 8.0941 - val_mean_absolute_error: 6.3973\n",
      "\n",
      "Epoch 00871: val_loss did not improve from 48.57585\n",
      "Epoch 872/2000\n",
      "143/143 [==============================] - 86s 602ms/step - loss: 48.3906 - root_mean_squared_error: 6.9425 - mean_absolute_error: 5.4459 - val_loss: 64.9262 - val_root_mean_squared_error: 8.0577 - val_mean_absolute_error: 6.3670\n",
      "\n",
      "Epoch 00872: val_loss did not improve from 48.57585\n",
      "Epoch 873/2000\n",
      "143/143 [==============================] - 87s 611ms/step - loss: 49.5125 - root_mean_squared_error: 7.0213 - mean_absolute_error: 5.4399 - val_loss: 56.5360 - val_root_mean_squared_error: 7.5190 - val_mean_absolute_error: 6.0589\n",
      "\n",
      "Epoch 00873: val_loss did not improve from 48.57585\n",
      "Epoch 874/2000\n",
      "143/143 [==============================] - 87s 612ms/step - loss: 49.2717 - root_mean_squared_error: 7.0105 - mean_absolute_error: 5.5820 - val_loss: 73.3059 - val_root_mean_squared_error: 8.5619 - val_mean_absolute_error: 6.6920\n",
      "\n",
      "Epoch 00874: val_loss did not improve from 48.57585\n",
      "Epoch 875/2000\n",
      "143/143 [==============================] - 84s 588ms/step - loss: 45.6180 - root_mean_squared_error: 6.7524 - mean_absolute_error: 5.4849 - val_loss: 56.8219 - val_root_mean_squared_error: 7.5380 - val_mean_absolute_error: 6.0711\n",
      "\n",
      "Epoch 00875: val_loss did not improve from 48.57585\n",
      "Epoch 876/2000\n",
      "143/143 [==============================] - 89s 624ms/step - loss: 44.9587 - root_mean_squared_error: 6.7020 - mean_absolute_error: 5.3166 - val_loss: 57.4854 - val_root_mean_squared_error: 7.5819 - val_mean_absolute_error: 5.9617\n",
      "\n",
      "Epoch 00876: val_loss did not improve from 48.57585\n",
      "Epoch 877/2000\n",
      "143/143 [==============================] - 89s 626ms/step - loss: 50.4481 - root_mean_squared_error: 7.0994 - mean_absolute_error: 5.6990 - val_loss: 60.8870 - val_root_mean_squared_error: 7.8030 - val_mean_absolute_error: 6.1027\n",
      "\n",
      "Epoch 00877: val_loss did not improve from 48.57585\n",
      "Epoch 878/2000\n",
      "143/143 [==============================] - 92s 641ms/step - loss: 43.7191 - root_mean_squared_error: 6.6092 - mean_absolute_error: 5.2801 - val_loss: 62.7382 - val_root_mean_squared_error: 7.9207 - val_mean_absolute_error: 6.0850\n",
      "\n",
      "Epoch 00878: val_loss did not improve from 48.57585\n",
      "Epoch 879/2000\n",
      "143/143 [==============================] - 88s 616ms/step - loss: 50.7529 - root_mean_squared_error: 7.1217 - mean_absolute_error: 5.8246 - val_loss: 59.8468 - val_root_mean_squared_error: 7.7361 - val_mean_absolute_error: 6.0236\n",
      "\n",
      "Epoch 00879: val_loss did not improve from 48.57585\n",
      "Epoch 880/2000\n",
      "143/143 [==============================] - 85s 595ms/step - loss: 44.1069 - root_mean_squared_error: 6.6363 - mean_absolute_error: 5.2941 - val_loss: 60.2916 - val_root_mean_squared_error: 7.7648 - val_mean_absolute_error: 6.1334\n",
      "\n",
      "Epoch 00880: val_loss did not improve from 48.57585\n",
      "Epoch 881/2000\n",
      "143/143 [==============================] - 76s 531ms/step - loss: 46.3867 - root_mean_squared_error: 6.8087 - mean_absolute_error: 5.5020 - val_loss: 67.6598 - val_root_mean_squared_error: 8.2256 - val_mean_absolute_error: 6.4584\n",
      "\n",
      "Epoch 00881: val_loss did not improve from 48.57585\n",
      "Epoch 882/2000\n",
      "143/143 [==============================] - 77s 542ms/step - loss: 45.5757 - root_mean_squared_error: 6.7482 - mean_absolute_error: 5.2873 - val_loss: 56.5464 - val_root_mean_squared_error: 7.5197 - val_mean_absolute_error: 5.8280\n",
      "\n",
      "Epoch 00882: val_loss did not improve from 48.57585\n",
      "Epoch 883/2000\n",
      "143/143 [==============================] - 79s 555ms/step - loss: 46.4030 - root_mean_squared_error: 6.8105 - mean_absolute_error: 5.4551 - val_loss: 59.0991 - val_root_mean_squared_error: 7.6876 - val_mean_absolute_error: 6.2413\n",
      "\n",
      "Epoch 00883: val_loss did not improve from 48.57585\n",
      "Epoch 884/2000\n",
      "143/143 [==============================] - 76s 529ms/step - loss: 47.1324 - root_mean_squared_error: 6.8621 - mean_absolute_error: 5.4907 - val_loss: 62.3123 - val_root_mean_squared_error: 7.8938 - val_mean_absolute_error: 6.3660\n",
      "\n",
      "Epoch 00884: val_loss did not improve from 48.57585\n",
      "Epoch 885/2000\n",
      "143/143 [==============================] - 77s 541ms/step - loss: 40.9613 - root_mean_squared_error: 6.3979 - mean_absolute_error: 5.0784 - val_loss: 62.8113 - val_root_mean_squared_error: 7.9254 - val_mean_absolute_error: 6.2162\n",
      "\n",
      "Epoch 00885: val_loss did not improve from 48.57585\n",
      "Epoch 886/2000\n",
      "143/143 [==============================] - 79s 551ms/step - loss: 51.7879 - root_mean_squared_error: 7.1949 - mean_absolute_error: 5.7543 - val_loss: 65.9417 - val_root_mean_squared_error: 8.1204 - val_mean_absolute_error: 6.5903\n",
      "\n",
      "Epoch 00886: val_loss did not improve from 48.57585\n",
      "Epoch 887/2000\n",
      "143/143 [==============================] - 77s 541ms/step - loss: 47.8187 - root_mean_squared_error: 6.9115 - mean_absolute_error: 5.4917 - val_loss: 68.7713 - val_root_mean_squared_error: 8.2928 - val_mean_absolute_error: 6.5571\n",
      "\n",
      "Epoch 00887: val_loss did not improve from 48.57585\n",
      "Epoch 888/2000\n",
      "143/143 [==============================] - 75s 527ms/step - loss: 43.6347 - root_mean_squared_error: 6.5982 - mean_absolute_error: 5.3547 - val_loss: 52.0517 - val_root_mean_squared_error: 7.2147 - val_mean_absolute_error: 5.7327\n",
      "\n",
      "Epoch 00888: val_loss did not improve from 48.57585\n",
      "Epoch 889/2000\n",
      "143/143 [==============================] - 75s 525ms/step - loss: 50.6977 - root_mean_squared_error: 7.1139 - mean_absolute_error: 5.6698 - val_loss: 60.9800 - val_root_mean_squared_error: 7.8090 - val_mean_absolute_error: 6.3201\n",
      "\n",
      "Epoch 00889: val_loss did not improve from 48.57585\n",
      "Epoch 890/2000\n",
      "143/143 [==============================] - 77s 542ms/step - loss: 44.9796 - root_mean_squared_error: 6.7021 - mean_absolute_error: 5.3843 - val_loss: 61.6476 - val_root_mean_squared_error: 7.8516 - val_mean_absolute_error: 6.1111\n",
      "\n",
      "Epoch 00890: val_loss did not improve from 48.57585\n",
      "Epoch 891/2000\n",
      "143/143 [==============================] - 76s 534ms/step - loss: 45.0674 - root_mean_squared_error: 6.7117 - mean_absolute_error: 5.4185 - val_loss: 63.7836 - val_root_mean_squared_error: 7.9865 - val_mean_absolute_error: 6.3190\n",
      "\n",
      "Epoch 00891: val_loss did not improve from 48.57585\n",
      "Epoch 892/2000\n",
      "143/143 [==============================] - 75s 527ms/step - loss: 46.1503 - root_mean_squared_error: 6.7925 - mean_absolute_error: 5.4031 - val_loss: 52.8107 - val_root_mean_squared_error: 7.2671 - val_mean_absolute_error: 5.6561\n",
      "\n",
      "Epoch 00892: val_loss did not improve from 48.57585\n",
      "Epoch 893/2000\n",
      "143/143 [==============================] - 76s 532ms/step - loss: 45.8593 - root_mean_squared_error: 6.7691 - mean_absolute_error: 5.3990 - val_loss: 58.5351 - val_root_mean_squared_error: 7.6508 - val_mean_absolute_error: 6.0566\n",
      "\n",
      "Epoch 00893: val_loss did not improve from 48.57585\n",
      "Epoch 894/2000\n",
      "143/143 [==============================] - 76s 529ms/step - loss: 46.0779 - root_mean_squared_error: 6.7844 - mean_absolute_error: 5.4978 - val_loss: 56.0078 - val_root_mean_squared_error: 7.4838 - val_mean_absolute_error: 5.9795\n",
      "\n",
      "Epoch 00894: val_loss did not improve from 48.57585\n",
      "Epoch 895/2000\n",
      "143/143 [==============================] - 75s 527ms/step - loss: 46.2510 - root_mean_squared_error: 6.7932 - mean_absolute_error: 5.4610 - val_loss: 66.1378 - val_root_mean_squared_error: 8.1325 - val_mean_absolute_error: 6.4884\n",
      "\n",
      "Epoch 00895: val_loss did not improve from 48.57585\n",
      "Epoch 896/2000\n",
      "143/143 [==============================] - 75s 525ms/step - loss: 46.0173 - root_mean_squared_error: 6.7738 - mean_absolute_error: 5.2961 - val_loss: 69.7722 - val_root_mean_squared_error: 8.3530 - val_mean_absolute_error: 6.5836\n",
      "\n",
      "Epoch 00896: val_loss did not improve from 48.57585\n",
      "Epoch 897/2000\n",
      "143/143 [==============================] - 75s 524ms/step - loss: 43.0194 - root_mean_squared_error: 6.5553 - mean_absolute_error: 5.2646 - val_loss: 66.5790 - val_root_mean_squared_error: 8.1596 - val_mean_absolute_error: 6.5849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00897: val_loss did not improve from 48.57585\n",
      "Epoch 898/2000\n",
      "143/143 [==============================] - 75s 528ms/step - loss: 44.7182 - root_mean_squared_error: 6.6848 - mean_absolute_error: 5.3195 - val_loss: 57.5303 - val_root_mean_squared_error: 7.5849 - val_mean_absolute_error: 6.1032\n",
      "\n",
      "Epoch 00898: val_loss did not improve from 48.57585\n",
      "Epoch 899/2000\n",
      "143/143 [==============================] - 75s 523ms/step - loss: 46.4311 - root_mean_squared_error: 6.8112 - mean_absolute_error: 5.4527 - val_loss: 69.5810 - val_root_mean_squared_error: 8.3415 - val_mean_absolute_error: 6.7588\n",
      "\n",
      "Epoch 00899: val_loss did not improve from 48.57585\n",
      "Epoch 900/2000\n",
      "143/143 [==============================] - 75s 526ms/step - loss: 47.6541 - root_mean_squared_error: 6.9011 - mean_absolute_error: 5.5875 - val_loss: 64.2698 - val_root_mean_squared_error: 8.0168 - val_mean_absolute_error: 6.3858\n",
      "\n",
      "Epoch 00900: val_loss did not improve from 48.57585\n",
      "Epoch 901/2000\n",
      "143/143 [==============================] - 75s 523ms/step - loss: 44.2038 - root_mean_squared_error: 6.6459 - mean_absolute_error: 5.2897 - val_loss: 63.0247 - val_root_mean_squared_error: 7.9388 - val_mean_absolute_error: 6.4092\n",
      "\n",
      "Epoch 00901: val_loss did not improve from 48.57585\n",
      "Epoch 902/2000\n",
      "143/143 [==============================] - 75s 527ms/step - loss: 47.3649 - root_mean_squared_error: 6.8776 - mean_absolute_error: 5.5728 - val_loss: 59.1681 - val_root_mean_squared_error: 7.6921 - val_mean_absolute_error: 6.1426\n",
      "\n",
      "Epoch 00902: val_loss did not improve from 48.57585\n",
      "Epoch 903/2000\n",
      "143/143 [==============================] - 74s 521ms/step - loss: 46.9725 - root_mean_squared_error: 6.8467 - mean_absolute_error: 5.5398 - val_loss: 57.8900 - val_root_mean_squared_error: 7.6085 - val_mean_absolute_error: 6.1216\n",
      "\n",
      "Epoch 00903: val_loss did not improve from 48.57585\n",
      "Epoch 904/2000\n",
      "143/143 [==============================] - 75s 524ms/step - loss: 43.6166 - root_mean_squared_error: 6.6027 - mean_absolute_error: 5.3219 - val_loss: 63.1096 - val_root_mean_squared_error: 7.9442 - val_mean_absolute_error: 6.2242\n",
      "\n",
      "Epoch 00904: val_loss did not improve from 48.57585\n",
      "Epoch 905/2000\n",
      "143/143 [==============================] - 75s 525ms/step - loss: 47.7172 - root_mean_squared_error: 6.8998 - mean_absolute_error: 5.5064 - val_loss: 56.7606 - val_root_mean_squared_error: 7.5340 - val_mean_absolute_error: 6.0082\n",
      "\n",
      "Epoch 00905: val_loss did not improve from 48.57585\n",
      "Epoch 906/2000\n",
      "143/143 [==============================] - 75s 522ms/step - loss: 46.6055 - root_mean_squared_error: 6.8202 - mean_absolute_error: 5.3436 - val_loss: 72.6952 - val_root_mean_squared_error: 8.5261 - val_mean_absolute_error: 6.7894\n",
      "\n",
      "Epoch 00906: val_loss did not improve from 48.57585\n",
      "Epoch 907/2000\n",
      "143/143 [==============================] - 74s 520ms/step - loss: 42.8704 - root_mean_squared_error: 6.5441 - mean_absolute_error: 5.2492 - val_loss: 65.3454 - val_root_mean_squared_error: 8.0836 - val_mean_absolute_error: 6.3466\n",
      "\n",
      "Epoch 00907: val_loss did not improve from 48.57585\n",
      "Epoch 908/2000\n",
      "143/143 [==============================] - 74s 520ms/step - loss: 47.4716 - root_mean_squared_error: 6.8853 - mean_absolute_error: 5.5597 - val_loss: 57.3133 - val_root_mean_squared_error: 7.5706 - val_mean_absolute_error: 6.2285\n",
      "\n",
      "Epoch 00908: val_loss did not improve from 48.57585\n",
      "Epoch 909/2000\n",
      "143/143 [==============================] - 76s 530ms/step - loss: 45.5718 - root_mean_squared_error: 6.7479 - mean_absolute_error: 5.4268 - val_loss: 69.5255 - val_root_mean_squared_error: 8.3382 - val_mean_absolute_error: 6.6914\n",
      "\n",
      "Epoch 00909: val_loss did not improve from 48.57585\n",
      "Epoch 910/2000\n",
      "143/143 [==============================] - 76s 530ms/step - loss: 48.0926 - root_mean_squared_error: 6.9298 - mean_absolute_error: 5.4999 - val_loss: 62.1271 - val_root_mean_squared_error: 7.8821 - val_mean_absolute_error: 6.2665\n",
      "\n",
      "Epoch 00910: val_loss did not improve from 48.57585\n",
      "Epoch 911/2000\n",
      "143/143 [==============================] - 78s 544ms/step - loss: 45.6040 - root_mean_squared_error: 6.7513 - mean_absolute_error: 5.5249 - val_loss: 68.0033 - val_root_mean_squared_error: 8.2464 - val_mean_absolute_error: 6.3775\n",
      "\n",
      "Epoch 00911: val_loss did not improve from 48.57585\n",
      "Epoch 912/2000\n",
      "143/143 [==============================] - 78s 543ms/step - loss: 48.1501 - root_mean_squared_error: 6.9372 - mean_absolute_error: 5.5096 - val_loss: 65.1684 - val_root_mean_squared_error: 8.0727 - val_mean_absolute_error: 6.3548\n",
      "\n",
      "Epoch 00912: val_loss did not improve from 48.57585\n",
      "Epoch 913/2000\n",
      "143/143 [==============================] - 79s 552ms/step - loss: 46.9193 - root_mean_squared_error: 6.8481 - mean_absolute_error: 5.4392 - val_loss: 64.4009 - val_root_mean_squared_error: 8.0250 - val_mean_absolute_error: 6.3954\n",
      "\n",
      "Epoch 00913: val_loss did not improve from 48.57585\n",
      "Epoch 914/2000\n",
      "143/143 [==============================] - 79s 550ms/step - loss: 47.2414 - root_mean_squared_error: 6.8718 - mean_absolute_error: 5.5584 - val_loss: 61.5245 - val_root_mean_squared_error: 7.8438 - val_mean_absolute_error: 6.2488\n",
      "\n",
      "Epoch 00914: val_loss did not improve from 48.57585\n",
      "Epoch 915/2000\n",
      "143/143 [==============================] - 77s 540ms/step - loss: 44.4562 - root_mean_squared_error: 6.6663 - mean_absolute_error: 5.3806 - val_loss: 67.3589 - val_root_mean_squared_error: 8.2072 - val_mean_absolute_error: 6.5537\n",
      "\n",
      "Epoch 00915: val_loss did not improve from 48.57585\n",
      "Epoch 916/2000\n",
      "143/143 [==============================] - 79s 550ms/step - loss: 45.7689 - root_mean_squared_error: 6.7605 - mean_absolute_error: 5.3694 - val_loss: 54.6340 - val_root_mean_squared_error: 7.3915 - val_mean_absolute_error: 5.9891\n",
      "\n",
      "Epoch 00916: val_loss did not improve from 48.57585\n",
      "Epoch 917/2000\n",
      "143/143 [==============================] - 79s 555ms/step - loss: 46.1639 - root_mean_squared_error: 6.7928 - mean_absolute_error: 5.4089 - val_loss: 58.7157 - val_root_mean_squared_error: 7.6626 - val_mean_absolute_error: 6.2722\n",
      "\n",
      "Epoch 00917: val_loss did not improve from 48.57585\n",
      "Epoch 918/2000\n",
      "143/143 [==============================] - 87s 607ms/step - loss: 45.2317 - root_mean_squared_error: 6.7243 - mean_absolute_error: 5.4574 - val_loss: 53.4234 - val_root_mean_squared_error: 7.3091 - val_mean_absolute_error: 5.9660\n",
      "\n",
      "Epoch 00918: val_loss did not improve from 48.57585\n",
      "Epoch 919/2000\n",
      "143/143 [==============================] - 84s 591ms/step - loss: 48.3666 - root_mean_squared_error: 6.9467 - mean_absolute_error: 5.5264 - val_loss: 54.1969 - val_root_mean_squared_error: 7.3619 - val_mean_absolute_error: 5.8238\n",
      "\n",
      "Epoch 00919: val_loss did not improve from 48.57585\n",
      "Epoch 920/2000\n",
      "143/143 [==============================] - 89s 621ms/step - loss: 48.5038 - root_mean_squared_error: 6.9510 - mean_absolute_error: 5.6770 - val_loss: 62.6088 - val_root_mean_squared_error: 7.9126 - val_mean_absolute_error: 6.3273\n",
      "\n",
      "Epoch 00920: val_loss did not improve from 48.57585\n",
      "Epoch 921/2000\n",
      "143/143 [==============================] - 90s 632ms/step - loss: 44.0652 - root_mean_squared_error: 6.6366 - mean_absolute_error: 5.3571 - val_loss: 57.6015 - val_root_mean_squared_error: 7.5896 - val_mean_absolute_error: 6.1733\n",
      "\n",
      "Epoch 00921: val_loss did not improve from 48.57585\n",
      "Epoch 922/2000\n",
      "143/143 [==============================] - 93s 653ms/step - loss: 41.6253 - root_mean_squared_error: 6.4480 - mean_absolute_error: 5.0870 - val_loss: 60.4238 - val_root_mean_squared_error: 7.7733 - val_mean_absolute_error: 6.0363\n",
      "\n",
      "Epoch 00922: val_loss did not improve from 48.57585\n",
      "Epoch 923/2000\n",
      "143/143 [==============================] - 83s 578ms/step - loss: 49.0293 - root_mean_squared_error: 7.0009 - mean_absolute_error: 5.6333 - val_loss: 67.3728 - val_root_mean_squared_error: 8.2081 - val_mean_absolute_error: 6.3425\n",
      "\n",
      "Epoch 00923: val_loss did not improve from 48.57585\n",
      "Epoch 924/2000\n",
      "143/143 [==============================] - 85s 591ms/step - loss: 45.0587 - root_mean_squared_error: 6.7063 - mean_absolute_error: 5.3867 - val_loss: 52.8814 - val_root_mean_squared_error: 7.2720 - val_mean_absolute_error: 5.7830\n",
      "\n",
      "Epoch 00924: val_loss did not improve from 48.57585\n",
      "Epoch 925/2000\n",
      "143/143 [==============================] - 77s 537ms/step - loss: 45.9872 - root_mean_squared_error: 6.7789 - mean_absolute_error: 5.4234 - val_loss: 51.6096 - val_root_mean_squared_error: 7.1840 - val_mean_absolute_error: 5.6870\n",
      "\n",
      "Epoch 00925: val_loss did not improve from 48.57585\n",
      "Epoch 926/2000\n",
      "143/143 [==============================] - 78s 545ms/step - loss: 43.7775 - root_mean_squared_error: 6.6144 - mean_absolute_error: 5.2937 - val_loss: 53.6027 - val_root_mean_squared_error: 7.3214 - val_mean_absolute_error: 5.7944\n",
      "\n",
      "Epoch 00926: val_loss did not improve from 48.57585\n",
      "Epoch 927/2000\n",
      "143/143 [==============================] - 76s 535ms/step - loss: 43.9165 - root_mean_squared_error: 6.6203 - mean_absolute_error: 5.2494 - val_loss: 55.8653 - val_root_mean_squared_error: 7.4743 - val_mean_absolute_error: 5.8691\n",
      "\n",
      "Epoch 00927: val_loss did not improve from 48.57585\n",
      "Epoch 928/2000\n",
      "143/143 [==============================] - 76s 535ms/step - loss: 50.3800 - root_mean_squared_error: 7.0944 - mean_absolute_error: 5.7098 - val_loss: 55.7156 - val_root_mean_squared_error: 7.4643 - val_mean_absolute_error: 5.9208\n",
      "\n",
      "Epoch 00928: val_loss did not improve from 48.57585\n",
      "Epoch 929/2000\n",
      "143/143 [==============================] - 78s 549ms/step - loss: 44.7425 - root_mean_squared_error: 6.6853 - mean_absolute_error: 5.2487 - val_loss: 56.9801 - val_root_mean_squared_error: 7.5485 - val_mean_absolute_error: 6.0031\n",
      "\n",
      "Epoch 00929: val_loss did not improve from 48.57585\n",
      "Epoch 930/2000\n",
      "143/143 [==============================] - 77s 540ms/step - loss: 46.4506 - root_mean_squared_error: 6.8108 - mean_absolute_error: 5.4995 - val_loss: 61.6526 - val_root_mean_squared_error: 7.8519 - val_mean_absolute_error: 6.1089\n",
      "\n",
      "Epoch 00930: val_loss did not improve from 48.57585\n",
      "Epoch 931/2000\n",
      "143/143 [==============================] - 77s 540ms/step - loss: 46.4981 - root_mean_squared_error: 6.8162 - mean_absolute_error: 5.3839 - val_loss: 56.6012 - val_root_mean_squared_error: 7.5234 - val_mean_absolute_error: 6.1041\n",
      "\n",
      "Epoch 00931: val_loss did not improve from 48.57585\n",
      "Epoch 932/2000\n",
      "143/143 [==============================] - 76s 535ms/step - loss: 49.7708 - root_mean_squared_error: 7.0398 - mean_absolute_error: 5.5051 - val_loss: 61.0884 - val_root_mean_squared_error: 7.8159 - val_mean_absolute_error: 6.2155\n",
      "\n",
      "Epoch 00932: val_loss did not improve from 48.57585\n",
      "Epoch 933/2000\n",
      "143/143 [==============================] - 78s 548ms/step - loss: 45.9307 - root_mean_squared_error: 6.7708 - mean_absolute_error: 5.4347 - val_loss: 71.5888 - val_root_mean_squared_error: 8.4610 - val_mean_absolute_error: 6.3968\n",
      "\n",
      "Epoch 00933: val_loss did not improve from 48.57585\n",
      "Epoch 934/2000\n",
      "143/143 [==============================] - 77s 536ms/step - loss: 47.3458 - root_mean_squared_error: 6.8756 - mean_absolute_error: 5.4406 - val_loss: 63.5052 - val_root_mean_squared_error: 7.9690 - val_mean_absolute_error: 6.3464\n",
      "\n",
      "Epoch 00934: val_loss did not improve from 48.57585\n",
      "Epoch 935/2000\n",
      "143/143 [==============================] - 77s 537ms/step - loss: 46.9213 - root_mean_squared_error: 6.8480 - mean_absolute_error: 5.5244 - val_loss: 66.6377 - val_root_mean_squared_error: 8.1632 - val_mean_absolute_error: 6.2888\n",
      "\n",
      "Epoch 00935: val_loss did not improve from 48.57585\n",
      "Epoch 936/2000\n",
      "143/143 [==============================] - 77s 537ms/step - loss: 50.4983 - root_mean_squared_error: 7.1033 - mean_absolute_error: 5.6421 - val_loss: 61.0545 - val_root_mean_squared_error: 7.8137 - val_mean_absolute_error: 6.1120\n",
      "\n",
      "Epoch 00936: val_loss did not improve from 48.57585\n",
      "Epoch 937/2000\n",
      "143/143 [==============================] - 77s 535ms/step - loss: 49.6570 - root_mean_squared_error: 7.0449 - mean_absolute_error: 5.7244 - val_loss: 55.6126 - val_root_mean_squared_error: 7.4574 - val_mean_absolute_error: 6.0958\n",
      "\n",
      "Epoch 00937: val_loss did not improve from 48.57585\n",
      "Epoch 938/2000\n",
      "143/143 [==============================] - 80s 562ms/step - loss: 44.5366 - root_mean_squared_error: 6.6714 - mean_absolute_error: 5.3454 - val_loss: 55.6051 - val_root_mean_squared_error: 7.4569 - val_mean_absolute_error: 5.8776\n",
      "\n",
      "Epoch 00938: val_loss did not improve from 48.57585\n",
      "Epoch 939/2000\n",
      "143/143 [==============================] - 78s 549ms/step - loss: 50.4550 - root_mean_squared_error: 7.0998 - mean_absolute_error: 5.6255 - val_loss: 62.0422 - val_root_mean_squared_error: 7.8767 - val_mean_absolute_error: 6.1882\n",
      "\n",
      "Epoch 00939: val_loss did not improve from 48.57585\n",
      "Epoch 940/2000\n",
      "143/143 [==============================] - 78s 547ms/step - loss: 43.7165 - root_mean_squared_error: 6.6066 - mean_absolute_error: 5.2035 - val_loss: 66.0103 - val_root_mean_squared_error: 8.1247 - val_mean_absolute_error: 6.2605\n",
      "\n",
      "Epoch 00940: val_loss did not improve from 48.57585\n",
      "Epoch 941/2000\n",
      "143/143 [==============================] - 78s 545ms/step - loss: 47.2424 - root_mean_squared_error: 6.8692 - mean_absolute_error: 5.3455 - val_loss: 56.4198 - val_root_mean_squared_error: 7.5113 - val_mean_absolute_error: 5.9498\n",
      "\n",
      "Epoch 00941: val_loss did not improve from 48.57585\n",
      "Epoch 942/2000\n",
      "143/143 [==============================] - 78s 545ms/step - loss: 43.8944 - root_mean_squared_error: 6.6222 - mean_absolute_error: 5.2287 - val_loss: 52.2014 - val_root_mean_squared_error: 7.2251 - val_mean_absolute_error: 5.7048\n",
      "\n",
      "Epoch 00942: val_loss did not improve from 48.57585\n",
      "Epoch 943/2000\n",
      "143/143 [==============================] - 77s 541ms/step - loss: 49.7406 - root_mean_squared_error: 7.0498 - mean_absolute_error: 5.6091 - val_loss: 56.6302 - val_root_mean_squared_error: 7.5253 - val_mean_absolute_error: 6.0175\n",
      "\n",
      "Epoch 00943: val_loss did not improve from 48.57585\n",
      "Epoch 944/2000\n",
      "143/143 [==============================] - 79s 553ms/step - loss: 47.6924 - root_mean_squared_error: 6.9046 - mean_absolute_error: 5.5631 - val_loss: 69.4464 - val_root_mean_squared_error: 8.3334 - val_mean_absolute_error: 6.5000\n",
      "\n",
      "Epoch 00944: val_loss did not improve from 48.57585\n",
      "Epoch 945/2000\n",
      "143/143 [==============================] - 79s 552ms/step - loss: 46.4812 - root_mean_squared_error: 6.8144 - mean_absolute_error: 5.3983 - val_loss: 63.3462 - val_root_mean_squared_error: 7.9590 - val_mean_absolute_error: 6.2361\n",
      "\n",
      "Epoch 00945: val_loss did not improve from 48.57585\n",
      "Epoch 946/2000\n",
      "143/143 [==============================] - 80s 557ms/step - loss: 48.3816 - root_mean_squared_error: 6.9451 - mean_absolute_error: 5.6242 - val_loss: 63.0997 - val_root_mean_squared_error: 7.9435 - val_mean_absolute_error: 6.4011\n",
      "\n",
      "Epoch 00946: val_loss did not improve from 48.57585\n",
      "Epoch 947/2000\n",
      "143/143 [==============================] - 79s 555ms/step - loss: 44.9122 - root_mean_squared_error: 6.6992 - mean_absolute_error: 5.3919 - val_loss: 58.6932 - val_root_mean_squared_error: 7.6611 - val_mean_absolute_error: 6.1537\n",
      "\n",
      "Epoch 00947: val_loss did not improve from 48.57585\n",
      "Epoch 948/2000\n",
      "143/143 [==============================] - 80s 559ms/step - loss: 47.0625 - root_mean_squared_error: 6.8557 - mean_absolute_error: 5.4303 - val_loss: 63.0978 - val_root_mean_squared_error: 7.9434 - val_mean_absolute_error: 6.2843\n",
      "\n",
      "Epoch 00948: val_loss did not improve from 48.57585\n",
      "Epoch 949/2000\n",
      "143/143 [==============================] - 79s 556ms/step - loss: 41.1679 - root_mean_squared_error: 6.4147 - mean_absolute_error: 5.2107 - val_loss: 66.2044 - val_root_mean_squared_error: 8.1366 - val_mean_absolute_error: 6.4593\n",
      "\n",
      "Epoch 00949: val_loss did not improve from 48.57585\n",
      "Epoch 950/2000\n",
      "143/143 [==============================] - 78s 549ms/step - loss: 44.2300 - root_mean_squared_error: 6.6482 - mean_absolute_error: 5.2316 - val_loss: 58.9051 - val_root_mean_squared_error: 7.6750 - val_mean_absolute_error: 6.1623\n",
      "\n",
      "Epoch 00950: val_loss did not improve from 48.57585\n",
      "Epoch 951/2000\n",
      "143/143 [==============================] - 78s 545ms/step - loss: 44.0088 - root_mean_squared_error: 6.6307 - mean_absolute_error: 5.2299 - val_loss: 60.1733 - val_root_mean_squared_error: 7.7571 - val_mean_absolute_error: 6.3069\n",
      "\n",
      "Epoch 00951: val_loss did not improve from 48.57585\n",
      "Epoch 952/2000\n",
      "143/143 [==============================] - 78s 544ms/step - loss: 46.5596 - root_mean_squared_error: 6.8206 - mean_absolute_error: 5.4541 - val_loss: 50.3543 - val_root_mean_squared_error: 7.0961 - val_mean_absolute_error: 5.6218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00952: val_loss did not improve from 48.57585\n",
      "Epoch 953/2000\n",
      "143/143 [==============================] - 77s 542ms/step - loss: 45.1069 - root_mean_squared_error: 6.7104 - mean_absolute_error: 5.3789 - val_loss: 53.8673 - val_root_mean_squared_error: 7.3394 - val_mean_absolute_error: 6.0017\n",
      "\n",
      "Epoch 00953: val_loss did not improve from 48.57585\n",
      "Epoch 954/2000\n",
      "143/143 [==============================] - 81s 566ms/step - loss: 44.6838 - root_mean_squared_error: 6.6734 - mean_absolute_error: 5.3476 - val_loss: 72.3202 - val_root_mean_squared_error: 8.5041 - val_mean_absolute_error: 6.9326\n",
      "\n",
      "Epoch 00954: val_loss did not improve from 48.57585\n",
      "Epoch 955/2000\n",
      "143/143 [==============================] - 83s 583ms/step - loss: 44.4511 - root_mean_squared_error: 6.6664 - mean_absolute_error: 5.4114 - val_loss: 57.7540 - val_root_mean_squared_error: 7.5996 - val_mean_absolute_error: 5.8980\n",
      "\n",
      "Epoch 00955: val_loss did not improve from 48.57585\n",
      "Epoch 956/2000\n",
      "143/143 [==============================] - 78s 546ms/step - loss: 44.2960 - root_mean_squared_error: 6.6543 - mean_absolute_error: 5.3740 - val_loss: 60.3946 - val_root_mean_squared_error: 7.7714 - val_mean_absolute_error: 6.3598\n",
      "\n",
      "Epoch 00956: val_loss did not improve from 48.57585\n",
      "Epoch 957/2000\n",
      "143/143 [==============================] - 81s 568ms/step - loss: 43.1776 - root_mean_squared_error: 6.5677 - mean_absolute_error: 5.1873 - val_loss: 60.5488 - val_root_mean_squared_error: 7.7813 - val_mean_absolute_error: 6.1787\n",
      "\n",
      "Epoch 00957: val_loss did not improve from 48.57585\n",
      "Epoch 958/2000\n",
      "143/143 [==============================] - 80s 561ms/step - loss: 44.3374 - root_mean_squared_error: 6.6469 - mean_absolute_error: 5.3457 - val_loss: 60.3351 - val_root_mean_squared_error: 7.7676 - val_mean_absolute_error: 6.1759\n",
      "\n",
      "Epoch 00958: val_loss did not improve from 48.57585\n",
      "Epoch 959/2000\n",
      "143/143 [==============================] - 80s 557ms/step - loss: 48.0794 - root_mean_squared_error: 6.9282 - mean_absolute_error: 5.5571 - val_loss: 60.3614 - val_root_mean_squared_error: 7.7693 - val_mean_absolute_error: 6.3541\n",
      "\n",
      "Epoch 00959: val_loss did not improve from 48.57585\n",
      "Epoch 960/2000\n",
      "143/143 [==============================] - 80s 559ms/step - loss: 45.1319 - root_mean_squared_error: 6.7123 - mean_absolute_error: 5.3558 - val_loss: 58.1679 - val_root_mean_squared_error: 7.6268 - val_mean_absolute_error: 6.1493\n",
      "\n",
      "Epoch 00960: val_loss did not improve from 48.57585\n",
      "Epoch 961/2000\n",
      "143/143 [==============================] - 79s 551ms/step - loss: 47.4168 - root_mean_squared_error: 6.8852 - mean_absolute_error: 5.5960 - val_loss: 59.8294 - val_root_mean_squared_error: 7.7349 - val_mean_absolute_error: 5.9730\n",
      "\n",
      "Epoch 00961: val_loss did not improve from 48.57585\n",
      "Epoch 962/2000\n",
      "143/143 [==============================] - 84s 587ms/step - loss: 51.7765 - root_mean_squared_error: 7.1846 - mean_absolute_error: 5.6683 - val_loss: 58.7502 - val_root_mean_squared_error: 7.6649 - val_mean_absolute_error: 6.0440\n",
      "\n",
      "Epoch 00962: val_loss did not improve from 48.57585\n",
      "Epoch 963/2000\n",
      "143/143 [==============================] - 78s 546ms/step - loss: 48.6370 - root_mean_squared_error: 6.9728 - mean_absolute_error: 5.4842 - val_loss: 60.7233 - val_root_mean_squared_error: 7.7925 - val_mean_absolute_error: 6.2922\n",
      "\n",
      "Epoch 00963: val_loss did not improve from 48.57585\n",
      "Epoch 964/2000\n",
      "143/143 [==============================] - 78s 548ms/step - loss: 46.7857 - root_mean_squared_error: 6.8379 - mean_absolute_error: 5.4830 - val_loss: 58.1511 - val_root_mean_squared_error: 7.6257 - val_mean_absolute_error: 6.1326\n",
      "\n",
      "Epoch 00964: val_loss did not improve from 48.57585\n",
      "Epoch 965/2000\n",
      "143/143 [==============================] - 77s 539ms/step - loss: 45.9376 - root_mean_squared_error: 6.7761 - mean_absolute_error: 5.4790 - val_loss: 58.5959 - val_root_mean_squared_error: 7.6548 - val_mean_absolute_error: 5.8904\n",
      "\n",
      "Epoch 00965: val_loss did not improve from 48.57585\n",
      "Epoch 966/2000\n",
      "143/143 [==============================] - 80s 561ms/step - loss: 45.5175 - root_mean_squared_error: 6.7455 - mean_absolute_error: 5.4698 - val_loss: 62.3591 - val_root_mean_squared_error: 7.8968 - val_mean_absolute_error: 6.4815\n",
      "\n",
      "Epoch 00966: val_loss did not improve from 48.57585\n",
      "Epoch 967/2000\n",
      "143/143 [==============================] - 78s 549ms/step - loss: 44.2823 - root_mean_squared_error: 6.6530 - mean_absolute_error: 5.1669 - val_loss: 53.5455 - val_root_mean_squared_error: 7.3175 - val_mean_absolute_error: 5.8845\n",
      "\n",
      "Epoch 00967: val_loss did not improve from 48.57585\n",
      "Epoch 968/2000\n",
      "143/143 [==============================] - 79s 550ms/step - loss: 50.4141 - root_mean_squared_error: 7.0882 - mean_absolute_error: 5.4484 - val_loss: 53.9060 - val_root_mean_squared_error: 7.3421 - val_mean_absolute_error: 5.7636\n",
      "\n",
      "Epoch 00968: val_loss did not improve from 48.57585\n",
      "Epoch 969/2000\n",
      "143/143 [==============================] - 77s 537ms/step - loss: 45.2436 - root_mean_squared_error: 6.7249 - mean_absolute_error: 5.3622 - val_loss: 57.1964 - val_root_mean_squared_error: 7.5628 - val_mean_absolute_error: 6.0711\n",
      "\n",
      "Epoch 00969: val_loss did not improve from 48.57585\n",
      "Epoch 970/2000\n",
      "143/143 [==============================] - 77s 540ms/step - loss: 49.6224 - root_mean_squared_error: 7.0346 - mean_absolute_error: 5.6952 - val_loss: 49.6984 - val_root_mean_squared_error: 7.0497 - val_mean_absolute_error: 5.6888\n",
      "\n",
      "Epoch 00970: val_loss did not improve from 48.57585\n",
      "Epoch 971/2000\n",
      "143/143 [==============================] - 78s 545ms/step - loss: 45.0528 - root_mean_squared_error: 6.7089 - mean_absolute_error: 5.3391 - val_loss: 66.6248 - val_root_mean_squared_error: 8.1624 - val_mean_absolute_error: 6.3659\n",
      "\n",
      "Epoch 00971: val_loss did not improve from 48.57585\n",
      "Epoch 972/2000\n",
      "143/143 [==============================] - 76s 535ms/step - loss: 48.1979 - root_mean_squared_error: 6.9316 - mean_absolute_error: 5.6785 - val_loss: 65.1114 - val_root_mean_squared_error: 8.0692 - val_mean_absolute_error: 6.1357\n",
      "\n",
      "Epoch 00972: val_loss did not improve from 48.57585\n",
      "Epoch 973/2000\n",
      "143/143 [==============================] - 78s 546ms/step - loss: 46.8682 - root_mean_squared_error: 6.8397 - mean_absolute_error: 5.4964 - val_loss: 61.1385 - val_root_mean_squared_error: 7.8191 - val_mean_absolute_error: 6.2225\n",
      "\n",
      "Epoch 00973: val_loss did not improve from 48.57585\n",
      "Epoch 974/2000\n",
      "143/143 [==============================] - 79s 556ms/step - loss: 48.1519 - root_mean_squared_error: 6.9380 - mean_absolute_error: 5.5928 - val_loss: 56.7633 - val_root_mean_squared_error: 7.5341 - val_mean_absolute_error: 5.8905\n",
      "\n",
      "Epoch 00974: val_loss did not improve from 48.57585\n",
      "Epoch 975/2000\n",
      "143/143 [==============================] - 83s 580ms/step - loss: 45.3819 - root_mean_squared_error: 6.7336 - mean_absolute_error: 5.3810 - val_loss: 67.4434 - val_root_mean_squared_error: 8.2124 - val_mean_absolute_error: 6.5010\n",
      "\n",
      "Epoch 00975: val_loss did not improve from 48.57585\n",
      "Epoch 976/2000\n",
      "143/143 [==============================] - 80s 563ms/step - loss: 43.5218 - root_mean_squared_error: 6.5948 - mean_absolute_error: 5.2115 - val_loss: 60.1312 - val_root_mean_squared_error: 7.7544 - val_mean_absolute_error: 6.1878\n",
      "\n",
      "Epoch 00976: val_loss did not improve from 48.57585\n",
      "Epoch 977/2000\n",
      "143/143 [==============================] - 78s 542ms/step - loss: 47.7522 - root_mean_squared_error: 6.9036 - mean_absolute_error: 5.5447 - val_loss: 61.9937 - val_root_mean_squared_error: 7.8736 - val_mean_absolute_error: 6.1478\n",
      "\n",
      "Epoch 00977: val_loss did not improve from 48.57585\n",
      "Epoch 978/2000\n",
      "143/143 [==============================] - 80s 563ms/step - loss: 45.9461 - root_mean_squared_error: 6.7731 - mean_absolute_error: 5.3848 - val_loss: 62.4874 - val_root_mean_squared_error: 7.9049 - val_mean_absolute_error: 6.2292\n",
      "\n",
      "Epoch 00978: val_loss did not improve from 48.57585\n",
      "Epoch 979/2000\n",
      "143/143 [==============================] - 79s 555ms/step - loss: 42.5346 - root_mean_squared_error: 6.5171 - mean_absolute_error: 5.1601 - val_loss: 66.7663 - val_root_mean_squared_error: 8.1711 - val_mean_absolute_error: 6.3320\n",
      "\n",
      "Epoch 00979: val_loss did not improve from 48.57585\n",
      "Epoch 980/2000\n",
      "143/143 [==============================] - 79s 550ms/step - loss: 45.1271 - root_mean_squared_error: 6.7155 - mean_absolute_error: 5.3580 - val_loss: 68.5569 - val_root_mean_squared_error: 8.2799 - val_mean_absolute_error: 6.4808\n",
      "\n",
      "Epoch 00980: val_loss did not improve from 48.57585\n",
      "Epoch 981/2000\n",
      "143/143 [==============================] - 78s 544ms/step - loss: 43.8457 - root_mean_squared_error: 6.6027 - mean_absolute_error: 5.3379 - val_loss: 63.2883 - val_root_mean_squared_error: 7.9554 - val_mean_absolute_error: 6.2431\n",
      "\n",
      "Epoch 00981: val_loss did not improve from 48.57585\n",
      "Epoch 982/2000\n",
      "143/143 [==============================] - 77s 542ms/step - loss: 48.4552 - root_mean_squared_error: 6.9576 - mean_absolute_error: 5.5734 - val_loss: 60.0800 - val_root_mean_squared_error: 7.7511 - val_mean_absolute_error: 6.2283\n",
      "\n",
      "Epoch 00982: val_loss did not improve from 48.57585\n",
      "Epoch 983/2000\n",
      "143/143 [==============================] - 77s 539ms/step - loss: 47.1564 - root_mean_squared_error: 6.8629 - mean_absolute_error: 5.5506 - val_loss: 61.7998 - val_root_mean_squared_error: 7.8613 - val_mean_absolute_error: 6.3217\n",
      "\n",
      "Epoch 00983: val_loss did not improve from 48.57585\n",
      "Epoch 00983: early stopping\n",
      "CPU times: user 23h 15min 51s, sys: 9h 8min 1s, total: 1d 8h 23min 53s\n",
      "Wall time: 1d 58min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "epochs = 2000\n",
    "\n",
    "# fit network\n",
    "history = model.fit(x=train_generator_noise,\n",
    "                    validation_data=val_generator,\n",
    "                    epochs=epochs, \n",
    "                    callbacks=[checkpointer, earlystopper, reduce_lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. BLSTM-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blstm_lstm_model():\n",
    "    \"\"\" Returns the BLSTM-LSTM model from Kaushik et al. (2019). \"\"\"\n",
    "\n",
    "    # MARK: This model compresses too much in the last phase, check if possible to improve.\n",
    "\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    # BLSTM layer\n",
    "    model.add(Bidirectional(LSTM(256, return_sequences=True), input_shape=input_shape))\n",
    "    model.add(Dropout(.2))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # LSTM layer\n",
    "    model.add(LSTM(128, return_sequences=True))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # LSTM layer\n",
    "    model.add(LSTM(64, return_sequences=False))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # Fully connected layer\n",
    "    model.add(Dense(32))\n",
    "\n",
    "    model.add(Dense(n_outputs))\n",
    "\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_2 (Bidirection (None, 501, 512)          587776    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 501, 512)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 501, 512)          2048      \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 501, 128)          328192    \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 501, 128)          512       \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 64)                49408     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 970,305\n",
      "Trainable params: 968,897\n",
      "Non-trainable params: 1,408\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = blstm_lstm_model()\n",
    "\n",
    "optimizer = Adam(learning_rate=0.01)    \n",
    "              \n",
    "model.compile(loss='mean_squared_error', \n",
    "              optimizer=optimizer, \n",
    "              metrics=[RootMeanSquaredError(), MeanAbsoluteError()])\n",
    "\n",
    "# BLSTM_regressor_01: MSE, Adam, N_average=30, 1500 epochs, ES=250, RLR=50, gaussian=0.01\n",
    "output_filename = 'BLSTM_regressor_01'\n",
    "output_file = os.path.join(PATH_MODELS, output_filename)\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath = output_file + \".hdf5\", monitor='val_loss', verbose=1, save_best_only=True)\n",
    "earlystopper = EarlyStopping(monitor='val_loss', patience=250, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=50, min_lr=0.0001, verbose=1)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "83/83 [==============================] - 81s 973ms/step - loss: 226.7901 - root_mean_squared_error: 15.0596 - mean_absolute_error: 12.0603 - val_loss: 277.5875 - val_root_mean_squared_error: 16.6610 - val_mean_absolute_error: 14.4406\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 277.58746, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/BLSTM_regressor_01.hdf5\n",
      "Epoch 2/1500\n",
      "61/83 [=====================>........] - ETA: 24s - loss: 131.2852 - root_mean_squared_error: 11.4580 - mean_absolute_error: 9.6893"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mne/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mne/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mne/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mne/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mne/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/anaconda3/envs/mne/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mne/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "epochs = 1500\n",
    "\n",
    "# fit network\n",
    "history = model.fit(x=train_generator_noise,\n",
    "                    validation_data=val_generator,\n",
    "                    epochs=epochs, \n",
    "                    callbacks=[checkpointer, earlystopper, reduce_lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. InceptionTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Regressor_Inception:\n",
    "\n",
    "    def __init__(self, output_directory, input_shape, verbose=False, build=True, batch_size=64,\n",
    "                 nb_filters=32, use_residual=True, use_bottleneck=True, depth=6, kernel_size=41, nb_epochs=1500):\n",
    "\n",
    "        self.output_directory = output_directory\n",
    "\n",
    "        self.nb_filters = nb_filters\n",
    "        self.use_residual = use_residual\n",
    "        self.use_bottleneck = use_bottleneck\n",
    "        self.depth = depth\n",
    "        self.kernel_size = kernel_size - 1\n",
    "        self.callbacks = None\n",
    "        self.batch_size = batch_size\n",
    "        self.bottleneck_size = 32\n",
    "        self.nb_epochs = nb_epochs\n",
    "\n",
    "        if build == True:\n",
    "            self.model = self.build_model(input_shape)\n",
    "            if (verbose == True):\n",
    "                self.model.summary()\n",
    "            self.verbose = verbose\n",
    "            self.model.save_weights(self.output_directory + 'inception_model_init.hdf5')\n",
    "\n",
    "    def _inception_module(self, input_tensor, stride=1, activation='linear'):\n",
    "\n",
    "        if self.use_bottleneck and int(input_tensor.shape[-1]) > 1:\n",
    "            input_inception = tf.keras.layers.Conv1D(filters=self.bottleneck_size, kernel_size=1,\n",
    "                                                  padding='same', activation=activation, use_bias=False)(input_tensor)\n",
    "        else:\n",
    "            input_inception = input_tensor\n",
    "\n",
    "        # kernel_size_s = [3, 5, 8, 11, 17]\n",
    "        kernel_size_s = [self.kernel_size // (2 ** i) for i in range(3)]\n",
    "\n",
    "        conv_list = []\n",
    "\n",
    "        for i in range(len(kernel_size_s)):\n",
    "            conv_list.append(tf.keras.layers.Conv1D(filters=self.nb_filters, kernel_size=kernel_size_s[i],\n",
    "                                                 strides=stride, padding='same', activation=activation, use_bias=False)(\n",
    "                input_inception))\n",
    "\n",
    "        max_pool_1 = tf.keras.layers.MaxPool1D(pool_size=3, strides=stride, padding='same')(input_tensor)\n",
    "\n",
    "        conv_6 = tf.keras.layers.Conv1D(filters=self.nb_filters, kernel_size=1,\n",
    "                                     padding='same', activation=activation, use_bias=False)(max_pool_1)\n",
    "\n",
    "        conv_list.append(conv_6)\n",
    "\n",
    "        x = tf.keras.layers.Concatenate(axis=2)(conv_list)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.Activation(activation='relu')(x)\n",
    "        return x\n",
    "\n",
    "    def _shortcut_layer(self, input_tensor, out_tensor):\n",
    "        shortcut_y = tf.keras.layers.Conv1D(filters=int(out_tensor.shape[-1]), kernel_size=1,\n",
    "                                         padding='same', use_bias=False)(input_tensor)\n",
    "        shortcut_y = tf.keras.layers.BatchNormalization()(shortcut_y)\n",
    "\n",
    "        x = tf.keras.layers.Add()([shortcut_y, out_tensor])\n",
    "        x = tf.keras.layers.Activation('relu')(x)\n",
    "        return x\n",
    "\n",
    "    def build_model(self, input_shape):\n",
    "        input_layer = tf.keras.layers.Input(input_shape)\n",
    "\n",
    "        x = input_layer\n",
    "        input_res = input_layer\n",
    "\n",
    "        for d in range(self.depth):\n",
    "\n",
    "            x = self._inception_module(x)\n",
    "\n",
    "            if self.use_residual and d % 3 == 2:\n",
    "                x = self._shortcut_layer(input_res, x)\n",
    "                input_res = x\n",
    "\n",
    "        pooling_layer = tf.keras.layers.AveragePooling1D(pool_size=50)(x)\n",
    "        flat_layer = tf.keras.layers.Flatten()(pooling_layer)\n",
    "        dense_layer = tf.keras.layers.Dense(128, activation='relu')(flat_layer)\n",
    "        output_layer = tf.keras.layers.Dense(1)(dense_layer)\n",
    "\n",
    "        model = tf.keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Regressor_Inception(PATH_MODELS, input_shape, verbose=True).model\n",
    "\n",
    "optimizer = Adam(learning_rate=0.01)   \n",
    "              \n",
    "model.compile(loss='mean_squared_error', \n",
    "              optimizer=optimizer, \n",
    "              metrics=[RootMeanSquaredError(), MeanAbsoluteError()])\n",
    "\n",
    "# 'Inception_regressor_01' (n_average = 40, gaussian_noise = 0.01, MAE)\n",
    "# 'Inception_regressor_02' (n_average = 1, gaussian_noise = 0.01, MAE)\n",
    "# 'Inception_regressor_03' (n_average = 40, gaussian_noise = 0.01, MSE)\n",
    "# 'Inception_regressor_04' (n_average = 1, gaussian_noise = 0.01, MSE)\n",
    "# 'Inception_regressor_05' (n_average = 100, gaussian_noise = 0.01, MAE)\n",
    "output_filename = 'Inception_regressor_05'\n",
    "output_file = os.path.join(PATH_MODELS, output_filename)\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath = output_file + \".hdf5\", monitor='val_loss', verbose=1, save_best_only=True)\n",
    "earlystopper = EarlyStopping(monitor='val_loss', patience=100, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=20, min_lr=0.0001, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "143/143 [==============================] - 249s 2s/step - loss: 14.8795 - root_mean_squared_error: 21.7512 - mean_absolute_error: 14.8795 - val_loss: 14.4589 - val_root_mean_squared_error: 18.1789 - val_mean_absolute_error: 14.4589\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 14.45891, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/Inception_regressor_05.hdf5\n",
      "Epoch 2/1500\n",
      "143/143 [==============================] - 238s 2s/step - loss: 8.9878 - root_mean_squared_error: 11.2585 - mean_absolute_error: 8.9878 - val_loss: 8.4816 - val_root_mean_squared_error: 10.7197 - val_mean_absolute_error: 8.4816\n",
      "\n",
      "Epoch 00002: val_loss improved from 14.45891 to 8.48164, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/Inception_regressor_05.hdf5\n",
      "Epoch 3/1500\n",
      "143/143 [==============================] - 241s 2s/step - loss: 7.9297 - root_mean_squared_error: 9.8073 - mean_absolute_error: 7.9297 - val_loss: 8.6225 - val_root_mean_squared_error: 10.7096 - val_mean_absolute_error: 8.6225\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 8.48164\n",
      "Epoch 4/1500\n",
      "143/143 [==============================] - 251s 2s/step - loss: 7.5862 - root_mean_squared_error: 9.5560 - mean_absolute_error: 7.5862 - val_loss: 7.9495 - val_root_mean_squared_error: 9.8804 - val_mean_absolute_error: 7.9495\n",
      "\n",
      "Epoch 00004: val_loss improved from 8.48164 to 7.94954, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/Inception_regressor_05.hdf5\n",
      "Epoch 5/1500\n",
      "143/143 [==============================] - 248s 2s/step - loss: 7.4818 - root_mean_squared_error: 9.3210 - mean_absolute_error: 7.4818 - val_loss: 8.2277 - val_root_mean_squared_error: 10.2282 - val_mean_absolute_error: 8.2277\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 7.94954\n",
      "Epoch 6/1500\n",
      "143/143 [==============================] - 236s 2s/step - loss: 7.4864 - root_mean_squared_error: 9.3487 - mean_absolute_error: 7.4864 - val_loss: 7.5866 - val_root_mean_squared_error: 9.1670 - val_mean_absolute_error: 7.5866\n",
      "\n",
      "Epoch 00006: val_loss improved from 7.94954 to 7.58664, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/Inception_regressor_05.hdf5\n",
      "Epoch 7/1500\n",
      "143/143 [==============================] - 243s 2s/step - loss: 7.3161 - root_mean_squared_error: 8.9779 - mean_absolute_error: 7.3161 - val_loss: 7.4808 - val_root_mean_squared_error: 9.2119 - val_mean_absolute_error: 7.4808\n",
      "\n",
      "Epoch 00007: val_loss improved from 7.58664 to 7.48085, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/Inception_regressor_05.hdf5\n",
      "Epoch 8/1500\n",
      "143/143 [==============================] - 240s 2s/step - loss: 7.2086 - root_mean_squared_error: 9.0140 - mean_absolute_error: 7.2086 - val_loss: 7.0342 - val_root_mean_squared_error: 8.4642 - val_mean_absolute_error: 7.0342\n",
      "\n",
      "Epoch 00008: val_loss improved from 7.48085 to 7.03424, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/Inception_regressor_05.hdf5\n",
      "Epoch 9/1500\n",
      "143/143 [==============================] - 251s 2s/step - loss: 7.1712 - root_mean_squared_error: 8.8799 - mean_absolute_error: 7.1712 - val_loss: 8.4158 - val_root_mean_squared_error: 10.9831 - val_mean_absolute_error: 8.4158\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 7.03424\n",
      "Epoch 10/1500\n",
      "143/143 [==============================] - 244s 2s/step - loss: 6.7448 - root_mean_squared_error: 8.4794 - mean_absolute_error: 6.7448 - val_loss: 7.1160 - val_root_mean_squared_error: 8.7954 - val_mean_absolute_error: 7.1160\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 7.03424\n",
      "Epoch 11/1500\n",
      "143/143 [==============================] - 236s 2s/step - loss: 6.5643 - root_mean_squared_error: 8.1029 - mean_absolute_error: 6.5643 - val_loss: 6.6782 - val_root_mean_squared_error: 8.7689 - val_mean_absolute_error: 6.6782\n",
      "\n",
      "Epoch 00011: val_loss improved from 7.03424 to 6.67820, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/Inception_regressor_05.hdf5\n",
      "Epoch 12/1500\n",
      "143/143 [==============================] - 237s 2s/step - loss: 6.8608 - root_mean_squared_error: 8.5189 - mean_absolute_error: 6.8608 - val_loss: 7.4391 - val_root_mean_squared_error: 8.9641 - val_mean_absolute_error: 7.4391\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 6.67820\n",
      "Epoch 13/1500\n",
      "143/143 [==============================] - 236s 2s/step - loss: 6.3620 - root_mean_squared_error: 8.0811 - mean_absolute_error: 6.3620 - val_loss: 6.2322 - val_root_mean_squared_error: 7.8516 - val_mean_absolute_error: 6.2322\n",
      "\n",
      "Epoch 00013: val_loss improved from 6.67820 to 6.23218, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/Inception_regressor_05.hdf5\n",
      "Epoch 14/1500\n",
      "143/143 [==============================] - 254s 2s/step - loss: 6.4244 - root_mean_squared_error: 8.0315 - mean_absolute_error: 6.4244 - val_loss: 6.3984 - val_root_mean_squared_error: 7.7712 - val_mean_absolute_error: 6.3984\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 6.23218\n",
      "Epoch 15/1500\n",
      "143/143 [==============================] - 275s 2s/step - loss: 6.4621 - root_mean_squared_error: 8.0164 - mean_absolute_error: 6.4621 - val_loss: 7.3512 - val_root_mean_squared_error: 8.9388 - val_mean_absolute_error: 7.3512\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 6.23218\n",
      "Epoch 16/1500\n",
      "143/143 [==============================] - 261s 2s/step - loss: 6.1071 - root_mean_squared_error: 7.7785 - mean_absolute_error: 6.1071 - val_loss: 6.4946 - val_root_mean_squared_error: 8.0373 - val_mean_absolute_error: 6.4946\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 6.23218\n",
      "Epoch 17/1500\n",
      "143/143 [==============================] - 246s 2s/step - loss: 6.1679 - root_mean_squared_error: 7.8029 - mean_absolute_error: 6.1679 - val_loss: 8.4570 - val_root_mean_squared_error: 10.6252 - val_mean_absolute_error: 8.4570\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 6.23218\n",
      "Epoch 18/1500\n",
      "143/143 [==============================] - 238s 2s/step - loss: 6.8549 - root_mean_squared_error: 8.7218 - mean_absolute_error: 6.8549 - val_loss: 6.1978 - val_root_mean_squared_error: 8.1316 - val_mean_absolute_error: 6.1978\n",
      "\n",
      "Epoch 00018: val_loss improved from 6.23218 to 6.19785, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/Inception_regressor_05.hdf5\n",
      "Epoch 19/1500\n",
      "143/143 [==============================] - 243s 2s/step - loss: 6.2660 - root_mean_squared_error: 7.9510 - mean_absolute_error: 6.2660 - val_loss: 6.3488 - val_root_mean_squared_error: 8.0715 - val_mean_absolute_error: 6.3488\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 6.19785\n",
      "Epoch 20/1500\n",
      "143/143 [==============================] - 241s 2s/step - loss: 6.1776 - root_mean_squared_error: 7.8016 - mean_absolute_error: 6.1776 - val_loss: 6.4078 - val_root_mean_squared_error: 8.3664 - val_mean_absolute_error: 6.4078\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 6.19785\n",
      "Epoch 21/1500\n",
      "143/143 [==============================] - 261s 2s/step - loss: 6.2853 - root_mean_squared_error: 7.9542 - mean_absolute_error: 6.2853 - val_loss: 5.8297 - val_root_mean_squared_error: 7.3711 - val_mean_absolute_error: 5.8297\n",
      "\n",
      "Epoch 00021: val_loss improved from 6.19785 to 5.82968, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/Inception_regressor_05.hdf5\n",
      "Epoch 22/1500\n",
      "143/143 [==============================] - 257s 2s/step - loss: 5.9138 - root_mean_squared_error: 7.4956 - mean_absolute_error: 5.9138 - val_loss: 7.0646 - val_root_mean_squared_error: 9.2816 - val_mean_absolute_error: 7.0646\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 5.82968\n",
      "Epoch 23/1500\n",
      "143/143 [==============================] - 243s 2s/step - loss: 6.3951 - root_mean_squared_error: 7.9844 - mean_absolute_error: 6.3951 - val_loss: 6.0768 - val_root_mean_squared_error: 7.4813 - val_mean_absolute_error: 6.0768\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 5.82968\n",
      "Epoch 24/1500\n",
      "143/143 [==============================] - 239s 2s/step - loss: 6.1319 - root_mean_squared_error: 7.6512 - mean_absolute_error: 6.1319 - val_loss: 5.9292 - val_root_mean_squared_error: 7.5341 - val_mean_absolute_error: 5.9292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00024: val_loss did not improve from 5.82968\n",
      "Epoch 25/1500\n",
      "143/143 [==============================] - 249s 2s/step - loss: 5.9342 - root_mean_squared_error: 7.4770 - mean_absolute_error: 5.9342 - val_loss: 5.8190 - val_root_mean_squared_error: 7.3576 - val_mean_absolute_error: 5.8190\n",
      "\n",
      "Epoch 00025: val_loss improved from 5.82968 to 5.81904, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/Inception_regressor_05.hdf5\n",
      "Epoch 26/1500\n",
      "143/143 [==============================] - 244s 2s/step - loss: 5.8491 - root_mean_squared_error: 7.5007 - mean_absolute_error: 5.8491 - val_loss: 6.2931 - val_root_mean_squared_error: 7.9237 - val_mean_absolute_error: 6.2931\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 5.81904\n",
      "Epoch 27/1500\n",
      "143/143 [==============================] - 234s 2s/step - loss: 5.7424 - root_mean_squared_error: 7.2581 - mean_absolute_error: 5.7424 - val_loss: 5.7668 - val_root_mean_squared_error: 7.2636 - val_mean_absolute_error: 5.7668\n",
      "\n",
      "Epoch 00027: val_loss improved from 5.81904 to 5.76682, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/Inception_regressor_05.hdf5\n",
      "Epoch 28/1500\n",
      "143/143 [==============================] - 235s 2s/step - loss: 5.8539 - root_mean_squared_error: 7.4210 - mean_absolute_error: 5.8539 - val_loss: 5.9676 - val_root_mean_squared_error: 7.4512 - val_mean_absolute_error: 5.9676\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 5.76682\n",
      "Epoch 29/1500\n",
      "143/143 [==============================] - 299s 2s/step - loss: 6.2702 - root_mean_squared_error: 7.8800 - mean_absolute_error: 6.2702 - val_loss: 6.6341 - val_root_mean_squared_error: 8.5622 - val_mean_absolute_error: 6.6341\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 5.76682\n",
      "Epoch 30/1500\n",
      "143/143 [==============================] - 316s 2s/step - loss: 6.1907 - root_mean_squared_error: 7.7523 - mean_absolute_error: 6.1907 - val_loss: 6.2649 - val_root_mean_squared_error: 7.8693 - val_mean_absolute_error: 6.2649\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 5.76682\n",
      "Epoch 31/1500\n",
      "143/143 [==============================] - 313s 2s/step - loss: 5.7100 - root_mean_squared_error: 7.1804 - mean_absolute_error: 5.7100 - val_loss: 6.0504 - val_root_mean_squared_error: 7.8267 - val_mean_absolute_error: 6.0504\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 5.76682\n",
      "Epoch 32/1500\n",
      "143/143 [==============================] - 318s 2s/step - loss: 5.9910 - root_mean_squared_error: 7.4899 - mean_absolute_error: 5.9910 - val_loss: 6.4460 - val_root_mean_squared_error: 8.3708 - val_mean_absolute_error: 6.4460\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 5.76682\n",
      "Epoch 33/1500\n",
      "143/143 [==============================] - 319s 2s/step - loss: 5.6621 - root_mean_squared_error: 7.1718 - mean_absolute_error: 5.6621 - val_loss: 5.8890 - val_root_mean_squared_error: 7.3299 - val_mean_absolute_error: 5.8890\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 5.76682\n",
      "Epoch 34/1500\n",
      "143/143 [==============================] - 320s 2s/step - loss: 5.8712 - root_mean_squared_error: 7.3847 - mean_absolute_error: 5.8712 - val_loss: 5.4592 - val_root_mean_squared_error: 6.9547 - val_mean_absolute_error: 5.4592\n",
      "\n",
      "Epoch 00034: val_loss improved from 5.76682 to 5.45922, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/Inception_regressor_05.hdf5\n",
      "Epoch 35/1500\n",
      "143/143 [==============================] - 320s 2s/step - loss: 5.8828 - root_mean_squared_error: 7.3813 - mean_absolute_error: 5.8828 - val_loss: 6.4062 - val_root_mean_squared_error: 8.0320 - val_mean_absolute_error: 6.4062\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 5.45922\n",
      "Epoch 36/1500\n",
      "143/143 [==============================] - 323s 2s/step - loss: 5.9062 - root_mean_squared_error: 7.4350 - mean_absolute_error: 5.9062 - val_loss: 6.7559 - val_root_mean_squared_error: 8.2158 - val_mean_absolute_error: 6.7559\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 5.45922\n",
      "Epoch 37/1500\n",
      "143/143 [==============================] - 321s 2s/step - loss: 5.7114 - root_mean_squared_error: 7.0872 - mean_absolute_error: 5.7114 - val_loss: 5.9974 - val_root_mean_squared_error: 7.5208 - val_mean_absolute_error: 5.9974\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 5.45922\n",
      "Epoch 38/1500\n",
      "143/143 [==============================] - 303s 2s/step - loss: 5.8101 - root_mean_squared_error: 7.2883 - mean_absolute_error: 5.8101 - val_loss: 6.1404 - val_root_mean_squared_error: 7.8697 - val_mean_absolute_error: 6.1404\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 5.45922\n",
      "Epoch 39/1500\n",
      "143/143 [==============================] - 320s 2s/step - loss: 5.8942 - root_mean_squared_error: 7.5031 - mean_absolute_error: 5.8942 - val_loss: 6.1046 - val_root_mean_squared_error: 7.3898 - val_mean_absolute_error: 6.1046\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 5.45922\n",
      "Epoch 40/1500\n",
      "143/143 [==============================] - 321s 2s/step - loss: 5.6439 - root_mean_squared_error: 7.0831 - mean_absolute_error: 5.6439 - val_loss: 6.3874 - val_root_mean_squared_error: 8.3137 - val_mean_absolute_error: 6.3874\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 5.45922\n",
      "Epoch 41/1500\n",
      "143/143 [==============================] - 304s 2s/step - loss: 5.4410 - root_mean_squared_error: 7.1037 - mean_absolute_error: 5.4410 - val_loss: 5.7133 - val_root_mean_squared_error: 7.4787 - val_mean_absolute_error: 5.7133\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 5.45922\n",
      "Epoch 42/1500\n",
      "143/143 [==============================] - 314s 2s/step - loss: 5.8531 - root_mean_squared_error: 7.6008 - mean_absolute_error: 5.8531 - val_loss: 5.8567 - val_root_mean_squared_error: 7.3285 - val_mean_absolute_error: 5.8567\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 5.45922\n",
      "Epoch 43/1500\n",
      "143/143 [==============================] - 320s 2s/step - loss: 5.6052 - root_mean_squared_error: 7.0247 - mean_absolute_error: 5.6052 - val_loss: 6.3827 - val_root_mean_squared_error: 7.7829 - val_mean_absolute_error: 6.3827\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 5.45922\n",
      "Epoch 44/1500\n",
      "143/143 [==============================] - 316s 2s/step - loss: 5.4933 - root_mean_squared_error: 6.9112 - mean_absolute_error: 5.4933 - val_loss: 5.6770 - val_root_mean_squared_error: 7.2431 - val_mean_absolute_error: 5.6770\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 5.45922\n",
      "Epoch 45/1500\n",
      "143/143 [==============================] - 321s 2s/step - loss: 5.5571 - root_mean_squared_error: 6.9920 - mean_absolute_error: 5.5571 - val_loss: 6.0411 - val_root_mean_squared_error: 8.2707 - val_mean_absolute_error: 6.0411\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 5.45922\n",
      "Epoch 46/1500\n",
      "143/143 [==============================] - 325s 2s/step - loss: 5.3796 - root_mean_squared_error: 6.8703 - mean_absolute_error: 5.3796 - val_loss: 6.0636 - val_root_mean_squared_error: 7.8309 - val_mean_absolute_error: 6.0636\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 5.45922\n",
      "Epoch 47/1500\n",
      "143/143 [==============================] - 325s 2s/step - loss: 6.2423 - root_mean_squared_error: 7.7567 - mean_absolute_error: 6.2423 - val_loss: 6.2174 - val_root_mean_squared_error: 8.0410 - val_mean_absolute_error: 6.2174\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 5.45922\n",
      "Epoch 48/1500\n",
      "143/143 [==============================] - 325s 2s/step - loss: 5.5220 - root_mean_squared_error: 7.0047 - mean_absolute_error: 5.5220 - val_loss: 6.3585 - val_root_mean_squared_error: 8.2883 - val_mean_absolute_error: 6.3585\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 5.45922\n",
      "Epoch 49/1500\n",
      "143/143 [==============================] - 302s 2s/step - loss: 5.7821 - root_mean_squared_error: 7.1848 - mean_absolute_error: 5.7821 - val_loss: 6.2673 - val_root_mean_squared_error: 7.9553 - val_mean_absolute_error: 6.2673\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 5.45922\n",
      "Epoch 50/1500\n",
      "143/143 [==============================] - 322s 2s/step - loss: 5.5901 - root_mean_squared_error: 7.1540 - mean_absolute_error: 5.5901 - val_loss: 5.3703 - val_root_mean_squared_error: 6.5649 - val_mean_absolute_error: 5.3703\n",
      "\n",
      "Epoch 00050: val_loss improved from 5.45922 to 5.37030, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/Inception_regressor_05.hdf5\n",
      "Epoch 51/1500\n",
      "143/143 [==============================] - 299s 2s/step - loss: 5.3059 - root_mean_squared_error: 6.8131 - mean_absolute_error: 5.3059 - val_loss: 6.3178 - val_root_mean_squared_error: 8.0246 - val_mean_absolute_error: 6.3178\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 5.37030\n",
      "Epoch 52/1500\n",
      "143/143 [==============================] - 306s 2s/step - loss: 5.3777 - root_mean_squared_error: 6.8726 - mean_absolute_error: 5.3777 - val_loss: 5.9000 - val_root_mean_squared_error: 7.3742 - val_mean_absolute_error: 5.9000\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 5.37030\n",
      "Epoch 53/1500\n",
      "143/143 [==============================] - 308s 2s/step - loss: 5.5860 - root_mean_squared_error: 7.2147 - mean_absolute_error: 5.5860 - val_loss: 6.2914 - val_root_mean_squared_error: 7.8381 - val_mean_absolute_error: 6.2914\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 5.37030\n",
      "Epoch 54/1500\n",
      "143/143 [==============================] - 319s 2s/step - loss: 5.5746 - root_mean_squared_error: 7.1573 - mean_absolute_error: 5.5746 - val_loss: 6.2876 - val_root_mean_squared_error: 8.1348 - val_mean_absolute_error: 6.2876\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 5.37030\n",
      "Epoch 55/1500\n",
      "143/143 [==============================] - 316s 2s/step - loss: 5.4375 - root_mean_squared_error: 7.1129 - mean_absolute_error: 5.4375 - val_loss: 5.8066 - val_root_mean_squared_error: 7.2449 - val_mean_absolute_error: 5.8066\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 5.37030\n",
      "Epoch 56/1500\n",
      "143/143 [==============================] - 317s 2s/step - loss: 5.3117 - root_mean_squared_error: 6.7036 - mean_absolute_error: 5.3117 - val_loss: 6.0591 - val_root_mean_squared_error: 7.6734 - val_mean_absolute_error: 6.0591\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 5.37030\n",
      "Epoch 57/1500\n",
      "143/143 [==============================] - 320s 2s/step - loss: 5.4715 - root_mean_squared_error: 6.9770 - mean_absolute_error: 5.4715 - val_loss: 6.9322 - val_root_mean_squared_error: 8.8755 - val_mean_absolute_error: 6.9322\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 5.37030\n",
      "Epoch 58/1500\n",
      "143/143 [==============================] - 322s 2s/step - loss: 5.5684 - root_mean_squared_error: 7.1288 - mean_absolute_error: 5.5684 - val_loss: 5.9887 - val_root_mean_squared_error: 7.6768 - val_mean_absolute_error: 5.9887\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 5.37030\n",
      "Epoch 59/1500\n",
      "143/143 [==============================] - 322s 2s/step - loss: 5.4141 - root_mean_squared_error: 7.0562 - mean_absolute_error: 5.4141 - val_loss: 6.2923 - val_root_mean_squared_error: 8.3014 - val_mean_absolute_error: 6.2923\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 5.37030\n",
      "Epoch 60/1500\n",
      "143/143 [==============================] - 323s 2s/step - loss: 5.1682 - root_mean_squared_error: 6.5447 - mean_absolute_error: 5.1682 - val_loss: 6.5051 - val_root_mean_squared_error: 8.2194 - val_mean_absolute_error: 6.5051\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 5.37030\n",
      "Epoch 61/1500\n",
      "143/143 [==============================] - 301s 2s/step - loss: 5.6133 - root_mean_squared_error: 7.1097 - mean_absolute_error: 5.6133 - val_loss: 5.5708 - val_root_mean_squared_error: 6.9885 - val_mean_absolute_error: 5.5708\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 5.37030\n",
      "Epoch 62/1500\n",
      "143/143 [==============================] - 323s 2s/step - loss: 5.3123 - root_mean_squared_error: 6.7821 - mean_absolute_error: 5.3123 - val_loss: 5.6288 - val_root_mean_squared_error: 6.8872 - val_mean_absolute_error: 5.6288\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 5.37030\n",
      "Epoch 63/1500\n",
      "143/143 [==============================] - 322s 2s/step - loss: 5.5112 - root_mean_squared_error: 6.8826 - mean_absolute_error: 5.5112 - val_loss: 6.1421 - val_root_mean_squared_error: 7.9613 - val_mean_absolute_error: 6.1421\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 5.37030\n",
      "Epoch 64/1500\n",
      "143/143 [==============================] - 323s 2s/step - loss: 5.6060 - root_mean_squared_error: 7.1898 - mean_absolute_error: 5.6060 - val_loss: 6.1966 - val_root_mean_squared_error: 8.0382 - val_mean_absolute_error: 6.1966\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 5.37030\n",
      "Epoch 65/1500\n",
      "143/143 [==============================] - 323s 2s/step - loss: 5.2813 - root_mean_squared_error: 6.7476 - mean_absolute_error: 5.2813 - val_loss: 6.0968 - val_root_mean_squared_error: 7.7787 - val_mean_absolute_error: 6.0968\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 5.37030\n",
      "Epoch 66/1500\n",
      "143/143 [==============================] - 324s 2s/step - loss: 5.5218 - root_mean_squared_error: 7.0432 - mean_absolute_error: 5.5218 - val_loss: 6.5812 - val_root_mean_squared_error: 8.6266 - val_mean_absolute_error: 6.5812\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 5.37030\n",
      "Epoch 67/1500\n",
      "143/143 [==============================] - 324s 2s/step - loss: 5.5761 - root_mean_squared_error: 7.1770 - mean_absolute_error: 5.5761 - val_loss: 6.2223 - val_root_mean_squared_error: 7.9365 - val_mean_absolute_error: 6.2223\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 5.37030\n",
      "Epoch 68/1500\n",
      "143/143 [==============================] - 322s 2s/step - loss: 5.2935 - root_mean_squared_error: 6.7741 - mean_absolute_error: 5.2935 - val_loss: 5.9250 - val_root_mean_squared_error: 7.5247 - val_mean_absolute_error: 5.9250\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 5.37030\n",
      "Epoch 69/1500\n",
      "143/143 [==============================] - 322s 2s/step - loss: 5.3101 - root_mean_squared_error: 6.8921 - mean_absolute_error: 5.3101 - val_loss: 6.2541 - val_root_mean_squared_error: 7.7738 - val_mean_absolute_error: 6.2541\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 5.37030\n",
      "Epoch 70/1500\n",
      "143/143 [==============================] - 325s 2s/step - loss: 5.3736 - root_mean_squared_error: 6.7461 - mean_absolute_error: 5.3736 - val_loss: 5.5508 - val_root_mean_squared_error: 7.2596 - val_mean_absolute_error: 5.5508\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 5.37030\n",
      "\n",
      "Epoch 00070: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "Epoch 71/1500\n",
      "143/143 [==============================] - 323s 2s/step - loss: 5.5211 - root_mean_squared_error: 7.2435 - mean_absolute_error: 5.5211 - val_loss: 5.3724 - val_root_mean_squared_error: 6.7228 - val_mean_absolute_error: 5.3724\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 5.37030\n",
      "Epoch 72/1500\n",
      "143/143 [==============================] - 305s 2s/step - loss: 5.0939 - root_mean_squared_error: 6.5244 - mean_absolute_error: 5.0939 - val_loss: 5.9290 - val_root_mean_squared_error: 7.4134 - val_mean_absolute_error: 5.9290\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 5.37030\n",
      "Epoch 73/1500\n",
      "143/143 [==============================] - 322s 2s/step - loss: 5.0465 - root_mean_squared_error: 6.3506 - mean_absolute_error: 5.0465 - val_loss: 5.6961 - val_root_mean_squared_error: 7.1331 - val_mean_absolute_error: 5.6961\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 5.37030\n",
      "Epoch 74/1500\n",
      "143/143 [==============================] - 320s 2s/step - loss: 5.1368 - root_mean_squared_error: 6.6248 - mean_absolute_error: 5.1368 - val_loss: 6.2430 - val_root_mean_squared_error: 8.1255 - val_mean_absolute_error: 6.2430\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 5.37030\n",
      "Epoch 75/1500\n",
      "143/143 [==============================] - 324s 2s/step - loss: 5.0769 - root_mean_squared_error: 6.3914 - mean_absolute_error: 5.0769 - val_loss: 5.7746 - val_root_mean_squared_error: 7.2127 - val_mean_absolute_error: 5.7746\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 5.37030\n",
      "Epoch 76/1500\n",
      "143/143 [==============================] - 320s 2s/step - loss: 4.7469 - root_mean_squared_error: 6.1836 - mean_absolute_error: 4.7469 - val_loss: 5.6753 - val_root_mean_squared_error: 7.2940 - val_mean_absolute_error: 5.6753\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 5.37030\n",
      "Epoch 77/1500\n",
      "143/143 [==============================] - 319s 2s/step - loss: 5.0856 - root_mean_squared_error: 6.5376 - mean_absolute_error: 5.0856 - val_loss: 5.2308 - val_root_mean_squared_error: 6.5546 - val_mean_absolute_error: 5.2308\n",
      "\n",
      "Epoch 00077: val_loss improved from 5.37030 to 5.23083, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/Inception_regressor_05.hdf5\n",
      "Epoch 78/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 316s 2s/step - loss: 5.1042 - root_mean_squared_error: 6.6133 - mean_absolute_error: 5.1042 - val_loss: 5.6670 - val_root_mean_squared_error: 7.2707 - val_mean_absolute_error: 5.6670\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 5.23083\n",
      "Epoch 79/1500\n",
      "143/143 [==============================] - 321s 2s/step - loss: 4.9956 - root_mean_squared_error: 6.3485 - mean_absolute_error: 4.9956 - val_loss: 5.4951 - val_root_mean_squared_error: 7.2871 - val_mean_absolute_error: 5.4951\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 5.23083\n",
      "Epoch 80/1500\n",
      "143/143 [==============================] - 324s 2s/step - loss: 5.1040 - root_mean_squared_error: 6.4311 - mean_absolute_error: 5.1040 - val_loss: 5.6553 - val_root_mean_squared_error: 7.0254 - val_mean_absolute_error: 5.6553\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 5.23083\n",
      "Epoch 81/1500\n",
      "143/143 [==============================] - 324s 2s/step - loss: 4.8514 - root_mean_squared_error: 6.2461 - mean_absolute_error: 4.8514 - val_loss: 5.9242 - val_root_mean_squared_error: 7.5982 - val_mean_absolute_error: 5.9242\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 5.23083\n",
      "Epoch 82/1500\n",
      "143/143 [==============================] - 322s 2s/step - loss: 4.9235 - root_mean_squared_error: 6.3052 - mean_absolute_error: 4.9235 - val_loss: 6.2396 - val_root_mean_squared_error: 8.1130 - val_mean_absolute_error: 6.2396\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 5.23083\n",
      "Epoch 83/1500\n",
      "143/143 [==============================] - 303s 2s/step - loss: 5.0034 - root_mean_squared_error: 6.3874 - mean_absolute_error: 5.0034 - val_loss: 6.0801 - val_root_mean_squared_error: 7.6447 - val_mean_absolute_error: 6.0801\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 5.23083\n",
      "Epoch 84/1500\n",
      "143/143 [==============================] - 323s 2s/step - loss: 5.1944 - root_mean_squared_error: 6.5843 - mean_absolute_error: 5.1944 - val_loss: 5.8311 - val_root_mean_squared_error: 7.4682 - val_mean_absolute_error: 5.8311\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 5.23083\n",
      "Epoch 85/1500\n",
      "143/143 [==============================] - 323s 2s/step - loss: 4.9269 - root_mean_squared_error: 6.3644 - mean_absolute_error: 4.9269 - val_loss: 5.4288 - val_root_mean_squared_error: 6.8519 - val_mean_absolute_error: 5.4288\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 5.23083\n",
      "Epoch 86/1500\n",
      "143/143 [==============================] - 323s 2s/step - loss: 4.9025 - root_mean_squared_error: 6.2913 - mean_absolute_error: 4.9025 - val_loss: 6.0521 - val_root_mean_squared_error: 7.6236 - val_mean_absolute_error: 6.0521\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 5.23083\n",
      "Epoch 87/1500\n",
      "143/143 [==============================] - 325s 2s/step - loss: 4.9290 - root_mean_squared_error: 6.3348 - mean_absolute_error: 4.9290 - val_loss: 5.7184 - val_root_mean_squared_error: 7.5016 - val_mean_absolute_error: 5.7184\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 5.23083\n",
      "Epoch 88/1500\n",
      "143/143 [==============================] - 324s 2s/step - loss: 4.9786 - root_mean_squared_error: 6.3027 - mean_absolute_error: 4.9786 - val_loss: 5.7292 - val_root_mean_squared_error: 7.3241 - val_mean_absolute_error: 5.7292\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 5.23083\n",
      "Epoch 89/1500\n",
      "143/143 [==============================] - 322s 2s/step - loss: 4.8981 - root_mean_squared_error: 6.3600 - mean_absolute_error: 4.8981 - val_loss: 5.8437 - val_root_mean_squared_error: 7.3946 - val_mean_absolute_error: 5.8437\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 5.23083\n",
      "Epoch 90/1500\n",
      "143/143 [==============================] - 318s 2s/step - loss: 4.5602 - root_mean_squared_error: 5.8556 - mean_absolute_error: 4.5602 - val_loss: 5.7343 - val_root_mean_squared_error: 7.3305 - val_mean_absolute_error: 5.7343\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 5.23083\n",
      "Epoch 91/1500\n",
      "143/143 [==============================] - 318s 2s/step - loss: 4.9309 - root_mean_squared_error: 6.2771 - mean_absolute_error: 4.9309 - val_loss: 6.1152 - val_root_mean_squared_error: 7.8737 - val_mean_absolute_error: 6.1152\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 5.23083\n",
      "Epoch 92/1500\n",
      "143/143 [==============================] - 302s 2s/step - loss: 4.8039 - root_mean_squared_error: 6.1941 - mean_absolute_error: 4.8039 - val_loss: 5.2960 - val_root_mean_squared_error: 6.8391 - val_mean_absolute_error: 5.2960\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 5.23083\n",
      "Epoch 93/1500\n",
      "143/143 [==============================] - 316s 2s/step - loss: 4.7839 - root_mean_squared_error: 6.1408 - mean_absolute_error: 4.7839 - val_loss: 5.7807 - val_root_mean_squared_error: 7.4666 - val_mean_absolute_error: 5.7807\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 5.23083\n",
      "Epoch 94/1500\n",
      "143/143 [==============================] - 306s 2s/step - loss: 5.1139 - root_mean_squared_error: 6.4008 - mean_absolute_error: 5.1139 - val_loss: 5.9130 - val_root_mean_squared_error: 7.6219 - val_mean_absolute_error: 5.9130\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 5.23083\n",
      "Epoch 95/1500\n",
      "143/143 [==============================] - 312s 2s/step - loss: 5.0633 - root_mean_squared_error: 6.4091 - mean_absolute_error: 5.0633 - val_loss: 5.2556 - val_root_mean_squared_error: 6.8085 - val_mean_absolute_error: 5.2556\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 5.23083\n",
      "Epoch 96/1500\n",
      "143/143 [==============================] - 293s 2s/step - loss: 4.7494 - root_mean_squared_error: 6.0502 - mean_absolute_error: 4.7494 - val_loss: 5.8226 - val_root_mean_squared_error: 7.5515 - val_mean_absolute_error: 5.8226\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 5.23083\n",
      "Epoch 97/1500\n",
      "143/143 [==============================] - 303s 2s/step - loss: 4.8282 - root_mean_squared_error: 6.1261 - mean_absolute_error: 4.8282 - val_loss: 6.0259 - val_root_mean_squared_error: 7.8249 - val_mean_absolute_error: 6.0259\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 5.23083\n",
      "\n",
      "Epoch 00097: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "Epoch 98/1500\n",
      "143/143 [==============================] - 322s 2s/step - loss: 4.7551 - root_mean_squared_error: 6.2106 - mean_absolute_error: 4.7551 - val_loss: 5.4761 - val_root_mean_squared_error: 6.9280 - val_mean_absolute_error: 5.4761\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 5.23083\n",
      "Epoch 99/1500\n",
      "143/143 [==============================] - 322s 2s/step - loss: 4.6490 - root_mean_squared_error: 6.0194 - mean_absolute_error: 4.6490 - val_loss: 5.6415 - val_root_mean_squared_error: 7.1622 - val_mean_absolute_error: 5.6415\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 5.23083\n",
      "Epoch 100/1500\n",
      "143/143 [==============================] - 325s 2s/step - loss: 4.9259 - root_mean_squared_error: 6.2554 - mean_absolute_error: 4.9259 - val_loss: 5.7163 - val_root_mean_squared_error: 7.1453 - val_mean_absolute_error: 5.7163\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 5.23083\n",
      "Epoch 101/1500\n",
      "143/143 [==============================] - 324s 2s/step - loss: 4.7001 - root_mean_squared_error: 5.9860 - mean_absolute_error: 4.7001 - val_loss: 5.5464 - val_root_mean_squared_error: 7.0949 - val_mean_absolute_error: 5.5464\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 5.23083\n",
      "Epoch 102/1500\n",
      "143/143 [==============================] - 322s 2s/step - loss: 5.0902 - root_mean_squared_error: 6.6247 - mean_absolute_error: 5.0902 - val_loss: 5.5821 - val_root_mean_squared_error: 7.2534 - val_mean_absolute_error: 5.5821\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 5.23083\n",
      "Epoch 103/1500\n",
      "143/143 [==============================] - 323s 2s/step - loss: 4.9101 - root_mean_squared_error: 6.1880 - mean_absolute_error: 4.9101 - val_loss: 5.4474 - val_root_mean_squared_error: 6.7688 - val_mean_absolute_error: 5.4474\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 5.23083\n",
      "Epoch 104/1500\n",
      "143/143 [==============================] - 325s 2s/step - loss: 4.4637 - root_mean_squared_error: 5.7078 - mean_absolute_error: 4.4637 - val_loss: 5.7268 - val_root_mean_squared_error: 7.3430 - val_mean_absolute_error: 5.7268\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 5.23083\n",
      "Epoch 105/1500\n",
      "143/143 [==============================] - 323s 2s/step - loss: 4.9443 - root_mean_squared_error: 6.2887 - mean_absolute_error: 4.9443 - val_loss: 5.6935 - val_root_mean_squared_error: 7.1808 - val_mean_absolute_error: 5.6935\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 5.23083\n",
      "Epoch 106/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 303s 2s/step - loss: 4.9634 - root_mean_squared_error: 6.4851 - mean_absolute_error: 4.9634 - val_loss: 6.0805 - val_root_mean_squared_error: 7.7360 - val_mean_absolute_error: 6.0805\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 5.23083\n",
      "Epoch 107/1500\n",
      "143/143 [==============================] - 323s 2s/step - loss: 4.9089 - root_mean_squared_error: 6.3690 - mean_absolute_error: 4.9089 - val_loss: 5.7419 - val_root_mean_squared_error: 7.3350 - val_mean_absolute_error: 5.7419\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 5.23083\n",
      "Epoch 108/1500\n",
      "143/143 [==============================] - 324s 2s/step - loss: 4.6513 - root_mean_squared_error: 5.9217 - mean_absolute_error: 4.6513 - val_loss: 6.1858 - val_root_mean_squared_error: 7.8471 - val_mean_absolute_error: 6.1858\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 5.23083\n",
      "Epoch 109/1500\n",
      "143/143 [==============================] - 321s 2s/step - loss: 5.0534 - root_mean_squared_error: 6.3555 - mean_absolute_error: 5.0534 - val_loss: 5.6565 - val_root_mean_squared_error: 7.3164 - val_mean_absolute_error: 5.6565\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 5.23083\n",
      "Epoch 110/1500\n",
      "143/143 [==============================] - 322s 2s/step - loss: 4.7987 - root_mean_squared_error: 6.1015 - mean_absolute_error: 4.7987 - val_loss: 5.8085 - val_root_mean_squared_error: 7.8590 - val_mean_absolute_error: 5.8085\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 5.23083\n",
      "Epoch 111/1500\n",
      "143/143 [==============================] - 324s 2s/step - loss: 4.9521 - root_mean_squared_error: 6.3482 - mean_absolute_error: 4.9521 - val_loss: 5.6258 - val_root_mean_squared_error: 7.0582 - val_mean_absolute_error: 5.6258\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 5.23083\n",
      "Epoch 112/1500\n",
      "143/143 [==============================] - 322s 2s/step - loss: 4.7591 - root_mean_squared_error: 6.1641 - mean_absolute_error: 4.7591 - val_loss: 5.7334 - val_root_mean_squared_error: 7.1483 - val_mean_absolute_error: 5.7334\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 5.23083\n",
      "Epoch 113/1500\n",
      "143/143 [==============================] - 321s 2s/step - loss: 4.7978 - root_mean_squared_error: 6.3452 - mean_absolute_error: 4.7978 - val_loss: 5.7830 - val_root_mean_squared_error: 7.4701 - val_mean_absolute_error: 5.7830\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 5.23083\n",
      "Epoch 114/1500\n",
      "143/143 [==============================] - 322s 2s/step - loss: 4.8877 - root_mean_squared_error: 6.3412 - mean_absolute_error: 4.8877 - val_loss: 6.1257 - val_root_mean_squared_error: 8.1151 - val_mean_absolute_error: 6.1257\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 5.23083\n",
      "Epoch 115/1500\n",
      "143/143 [==============================] - 319s 2s/step - loss: 4.7927 - root_mean_squared_error: 6.1177 - mean_absolute_error: 4.7927 - val_loss: 5.8735 - val_root_mean_squared_error: 7.3505 - val_mean_absolute_error: 5.8735\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 5.23083\n",
      "Epoch 116/1500\n",
      "143/143 [==============================] - 304s 2s/step - loss: 4.8379 - root_mean_squared_error: 6.2262 - mean_absolute_error: 4.8379 - val_loss: 5.7452 - val_root_mean_squared_error: 7.5138 - val_mean_absolute_error: 5.7452\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 5.23083\n",
      "Epoch 117/1500\n",
      "143/143 [==============================] - 291s 2s/step - loss: 4.8603 - root_mean_squared_error: 6.2017 - mean_absolute_error: 4.8603 - val_loss: 5.8562 - val_root_mean_squared_error: 7.5511 - val_mean_absolute_error: 5.8562\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 5.23083\n",
      "Epoch 118/1500\n",
      "143/143 [==============================] - 319s 2s/step - loss: 5.0065 - root_mean_squared_error: 6.3178 - mean_absolute_error: 5.0065 - val_loss: 5.2069 - val_root_mean_squared_error: 6.6924 - val_mean_absolute_error: 5.2069\n",
      "\n",
      "Epoch 00118: val_loss improved from 5.23083 to 5.20694, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/Inception_regressor_05.hdf5\n",
      "Epoch 119/1500\n",
      "143/143 [==============================] - 316s 2s/step - loss: 4.6306 - root_mean_squared_error: 6.0164 - mean_absolute_error: 4.6306 - val_loss: 5.9103 - val_root_mean_squared_error: 7.5026 - val_mean_absolute_error: 5.9103\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 5.20694\n",
      "Epoch 120/1500\n",
      "143/143 [==============================] - 322s 2s/step - loss: 4.9807 - root_mean_squared_error: 6.3497 - mean_absolute_error: 4.9807 - val_loss: 6.0790 - val_root_mean_squared_error: 7.7732 - val_mean_absolute_error: 6.0790\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 5.20694\n",
      "Epoch 121/1500\n",
      "143/143 [==============================] - 321s 2s/step - loss: 4.5307 - root_mean_squared_error: 5.8210 - mean_absolute_error: 4.5307 - val_loss: 5.5513 - val_root_mean_squared_error: 7.1152 - val_mean_absolute_error: 5.5513\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 5.20694\n",
      "Epoch 122/1500\n",
      "143/143 [==============================] - 322s 2s/step - loss: 5.0140 - root_mean_squared_error: 6.4734 - mean_absolute_error: 5.0140 - val_loss: 5.7108 - val_root_mean_squared_error: 7.1283 - val_mean_absolute_error: 5.7108\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 5.20694\n",
      "Epoch 123/1500\n",
      "143/143 [==============================] - 323s 2s/step - loss: 4.9027 - root_mean_squared_error: 6.3512 - mean_absolute_error: 4.9027 - val_loss: 5.5557 - val_root_mean_squared_error: 7.2035 - val_mean_absolute_error: 5.5557\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 5.20694\n",
      "Epoch 124/1500\n",
      "143/143 [==============================] - 322s 2s/step - loss: 5.0642 - root_mean_squared_error: 6.4613 - mean_absolute_error: 5.0642 - val_loss: 5.7504 - val_root_mean_squared_error: 7.3054 - val_mean_absolute_error: 5.7504\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 5.20694\n",
      "Epoch 125/1500\n",
      "143/143 [==============================] - 322s 2s/step - loss: 4.6488 - root_mean_squared_error: 6.0278 - mean_absolute_error: 4.6488 - val_loss: 5.6948 - val_root_mean_squared_error: 7.1898 - val_mean_absolute_error: 5.6948\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 5.20694\n",
      "Epoch 126/1500\n",
      "143/143 [==============================] - 322s 2s/step - loss: 4.7458 - root_mean_squared_error: 6.1667 - mean_absolute_error: 4.7458 - val_loss: 5.5489 - val_root_mean_squared_error: 7.1243 - val_mean_absolute_error: 5.5489\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 5.20694\n",
      "Epoch 127/1500\n",
      "143/143 [==============================] - 325s 2s/step - loss: 4.4875 - root_mean_squared_error: 5.8030 - mean_absolute_error: 4.4875 - val_loss: 5.2562 - val_root_mean_squared_error: 6.9343 - val_mean_absolute_error: 5.2562\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 5.20694\n",
      "Epoch 128/1500\n",
      "143/143 [==============================] - 304s 2s/step - loss: 4.7484 - root_mean_squared_error: 6.1101 - mean_absolute_error: 4.7484 - val_loss: 5.5019 - val_root_mean_squared_error: 7.1122 - val_mean_absolute_error: 5.5019\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 5.20694\n",
      "Epoch 129/1500\n",
      "143/143 [==============================] - 318s 2s/step - loss: 4.9938 - root_mean_squared_error: 6.3774 - mean_absolute_error: 4.9938 - val_loss: 5.3541 - val_root_mean_squared_error: 7.0920 - val_mean_absolute_error: 5.3541\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 5.20694\n",
      "Epoch 130/1500\n",
      "143/143 [==============================] - 324s 2s/step - loss: 4.6690 - root_mean_squared_error: 5.9687 - mean_absolute_error: 4.6690 - val_loss: 5.6346 - val_root_mean_squared_error: 7.2592 - val_mean_absolute_error: 5.6346\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 5.20694\n",
      "Epoch 131/1500\n",
      "143/143 [==============================] - 324s 2s/step - loss: 4.8899 - root_mean_squared_error: 6.1621 - mean_absolute_error: 4.8899 - val_loss: 5.5427 - val_root_mean_squared_error: 7.0064 - val_mean_absolute_error: 5.5427\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 5.20694\n",
      "Epoch 132/1500\n",
      "143/143 [==============================] - 320s 2s/step - loss: 4.5110 - root_mean_squared_error: 5.8782 - mean_absolute_error: 4.5110 - val_loss: 5.8111 - val_root_mean_squared_error: 7.4283 - val_mean_absolute_error: 5.8111\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 5.20694\n",
      "Epoch 133/1500\n",
      "143/143 [==============================] - 324s 2s/step - loss: 4.8568 - root_mean_squared_error: 6.2208 - mean_absolute_error: 4.8568 - val_loss: 5.9040 - val_root_mean_squared_error: 7.4618 - val_mean_absolute_error: 5.9040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00133: val_loss did not improve from 5.20694\n",
      "Epoch 134/1500\n",
      "143/143 [==============================] - 323s 2s/step - loss: 4.9270 - root_mean_squared_error: 6.2901 - mean_absolute_error: 4.9270 - val_loss: 5.5962 - val_root_mean_squared_error: 7.2905 - val_mean_absolute_error: 5.5962\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 5.20694\n",
      "Epoch 135/1500\n",
      "143/143 [==============================] - 323s 2s/step - loss: 4.8693 - root_mean_squared_error: 6.1092 - mean_absolute_error: 4.8693 - val_loss: 5.6170 - val_root_mean_squared_error: 7.3019 - val_mean_absolute_error: 5.6170\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 5.20694\n",
      "Epoch 136/1500\n",
      "143/143 [==============================] - 323s 2s/step - loss: 4.7565 - root_mean_squared_error: 6.1799 - mean_absolute_error: 4.7565 - val_loss: 5.7584 - val_root_mean_squared_error: 7.4199 - val_mean_absolute_error: 5.7584\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 5.20694\n",
      "Epoch 137/1500\n",
      "143/143 [==============================] - 323s 2s/step - loss: 4.7995 - root_mean_squared_error: 6.0571 - mean_absolute_error: 4.7995 - val_loss: 5.8984 - val_root_mean_squared_error: 7.5353 - val_mean_absolute_error: 5.8984\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 5.20694\n",
      "Epoch 138/1500\n",
      "143/143 [==============================] - 326s 2s/step - loss: 4.6271 - root_mean_squared_error: 5.9737 - mean_absolute_error: 4.6271 - val_loss: 6.0369 - val_root_mean_squared_error: 7.8678 - val_mean_absolute_error: 6.0369\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 5.20694\n",
      "Epoch 139/1500\n",
      "143/143 [==============================] - 321s 2s/step - loss: 4.6795 - root_mean_squared_error: 6.0294 - mean_absolute_error: 4.6795 - val_loss: 5.4876 - val_root_mean_squared_error: 7.0529 - val_mean_absolute_error: 5.4876\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 5.20694\n",
      "Epoch 140/1500\n",
      "143/143 [==============================] - 296s 2s/step - loss: 4.6730 - root_mean_squared_error: 6.0468 - mean_absolute_error: 4.6730 - val_loss: 5.6842 - val_root_mean_squared_error: 7.3153 - val_mean_absolute_error: 5.6842\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 5.20694\n",
      "Epoch 141/1500\n",
      "143/143 [==============================] - 320s 2s/step - loss: 4.5330 - root_mean_squared_error: 5.8502 - mean_absolute_error: 4.5330 - val_loss: 5.9869 - val_root_mean_squared_error: 7.6452 - val_mean_absolute_error: 5.9869\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 5.20694\n",
      "Epoch 142/1500\n",
      "143/143 [==============================] - 323s 2s/step - loss: 4.8415 - root_mean_squared_error: 6.1866 - mean_absolute_error: 4.8415 - val_loss: 5.3403 - val_root_mean_squared_error: 6.7350 - val_mean_absolute_error: 5.3403\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 5.20694\n",
      "Epoch 143/1500\n",
      "143/143 [==============================] - 323s 2s/step - loss: 4.9459 - root_mean_squared_error: 6.2568 - mean_absolute_error: 4.9459 - val_loss: 5.6268 - val_root_mean_squared_error: 7.2411 - val_mean_absolute_error: 5.6268\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 5.20694\n",
      "Epoch 144/1500\n",
      "143/143 [==============================] - 323s 2s/step - loss: 4.7906 - root_mean_squared_error: 6.0757 - mean_absolute_error: 4.7906 - val_loss: 5.6572 - val_root_mean_squared_error: 7.1513 - val_mean_absolute_error: 5.6572\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 5.20694\n",
      "Epoch 145/1500\n",
      "143/143 [==============================] - 322s 2s/step - loss: 4.7588 - root_mean_squared_error: 6.2114 - mean_absolute_error: 4.7588 - val_loss: 5.7585 - val_root_mean_squared_error: 7.7572 - val_mean_absolute_error: 5.7585\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 5.20694\n",
      "Epoch 146/1500\n",
      "143/143 [==============================] - 320s 2s/step - loss: 5.0075 - root_mean_squared_error: 6.3629 - mean_absolute_error: 5.0075 - val_loss: 5.6981 - val_root_mean_squared_error: 7.5242 - val_mean_absolute_error: 5.6981\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 5.20694\n",
      "Epoch 147/1500\n",
      "143/143 [==============================] - 323s 2s/step - loss: 4.7627 - root_mean_squared_error: 6.1204 - mean_absolute_error: 4.7627 - val_loss: 5.3892 - val_root_mean_squared_error: 6.9870 - val_mean_absolute_error: 5.3892\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 5.20694\n",
      "Epoch 148/1500\n",
      "143/143 [==============================] - 324s 2s/step - loss: 4.7708 - root_mean_squared_error: 6.0847 - mean_absolute_error: 4.7708 - val_loss: 5.5782 - val_root_mean_squared_error: 7.0987 - val_mean_absolute_error: 5.5782\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 5.20694\n",
      "Epoch 149/1500\n",
      "143/143 [==============================] - 322s 2s/step - loss: 4.7899 - root_mean_squared_error: 5.9793 - mean_absolute_error: 4.7899 - val_loss: 6.1739 - val_root_mean_squared_error: 7.5452 - val_mean_absolute_error: 6.1739\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 5.20694\n",
      "Epoch 150/1500\n",
      "143/143 [==============================] - 321s 2s/step - loss: 4.7308 - root_mean_squared_error: 6.1345 - mean_absolute_error: 4.7308 - val_loss: 5.7093 - val_root_mean_squared_error: 7.3292 - val_mean_absolute_error: 5.7093\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 5.20694\n",
      "Epoch 151/1500\n",
      "143/143 [==============================] - 302s 2s/step - loss: 4.7578 - root_mean_squared_error: 6.1183 - mean_absolute_error: 4.7578 - val_loss: 5.6714 - val_root_mean_squared_error: 7.6167 - val_mean_absolute_error: 5.6714\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 5.20694\n",
      "Epoch 152/1500\n",
      "143/143 [==============================] - 320s 2s/step - loss: 4.8951 - root_mean_squared_error: 6.2551 - mean_absolute_error: 4.8951 - val_loss: 5.7819 - val_root_mean_squared_error: 7.3700 - val_mean_absolute_error: 5.7819\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 5.20694\n",
      "Epoch 153/1500\n",
      "143/143 [==============================] - 323s 2s/step - loss: 5.0190 - root_mean_squared_error: 6.4288 - mean_absolute_error: 5.0190 - val_loss: 5.5477 - val_root_mean_squared_error: 7.1894 - val_mean_absolute_error: 5.5477\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 5.20694\n",
      "Epoch 154/1500\n",
      "143/143 [==============================] - 325s 2s/step - loss: 5.1823 - root_mean_squared_error: 6.6188 - mean_absolute_error: 5.1823 - val_loss: 5.6999 - val_root_mean_squared_error: 7.3754 - val_mean_absolute_error: 5.6999\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 5.20694\n",
      "Epoch 155/1500\n",
      "143/143 [==============================] - 322s 2s/step - loss: 4.7492 - root_mean_squared_error: 6.0779 - mean_absolute_error: 4.7492 - val_loss: 5.9552 - val_root_mean_squared_error: 7.4454 - val_mean_absolute_error: 5.9552\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 5.20694\n",
      "Epoch 156/1500\n",
      "143/143 [==============================] - 321s 2s/step - loss: 4.6541 - root_mean_squared_error: 6.0529 - mean_absolute_error: 4.6541 - val_loss: 5.8362 - val_root_mean_squared_error: 7.4430 - val_mean_absolute_error: 5.8362\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 5.20694\n",
      "Epoch 157/1500\n",
      "143/143 [==============================] - 321s 2s/step - loss: 4.6994 - root_mean_squared_error: 5.9337 - mean_absolute_error: 4.6994 - val_loss: 5.6245 - val_root_mean_squared_error: 7.3345 - val_mean_absolute_error: 5.6245\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 5.20694\n",
      "Epoch 158/1500\n",
      "143/143 [==============================] - 321s 2s/step - loss: 4.7661 - root_mean_squared_error: 6.0269 - mean_absolute_error: 4.7661 - val_loss: 5.0405 - val_root_mean_squared_error: 6.5627 - val_mean_absolute_error: 5.0405\n",
      "\n",
      "Epoch 00158: val_loss improved from 5.20694 to 5.04051, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/Inception_regressor_05.hdf5\n",
      "Epoch 159/1500\n",
      "143/143 [==============================] - 319s 2s/step - loss: 4.8263 - root_mean_squared_error: 6.0217 - mean_absolute_error: 4.8263 - val_loss: 5.6694 - val_root_mean_squared_error: 7.2456 - val_mean_absolute_error: 5.6694\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 5.04051\n",
      "Epoch 160/1500\n",
      "143/143 [==============================] - 324s 2s/step - loss: 4.9190 - root_mean_squared_error: 6.5917 - mean_absolute_error: 4.9190 - val_loss: 5.4000 - val_root_mean_squared_error: 6.9878 - val_mean_absolute_error: 5.4000\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 5.04051\n",
      "Epoch 161/1500\n",
      "143/143 [==============================] - 324s 2s/step - loss: 4.9504 - root_mean_squared_error: 6.2298 - mean_absolute_error: 4.9504 - val_loss: 5.2148 - val_root_mean_squared_error: 6.5052 - val_mean_absolute_error: 5.2148\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 5.04051\n",
      "Epoch 162/1500\n",
      "143/143 [==============================] - 302s 2s/step - loss: 5.0769 - root_mean_squared_error: 6.4043 - mean_absolute_error: 5.0769 - val_loss: 5.3376 - val_root_mean_squared_error: 6.7863 - val_mean_absolute_error: 5.3376\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 5.04051\n",
      "Epoch 163/1500\n",
      "143/143 [==============================] - 322s 2s/step - loss: 4.7293 - root_mean_squared_error: 6.0027 - mean_absolute_error: 4.7293 - val_loss: 5.1770 - val_root_mean_squared_error: 6.5734 - val_mean_absolute_error: 5.1770\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 5.04051\n",
      "Epoch 164/1500\n",
      "143/143 [==============================] - 320s 2s/step - loss: 4.8319 - root_mean_squared_error: 6.1133 - mean_absolute_error: 4.8319 - val_loss: 6.1135 - val_root_mean_squared_error: 7.7944 - val_mean_absolute_error: 6.1135\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 5.04051\n",
      "Epoch 165/1500\n",
      "143/143 [==============================] - 325s 2s/step - loss: 5.1090 - root_mean_squared_error: 6.5479 - mean_absolute_error: 5.1090 - val_loss: 5.9482 - val_root_mean_squared_error: 7.5267 - val_mean_absolute_error: 5.9482\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 5.04051\n",
      "Epoch 166/1500\n",
      "143/143 [==============================] - 326s 2s/step - loss: 4.5435 - root_mean_squared_error: 5.9108 - mean_absolute_error: 4.5435 - val_loss: 5.7829 - val_root_mean_squared_error: 7.3109 - val_mean_absolute_error: 5.7829\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 5.04051\n",
      "Epoch 167/1500\n",
      "143/143 [==============================] - 319s 2s/step - loss: 4.9576 - root_mean_squared_error: 6.2293 - mean_absolute_error: 4.9576 - val_loss: 5.5738 - val_root_mean_squared_error: 7.2904 - val_mean_absolute_error: 5.5738\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 5.04051\n",
      "Epoch 168/1500\n",
      "143/143 [==============================] - 316s 2s/step - loss: 4.9382 - root_mean_squared_error: 6.4146 - mean_absolute_error: 4.9382 - val_loss: 5.3409 - val_root_mean_squared_error: 6.6990 - val_mean_absolute_error: 5.3409\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 5.04051\n",
      "Epoch 169/1500\n",
      "143/143 [==============================] - 305s 2s/step - loss: 4.9997 - root_mean_squared_error: 6.4097 - mean_absolute_error: 4.9997 - val_loss: 5.9832 - val_root_mean_squared_error: 7.7434 - val_mean_absolute_error: 5.9832\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 5.04051\n",
      "Epoch 170/1500\n",
      "143/143 [==============================] - 314s 2s/step - loss: 4.6625 - root_mean_squared_error: 6.0260 - mean_absolute_error: 4.6625 - val_loss: 5.3958 - val_root_mean_squared_error: 7.4136 - val_mean_absolute_error: 5.3958\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 5.04051\n",
      "Epoch 171/1500\n",
      "143/143 [==============================] - 321s 2s/step - loss: 4.8894 - root_mean_squared_error: 6.3500 - mean_absolute_error: 4.8894 - val_loss: 5.8241 - val_root_mean_squared_error: 7.4187 - val_mean_absolute_error: 5.8241\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 5.04051\n",
      "Epoch 172/1500\n",
      "143/143 [==============================] - 319s 2s/step - loss: 4.7815 - root_mean_squared_error: 6.3142 - mean_absolute_error: 4.7815 - val_loss: 5.7204 - val_root_mean_squared_error: 7.2427 - val_mean_absolute_error: 5.7204\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 5.04051\n",
      "Epoch 173/1500\n",
      "143/143 [==============================] - 308s 2s/step - loss: 4.9474 - root_mean_squared_error: 6.3330 - mean_absolute_error: 4.9474 - val_loss: 5.8809 - val_root_mean_squared_error: 7.4704 - val_mean_absolute_error: 5.8809\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 5.04051\n",
      "Epoch 174/1500\n",
      "143/143 [==============================] - 311s 2s/step - loss: 4.7659 - root_mean_squared_error: 6.1991 - mean_absolute_error: 4.7659 - val_loss: 5.8955 - val_root_mean_squared_error: 7.3922 - val_mean_absolute_error: 5.8955\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 5.04051\n",
      "Epoch 175/1500\n",
      "143/143 [==============================] - 321s 2s/step - loss: 4.7635 - root_mean_squared_error: 6.1842 - mean_absolute_error: 4.7635 - val_loss: 5.5446 - val_root_mean_squared_error: 6.8714 - val_mean_absolute_error: 5.5446\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 5.04051\n",
      "Epoch 176/1500\n",
      "143/143 [==============================] - 322s 2s/step - loss: 4.7022 - root_mean_squared_error: 6.0958 - mean_absolute_error: 4.7022 - val_loss: 5.2941 - val_root_mean_squared_error: 6.7480 - val_mean_absolute_error: 5.2941\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 5.04051\n",
      "Epoch 177/1500\n",
      "143/143 [==============================] - 323s 2s/step - loss: 5.0125 - root_mean_squared_error: 6.4927 - mean_absolute_error: 5.0125 - val_loss: 5.7977 - val_root_mean_squared_error: 7.4603 - val_mean_absolute_error: 5.7977\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 5.04051\n",
      "Epoch 178/1500\n",
      "143/143 [==============================] - 323s 2s/step - loss: 4.8558 - root_mean_squared_error: 6.1411 - mean_absolute_error: 4.8558 - val_loss: 5.3781 - val_root_mean_squared_error: 6.7899 - val_mean_absolute_error: 5.3781\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 5.04051\n",
      "Epoch 179/1500\n",
      "143/143 [==============================] - 324s 2s/step - loss: 4.7966 - root_mean_squared_error: 6.1557 - mean_absolute_error: 4.7966 - val_loss: 6.0253 - val_root_mean_squared_error: 7.7573 - val_mean_absolute_error: 6.0253\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 5.04051\n",
      "Epoch 180/1500\n",
      "143/143 [==============================] - 323s 2s/step - loss: 4.8659 - root_mean_squared_error: 6.2499 - mean_absolute_error: 4.8659 - val_loss: 6.2628 - val_root_mean_squared_error: 8.0656 - val_mean_absolute_error: 6.2628\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 5.04051\n",
      "Epoch 181/1500\n",
      "143/143 [==============================] - 323s 2s/step - loss: 4.7854 - root_mean_squared_error: 6.2447 - mean_absolute_error: 4.7854 - val_loss: 5.5746 - val_root_mean_squared_error: 7.3241 - val_mean_absolute_error: 5.5746\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 5.04051\n",
      "Epoch 182/1500\n",
      "143/143 [==============================] - 323s 2s/step - loss: 4.8431 - root_mean_squared_error: 6.2323 - mean_absolute_error: 4.8431 - val_loss: 5.3882 - val_root_mean_squared_error: 6.8919 - val_mean_absolute_error: 5.3882\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 5.04051\n",
      "Epoch 183/1500\n",
      "143/143 [==============================] - 325s 2s/step - loss: 4.8003 - root_mean_squared_error: 6.2705 - mean_absolute_error: 4.8003 - val_loss: 5.2593 - val_root_mean_squared_error: 6.8842 - val_mean_absolute_error: 5.2593\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 5.04051\n",
      "Epoch 184/1500\n",
      "143/143 [==============================] - 323s 2s/step - loss: 5.0008 - root_mean_squared_error: 6.3048 - mean_absolute_error: 5.0008 - val_loss: 5.7277 - val_root_mean_squared_error: 7.4730 - val_mean_absolute_error: 5.7277\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 5.04051\n",
      "Epoch 185/1500\n",
      "143/143 [==============================] - 302s 2s/step - loss: 4.7262 - root_mean_squared_error: 6.1513 - mean_absolute_error: 4.7262 - val_loss: 5.7804 - val_root_mean_squared_error: 7.2857 - val_mean_absolute_error: 5.7804\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 5.04051\n",
      "Epoch 186/1500\n",
      "143/143 [==============================] - 322s 2s/step - loss: 4.4992 - root_mean_squared_error: 5.7600 - mean_absolute_error: 4.4992 - val_loss: 5.5531 - val_root_mean_squared_error: 6.9290 - val_mean_absolute_error: 5.5531\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 5.04051\n",
      "Epoch 187/1500\n",
      "143/143 [==============================] - 320s 2s/step - loss: 4.9325 - root_mean_squared_error: 6.3248 - mean_absolute_error: 4.9325 - val_loss: 5.8506 - val_root_mean_squared_error: 7.3749 - val_mean_absolute_error: 5.8506\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 5.04051\n",
      "Epoch 188/1500\n",
      "143/143 [==============================] - 320s 2s/step - loss: 4.8370 - root_mean_squared_error: 6.1479 - mean_absolute_error: 4.8370 - val_loss: 5.5940 - val_root_mean_squared_error: 7.0616 - val_mean_absolute_error: 5.5940\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 5.04051\n",
      "Epoch 189/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 323s 2s/step - loss: 4.6652 - root_mean_squared_error: 6.0196 - mean_absolute_error: 4.6652 - val_loss: 6.1782 - val_root_mean_squared_error: 7.6756 - val_mean_absolute_error: 6.1782\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 5.04051\n",
      "Epoch 190/1500\n",
      "143/143 [==============================] - 323s 2s/step - loss: 4.8163 - root_mean_squared_error: 6.2274 - mean_absolute_error: 4.8163 - val_loss: 5.3501 - val_root_mean_squared_error: 6.8194 - val_mean_absolute_error: 5.3501\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 5.04051\n",
      "Epoch 191/1500\n",
      "143/143 [==============================] - 323s 2s/step - loss: 4.8694 - root_mean_squared_error: 6.2544 - mean_absolute_error: 4.8694 - val_loss: 5.5560 - val_root_mean_squared_error: 7.1667 - val_mean_absolute_error: 5.5560\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 5.04051\n",
      "Epoch 192/1500\n",
      "143/143 [==============================] - 324s 2s/step - loss: 4.8435 - root_mean_squared_error: 6.1235 - mean_absolute_error: 4.8435 - val_loss: 5.5419 - val_root_mean_squared_error: 7.2060 - val_mean_absolute_error: 5.5419\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 5.04051\n",
      "Epoch 193/1500\n",
      "143/143 [==============================] - 325s 2s/step - loss: 4.8865 - root_mean_squared_error: 6.2751 - mean_absolute_error: 4.8865 - val_loss: 5.8865 - val_root_mean_squared_error: 7.7323 - val_mean_absolute_error: 5.8865\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 5.04051\n",
      "Epoch 194/1500\n",
      "143/143 [==============================] - 323s 2s/step - loss: 5.0769 - root_mean_squared_error: 6.6029 - mean_absolute_error: 5.0769 - val_loss: 5.5031 - val_root_mean_squared_error: 7.0043 - val_mean_absolute_error: 5.5031\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 5.04051\n",
      "Epoch 195/1500\n",
      "143/143 [==============================] - 326s 2s/step - loss: 4.7929 - root_mean_squared_error: 6.2485 - mean_absolute_error: 4.7929 - val_loss: 5.4726 - val_root_mean_squared_error: 6.8638 - val_mean_absolute_error: 5.4726\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 5.04051\n",
      "Epoch 196/1500\n",
      "143/143 [==============================] - 304s 2s/step - loss: 4.7540 - root_mean_squared_error: 6.1283 - mean_absolute_error: 4.7540 - val_loss: 5.3282 - val_root_mean_squared_error: 6.7664 - val_mean_absolute_error: 5.3282\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 5.04051\n",
      "Epoch 197/1500\n",
      "143/143 [==============================] - 324s 2s/step - loss: 4.7573 - root_mean_squared_error: 6.1107 - mean_absolute_error: 4.7573 - val_loss: 5.3006 - val_root_mean_squared_error: 6.8323 - val_mean_absolute_error: 5.3006\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 5.04051\n",
      "Epoch 198/1500\n",
      "143/143 [==============================] - 324s 2s/step - loss: 4.9761 - root_mean_squared_error: 6.4923 - mean_absolute_error: 4.9761 - val_loss: 5.8414 - val_root_mean_squared_error: 7.3852 - val_mean_absolute_error: 5.8414\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 5.04051\n",
      "Epoch 199/1500\n",
      "143/143 [==============================] - 324s 2s/step - loss: 5.0259 - root_mean_squared_error: 6.4252 - mean_absolute_error: 5.0259 - val_loss: 5.6090 - val_root_mean_squared_error: 7.2203 - val_mean_absolute_error: 5.6090\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 5.04051\n",
      "Epoch 200/1500\n",
      "143/143 [==============================] - 325s 2s/step - loss: 4.8177 - root_mean_squared_error: 6.0919 - mean_absolute_error: 4.8177 - val_loss: 5.6196 - val_root_mean_squared_error: 7.1161 - val_mean_absolute_error: 5.6196\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 5.04051\n",
      "Epoch 201/1500\n",
      "143/143 [==============================] - 325s 2s/step - loss: 4.9170 - root_mean_squared_error: 6.2662 - mean_absolute_error: 4.9170 - val_loss: 5.1065 - val_root_mean_squared_error: 6.8218 - val_mean_absolute_error: 5.1065\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 5.04051\n",
      "Epoch 202/1500\n",
      "143/143 [==============================] - 323s 2s/step - loss: 4.6324 - root_mean_squared_error: 5.9229 - mean_absolute_error: 4.6324 - val_loss: 5.4781 - val_root_mean_squared_error: 7.0641 - val_mean_absolute_error: 5.4781\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 5.04051\n",
      "Epoch 203/1500\n",
      "143/143 [==============================] - 293s 2s/step - loss: 4.8426 - root_mean_squared_error: 6.1387 - mean_absolute_error: 4.8426 - val_loss: 5.3528 - val_root_mean_squared_error: 6.8364 - val_mean_absolute_error: 5.3528\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 5.04051\n",
      "Epoch 204/1500\n",
      "143/143 [==============================] - 287s 2s/step - loss: 4.7281 - root_mean_squared_error: 6.0725 - mean_absolute_error: 4.7281 - val_loss: 5.8679 - val_root_mean_squared_error: 7.4507 - val_mean_absolute_error: 5.8679\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 5.04051\n",
      "Epoch 205/1500\n",
      "143/143 [==============================] - 275s 2s/step - loss: 4.7399 - root_mean_squared_error: 6.0821 - mean_absolute_error: 4.7399 - val_loss: 5.9682 - val_root_mean_squared_error: 7.5256 - val_mean_absolute_error: 5.9682\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 5.04051\n",
      "Epoch 206/1500\n",
      "143/143 [==============================] - 2128s 15s/step - loss: 4.8784 - root_mean_squared_error: 6.3508 - mean_absolute_error: 4.8784 - val_loss: 5.3873 - val_root_mean_squared_error: 7.0144 - val_mean_absolute_error: 5.3873\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 5.04051\n",
      "Epoch 207/1500\n",
      "143/143 [==============================] - 272s 2s/step - loss: 4.7648 - root_mean_squared_error: 6.1376 - mean_absolute_error: 4.7648 - val_loss: 4.6946 - val_root_mean_squared_error: 6.0119 - val_mean_absolute_error: 4.6946\n",
      "\n",
      "Epoch 00207: val_loss improved from 5.04051 to 4.69455, saving model to /Users/bbruns/Desktop/Studie/Thesis/Code/EEG_age_prediction/trained_models/Inception_regressor_05.hdf5\n",
      "Epoch 208/1500\n",
      "143/143 [==============================] - 269s 2s/step - loss: 5.0114 - root_mean_squared_error: 6.3570 - mean_absolute_error: 5.0114 - val_loss: 5.4862 - val_root_mean_squared_error: 6.8584 - val_mean_absolute_error: 5.4862\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 4.69455\n",
      "Epoch 209/1500\n",
      "143/143 [==============================] - 250s 2s/step - loss: 4.4907 - root_mean_squared_error: 5.8185 - mean_absolute_error: 4.4907 - val_loss: 5.7294 - val_root_mean_squared_error: 7.3362 - val_mean_absolute_error: 5.7294\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 4.69455\n",
      "Epoch 210/1500\n",
      "143/143 [==============================] - 245s 2s/step - loss: 4.9703 - root_mean_squared_error: 6.3875 - mean_absolute_error: 4.9703 - val_loss: 5.9660 - val_root_mean_squared_error: 7.4091 - val_mean_absolute_error: 5.9660\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 4.69455\n",
      "Epoch 211/1500\n",
      "143/143 [==============================] - 242s 2s/step - loss: 4.5693 - root_mean_squared_error: 5.8561 - mean_absolute_error: 4.5693 - val_loss: 5.8066 - val_root_mean_squared_error: 7.2895 - val_mean_absolute_error: 5.8066\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 4.69455\n",
      "Epoch 212/1500\n",
      "143/143 [==============================] - 242s 2s/step - loss: 4.7879 - root_mean_squared_error: 6.1615 - mean_absolute_error: 4.7879 - val_loss: 5.6362 - val_root_mean_squared_error: 7.2071 - val_mean_absolute_error: 5.6362\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 4.69455\n",
      "Epoch 213/1500\n",
      "143/143 [==============================] - 253s 2s/step - loss: 4.6835 - root_mean_squared_error: 5.9570 - mean_absolute_error: 4.6835 - val_loss: 5.2189 - val_root_mean_squared_error: 6.7165 - val_mean_absolute_error: 5.2189\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 4.69455\n",
      "Epoch 214/1500\n",
      "143/143 [==============================] - 306s 2s/step - loss: 4.8686 - root_mean_squared_error: 6.3533 - mean_absolute_error: 4.8686 - val_loss: 5.7287 - val_root_mean_squared_error: 7.4326 - val_mean_absolute_error: 5.7287\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 4.69455\n",
      "Epoch 215/1500\n",
      "143/143 [==============================] - 308s 2s/step - loss: 4.8383 - root_mean_squared_error: 6.2667 - mean_absolute_error: 4.8383 - val_loss: 5.4112 - val_root_mean_squared_error: 6.9353 - val_mean_absolute_error: 5.4112\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 4.69455\n",
      "Epoch 216/1500\n",
      "143/143 [==============================] - 262s 2s/step - loss: 5.0741 - root_mean_squared_error: 6.3657 - mean_absolute_error: 5.0741 - val_loss: 6.1766 - val_root_mean_squared_error: 7.8160 - val_mean_absolute_error: 6.1766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00216: val_loss did not improve from 4.69455\n",
      "Epoch 217/1500\n",
      "143/143 [==============================] - 293s 2s/step - loss: 4.8800 - root_mean_squared_error: 6.2364 - mean_absolute_error: 4.8800 - val_loss: 5.8352 - val_root_mean_squared_error: 7.3876 - val_mean_absolute_error: 5.8352\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 4.69455\n",
      "Epoch 218/1500\n",
      "143/143 [==============================] - 284s 2s/step - loss: 4.6264 - root_mean_squared_error: 5.8839 - mean_absolute_error: 4.6264 - val_loss: 5.5292 - val_root_mean_squared_error: 7.0442 - val_mean_absolute_error: 5.5292\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 4.69455\n",
      "Epoch 219/1500\n",
      "143/143 [==============================] - 311s 2s/step - loss: 5.0450 - root_mean_squared_error: 6.4782 - mean_absolute_error: 5.0450 - val_loss: 5.7673 - val_root_mean_squared_error: 7.2827 - val_mean_absolute_error: 5.7673\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 4.69455\n",
      "Epoch 220/1500\n",
      "143/143 [==============================] - 276s 2s/step - loss: 4.8731 - root_mean_squared_error: 6.2059 - mean_absolute_error: 4.8731 - val_loss: 5.4898 - val_root_mean_squared_error: 6.9446 - val_mean_absolute_error: 5.4898\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 4.69455\n",
      "Epoch 221/1500\n",
      "143/143 [==============================] - 295s 2s/step - loss: 4.9015 - root_mean_squared_error: 6.2638 - mean_absolute_error: 4.9015 - val_loss: 5.4136 - val_root_mean_squared_error: 7.0744 - val_mean_absolute_error: 5.4136\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 4.69455\n",
      "Epoch 222/1500\n",
      "143/143 [==============================] - 258s 2s/step - loss: 4.9626 - root_mean_squared_error: 6.5825 - mean_absolute_error: 4.9626 - val_loss: 5.5923 - val_root_mean_squared_error: 7.3232 - val_mean_absolute_error: 5.5923\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 4.69455\n",
      "Epoch 223/1500\n",
      "143/143 [==============================] - 269s 2s/step - loss: 4.5341 - root_mean_squared_error: 5.7505 - mean_absolute_error: 4.5341 - val_loss: 6.0022 - val_root_mean_squared_error: 7.6524 - val_mean_absolute_error: 6.0022\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 4.69455\n",
      "Epoch 224/1500\n",
      "143/143 [==============================] - 300s 2s/step - loss: 4.8216 - root_mean_squared_error: 6.1067 - mean_absolute_error: 4.8216 - val_loss: 5.8432 - val_root_mean_squared_error: 7.3194 - val_mean_absolute_error: 5.8432\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 4.69455\n",
      "Epoch 225/1500\n",
      "143/143 [==============================] - 294s 2s/step - loss: 4.8358 - root_mean_squared_error: 6.1648 - mean_absolute_error: 4.8358 - val_loss: 4.8508 - val_root_mean_squared_error: 6.2729 - val_mean_absolute_error: 4.8508\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 4.69455\n",
      "Epoch 226/1500\n",
      "143/143 [==============================] - 311s 2s/step - loss: 4.7822 - root_mean_squared_error: 6.1104 - mean_absolute_error: 4.7822 - val_loss: 6.1147 - val_root_mean_squared_error: 7.7561 - val_mean_absolute_error: 6.1147\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 4.69455\n",
      "Epoch 227/1500\n",
      "143/143 [==============================] - 295s 2s/step - loss: 4.7817 - root_mean_squared_error: 6.1987 - mean_absolute_error: 4.7817 - val_loss: 5.6932 - val_root_mean_squared_error: 7.3216 - val_mean_absolute_error: 5.6932\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 4.69455\n",
      "Epoch 228/1500\n",
      "143/143 [==============================] - 291s 2s/step - loss: 4.8418 - root_mean_squared_error: 6.2398 - mean_absolute_error: 4.8418 - val_loss: 5.7705 - val_root_mean_squared_error: 7.3208 - val_mean_absolute_error: 5.7705\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 4.69455\n",
      "Epoch 229/1500\n",
      "143/143 [==============================] - 293s 2s/step - loss: 4.9628 - root_mean_squared_error: 6.2796 - mean_absolute_error: 4.9628 - val_loss: 5.8155 - val_root_mean_squared_error: 7.5935 - val_mean_absolute_error: 5.8155\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 4.69455\n",
      "Epoch 230/1500\n",
      "143/143 [==============================] - 343s 2s/step - loss: 4.8053 - root_mean_squared_error: 6.1763 - mean_absolute_error: 4.8053 - val_loss: 5.8018 - val_root_mean_squared_error: 7.5082 - val_mean_absolute_error: 5.8018\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 4.69455\n",
      "Epoch 231/1500\n",
      "143/143 [==============================] - 378s 3s/step - loss: 4.7521 - root_mean_squared_error: 6.1655 - mean_absolute_error: 4.7521 - val_loss: 6.0011 - val_root_mean_squared_error: 7.6342 - val_mean_absolute_error: 6.0011\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 4.69455\n",
      "Epoch 232/1500\n",
      "143/143 [==============================] - 314s 2s/step - loss: 4.7057 - root_mean_squared_error: 6.0167 - mean_absolute_error: 4.7057 - val_loss: 5.2635 - val_root_mean_squared_error: 6.9743 - val_mean_absolute_error: 5.2635\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 4.69455\n",
      "Epoch 233/1500\n",
      "143/143 [==============================] - 337s 2s/step - loss: 4.9519 - root_mean_squared_error: 6.2336 - mean_absolute_error: 4.9519 - val_loss: 5.2837 - val_root_mean_squared_error: 6.6962 - val_mean_absolute_error: 5.2837\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 4.69455\n",
      "Epoch 234/1500\n",
      "143/143 [==============================] - 414s 3s/step - loss: 4.9174 - root_mean_squared_error: 6.2818 - mean_absolute_error: 4.9174 - val_loss: 5.4133 - val_root_mean_squared_error: 7.0117 - val_mean_absolute_error: 5.4133\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 4.69455\n",
      "Epoch 235/1500\n",
      "143/143 [==============================] - 545s 4s/step - loss: 4.7633 - root_mean_squared_error: 6.2368 - mean_absolute_error: 4.7633 - val_loss: 5.9327 - val_root_mean_squared_error: 7.4576 - val_mean_absolute_error: 5.9327\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 4.69455\n",
      "Epoch 236/1500\n",
      "143/143 [==============================] - 522s 4s/step - loss: 4.9930 - root_mean_squared_error: 6.4533 - mean_absolute_error: 4.9930 - val_loss: 5.8887 - val_root_mean_squared_error: 7.6307 - val_mean_absolute_error: 5.8887\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 4.69455\n",
      "Epoch 237/1500\n",
      "143/143 [==============================] - 894s 6s/step - loss: 4.6050 - root_mean_squared_error: 5.8073 - mean_absolute_error: 4.6050 - val_loss: 5.4781 - val_root_mean_squared_error: 7.0113 - val_mean_absolute_error: 5.4781\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 4.69455\n",
      "Epoch 238/1500\n",
      "143/143 [==============================] - 604s 4s/step - loss: 4.9160 - root_mean_squared_error: 6.3321 - mean_absolute_error: 4.9160 - val_loss: 5.6976 - val_root_mean_squared_error: 7.2283 - val_mean_absolute_error: 5.6976\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 4.69455\n",
      "Epoch 239/1500\n",
      "143/143 [==============================] - 285s 2s/step - loss: 4.9762 - root_mean_squared_error: 6.3932 - mean_absolute_error: 4.9762 - val_loss: 5.4177 - val_root_mean_squared_error: 6.9163 - val_mean_absolute_error: 5.4177\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 4.69455\n",
      "Epoch 240/1500\n",
      "143/143 [==============================] - 267s 2s/step - loss: 4.6547 - root_mean_squared_error: 6.0445 - mean_absolute_error: 4.6547 - val_loss: 5.9957 - val_root_mean_squared_error: 7.4999 - val_mean_absolute_error: 5.9957\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 4.69455\n",
      "Epoch 241/1500\n",
      "143/143 [==============================] - 276s 2s/step - loss: 4.7439 - root_mean_squared_error: 6.1015 - mean_absolute_error: 4.7439 - val_loss: 5.5636 - val_root_mean_squared_error: 7.1143 - val_mean_absolute_error: 5.5636\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 4.69455\n",
      "Epoch 242/1500\n",
      "143/143 [==============================] - 2062s 15s/step - loss: 4.6916 - root_mean_squared_error: 6.1090 - mean_absolute_error: 4.6916 - val_loss: 5.7186 - val_root_mean_squared_error: 7.2993 - val_mean_absolute_error: 5.7186\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 4.69455\n",
      "Epoch 243/1500\n",
      "143/143 [==============================] - 268s 2s/step - loss: 4.7852 - root_mean_squared_error: 6.1017 - mean_absolute_error: 4.7852 - val_loss: 5.8263 - val_root_mean_squared_error: 7.2378 - val_mean_absolute_error: 5.8263\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 4.69455\n",
      "Epoch 244/1500\n",
      "143/143 [==============================] - 881s 6s/step - loss: 4.7268 - root_mean_squared_error: 6.1609 - mean_absolute_error: 4.7268 - val_loss: 5.7875 - val_root_mean_squared_error: 7.2667 - val_mean_absolute_error: 5.7875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00244: val_loss did not improve from 4.69455\n",
      "Epoch 245/1500\n",
      "143/143 [==============================] - 1083s 8s/step - loss: 4.8373 - root_mean_squared_error: 6.3008 - mean_absolute_error: 4.8373 - val_loss: 5.7162 - val_root_mean_squared_error: 7.2399 - val_mean_absolute_error: 5.7162\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 4.69455\n",
      "Epoch 246/1500\n",
      "143/143 [==============================] - 854s 6s/step - loss: 4.7068 - root_mean_squared_error: 6.0775 - mean_absolute_error: 4.7068 - val_loss: 5.7267 - val_root_mean_squared_error: 7.3911 - val_mean_absolute_error: 5.7267\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 4.69455\n",
      "Epoch 247/1500\n",
      "143/143 [==============================] - 484s 3s/step - loss: 4.9483 - root_mean_squared_error: 6.2214 - mean_absolute_error: 4.9483 - val_loss: 5.1563 - val_root_mean_squared_error: 6.7706 - val_mean_absolute_error: 5.1563\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 4.69455\n",
      "Epoch 248/1500\n",
      "143/143 [==============================] - 319s 2s/step - loss: 4.8704 - root_mean_squared_error: 6.1716 - mean_absolute_error: 4.8704 - val_loss: 5.7358 - val_root_mean_squared_error: 7.2530 - val_mean_absolute_error: 5.7358\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 4.69455\n",
      "Epoch 249/1500\n",
      "143/143 [==============================] - 322s 2s/step - loss: 4.7772 - root_mean_squared_error: 6.1153 - mean_absolute_error: 4.7772 - val_loss: 5.8663 - val_root_mean_squared_error: 7.3816 - val_mean_absolute_error: 5.8663\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 4.69455\n",
      "Epoch 250/1500\n",
      "143/143 [==============================] - 319s 2s/step - loss: 4.5594 - root_mean_squared_error: 6.0153 - mean_absolute_error: 4.5594 - val_loss: 5.3681 - val_root_mean_squared_error: 6.9636 - val_mean_absolute_error: 5.3681\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 4.69455\n",
      "Epoch 251/1500\n",
      "143/143 [==============================] - 303s 2s/step - loss: 5.0810 - root_mean_squared_error: 6.6498 - mean_absolute_error: 5.0810 - val_loss: 5.8722 - val_root_mean_squared_error: 7.6093 - val_mean_absolute_error: 5.8722\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 4.69455\n",
      "Epoch 252/1500\n",
      "143/143 [==============================] - 319s 2s/step - loss: 4.7291 - root_mean_squared_error: 6.0807 - mean_absolute_error: 4.7291 - val_loss: 5.7905 - val_root_mean_squared_error: 7.2700 - val_mean_absolute_error: 5.7905\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 4.69455\n",
      "Epoch 253/1500\n",
      "143/143 [==============================] - 319s 2s/step - loss: 4.6109 - root_mean_squared_error: 6.0907 - mean_absolute_error: 4.6109 - val_loss: 5.8634 - val_root_mean_squared_error: 7.3839 - val_mean_absolute_error: 5.8634\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 4.69455\n",
      "Epoch 254/1500\n",
      "143/143 [==============================] - 295s 2s/step - loss: 4.9132 - root_mean_squared_error: 6.4046 - mean_absolute_error: 4.9132 - val_loss: 5.3212 - val_root_mean_squared_error: 6.5861 - val_mean_absolute_error: 5.3212\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 4.69455\n",
      "Epoch 255/1500\n",
      "143/143 [==============================] - 280s 2s/step - loss: 4.9071 - root_mean_squared_error: 6.3919 - mean_absolute_error: 4.9071 - val_loss: 5.4392 - val_root_mean_squared_error: 7.0111 - val_mean_absolute_error: 5.4392\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 4.69455\n",
      "Epoch 256/1500\n",
      "143/143 [==============================] - 312s 2s/step - loss: 4.7860 - root_mean_squared_error: 6.0500 - mean_absolute_error: 4.7860 - val_loss: 5.7753 - val_root_mean_squared_error: 7.4458 - val_mean_absolute_error: 5.7753\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 4.69455\n",
      "Epoch 257/1500\n",
      "143/143 [==============================] - 298s 2s/step - loss: 4.8548 - root_mean_squared_error: 6.1738 - mean_absolute_error: 4.8548 - val_loss: 5.1632 - val_root_mean_squared_error: 6.9379 - val_mean_absolute_error: 5.1632\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 4.69455\n",
      "Epoch 258/1500\n",
      "143/143 [==============================] - 276s 2s/step - loss: 4.6948 - root_mean_squared_error: 6.0194 - mean_absolute_error: 4.6948 - val_loss: 5.5370 - val_root_mean_squared_error: 7.0687 - val_mean_absolute_error: 5.5370\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 4.69455\n",
      "Epoch 259/1500\n",
      "143/143 [==============================] - 298s 2s/step - loss: 4.9750 - root_mean_squared_error: 6.3101 - mean_absolute_error: 4.9750 - val_loss: 5.7828 - val_root_mean_squared_error: 7.2928 - val_mean_absolute_error: 5.7828\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 4.69455\n",
      "Epoch 260/1500\n",
      "143/143 [==============================] - 278s 2s/step - loss: 4.8603 - root_mean_squared_error: 6.3085 - mean_absolute_error: 4.8603 - val_loss: 5.6708 - val_root_mean_squared_error: 7.2135 - val_mean_absolute_error: 5.6708\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 4.69455\n",
      "Epoch 261/1500\n",
      "143/143 [==============================] - 281s 2s/step - loss: 4.5480 - root_mean_squared_error: 5.8718 - mean_absolute_error: 4.5480 - val_loss: 6.0383 - val_root_mean_squared_error: 7.7267 - val_mean_absolute_error: 6.0383\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 4.69455\n",
      "Epoch 262/1500\n",
      "143/143 [==============================] - 308s 2s/step - loss: 4.8662 - root_mean_squared_error: 6.2239 - mean_absolute_error: 4.8662 - val_loss: 5.5043 - val_root_mean_squared_error: 7.0815 - val_mean_absolute_error: 5.5043\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 4.69455\n",
      "Epoch 263/1500\n",
      "143/143 [==============================] - 331s 2s/step - loss: 4.8594 - root_mean_squared_error: 6.2190 - mean_absolute_error: 4.8594 - val_loss: 5.4815 - val_root_mean_squared_error: 6.9495 - val_mean_absolute_error: 5.4815\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 4.69455\n",
      "Epoch 264/1500\n",
      "143/143 [==============================] - 291s 2s/step - loss: 4.6237 - root_mean_squared_error: 5.9592 - mean_absolute_error: 4.6237 - val_loss: 6.1921 - val_root_mean_squared_error: 7.6494 - val_mean_absolute_error: 6.1921\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 4.69455\n",
      "Epoch 265/1500\n",
      "143/143 [==============================] - 280s 2s/step - loss: 4.9387 - root_mean_squared_error: 6.3696 - mean_absolute_error: 4.9386 - val_loss: 5.3327 - val_root_mean_squared_error: 6.9895 - val_mean_absolute_error: 5.3327\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 4.69455\n",
      "Epoch 266/1500\n",
      "143/143 [==============================] - 306s 2s/step - loss: 4.6182 - root_mean_squared_error: 6.0124 - mean_absolute_error: 4.6182 - val_loss: 5.6540 - val_root_mean_squared_error: 7.0306 - val_mean_absolute_error: 5.6540\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 4.69455\n",
      "Epoch 267/1500\n",
      "143/143 [==============================] - 294s 2s/step - loss: 4.6628 - root_mean_squared_error: 6.0783 - mean_absolute_error: 4.6628 - val_loss: 6.0017 - val_root_mean_squared_error: 7.5158 - val_mean_absolute_error: 6.0017\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 4.69455\n",
      "Epoch 268/1500\n",
      "143/143 [==============================] - 309s 2s/step - loss: 4.7577 - root_mean_squared_error: 6.1478 - mean_absolute_error: 4.7577 - val_loss: 5.4827 - val_root_mean_squared_error: 7.0207 - val_mean_absolute_error: 5.4827\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 4.69455\n",
      "Epoch 269/1500\n",
      "143/143 [==============================] - 324s 2s/step - loss: 4.8810 - root_mean_squared_error: 6.2940 - mean_absolute_error: 4.8810 - val_loss: 5.5935 - val_root_mean_squared_error: 7.3906 - val_mean_absolute_error: 5.5935\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 4.69455\n",
      "Epoch 270/1500\n",
      "143/143 [==============================] - 305s 2s/step - loss: 4.7379 - root_mean_squared_error: 6.0358 - mean_absolute_error: 4.7379 - val_loss: 5.5442 - val_root_mean_squared_error: 7.2252 - val_mean_absolute_error: 5.5442\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 4.69455\n",
      "Epoch 271/1500\n",
      "143/143 [==============================] - 289s 2s/step - loss: 4.7442 - root_mean_squared_error: 6.2146 - mean_absolute_error: 4.7442 - val_loss: 5.6291 - val_root_mean_squared_error: 7.0891 - val_mean_absolute_error: 5.6291\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 4.69455\n",
      "Epoch 272/1500\n",
      "143/143 [==============================] - 285s 2s/step - loss: 4.4160 - root_mean_squared_error: 5.6703 - mean_absolute_error: 4.4160 - val_loss: 5.8170 - val_root_mean_squared_error: 7.5235 - val_mean_absolute_error: 5.8170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00272: val_loss did not improve from 4.69455\n",
      "Epoch 273/1500\n",
      "143/143 [==============================] - 289s 2s/step - loss: 4.9148 - root_mean_squared_error: 6.3654 - mean_absolute_error: 4.9148 - val_loss: 5.6706 - val_root_mean_squared_error: 7.2174 - val_mean_absolute_error: 5.6706\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 4.69455\n",
      "Epoch 274/1500\n",
      "143/143 [==============================] - 276s 2s/step - loss: 4.6158 - root_mean_squared_error: 6.1187 - mean_absolute_error: 4.6158 - val_loss: 5.6966 - val_root_mean_squared_error: 7.5244 - val_mean_absolute_error: 5.6966\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 4.69455\n",
      "Epoch 275/1500\n",
      "143/143 [==============================] - 298s 2s/step - loss: 5.0629 - root_mean_squared_error: 6.5235 - mean_absolute_error: 5.0629 - val_loss: 6.1959 - val_root_mean_squared_error: 7.6484 - val_mean_absolute_error: 6.1959\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 4.69455\n",
      "Epoch 276/1500\n",
      "143/143 [==============================] - 287s 2s/step - loss: 4.8903 - root_mean_squared_error: 6.3941 - mean_absolute_error: 4.8903 - val_loss: 5.6276 - val_root_mean_squared_error: 7.3213 - val_mean_absolute_error: 5.6276\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 4.69455\n",
      "Epoch 277/1500\n",
      "143/143 [==============================] - 288s 2s/step - loss: 4.5528 - root_mean_squared_error: 5.8274 - mean_absolute_error: 4.5528 - val_loss: 5.5876 - val_root_mean_squared_error: 7.1010 - val_mean_absolute_error: 5.5876\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 4.69455\n",
      "Epoch 278/1500\n",
      "143/143 [==============================] - 289s 2s/step - loss: 4.7971 - root_mean_squared_error: 6.3085 - mean_absolute_error: 4.7971 - val_loss: 5.9176 - val_root_mean_squared_error: 7.6867 - val_mean_absolute_error: 5.9176\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 4.69455\n",
      "Epoch 279/1500\n",
      "143/143 [==============================] - 285s 2s/step - loss: 4.4988 - root_mean_squared_error: 5.8091 - mean_absolute_error: 4.4988 - val_loss: 5.2388 - val_root_mean_squared_error: 6.8276 - val_mean_absolute_error: 5.2388\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 4.69455\n",
      "Epoch 280/1500\n",
      "143/143 [==============================] - 294s 2s/step - loss: 4.7552 - root_mean_squared_error: 5.9508 - mean_absolute_error: 4.7552 - val_loss: 5.9823 - val_root_mean_squared_error: 7.8353 - val_mean_absolute_error: 5.9823\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 4.69455\n",
      "Epoch 281/1500\n",
      "143/143 [==============================] - 285s 2s/step - loss: 4.9642 - root_mean_squared_error: 6.2657 - mean_absolute_error: 4.9642 - val_loss: 5.7183 - val_root_mean_squared_error: 7.3327 - val_mean_absolute_error: 5.7183\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 4.69455\n",
      "Epoch 282/1500\n",
      "143/143 [==============================] - 2127s 15s/step - loss: 4.6912 - root_mean_squared_error: 5.9662 - mean_absolute_error: 4.6912 - val_loss: 5.8670 - val_root_mean_squared_error: 7.8798 - val_mean_absolute_error: 5.8670\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 4.69455\n",
      "Epoch 283/1500\n",
      "143/143 [==============================] - 301s 2s/step - loss: 4.8841 - root_mean_squared_error: 6.2511 - mean_absolute_error: 4.8841 - val_loss: 5.7431 - val_root_mean_squared_error: 7.4044 - val_mean_absolute_error: 5.7431\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 4.69455\n",
      "Epoch 284/1500\n",
      "143/143 [==============================] - 304s 2s/step - loss: 4.5820 - root_mean_squared_error: 5.8400 - mean_absolute_error: 4.5820 - val_loss: 5.8986 - val_root_mean_squared_error: 7.2511 - val_mean_absolute_error: 5.8986\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 4.69455\n",
      "Epoch 285/1500\n",
      "143/143 [==============================] - 5591s 39s/step - loss: 4.7531 - root_mean_squared_error: 6.0601 - mean_absolute_error: 4.7531 - val_loss: 5.9722 - val_root_mean_squared_error: 7.8504 - val_mean_absolute_error: 5.9722\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 4.69455\n",
      "Epoch 286/1500\n",
      "143/143 [==============================] - 318s 2s/step - loss: 4.8482 - root_mean_squared_error: 6.1827 - mean_absolute_error: 4.8482 - val_loss: 6.0374 - val_root_mean_squared_error: 7.7894 - val_mean_absolute_error: 6.0374\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 4.69455\n",
      "Epoch 287/1500\n",
      "143/143 [==============================] - 297s 2s/step - loss: 4.7140 - root_mean_squared_error: 6.0740 - mean_absolute_error: 4.7140 - val_loss: 5.6098 - val_root_mean_squared_error: 7.1654 - val_mean_absolute_error: 5.6098\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 4.69455\n",
      "Epoch 288/1500\n",
      "143/143 [==============================] - 327s 2s/step - loss: 4.8259 - root_mean_squared_error: 6.1730 - mean_absolute_error: 4.8259 - val_loss: 5.5306 - val_root_mean_squared_error: 6.8867 - val_mean_absolute_error: 5.5306\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 4.69455\n",
      "Epoch 289/1500\n",
      "143/143 [==============================] - 322s 2s/step - loss: 4.8247 - root_mean_squared_error: 6.0799 - mean_absolute_error: 4.8247 - val_loss: 5.7360 - val_root_mean_squared_error: 7.2957 - val_mean_absolute_error: 5.7360\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 4.69455\n",
      "Epoch 290/1500\n",
      "143/143 [==============================] - 317s 2s/step - loss: 4.6555 - root_mean_squared_error: 6.0285 - mean_absolute_error: 4.6555 - val_loss: 5.6533 - val_root_mean_squared_error: 7.2632 - val_mean_absolute_error: 5.6533\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 4.69455\n",
      "Epoch 291/1500\n",
      "143/143 [==============================] - 324s 2s/step - loss: 4.7484 - root_mean_squared_error: 6.0403 - mean_absolute_error: 4.7484 - val_loss: 5.9354 - val_root_mean_squared_error: 7.6447 - val_mean_absolute_error: 5.9354\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 4.69455\n",
      "Epoch 292/1500\n",
      "143/143 [==============================] - 323s 2s/step - loss: 5.0337 - root_mean_squared_error: 6.3537 - mean_absolute_error: 5.0337 - val_loss: 5.9938 - val_root_mean_squared_error: 7.5461 - val_mean_absolute_error: 5.9938\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 4.69455\n",
      "Epoch 293/1500\n",
      "143/143 [==============================] - 314s 2s/step - loss: 4.8646 - root_mean_squared_error: 6.1780 - mean_absolute_error: 4.8646 - val_loss: 5.5778 - val_root_mean_squared_error: 7.0862 - val_mean_absolute_error: 5.5778\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 4.69455\n",
      "Epoch 294/1500\n",
      "143/143 [==============================] - 316s 2s/step - loss: 4.8947 - root_mean_squared_error: 6.3379 - mean_absolute_error: 4.8947 - val_loss: 6.0107 - val_root_mean_squared_error: 7.4826 - val_mean_absolute_error: 6.0107\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 4.69455\n",
      "Epoch 295/1500\n",
      "143/143 [==============================] - 305s 2s/step - loss: 4.7742 - root_mean_squared_error: 6.0670 - mean_absolute_error: 4.7742 - val_loss: 5.7849 - val_root_mean_squared_error: 7.1540 - val_mean_absolute_error: 5.7849\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 4.69455\n",
      "Epoch 296/1500\n",
      "143/143 [==============================] - 309s 2s/step - loss: 4.6866 - root_mean_squared_error: 5.9768 - mean_absolute_error: 4.6866 - val_loss: 5.9071 - val_root_mean_squared_error: 7.5233 - val_mean_absolute_error: 5.9071\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 4.69455\n",
      "Epoch 297/1500\n",
      "143/143 [==============================] - 319s 2s/step - loss: 5.0390 - root_mean_squared_error: 6.3927 - mean_absolute_error: 5.0390 - val_loss: 5.5892 - val_root_mean_squared_error: 7.1937 - val_mean_absolute_error: 5.5892\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 4.69455\n",
      "Epoch 298/1500\n",
      "143/143 [==============================] - 316s 2s/step - loss: 4.8437 - root_mean_squared_error: 6.3076 - mean_absolute_error: 4.8437 - val_loss: 5.4853 - val_root_mean_squared_error: 6.9928 - val_mean_absolute_error: 5.4853\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 4.69455\n",
      "Epoch 299/1500\n",
      "143/143 [==============================] - 306s 2s/step - loss: 4.6842 - root_mean_squared_error: 6.1012 - mean_absolute_error: 4.6842 - val_loss: 5.4955 - val_root_mean_squared_error: 7.0559 - val_mean_absolute_error: 5.4955\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 4.69455\n",
      "Epoch 300/1500\n",
      "143/143 [==============================] - 323s 2s/step - loss: 4.7896 - root_mean_squared_error: 6.1547 - mean_absolute_error: 4.7896 - val_loss: 5.9495 - val_root_mean_squared_error: 7.6752 - val_mean_absolute_error: 5.9495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00300: val_loss did not improve from 4.69455\n",
      "Epoch 301/1500\n",
      "143/143 [==============================] - 321s 2s/step - loss: 4.8422 - root_mean_squared_error: 6.2162 - mean_absolute_error: 4.8422 - val_loss: 5.7874 - val_root_mean_squared_error: 7.3298 - val_mean_absolute_error: 5.7874\n",
      "\n",
      "Epoch 00301: val_loss did not improve from 4.69455\n",
      "Epoch 302/1500\n",
      "143/143 [==============================] - 323s 2s/step - loss: 4.9055 - root_mean_squared_error: 6.4589 - mean_absolute_error: 4.9055 - val_loss: 5.7145 - val_root_mean_squared_error: 7.0399 - val_mean_absolute_error: 5.7145\n",
      "\n",
      "Epoch 00302: val_loss did not improve from 4.69455\n",
      "Epoch 303/1500\n",
      "143/143 [==============================] - 322s 2s/step - loss: 4.8142 - root_mean_squared_error: 6.1713 - mean_absolute_error: 4.8142 - val_loss: 5.3505 - val_root_mean_squared_error: 6.8226 - val_mean_absolute_error: 5.3505\n",
      "\n",
      "Epoch 00303: val_loss did not improve from 4.69455\n",
      "Epoch 304/1500\n",
      "143/143 [==============================] - 300s 2s/step - loss: 4.9993 - root_mean_squared_error: 6.4471 - mean_absolute_error: 4.9993 - val_loss: 5.8908 - val_root_mean_squared_error: 7.7243 - val_mean_absolute_error: 5.8908\n",
      "\n",
      "Epoch 00304: val_loss did not improve from 4.69455\n",
      "Epoch 305/1500\n",
      "143/143 [==============================] - 278s 2s/step - loss: 4.8944 - root_mean_squared_error: 6.4209 - mean_absolute_error: 4.8944 - val_loss: 5.6028 - val_root_mean_squared_error: 7.1813 - val_mean_absolute_error: 5.6028\n",
      "\n",
      "Epoch 00305: val_loss did not improve from 4.69455\n",
      "Epoch 306/1500\n",
      "143/143 [==============================] - 311s 2s/step - loss: 4.7031 - root_mean_squared_error: 5.9291 - mean_absolute_error: 4.7031 - val_loss: 5.3597 - val_root_mean_squared_error: 6.9873 - val_mean_absolute_error: 5.3597\n",
      "\n",
      "Epoch 00306: val_loss did not improve from 4.69455\n",
      "Epoch 307/1500\n",
      "143/143 [==============================] - 321s 2s/step - loss: 4.8677 - root_mean_squared_error: 6.2137 - mean_absolute_error: 4.8677 - val_loss: 5.9973 - val_root_mean_squared_error: 7.5231 - val_mean_absolute_error: 5.9973\n",
      "\n",
      "Epoch 00307: val_loss did not improve from 4.69455\n",
      "Epoch 00307: early stopping\n",
      "CPU times: user 1d 2h 16min 46s, sys: 14h 14min 41s, total: 1d 16h 31min 28s\n",
      "Wall time: 1d 5h 59min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "epochs = 1500\n",
    "\n",
    "# fit network\n",
    "history = model.fit(x=train_generator_noise,\n",
    "                    validation_data=val_generator,\n",
    "                    epochs=epochs,\n",
    "                    callbacks = [checkpointer, earlystopper, reduce_lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 68s 473ms/step - loss: 5.3113 - root_mean_squared_error: 6.7612 - mean_absolute_error: 5.3113\n",
      "30/30 [==============================] - 14s 457ms/step - loss: 5.5717 - root_mean_squared_error: 6.9615 - mean_absolute_error: 5.5717\n",
      "35/35 [==============================] - 17s 474ms/step - loss: 6.1535 - root_mean_squared_error: 7.8651 - mean_absolute_error: 6.1535\n"
     ]
    }
   ],
   "source": [
    "# 'Inception_regressor_01' (n_average = 40, gaussian_noise = 0.01, MAE)\n",
    "model_path = os.path.join(PATH_MODELS, 'Inception_regressor_01.hdf5')\n",
    "\n",
    "loaded_model = tf.keras.models.load_model(model_path)\n",
    "evaluate_model(loaded_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 63s 442ms/step - loss: 13.8854 - root_mean_squared_error: 17.0043 - mean_absolute_error: 13.8854\n",
      "30/30 [==============================] - 13s 436ms/step - loss: 14.5290 - root_mean_squared_error: 17.6678 - mean_absolute_error: 14.5290\n",
      "35/35 [==============================] - 16s 466ms/step - loss: 14.0345 - root_mean_squared_error: 17.0194 - mean_absolute_error: 14.0345\n"
     ]
    }
   ],
   "source": [
    "# 'Inception_regressor_02' (n_average = 1, gaussian_noise = 0.01, MAE)\n",
    "model_path = os.path.join(PATH_MODELS, 'Inception_regressor_02.hdf5')\n",
    "\n",
    "loaded_model = tf.keras.models.load_model(model_path)\n",
    "evaluate_model(loaded_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 67s 468ms/step - loss: 41.0107 - root_mean_squared_error: 6.4040 - mean_absolute_error: 5.1479\n",
      "30/30 [==============================] - 15s 481ms/step - loss: 47.2327 - root_mean_squared_error: 6.8726 - mean_absolute_error: 5.5772\n",
      "35/35 [==============================] - 16s 445ms/step - loss: 58.4772 - root_mean_squared_error: 7.6470 - mean_absolute_error: 5.9643\n"
     ]
    }
   ],
   "source": [
    "# 'Inception_regressor_03' (n_average = 40, gaussian_noise = 0.01, MSE)\n",
    "model_path = os.path.join(PATH_MODELS, 'Inception_regressor_03.hdf5')\n",
    "\n",
    "loaded_model = tf.keras.models.load_model(model_path)\n",
    "evaluate_model(loaded_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 64s 441ms/step - loss: 204.6959 - root_mean_squared_error: 14.3072 - mean_absolute_error: 11.7594\n",
      "30/30 [==============================] - 14s 471ms/step - loss: 230.4466 - root_mean_squared_error: 15.1805 - mean_absolute_error: 12.5527\n",
      "35/35 [==============================] - 15s 433ms/step - loss: 221.2316 - root_mean_squared_error: 14.8739 - mean_absolute_error: 12.0842\n"
     ]
    }
   ],
   "source": [
    "# 'Inception_regressor_04' (n_average = 1, gaussian_noise = 0.01, MSE)\n",
    "model_path = os.path.join(PATH_MODELS, 'Inception_regressor_04.hdf5')\n",
    "\n",
    "loaded_model = tf.keras.models.load_model(model_path)\n",
    "evaluate_model(loaded_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 64s 441ms/step - loss: 5.7985 - root_mean_squared_error: 7.3101 - mean_absolute_error: 5.7985\n",
      "30/30 [==============================] - 14s 456ms/step - loss: 6.6003 - root_mean_squared_error: 8.2294 - mean_absolute_error: 6.6003\n",
      "35/35 [==============================] - 16s 448ms/step - loss: 6.9294 - root_mean_squared_error: 8.5678 - mean_absolute_error: 6.9294\n"
     ]
    }
   ],
   "source": [
    "# 'Inception_regressor_05' (n_average = 100, gaussian_noise = 0.01, MAE)\n",
    "model_path = os.path.join(PATH_MODELS, 'Inception_regressor_05.hdf5')\n",
    "\n",
    "loaded_model = tf.keras.models.load_model(model_path)\n",
    "evaluate_model(loaded_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 61s 425ms/step - loss: 40.9465 - root_mean_squared_error: 6.3989 - mean_absolute_error: 4.9586\n",
      "30/30 [==============================] - 12s 390ms/step - loss: 69.2260 - root_mean_squared_error: 8.3202 - mean_absolute_error: 6.5920\n",
      "35/35 [==============================] - 12s 342ms/step - loss: 71.6239 - root_mean_squared_error: 8.4631 - mean_absolute_error: 6.5200\n"
     ]
    }
   ],
   "source": [
    "# Fully_connected_regressor_02: MSE, Adadelta, N_average=30, 5000 epochs, ES=1000, RLR=200, gaussian=0.01\n",
    "model_path = os.path.join(PATH_MODELS, 'Fully_connected_regressor_02.hdf5')\n",
    "\n",
    "loaded_model = tf.keras.models.load_model(model_path)\n",
    "evaluate_model(loaded_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 62s 433ms/step - loss: 51.7955 - root_mean_squared_error: 7.1969 - mean_absolute_error: 5.8455\n",
      "30/30 [==============================] - 13s 434ms/step - loss: 69.0331 - root_mean_squared_error: 8.3086 - mean_absolute_error: 6.8263\n",
      "35/35 [==============================] - 15s 420ms/step - loss: 62.4980 - root_mean_squared_error: 7.9056 - mean_absolute_error: 6.1974\n"
     ]
    }
   ],
   "source": [
    "# CNN_regressor_01: MSE, Adam, N_average=30, 2000 epochs, ES=250, RLR=50, gaussian=0.01\n",
    "model_path = os.path.join(PATH_MODELS, 'CNN_regressor_01.hdf5')\n",
    "\n",
    "loaded_model = tf.keras.models.load_model(model_path)\n",
    "evaluate_model(loaded_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 64s 445ms/step - loss: 57.1688 - root_mean_squared_error: 7.5610 - mean_absolute_error: 6.1211\n",
      "30/30 [==============================] - 13s 445ms/step - loss: 64.8247 - root_mean_squared_error: 8.0514 - mean_absolute_error: 6.3918\n",
      "35/35 [==============================] - 17s 473ms/step - loss: 77.0855 - root_mean_squared_error: 8.7798 - mean_absolute_error: 6.6343\n"
     ]
    }
   ],
   "source": [
    "# ResNet_regressor_01: MSE, Adam, N_average=30, 1500 epochs, ES=250, RLR=50, gaussian=0.01\n",
    "model_path = os.path.join(PATH_MODELS, 'ResNet_regressor_01.hdf5')\n",
    "\n",
    "loaded_model = tf.keras.models.load_model(model_path)\n",
    "evaluate_model(loaded_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 66s 461ms/step - loss: 60.4153 - root_mean_squared_error: 7.7727 - mean_absolute_error: 6.1008\n",
      "30/30 [==============================] - 14s 476ms/step - loss: 78.0616 - root_mean_squared_error: 8.8352 - mean_absolute_error: 7.0294\n",
      "35/35 [==============================] - 15s 434ms/step - loss: 73.6694 - root_mean_squared_error: 8.5831 - mean_absolute_error: 6.6446\n"
     ]
    }
   ],
   "source": [
    "# Encoder_regressor_01: MSE, Adam, N_average=30, 1500 epochs, ES=250, RLR=50, gaussian=0.01 (LR = 0.0001, no reduction)\n",
    "model_path = os.path.join(PATH_MODELS, 'Encoder_regressor_01.hdf5')\n",
    "\n",
    "loaded_model = tf.keras.models.load_model(model_path)\n",
    "evaluate_model(loaded_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 65s 452ms/step - loss: 43.6008 - root_mean_squared_error: 6.6031 - mean_absolute_error: 5.1059\n",
      "30/30 [==============================] - 14s 453ms/step - loss: 56.7583 - root_mean_squared_error: 7.5338 - mean_absolute_error: 6.0041\n",
      "35/35 [==============================] - 16s 473ms/step - loss: 62.2474 - root_mean_squared_error: 7.8897 - mean_absolute_error: 6.1511\n"
     ]
    }
   ],
   "source": [
    "# TimeCNN_regressor_01: MSE, Adam, N_average=30, 2000 epochs, ES=250, RLR=50, gaussian=0.01\n",
    "model_path = os.path.join(PATH_MODELS, 'TimeCNN_regressor_01.hdf5')\n",
    "\n",
    "loaded_model = tf.keras.models.load_model(model_path)\n",
    "evaluate_model(loaded_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
